{
    "articles": [
        {
            "title": "XCL1: Two Folds Are Better Than One",
            "author": "Madison Houck",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Houck_4-500x216.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "About twenty years ago, when Brian Volkman was still a postdoctoral student, he was approached by a colleague who was studying HIV and looking to characterize a protein he had encountered in his studies on the immune system. The protein, now referred to as XCL1, was identified as having an important role in the immune system\u2019s response. Essentially, Volkman was tasked with determining how the protein folds in three dimensions, like a piece of paper folds to create an origami shape. Using nuclear magnetic resonance (NMR), he started to uncover the structure of XCL1, which would in turn tell him and his colleague a lot about its function. When he got his first batch of data back, he was at a loss; it was uninterpretable and seemed to suggest that the protein was unfolded, or had no consistent structure.\nIt was only after running many more tests under many different temperatures and salt concentrations that Volkman came to a startling conclusion: the XCL1 protein had two folds.\nWe now know that one fold of XCL1 tells white blood cells where to go in the body in order to fight off invaders. The other fold also directs an immune response, through a different mechanism, but can also directly fight off invasive cells. Because of these alternative forms, one protein can have a much greater impact on the body\u2019s overall immune response.\nBut back then, not much was known about the protein\u2019s form or function. As Volkman says, anyone who has taken a biochemistry class as an undergraduate will tell you that a protein folds in a single specific way that is most thermodynamically favorable. The structure of this protein then determines its specific function in the body. This principle is one of the core tenets of biochemistry, and Volkman\u2019s work was challenging everything his field believed in.\n\u201cIt took years to reach the point where I felt confident enough to know what was happening and write the paper. Even now, almost twenty years later, there are people, experts in biochemistry, who if you asked them, \u2018Can a protein do this?\u2019 They would say, \u2018No, no, we know that\u2019s not the case,\u2019\u201d Volkman said. \u201cThat\u2019s the hardest part\u2014looking at some data, some evidence, and realizing that it\u2019s the opposite of what you learned in your biochemistry class and wondering what\u2019s right: what you learned in the textbook or what you\u2019re looking at on the page in front of you.\u201d\nAfter Volkman\u2019s work was finally published, the term \u201cmetamorphic protein\u201d was coined. Because of this, he considers XCL1 to be one of the first metamorphic proteins.\nBut his work with XCL1 didn\u2019t end there. Volkman received several National Institutes of Health grants to continue his research. \u201cI like to think that Tony Fauci has been supporting this over the years,\u201d Volkman said, laughing. With this level of funding, he continued to study XCL1 until he met an interested graduate student, Caci Dishman.\nAcacia \u201cCaci\u201d Dishamn met Volkman early in her MD/PhD program at the Medical College of Wisconsin, where he was her advisor. She was specifically excited about his research in metamorphic proteins because it went against what she had been taught for her entire undergraduate career. Dishman said early on in her conversations with Volkman she could see that this would be \u201cparadigm-defying work.\u201d\u00a0\nShe compiled preliminary data that other postdocs and graduate students had collected about the evolutionary ancestry of XCL1 and combined it with her own work, eventually being published as the first author on a recent paper about how XCL1 came to be. Volkman says that Dishman\u2019s drive to push the project forward was the reason they found something genuinely new that they wanted to share with a broader audience.\nDishman\u2019s work had two main findings. First of all, it was discovered that XCL1\u2019s simultaneous evolution of two folds wasn\u2019t an accident. When many scientists look at metamorphic proteins, they come to the conclusion that one fold must be an evolutionary artifact, like an appendix in humans. The prevailing belief was that XCL1 and other similar proteins only had two folds because they were unfinished with their evolutionary journey and someday would return to only having one fold. However, when Dishman and Volkman modelled the ancestry of the protein, they found that XCL1 started out with one fold. Over time, it evolved to have two folds, but primarily occupied the old fold in a ratio of about nine to one. As more time passed, the ratio became one to nine, now primarily occupying the new fold. If the protein was evolving to only occupy the new fold, as was the conventional belief, the next step would see only the new fold.\nThat wasn\u2019t the case. The protein is now present in a ratio of one to one, found equally in both forms, and is able to spontaneously and randomly switch between folds under conditions within the human body. This protein wasn\u2019t the result of an ill-timed snapshot or an evolutionary mistake; rather, it was evolution\u2019s creative improvement to the immune response.\nBut how does a protein evolve from having only one fold to having two folds? Dishman\u2019s next goal was to make changes in the amino acid sequence of a chemokine protein like XCL1, until it expressed two folds. At first, she made small changes, trying to isolate the specific amino acids that were important. After making about fifteen individual changes, one or two at a time, it didn\u2019t seem like her approach was going to work. It was only when she had the idea to employ three sets of changes at once, eleven in total, that the protein finally became metamorphic.\nDishman says that was both the most challenging part of the project and the most rewarding. \u201cWhen I finally figured out that set of mutations that caused XCL1 to become metamorphic, I was so excited,\u201d she said. \u201cI had collected data for an experiment overnight, and I went in the next morning, and the protein I had made was metamorphic and I was just so amped.\u201d She added \u201cPeople in the lab were starting to be like \u2018Caci, I don\u2019t know if you\u2019re going to do this. You\u2019ve been trying for a while. You might want to stop.\u2019 But finally I got it.\u201d\nWhy is all of this important? First of all, now that we know that XCL1 isn\u2019t an accident, biologists across the world can search for more metamorphic proteins and learn about their functions. One important application is the creation of targeted therapies for diseases: if a metamorphic protein can cause a genetic disease, finding and understanding its structure is the next step in developing a treatment. Essentially, if one fold of a protein causes a disease, a powerful therapy would be to determine how to switch to only the other fold of that protein.\nWhy is this important? Now that they have an \u201cinstruction manual,\u201d Dishman and Volkman are attempting to create metamorphic proteins with specific functions for biological sensors, self-assembling materials, and components of molecular machines. The level of control researchers have with metamorphic proteins is much greater than that with a regular protein\u2014an \u201cactive\u201d fold could be engineered only to occur in certain conditions. This would allow researchers to turn a protein \u201con\u201d by changing the environment. The applications of metamorphic proteins are far-reaching, and will likely have a significant impact on the fields of biochemistry and bioengineering as more developments are made.\nIf Volkman and Dishman had believed in convention over their own data or listened to critics, such advancements would not be possible. It is only through their willingness to defy commonly held beliefs and their unwavering perseverance that we can even imagine these treatments and technologies, let alone develop them in years to come.\nSources:\u00a0\nDishman, A. F., Tyler, R. C., Fox, J. C., Kleist, A. B., Prehoda, K. E., Babu, M. M., \u2026 & Volkman, B. F. (2021). Evolution of fold switching in a metamorphic protein. Science, 371(6524), 86-90.\nFilo, Rider, P., Nuthep, S., JuliarStudio, D-L-B, Rambo182, . . . Creative, A. (n.d.). Evolution silhouettes stock vector art 512124114. Retrieved February 16, 2021, from https://www.istockphoto.com/illustrations/evolution\nFotoGraphik, Calvindexter, BravissimoS, Ptasha, Greens87, 300_librarians, . . . Agil, M. (n.d.). Origami font stock vector art 1159344935. Retrieved February 16, 2021, from https://www.istockphoto.com/photos/origami\nUltrasensitive biosensor detects cancer from circulating dna. (2020, March 27). Retrieved February 16, 2021, from https://biotechscope.com/ultrasensitive-biosensor-detects-cancer-from-circulating-dna/\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/xcl1-two-folds-are-better-than-one/",
            "captions": [
                "Evolution ape to man silhouette illustration concept."
            ]
        },
        {
            "title": "Testing the Marshmallow Test",
            "author": "Dana Kim",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Kim_2-500x280.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "A few months ago, moms from all over the world flooded TikTok with videos of their toddlers being put to the \u201cmarshmallow test,\u201d in which a marshmallow was placed in front of a child with the promise that they would receive two treats if they did not eat it while the parent left the room. The claim was that children who displayed enough self-control for a greater reward would have the self-discipline to become successful as adults.\u00a0\nLeah S. Richmond-Rakerd, assistant professor of psychology at the University of Michigan, and Terrie Moffitt, professor in the Department of Psychology and Neuroscience at Duke University, tested this theory in their recent paper. Richmond-Rakerd explained that the results of this study could help people age more healthily by better understanding the effects of childhood self-control on life decisions made later in life. \u201cWe were interested in whether people with better self-control also age more slowly and are better prepared to manage their health, financial, and social demands of later life,\u201d Richmond-Rakerd said. This life skill may be more important now than ever before.\u00a0\nRichmond-Rakerd and Moffitt conducted their longitudinal study using data collected from the Dunedin Study, a prospective study of a birth cohort of over one thousand babies followed from birth to age forty-five. The study members\u2019 self-control was measured at ages three, five, seven, nine, and eleven using a multi-occasion and multi-informant strategy in which reports were collected from parents, teachers, and even the children themselves. This differs from most approaches: other studies of self-control use behavioral tasks, but the accuracy of the findings from these less holistic experimental models are highly contested in how well they actually predict behavior in the real world. The reporting system instead identifies behavior in the children\u2019s day-to-day lives, such as how well they are able to wait their turn to play a game or how frustrated they get when something doesn\u2019t go their way. In the study participants\u2019 adulthood, aging was measured, biologically and socially\u2014how quickly they were doing so across different organ systems, in addition to their financial, health, and social skills. Did the participants have sufficient financial knowledge? How strong was their social network?\u00a0\nThe study found surprising results. Although childhood self-control has long-lasting implications, there is still an opportunity to prepare ourselves for aging even when we are forty. Moreover, for the participants, self-control was not confounded by IQ, education, or cognitive skills as expected. This is an optimistic finding: it tells us that social skills such as financial literacy are teachable. \u201cEarly beginnings matter, but adulthood matters too,\u201d Richmond-Rakert said. \u201cWe found that adults who exercise better self-control developed more health, financial, and social reserves for old age\u2014even if they didn\u2019t have so much self-control in early life. This is encouraging because it opens up middle age as a potential intervention window. A lot of research has focused on intervening in childhood, and our results indicate that the early years are certainly important, but middle age may also be a good time to revisit the opportunity to get better prepared for later life.\u201d\nThe study results may also have social implications on our social security system. The results shed light on a concerning pattern: people are beginning to struggle with their physical fitness and health at an earlier age. \u201cThose rules for when you can retire and when you can get support for your retirement were developed years and years ago when in the U.S., the median age of death was sixty-five. What we have now is that people are living longer but they\u2019re also falling apart younger,\u201d Moffitt said. This opens up an essential conversation of the importance of chronological age compared to that of biological age.\u00a0\nTo conclude, Moffitt gave a more concrete example. \u201cThere are factory workers who have had really intense, heavy-duty, physical labor all their lives. By the time they\u2019re fifty-five, they are pretty worn out and they should be able to retire. Whereas someone like me, a college professor who has sat in a comfy office with air conditioning and worked on a computer, I could really work until I\u2019m seventy-five,\u201d Moffitt said.\u00a0\nSource:\u00a0\nRichmond-Rakerd, L. S., Caspi, A., Ambler, A., D\u2019Arbeloff, T., De Bruine, M., Elliott, M., . . . Moffitt, T. E. (2021). Childhood self-control forecasts the pace of midlife aging and preparedness for old age. Proceedings of the National Academy of Sciences, 118(3). doi:10.1073/pnas.2010211118\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/testing-the-marshmallow-test/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Magic Number Behind the Universe?",
            "author": "Malia Kuo",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Kuo_2-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Unfortunately for fans of The Hitchhiker\u2019s Guide to the Galaxy, the answer to life, the universe, and everything is not forty-two.\u00a0\n\u00a0 It\u2019s actually closer to 1/137.\n\u00a0 This \u201cmagic number,\u201d as physicist Richard Feynman puts it, approaches the value of the fine structure constant ?, a dimensionless constant that specifies the strength of interactions between electromagnetic forces and charged elementary particles, such as electrons or muons. It\u2019s a number that necessitates precision. In fact, according to astrophysicist Biman Nath, if the fine structure constant was even four percent smaller or larger, stars would be incapable of sustaining the nuclear reactions that ultimately create carbon-based life as we know it.\n\u00a0 The constant is a critical component in predicting the Standard Model of particle physics, a theory created in the 1970s that describes the interactions between fundamental particles and therefore describes the basic laws of physics. The Standard Model can predict a property of the electron\u2014its magnetic moment\u2014with high accuracy, which is measured very well experimentally. However, to compare the measurement and the theory, the fine structure constant\u2019s value is needed, as it is a parameter of the theory. The comparison between measurement and theory could result in a difference between the two\u2014a discrepancy that could point to potentially new physics, or new particles that we haven\u2019t seen yet.\u00a0\n\u00a0 Researchers Saida Guellati-Khelifa and Pierre Clad\u00e9 in the Kastler Brossel Laboratory (the LKB) in Paris have made the most precise measurement of this constant to an astonishing eleven decimal points: 1/137.035999206, with a relative accuracy of eighty-one parts per trillion. The precision is almost unbelievable\u2014this value is three times more precise than the previous most precise measurement of the constant, which was measured by the M\u00fcller group at University of California, Berkeley.\u00a0\n\u00a0 Using a specially designed set up, the LKB calculated ? using the recoil velocity of the rubidium atoms when absorbing a photon. This velocity measurement relates directly to the mass of the rubidium atoms, which is the limiting factor when calculating high precision values of ?.\n\u00a0 They began with cooling the rubidium atoms with lasers. \u201cIf we reduce the velocity distribution, we enhance the wave behavior of the matter,\u201d Guellati-Khelifa said. Clear wave behavior is critical to observing the wave patterns\u2014atomic fringes\u2014that are the key to measuring the recoil velocity. These atoms were launched into an atomic elevator, essentially a vacuum chamber that the researchers used to position the atoms and cancel out factors as significant as gravity or the Earth\u2019s rotation, which could affect their velocity measurements.\u00a0\nHere\u2019s where it gets a little insane.\u00a0The LKB chose atoms that would occupy two stable atomic levels. They used lasers to \u201csplit\u201d the atom wave packet in half and created a superposition between those two levels; one half would remain with a velocity of zero, while the other that was prepared into the second atomic level would gain recoil velocity. A split second later, they would use another laser pulse to recombine these atomic halves or wave packets into one. They measured the phase shift between these two different wave patterns to determine the recoil velocity and therefore determine the rubidium atom mass needed to calculate the fine structure constant.\u00a0\nThe LKB found that their measurement of the fine structure constant was in better agreement with the experimental value of the Standard Model than any before. Effectively, it places limitations on the structure of electrons. Moreover, it sets the stage for potentially new physics, though the team is excitedly waiting on results of a similar experiment with the muon, which\u2014if it has a similar discrepancy as their results\u2014could provide the basis for new physics or a new particle. In the meantime, they will continue improving their measurement of the fine structure constant. Dr. Clad\u00e9 projected that they might change the isotope of rubidium from Rb-87 to Rb-85 to check their measurements as well as for systematic effects, as well as cool the atomic cloud to ten or even one hundred times smaller to check the measurement even further.\u00a0\u00a0\n\u00a0 When asked what her favorite part of the experiment was, Guellati immediately displayed the graphs of the atomic fringes found from the wave patterns. \u201cWhen we started the project, it was my third version. It\u2019s exactly like a clockmaker, a very high technology clockmaker. You have to control everything. And what was most exciting was when we first observed the most beautiful atomic fringes in the world. When you see these measurements, you think, ah, my clock worked very precisely,\u201d Guellati said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/the-magic-number-behind-the-universe/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Robotic Theory of Mind",
            "author": "Veronica Lee",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Lee_2-500x390.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "With self-driving cars, powerful AI-like facial recognition powering our smartphones, and machine learning inside of transportation apps like Uber, it seems like we already live in a world run by robots. However, many still believe that there remains a clear division between \u201chuman\u201d and \u201cnon-human.\u201d Sure, robots may be able to drive along a street or play a specific song when asked, but humans claim the realm of emotion and empathy for ourselves. But recent robotic innovations suggest that such traits may not be so unique to humans after all.\nPh.D. student Boyuan Chen and professor of mechanical engineering and data science Hod Lipson at Columbia University are among the researchers seeking to demonstrate just that\u2014starting by giving robots the ability to predict behavior based on visual processing alone.\n\u201cWe\u2019re trying to get robots to understand other robots, machines, and intelligent agents around them,\u201d Lipson said. \u201cIf you want robots to integrate into society in any meaningful way, they need to have social intelligence\u2014the ability to read other agents and understand what they are planning to do.\u201d\u00a0\nTheory of mind, the ability to recognize that others have different mental states, goals, and plans than your own, is an integral part of early development in humans, appearing at around the age of three. Allowing us to understand the mental state of those around us, theory of mind acts as the basic foundation for more complex social interactions such as cooperation, empathy, and deception.\u00a0\nIn children, it can be observed in successful participation in \u201cfalse-belief\u201d tasks, such as the famous Sally-Anne test, in which the participant is asked questions to see if they understand that two fictional characters, Sally and Anne, have different information thus different beliefs. If a child is able to recognize that different information is known to different people, this is a strong indicator that they possess theory of mind. As children develop further, they naturally develop the social skills needed to navigate the world around them.\n\u201cWe humans do this all the time in lots of subtle ways,\u201d Lipson said. \u201cAs we communicate with each other, we read facial expressions to see what the other person is thinking.\u201d\nIt is this very ability that Chen and Lipson hope to one day give to robots. To do so, however, they must first start with the basics of theory of mind. After all, what comes so easily to us as humans is not so easily produced in robots. In their recent research, they sought to find evidence that theory of mind is preceded by something called \u201cvisual behavior modeling.\u201d In essence, they wanted to see if robots could understand and predict the behaviors of another agent purely from visual analysis of the situation.\u00a0\nIn their experiments, the researchers used a simple setup with a physical robot \u201cactor\u201d and \u201cobserver,\u201d in which the observer, via a camera above, had a complete visual of the actor\u2019s surroundings, including a green dot and sometimes a barrier object. The actor robot would only pursue the green dot if it was visible from its point of view. If a barrier was blocking the view of the green dot, the actor robot would not move. Most importantly, the observer robot had no prior knowledge of the actor\u2019s intentions to pursue the green dot or the coordinates of any of the objects in the setup. The only information given to the observer robot was the raw camera view. Everything else would have to be discovered and understood by the robot.\nSuch an experiment differed from other research in the field because the observer robot used purely visual inputs and explicitly modeled the long-term expected behavior of the actor. Previous experiments gave the observer robot symbolic information, such as the coordinates of the actor robot and green dot, that would make the observer robot\u2019s job much easier. Furthermore, Lipson and Chen carried out their experiments in the real world, rather than in simulations, which added new challenges but ultimately gave their findings more substance for application in existing technologies.\nAfter being trained with 2400 input-output image pairs of the actor robot\u2019s actions given different scenarios, the observer robot was presented with a new scenario and asked to produce a single image showing the predicted long-term path of the actor robot. The researchers hypothesized that the observer robot could only be successful if it had the ability to visualize the point of view of the actor robot and understand from limited information that the actor robot was pursuing the green dot only when it was in its field of vision\u2014in other words, if the observer had theory of mind.\u00a0\nTo Chen and Lipson\u2019s delight, the observer robot had a 98.5 percent success rate in predicting the path of the actor robot. This means that the observer robot was able to understand the actor robot\u2019s point of view, learn its intentions, and predict its trajectory from visual analysis alone. In other words, the observer robot understood that the actor robot had different information and thus a different way of thinking and behaving. Interestingly, such results hint at how our ancestors may have evolved theory of mind, and that they too perhaps once used a purely visual system to predict the behaviors of other beings.\n\u201cThis was a very remarkable finding,\u201d Lipson said. \u201cThis is the first step towards giving machines the ability to model themselves, for them to have some type of self-awareness. We\u2019re on a path towards more complex ideas, like feelings and emotions.\u201d\u00a0\nFrom their findings, Chen and Lipson are optimistic about how robotic theory of mind can help create more reliable machines. For example, driverless cars will be much more effective if they can read the nonverbal cues of other cars and pedestrians in their surroundings. Chen also reflects on a funny story from his stay at an intelligent hotel in China, in which a robot delivered the wrong food to his room and could not recognize its mistake. According to Chen, such errors could be avoided if robots were trained with some social awareness and ability to understand what other agents\u2014in this case, their customers\u2014are thinking.\nUltimately, the researchers hope to create a machine that can model itself, leading to introspection and self-reflection that can advance the social integration of robots into human society. In the short term, however, they are working on making the experimental situations more complex for the observer robots. For example, what will happen if two robots are modeling each other at the same time? If there is some type of challenge introduced, will they take part in manipulation and deception?\u00a0\nOf course, both Chen and Lipson understand that giving such capabilities to robots is a double-edged sword. Both agree that discussion about the ethics of AI are important across all fields, not just science. For example, issues of privacy and surveillance, risks of manipulating or influencing human behavior, and the distribution of access to such powerful technologies are all very important as we move forward with AI.\u00a0\nHowever, Chen remains optimistic about the future of robots and how they will contribute to our lives.\n\u201cI\u2019m so excited about this area of research,\u201d Chen said. \u201cEven though people may be afraid that AI will become a threat to humans, I really view it as a tool and resource that will be used to improve our quality of life. Eventually, it will become just like electricity\u2014so integrated into our lives that we can\u2019t even feel it.\u201d\nAcknowledgements:\u00a0\nChen, Boyuan, Carl Vondrick, and Hod Lipson. \u201cVisual Behavior Modelling for Robotic Theory\nof Mind.\u201d Scientific Reports 11, no. 1 (2021). doi:10.1038/s41598-020-77918-x.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/robotic-theory-of-mind/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Learning the Language of a Virus",
            "author": "Angelica Lorenzo",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Lorenzo_1-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Viral escape, the strategy a virus adopts to evade the human immune system by mutating just enough to avoid recognition and destruction by host antibodies, is one of the biggest challenges virologists face while developing effective vaccines. It is why a vaccine for HIV and a universal vaccine for influenza have yet to exist. Furthermore, it is why current vaccines approved for emergency use against SARS-CoV-2 may ultimately prove ineffective against new strains of the virus such as the U.K. and South African variants.\u00a0\nIn an effort to predict which viral mutations could result in successful escape, a team of MIT researchers made use of a machine learning technique originally intended for natural language processing to construct computational models of three different surface proteins: influenza A hemagglutinin, HIV-1 envelope glycoprotein, and SARS-CoV-2 spike glycoprotein.\u00a0\u00a0\nIn a recent article published in Science, Brian Hie, an electrical engineering and computer science graduate student at MIT graduate student, along with senior advisors Bryan Bryson, an MIT assistant professor of biological engineering, and Bonnie Berger, head of computation and biology at MIT\u2019s Computer Science and AI Lab, explore how natural language components such as grammaticality, or syntax, and semantics, or meaning, can be used to better understand viral evolution.\u00a0\nSo, why a language model? To begin, techniques for studying viral escape fall into two main categories: experimental and computational. One high-throughput experimental technique known as a Deep Mutational Scan (DMS) makes every possible amino acid change to a protein and then measures the effect of each mutation by analyzing some property of that protein, such as cellular binding or infectivity. While a DMS is effective in analyzing mutations on a singular amino acid, it becomes impractical\u2014and quite expensive\u2014to analyze the escape potential of combinatorial mutations. To put it into perspective, proteins are made up of chains of polypeptides with between fifty to two thousand amino acid residues, each of which can be one of twenty unique amino acids. Considering this complexity, testing every possible combination of mutations in a laboratory setting would be unfeasible.\nAlternatively, machine learning models can use statistics and algorithms to draw patterns from large collections of data without being explicitly told what patterns to learn. \u201cIn natural language, that corresponds to completing sentences and modeling grammar and semantic similarity or semantic change,\u201d Hie said. For viral escape, semantic change is analogous to antigenic change, where the virus mutates its surface proteins, and grammaticality relates to adhering to biological rules in order to survive and replicate.\nTraining the algorithm to model viral escape rather than human language involves feeding it sequences of viral amino acid data instead of English sentences. While machine learning language models of proteins previously existed, none of them looked at both protein fitness and function simultaneously and, therefore, could not predict escape nearly as well as the MIT model, which captures both fitness and function through the language components of grammaticality and semantic change.\nViral fitness, more specifically replicative fitness, refers to a virus\u2019s ability to bind to a host cell, infect it, and produce infectious offspring inside the host cell. In the language model, viral fitness corresponds to grammaticality while protein function is captured by semantic change, or the ability of the virus to alter its surface proteins enough to evade neutralizing antibodies. Mutating viruses must sufficiently change their proteins so as not to initiate an immune response, but not so much that they are unable to fold into the correct conformation and, therefore, lose function. Thus, the host immune system will lose the original ability to recognize the viruses as foreign invaders and the viruses will be able to successfully enter and infect host cells.\u00a0\nThe model was given the task of identifying viral mutations with high grammaticality and high semantic change, which are characteristics of high escape potential. Operating on amino acid data alone and without human instruction, the model was able to execute this task, known as constrained semantic change search (CSCS), by ranking mutations based on fitness and function. Mutations with higher scores corresponded to viruses that were both grammatical\u2014able to preserve fitness by following biological rules\u2014and had experienced high semantic change\u2014were antigenically different from the original wildtype sequence. The results of the model\u2019s rankings were then validated by comparing it to the results of a DMS.\n\u201cWe started [this project] in response to the pandemic and out of curiosity of how we can better understand viral evolution,\u201d Hie said. While Bryson and Hie usually focus their work on tuberculosis research in Bryson\u2019s lab, they transitioned to studying viral escape because \u201cwhen you\u2019re in a pandemic, you learn about the pathogen that is wreaking havoc,\u201d said Bryson.\u00a0\nInitially, the researchers trained their model using influenza A and HIV data. \u201cOnce we validated the model on influenza A and HIV, by then the data had been released for SARS-CoV-2 and we were able to run it\u2026 The timing was perfect,\u201d Hie said.\u00a0\nIn addition to scoring mutations based on grammaticality and semantic change, the researchers also created visual representations of each protein structure that showed escape potential in different regions of each protein. Different sections of the proteins were color coded according to high escape potential or high escape depletion. Visualizing and quantifying escape potential is significant in identifying which areas of a protein should be targeted by drugs. \u201cOur whole idea is that we look for areas that are depleted by our predictions for escape, and we\u2019re suggesting that [vaccine developers] target those areas,\u201d Berger said.\u00a0\nFor example, areas such as the receptor binding domain (RBD), a region of a virus located on its surface proteins that allows the virus to attach to and enter host cells, have high escape potential. This means that targeting RBDs may be less effective due to the fact that they have a high possibility of mutating and avoiding immune defenses. \u201cFor Covid, we found this subunit domain\u2014the S2 domain\u2014that is low on depletion, whereas the N-terminal domain and receptor binding domain have high escape potential,\u201d Berger said. This finding suggests that because the S2 domain is less likely to mutate, it is characterized as a good target of antibodies instead of the receptor binding domain.\u00a0\nThis idea of identifying areas of escape depletion raises the question many immunologists are trying to solve: \u201cHow do you design immunogens for regions of a protein instead of a whole protein or a whole inactivated virus?\u201d Bryson said. Immunogen design is something immunologists must keep in mind while developing vaccines. The Pfizer-BioNTech and Moderna vaccines currently being distributed in the United States target the entire SARS-CoV-2 spike protein rather than particular subunits. Because new variants have successfully mutated their spike proteins, current vaccines may not be as effective against them, as areas of the protein may be unrecognizable to neutralizing antibodies.\u00a0\nGiven that the language model was successful in learning viral dynamics from sequence data alone, the researchers can now search for possible mutations on top of the new variants of the SARS-CoV-2 Wuhan strain. \u201cThis can tell us what are the best experiments to go test to anticipate potential even further escape,\u201d Bryson said.\u00a0\nAs new data for SARS-CoV-2 is being generated in real time, the researchers consistently re-train the model and publish the results on their GitHub repository. Considering the model\u2019s successful performance, the researchers hope that the Centers for Disease Control and Prevention will adopt their model as a tool for understanding viral epidemics. If this happens, as new strains of SARS-CoV-2 surface, the model could predict more variants on top of the current mutations, which would give scientists a narrow set of experiments to test the efficacy of current vaccines on and allow for modification of the vaccines as needed.\nReferences:\nHie, B., Zhong, E. D., Berger, B., & Bryson, B. (2021). Learning the language of viral evolution and escape. Science, 371(6526), 284-288.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/learning-the-language-of-a-virus/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Counting Elephants from Space",
            "author": "Clay Thames",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Thames_4-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Protection of the world\u2019s animals presents many challenges, but conservation\u2019s newest defense weapon actually works from space. One of the problems conservationists and zoologists face is tracking the location and movements of the animals they are studying. Isla Duporge, a Zoology Ph.D. candidate at Oxford University, and Olga Isupova, assistant professor of Artificial Intelligence at the University of Bath, led a team that found a niche in the field of satellite imagery technology, using their creativity to assist the conservation fight for African elephants. Duporge focuses on Addo Elephant National Park in South Africa, an elephant reserve. There, the large population of elephants allows for a more controlled environment in which to test elephant detection software. Though the technology for studying large animals in a homogeneous environment has existed for quite some time, the novelty in Isla\u2019s approach lies in the application of machine learning.\u00a0\nThe Isupova lab\u2019s neural network (NN) was applied by passing a satellite\u2019s gaze over a particular area, such that the contrast between the animals and the surrounding landscape could be used to count animal populations. A NN is a type of machine learning where the makers of the study use a computer algorithm that takes in mass amounts of data\u2014in this case, images of the savannah. First, the satellite takes in images of the savannah as input. Within these images, the study makers identify the elephants. This is the training phase; after a while, the NN sees what study makers have previously identified as elephants, and \u201clearns\u201d that a grey blur is actually an elephant. The NN then produces an output based on whether or not the data fulfills the requirements (Does the image contain an elephant?). This is an example of supervised machine learning: the study makers input the first large dataset manually in hopes that when the NN encounters new information, it can correctly identify elephants as elephants and leave non-elephants unmarked.\u00a0\nThe study concluded that the CNN program had a success rate of around seventy-three percent for identifying elephants against a homogeneous background, and a seventy-eight percent success rate for a heterogeneous background. Compared with the normal human success rate of seventy-seven percent and eighty percent, this is an astounding rate of accuracy. With this new technology, workers on reserves would be able to spend less time monitoring the animals and dedicate more time towards habitat conservation, protection of the species from disease, and advocacy efforts. The satellite used, Worldview3, has a wide range of vision and is also capable of completing a full loop around the Earth in less than twenty-four hours. The satellite also boasts a range of 680,000 square kilometers roughly every twenty-four hours. Due to the magnitude of area the satellite is able to process, miscounting or double-counting, which are common human errors, are far less likely to occur.\u00a0\n\u201cWhile the technology has been used for identifying herding animals like elephants, our NN is capable of identifying one elephant even if it was alone. The NN can actually identify the crowd of animals as has been done with penguins in the past and then, from that large concentration, tell how many elephants are there by marking them individually,\u201d Isupova said.\nThe ramifications of this research? \u201cThe first step in conservation is knowing where the animals are and how many. From there, conservationists in Africa can use this data to identify where large elephant populations are in the wild so that they can be protected,\u201d Isupova said. Elephants are frequently subject to poaching, so keeping an accurate tally of how many are present is vital data in order to protect them from poachers.\u00a0\nThis research could potentially be applied to other animals that are more endangered than African elephants as well. \u201cMy professor is now working on wildebeests, and others are working on cattle,\u201d Duporge said.\nTo sum up Duporge\u2019s research findings in one sentence: The future of conservation comes from space. While the original purpose of the NN developed by Duporge\u2019s team was elephant identification, it\u2019s possible that as technology and satellite imaging improve, the same process could be applied to smaller animals or more heterogeneous landscapes. Though the use of satellite imagery may be costly, its benefits far outweigh the costs\u2014offering reduced resources concentrated on finding the elephants, comparable accuracy to that of traditional conservatory counting methods, and rapid identification of the target species in unknown locations. As conservationists continue to battle to protect animals, this particular research can shine like the North Star, guiding more conservation efforts that begin in space.\u00a0\nSource:\u00a0\nDuporge, I., Isupova, O., Reece, S., Macdonald, D. W., & Wang, T. (2020). Using very-high-resolution satellite imagery and deeplearning to detect and count African elephants in heterogeneous landscapes. Remote Sensing in Ecology and Conservation. doi:10.1101/2020.09.09.289231\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/counting-elephants-from-space/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Nsp1 protein: COVID-19\u2019s secret, but fatal weapon",
            "author": "Britt Bistis",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Graphic1-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "While Moderna and Pfizer\u2019s mRNA vaccines prevent sickness with COVID-19, they do not help people who have already become sick with the novel coronavirus. These prophylactic measures target the most famous protein encoded by the SARS-CoV-2 genome: the spear-shaped spike protein that transverses the viral protein coat and punctures the host cell, allowing the virus to inject its genetic information. The spike protein enables the infection to occur, but what is it about the novel coronavirus that poisons our cells and makes us sick?\nSARS-CoV-2\u2014like many other viruses such as Influenza A and SARS-CoV, the agent responsible for the SARS outbreak in 2003\u2014contains an mRNA transcript that encodes its viral proteins. Among them is nonstructural protein 1, or Nsp1. As its name would suggest, nonstructural protein 1 is not a structural building block of the viral particle. The main function of the viral protein Nsp1 is to stop the host cell from expressing its own genes. Produced early after viral infection, this protein starts reshaping the cellular environment to accommodate viral proliferation. A previous study found that, in SARS-CoV, Nsp1 is also necessary for viral replication, making it a vital component of sickness progression and a strong candidate for target therapeutics against coronaviruses.\nWith the COVID-19 outbreak, coronavirus research became critical, and scientists applied what was already known about SARS-CoV to make hypotheses about the novel coronavirus. Yale Molecular Biophysics and Biochemistry professor Yong Xiong, whose research group studies how viruses suppress and escape a host\u2019s immune system, hypothesized that SARS-CoV-2 Nsp1 is likely critical for disease progression and poisoning host cells.\u00a0\nTo test this hypothesis, his collaborator, associate professor Sidi Chen, investigated twenty-seven of the twenty-nine proteins encoded by the SARS-CoV-2 genome. Chen transfected each protein individually into human lung epithelial cells and found that out of the twenty-seven SARS-CoV-2 proteins tested, Nsp1 caused the most severe decrease in cell viability. To confirm that Nsp1 is the linchpin of this phenotype, a new population of cells was transfected with a mutated, defunct copy of Nsp1. This group of cells remained healthy, leading Xiong and Chen to conclude in a recent paper published in Molecular Cell that SARS-CoV-2 Nsp1 is \u201cone of the most potent pathogenicity protein factors of SARS-CoV-2 in human cells of lung origin.\u201d\nShifting gears\nAfter Xiong and his collaborators knew with greater certainty what leads to pathogenicity, they began to investigate how Nsp1 led to this cell sickness. Nsp1 infection causes a large-scale shift in the host cell\u2019s transcriptome, with the expression of 9,262 genes being altered as a result of this protein\u2019s presence in the cell. By sequencing cellular mRNAs and quantifying the amount of each mRNA transcript present using mRNA-seq, the research team was able to determine which host genes were affected by Nsp1 expression. Nsp1 expression led to the decreased expression of 5,394 genes, the majority of which are related to protein synthesis, cellular metabolism, and the immune system. To express the proteins encoded in their own genome, cells need the protein-production machinery, the ribosome, and energy to translate their mRNA transcripts into proteins. By suppressing genes involved in these processes, Nsp1 shuts down cellular protein synthesis\u2014hijacking the host cell, re-routing resources to build viral machinery, and dampening the cell\u2019s immune response to allow the infection to occur.\nThe connection between Nsp1 expression and the genes it upregulates is less clear than those it downregulates. Nsp1 upregulates the expression of 3,868 genes that encode transcription factors that regulate higher-order chromatin structure, homeobox genes that are most known for driving body patterning, DEAD-box genes that regulate RNA metabolism, and regulators that drive cell fate determination. How upregulation of these genes might affect the pathogenicity of SARS-CoV-2 is not yet understood. \u201cLogically, Nsp1 programs the cellular transcriptome in order to redirect cellular resources to the virus, but there is nothing specific that jumps out to us,\u201d\u00a0 \u00a0 \u00a0 Xiong said. How Nsp1 alters gene expression on a molecular level is still unclear as Nsp1 has no nuclear activity, meaning that it never enters the host cell nucleus where all the cell\u2019s genetic information is stored.\nThe two-pronged approach\nIn the case of SARS-CoV, Nsp1 has been shown to bind to 40S, the small ribosomal subunit, to block translation of mRNA into protein and promote cleavage and degradation of cellular mRNA. However, the molecular mechanisms of these activities remained unexplained. Recent advancements in cryogenic electron microscopy (cryo-EM) and Xiong\u2019s role in bringing this technology to Yale has made it possible to use these clues from SARS-CoV to look at SARS-CoV-2 activities at the atomic scale.\nXiong used cryo-EM to investigate how Nsp1 inhibits protein synthesis. By freezing proteins down to cryogenic temperatures (approximately below negative 150 degrees Celsius), Xiong was able to capture proteins in their native form and image these native structures at the resolution of 2.7 angstroms, about the width of a water molecule. His lab found that the C-terminus, or back end, of the Nsp1 protein tightly binds to the mRNA entry channel on the 40S subunit, while the N-terminus interacts more loosely with subunit\u2019s head domain. \u201cThink of a body with a neck and head. Around the neck is the mRNA path, where it is loaded and translated,\u201d Ivan Lomakin, an associate research scientist in the Bunick lab and expert in human protein synthesis, explained. \u201cPart of Nsp1 binds to this path. The other portion binds to the head, which is a moving part that would otherwise enable mRNA to slide along the channel.\u201d While the C-terminus of Nsp1 physically sits in the entry channel at the neck and binds to the ribosomal RNA and ribosomal proteins uS3 and uS5, the rest of the Nsp1 molecule interacts with the head domain of the ribosome.\nThe exact effect of this is unknown since the N-terminus does not bind tightly to the ribosome, so the cryo-EM image could not precisely determine how the N-terminus makes contact with the 40S subunit. Nsp1 also competes with some initiation factors critical for eukaryotic translation for binding to the 40S subunit and locks the 40S subunit in a \u201cclosed\u201d conformation, which is the state where the ribosome is unable to load mRNA.\nIn addition to preventing mRNA from loading onto the ribosome, previous studies focusing on SARS-CoV have shown that Nsp1 prompts the cutting of host cell mRNA. mRNA stability is determined by many structural features within the mRNA transcript, which contains caps, tails, and sequences that can loop back on themselves and provide stability. By prompting cutting of the mRNA transcript, Nsp1 targets the host cell transcript for rapid degradation. How Nsp1 does this remains a completely open question.\nHow does SARS-CoV-2 mRNA escape?\n\u201cThe two-pronged approach on inhibiting cellular protein production is just half the story. The other half is how viral mRNA escapes,\u201d said Xiong. With such a well-defined notion of Nsp1 blocking and cutting host cell mRNA, an important question remained: how does the viral mRNA escape this mechanism and translate its own genome?\nXiong explains that the answer likely lies in the 5\u2019 untranslated region (UTR) of the SARS-CoV-2 genome, a portion of the mRNA strand upstream of the protein-encoding segments. \u201cWe have a clue from the literature already. Some viruses harbor a mutation that prevents mRNA cutting,\u201d he said. These genes harbor an internal ribosome entry site (IRES) that directly binds to the 40S subunit and enables protein translation initiation without the normally required 5\u2019 mRNA cap and cellular initiation factors.\nPrevious studies found that SARS-CoV relies on its 5\u2032-UTR for evading the Nsp-1-mediated translation block. SARS-CoV-2 may use an \u201cIRES-like\u201d mechanism where the 5\u2032-UTR enables translation without the initiation factors blocked by Nsp1 binding to the ribosome. In addition, viral 5\u2032-UTR could cause the Nsp1 C-terminus to dissociate from the mRNA entry channel of the 40S subunit, effectively unplugging the protein from the channel and allowing the ribosome complex to form and to load mRNA. However, the exact mechanism by which SARS-CoV-2 evades the translation shutdown still remains to be demonstrated.\nNsp1 as a therapeutic target\u00a0\nThe new COVID-19 vaccines are designed to prevent us from getting sick with COVID-19, but they do not cure the many who already are sick. Moreover, there is insufficient information as to whether these vaccines guard against other related coronaviruses.\u00a0\nScientists already speculate that, like the flu vaccine, we may need booster shots regularly to protect against evolving SARS-CoV-2 strains. Although coronaviruses do not mutate as rapidly as the flu, there are already multiple new and more infectious forms of the novel coronavirus, and COVID-19 is the third coronavirus outbreak to occur in the last two decades.\nUnfortunately, it seems that coronaviruses will not be leaving the human population soon, and therefore it is critical that, in addition to vaccination prevention, there are also\u00a0 \u00a0 \u00a0 effective treatment options. Nsp1 is a particularly attractive target due to its largest role, among all viral proteins, in affecting cell viability.\nXiong\u2019s research on how Nsp1 leads to pathogenicity through host cell translation suppression suggests it may be an effective therapeutic target. \u201cOur hope is that what we learn from these interactions will give us something on the treatment front,\u201d Xiong said. While more research needs to be done on the molecular interactions between Nsp1, the ribosome, and the viral mRNA transcript before therapies can begin to be developed, Nsp1 seems to be a promising future drug target.\nAcknowledgements\nThank you to professor Yong Xiong and Ivan Lomakin for their time and commitment to their research.\nAbout the Author\nBritt Bistis is a senior majoring in Molecular Biophysics and Biochemistry. She works in the Noonan lab investigating how mutations in high-confidence autism risk gene CHD8 alter corticogenesis and the regulatory mechanisms through which this may occur. Outside of the lab she can be found doing volunteer work in programs for special needs students and science outreach programs or horseback riding.\nReferences\nYuan, S., Peng, L., Park, J. J., Hu, Y., Devarkar, S. C., Dong, M. B., Shen, Q., Wu, S., Chen, S., Lomakin, I. B., & Xiong, Y. (2020). Nonstructural Protein 1 of SARS-CoV-2 Is a Potent Pathogenicity Factor Redirecting Host Protein Synthesis Machinery toward Viral RNA.\u00a0Molecular cell,\u00a080(6), 1055\u20131066.e6. https://doi.org/10.1016/j.molcel.2020.10.034\nWathelet, M. G., Orr, M., Frieman, M. B., & Baric, R. S. (2007). Severe acute respiratory syndrome coronavirus evades antiviral signaling: role of nsp1 and rational design of an attenuated strain.\u00a0Journal of virology,\u00a081(21), 11620\u201311633. https://doi.org/10.1128/JVI.00702-07.\nKamitani, W., Huang, C., Narayanan, K., Lokugamage, K.G., Makino, S. (2009). A two-pronged strategy to suppress host protein synthesis by SARS coronavirus Nsp1 protein. Nat Struct Mol Biol, 16(11), 1134-1140. DOI: 10.1038/nsmb.1680\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/the-nsp1-protein-covid-19s-secret-but-fatal-weapon/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Unfinished Puzzle of Alzheimer\u2019s Disease",
            "author": "Rayyan Darji",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2-1-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Memory loss. Frustrated struggles to piece together past events. Forgetting the names of loved ones. These are likely some of the first symptoms that come to mind upon hearing the word \u201cAlzheimer\u2019s.\u201d As a neurodegenerative disease, Alzheimer\u2019s is characterized by a progressive loss of neuronal function that ultimately results in neuron death. This degeneration is responsible for the deterioration in cognitive and functional abilities associated with disease progression.\nThe devastating toll of Alzheimer\u2019s\u2014a currently incurable and extensively debilitating illness\u2014touches thousands of American families every year, with over six million current cases in the U.S. alone. As the population ages, the number of Americans living with this condition is projected to reach 13.8 million by the year 2060. Yet, despite afflicting so many people, the complex puzzle of Alzheimer\u2019s disease and the quest for how to treat it remains largely unfinished.\u00a0\nThe progressive accumulation of a protein fragment known as amyloid-beta (A\u03b2) in brain regions important for cognition has long been believed to be the underlying cause of the neurodegeneration, neuronal death, and cognitive decline seen in Alzheimer\u2019s. However, components of this hypothesis have been critically questioned, such as the scientific community\u2019s understanding of the role of A\u03b2 in Alzheimer\u2019s and its relationship with other neuropathological hallmarks.\u00a0\nBeyond A\u03b2, synaptic loss, or the reduction of connections between neurons, has been described as the strongest neuropathological correlate with cognitive impairment in Alzheimer\u2019s. Prior to this study, however, there had been no known publications investigating this relationship in living people, as previous work focused almost exclusively on postmortem analyses.\nTo fill in these gaps, a group of researchers at the Yale Alzheimer\u2019s Disease Research Unit (ADRU) recently conducted an in vivo positron emission tomography (PET) imaging study, imaging the brains of living humans to investigate the relationship between A\u03b2 deposition and synaptic density in the early symptomatic stages of Alzheimer\u2019s. Because PET is an imaging technique that uses radioactive tracers, this allows scientists to detect and analyze A\u03b2 deposition in people living with Alzheimer\u2019s disease.\n\u201cThe synaptic density PET tracer came out very recently, and now we can look in vivo at a live brain to study the relationship between synapse and A\u03b2,\u201d said Christopher van Dyck, director of the ADRU and a co-author of the paper. There were two tracers used in this study: one that allows for the measurement of synaptic density and a second that allows for the quantification of A\u03b2 in the brain.\nAlthough the clinical presentation of Alzheimer\u2019s spans a broad range of cognitive and functional deficits, the focus of this study was on early stages of the disease, which are known as the prodromal and mildly symptomatic stages. Importantly, while Alzheimer\u2019s can only be definitively ascertained after death through an autopsy of the brain, it can still be clinically diagnosed using a thorough clinical history, neurological examinations, and magnetic resonance imaging (MRI), which can help rule out other contributing causes that could generate similar symptoms. \u201cThe autopsy report demonstrating those A\u03b2 plaques, that was the gold standard diagnosis of Alzheimer\u2019s for a long time, but you can still clinically diagnose Alzheimer\u2019s disease without autopsies today,\u201d van Dyck said.\nA\u03b2 Deposition and Synaptic Density\nWhile the full physiologic role of A\u03b2 is still unknown, it is understood that pathologic A\u03b2 forms from the sequential division of a protein called amyloid precursor protein. These A\u03b2 protein fragments then aggregate and ultimately form larger A\u03b2 fibrils outside of cells. This insoluble fibrillar A\u03b2 is what comprises amyloid plaques, the large deposits of A\u03b2 outside of cells that are characteristic signs of Alzheimer\u2019s.\u00a0\nOver time, the deposition of fibrillar A\u03b2 in the brain is thought to approach a plateau. \u201cI like to think of it as sort of an equilibrium; it reaches a point where you\u2019re accumulating amyloid at the same rate as you\u2019re clearing it, and fibrils are aggregating at the same rate they\u2019re being cleared,\u201d said Ryan O\u2019Dell, first author of the paper and a fourth-year resident in the Yale Department of Psychiatry.\u00a0\nAlthough the presence of A\u03b2 deposition is certainly a pathologic hallmark of Alzheimer\u2019s, A\u03b2 plaque buildup is generally not well correlated with measures of either disease severity or symptom duration. \u201cEven in early studies when we only had autopsy reports to base off of, amyloid plaques tended to correlate relatively poorly with any index of disease severity,\u201d van Dyck said. These observations are likely due to the deposition of A\u03b2 reaching the aforementioned ceiling, at least in later stages of the disease.\u00a0\nWith the advent of A\u03b2 PET imaging and the ability to longitudinally track the in vivo accumulation of A\u03b2 over time, the definition of this \u201cplateau\u201d has become more refined. Specifically, the continued accumulation of A\u03b2 has been demonstrated through the early, prodromal stages of Alzheimer\u2019s, with minimal accumulation by the time of conversion to dementia.\u00a0\nTherefore, the authors postulated that in the earlier stages of Alzheimer\u2019s\u2014when A\u03b2 is still accumulating\u2014there would be an observed association with measures of disease severity, including synaptic loss. In addition, they hypothesized these associations would be strongest in brain regions characterized by early synaptic loss, such as the hippocampus.\nIn this study, the primary analysis focused on the relationship between A\u03b2 deposition and synaptic density in the hippocampus, a brain region that plays an important role in the consolidation of long-term memories and that is marked by early synaptic loss in Alzheimer\u2019s. \u201cSynaptic density is the best correlate of cognition, which makes it important to being able to look at a person with Alzheimer\u2019s disease and evaluate how well their memory and cognitive function are working,\u201d van Dyck said.\u00a0\nParticipants were placed into three distinct groups after completing a series of clinical interviews, cognitive tests, and brain scans. The study enrolled 57 individuals\u201419 who were cognitively normal (CN), 14 with amnestic mild cognitive impairment (aMCI; an earlier prodromal stage) due to Alzheimer\u2019s, and 24 with mild Alzheimer\u2019s dementia (a more advanced, albeit still mild clinical stage). An important distinction between the CN group and the aMCI and dementia groups was that all CN participants were characterized by an absence of A\u03b2 deposition, as assessed by the A\u03b2 PET imaging, while all aMCI and dementia participants were classified as positive for brain amyloid. Additionally, and as expected, participants with aMCI exhibited less severe cognitive impairment than those with dementia.\u00a0\nRelationship Between A\u03b2 Deposition and Synaptic Density\nConsistent with the researchers\u2019 primary hypothesis, there were statistically significant results demonstrating an inverse association between global A\u03b2 deposition and hippocampal synaptic density within aMCI participants, but not within participants with dementia. These findings lend support to the model that A\u03b2 continues to accumulate in the early stages of the disease before approaching a plateau, a point at which A\u03b2 may uncouple as a primary contributor to the ongoing neurodegenerative processes, including synaptic loss.\u00a0\nHowever, the authors recognized that the study\u2019s overall findings are limited by its small sample size and the lack of longitudinal data gathered over a longer time. Including this kind of data could allow for a more powerful analysis of the relationship between A\u03b2 deposition and synaptic density across the Alzheimer\u2019s disease clinical continuum.\nExtending Our Understanding of A\u03b2 and Synaptic Density\nAlthough this study showed an inverse relationship between global A\u03b2 deposition and hippocampal synaptic loss in the early, prodromal stages of the disease, this relationship was not generally observed across other brain regions. This opens the door to future molecular imaging studies of Alzheimer\u2019s.\u00a0\nThus, while past postmortem and in vivo imaging studies have shown that A\u03b2 is not generally well correlated with disease severity, other pathologic proteins associated with Alzheimer\u2019s, such as the hyperphosphorylated tau protein, may have a more specific regional relationship with synaptic density. Ongoing PET imaging studies at the ADRU are investigating this relationship between synaptic density and structures known as tau tangles, and this direction is promising.\nModifications to the current study could also allow for a more comprehensive understanding of the relationship between A\u03b2 deposition and synaptic density across the clinical continuum of Alzheimer\u2019s. \u201cWe are also interested in longitudinal work, which is one of the limitations of this study, because this would allow us to measure these markers of synaptic density, of amyloid, over time\u2026 allowing us to see not only how those individual proteins and measures change over time but also how their relationship changes over time,\u201d O\u2019Dell said.\u00a0\nAdditionally, these investigations into the longitudinal relationship between synaptic density and other pathologic hallmarks of Alzheimer\u2019s are currently being expanded into the preclinical, or symptomatically silent, stage of the disease. \u201cThe other big project that is really exciting is looking at a preclinical model of Alzheimer\u2019s,\u201d O\u2019Dell said. \u201cThese would be participants who are younger than our typical cohort, maybe in their fifties or sixties, and have no subjective or objective cognitive impairment, but who are biomarker positive, confirmed by either PET imaging or fluid biomarker testing, for these pathologic amyloid and tau proteins.\u201d\nAlzheimer\u2019s disease is devastating; it progressively destroys the control center of the human body to the point that it can no longer function normally. But there is much optimism in the advancing field of Alzheimer\u2019s research. Research like this helps shed light on the complex relationship between A\u03b2 and synaptic density in this disease, bringing us closer to fitting one more piece in the complex, unfinished puzzle of Alzheimer\u2019s disease.\nAbout the Author: Rayyan Darji is a first-year student in Grace Hopper interested in studying neuroscience on the pre-med track. In addition to writing for YSM, Rayyan is involved with Alzheimer\u2019s Buddies, Yale Muslim Students Association, and Refugee and Immigrant Student Education.\nAcknowledgements:The author would like to thank Ryan O\u2019Dell and Christopher van Dyck for taking the time to speak and discuss their research with him.\nSupplemental Reading:\u00a0\nO\u2019Dell, R.S., Mecca, A.P., Chen, MK., Naganawa, M., Toyonaga, T., Lu, Y., Godek, T.A., Harris, J.E., Bartlett, H.H., Banks, E.R., Banks, Kominek, V.L., Zhao, W., Nabulsi, N.B., Ropchan, J., Ye, Y., Vander Wyk, B.C., Huang, Y., Arnsten, A.F.T., Carson, R.E., & van Dyck, C.H. (2021). Association of A\u03b2 deposition and regional synaptic density in early Alzheimer\u2019s disease: a PET imaging study with [11C]UCB-J. Alzheimer\u2019s Research & Therapy, 13(11). https://doi.org/10.1186/s13195-020-00742-y\nMecca, A.P., Chen, MK., O\u2019Dell, R.S, Naganawa, M., Toyonaga, T., Godek, T.A., Harris, J.E., Bartlett, H.H., Zhao, W., Nabulsi, N.B., Vander Wyk, B.C., Varma, P., Arnsten, A.F.T., Huang, Y., Carson, R.E., & van Dyck, C.H. (2020) In vivo measurement of widespread synaptic loss in Alzheimer\u2019s disease with SV2A PET. Alzheimer\u2019s & Dementia, 16(7), 974\u201382. https://doi.org/10.1002/alz.12097\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/the-unfinished-puzzle-of-alzheimers-disease/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Out of the Blue: Islands of Life",
            "author": "Alexa Jeanne Loste",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/hawaiian-islands-500x245.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "If you were to take apart a cell and examine each of its components\u2014from the mitochondrial powerhouse to the Golgi packaging center\u2014none of them, on their own, could be classified as living. Zoom in even closer, and you\u2019ll find an unfathomably complex network of chemistry: clusters of macromolecules whizzing past each other, transforming in spectacular collisions to reach more energetically favorable states.\u00a0\u00a0\nLife is an emergent property. Every living thing consists of billions upon billions of nonliving things, engaging in highly specific interactions that sustain the larger system. How, exactly, they do so is at the heart of the origin of life problem\u2014the transition from the abiotic to the biotic, from macromolecules to the cell.\nForming a living system requires a vast array of chemical reactions, which in turn need to be propelled by a robust energy source. In a groundbreaking experiment in 1952, Stanley Miller and Harold Urey electrified an \u201corganic soup\u201d of methane, ammonia, and hydrogen, elements thought to have been present in the early Earth\u2019s atmosphere. In this miniature simulation of the ancient world, simple organic molecules and naturally occurring amino acids emerged, demonstrating how the most fundamental building blocks of life could have come to be. However, their system could not form polymers\u2014the more complex chains of molecules that make up essential structures in living organisms. This provoked questions of which environmental conditions would be most suitable for polymerization, and, importantly, which among these systems could have existed on the Archaean Earth.\u00a0\u00a0\nThere are two leading theories in the abiogenesis, or origin of life, debate: some researchers conjecture that life originated in warm little ponds, while others argue that it was born out of hydrothermal vents\u2014cracks in the deep-sea floor where tectonic plates diverge. The former theory is popular among scientists since the \u201cwet and dry\u201d seasonal cycles available to warm little ponds have been shown to polymerize long chains of nucleotides, while the latter set of conditions has experimentally produced much shorter chains. However, up to now, the debate has favored the hydrothermal vents theory, largely because of a glaring Achilles\u2019 heel in the warm little pond theory: geologists have had good reason to suspect that the ancient Earth was completely covered in water.\nReimagining the Water World\nAn article published in Nature Geoscience by Yale professor Jun Korenaga and Juan Carlos Rosas, a former postdoctoral researcher at Korenaga\u2019s lab and currently a researcher at the Ensenada Center for Scientific Research and Higher Education in Mexico, challenges the hydrothermal vent paradigm. By modeling changes to the depth of the seafloor due to radiogenic heating, or the heat produced by radioactive decay in the Earth\u2019s mantle, the researchers found a surprising result: the internal heat may have caused seafloor shallowing, allowing for the emergence of landmasses from under the sea. The presence of these islands implies that the warm little ponds may have existed as theorized, containing the \u201corganic soup\u201d that eventually birthed life.\u00a0\nThe existence of subaerial landmasses, or land exposed to the atmosphere, is subject to the dynamics of plate tectonics. Korenaga explained that when the layers of earth beneath the crust of two tectonic plates converge, the older, heavier plate can subduct under the other into the mantle, bringing water along with it. Therefore, over time, the net effect is that the earth absorbs water. Reversing that process, scientists predict that oceans during the Archaean era had much greater volumes of water than they do today, submerging all continental landmasses and providing the rationale for the \u201cwater world\u201d view of ancient Earth.\nOvercoming Seafloor Subsidence\nKorenaga and Rosas approached the problem from a different layer\u2014the seafloor topography. Presently, geologists observe a phenomenon known as seafloor subsidence\u2014the lowering of the seafloor as its tectonic plate becomes colder and denser, moving away from the mid-ocean ridge where it originated. This is the process by which volcanic islands are gradually submerged and become seamounts. However, the Yale team predicted that sufficient internal heating could overcome the cooling effect, leading seamounts to resurface as the seafloor shallows.\nIt so happens that there was a source of additional heat under the Earth\u2019s surface: the radioactive decay of trace elements in the mantle. Some elements radioactively decay naturally with time, releasing atomic energy and a small amount of heat in the process. Currently, the concentration of radioactive elements in the mantle is relatively low, such that only a moderate amount of heat is produced. However, Korenaga and Rosas found that, by reversing the clock on the present-day mantle concentrations of potassium, uranium, and thorium, the much higher concentrations that existed during the Archaean would have sufficiently increased radiogenic heating to induce seafloor shallowing.\nThe Case for Warm Little Ponds\nThe argument for hydrothermal vents is based on the extremely reactive conditions formed at mid-ocean ridges where tectonic plates diverge. The high temperatures from magma heating provide a robust energy source around which rich ecosystems and complex reactions can thrive. Nevertheless, it has been suggested that the concentrations of chemicals necessary for reactivity would have been extremely low given the massiveness of oceans. \u201cThe ocean is, intrinsically, a difficult place for life to emerge,\u201d Korenaga said. Additionally, because the formation of peptide bonds between amino acids to form proteins is a dehydration reaction, this would be difficult to accomplish with water as the medium. Therefore, some scientists would consider dry land essential to initiate life.\nThe evidence for land above sea level provides the necessary geological environment for warm little ponds to exist. In addition to concentrating chemical compounds more effectively, these ponds would be exposed to a variation in annual rainfall. The seasonal wet and dry conditions could have driven bond formation in RNA, which is widely accepted to have been the original information-carrying molecule in all organisms, before DNA had evolved. Its ability to store and pass on information would subject it to the Darwinian theory of natural selection, leading to the evolution of organisms and life as we know it.\nBuilding Bridges, Traversing the Divide\u00a0\nWhile Korenaga and Rosas\u2019 work fits another piece into the puzzle of the origin of life, the specifics of the prebiotic chemistry involved remain to be understood. Abiogenesis lies at the intersection of Earth sciences and inorganic chemistry. According to Korenaga, his research focus lies within the more straightforward of the two problems, involving building models of the Archaean Earth using physical and chemical principles that are already well-understood. \u201cThe abiological to biological bridge remains a huge question,\u201d Korenaga said. He explained that once the first organism had been formed, one could trace a line down to the currently existing species by Darwin\u2019s theory of evolution.\u00a0\nKorenaga shared that one of the limitations of the field is a lack of communication between scientists from the geological and chemical disciplines. \u201cAs science matures, people start to specialize in a very narrow discipline,\u201d he said. \u201cMany of the people working on the origin of life problem are not very aware of our contemporary understanding of geology,\u201d he said. He plans to continue refining the understanding of early Earth conditions by accounting for more components and interactions and testing model predictions against geological records. Communication with prebiotic chemists is also a priority, since an understanding of the early Earth would provide knowledge of the relevant environmental conditions.\nKorenaga spoke about the loftiness of the abiogenesis project and how filling the gap between physical and biological systems seems inconceivable at the moment. \u201cI probably won\u2019t see the result in my lifetime,\u201d he said. Nevertheless, by opening up a new paradigm for islands on the ancient Earth, their research contributes to the larger international endeavor. \u201cOnce we understand the transition from abiological to biological stuff, it\u2019s probably as big as Darwin\u2019s discovery of biological evolution,\u201d he said.\u00a0\nCitations:\nDa Silva, Laura, Marie-Christine Maurel, and David Deamer. 2015. \u201cSalt-Promoted Synthesis of RNA-like Molecules in Simulated Hydrothermal Conditions.\u201d Journal of Molecular Evolution 80 (2): 86\u201397.\nMartin, William, John Baross, Deborah Kelley, and Michael J. Russell. 2008. \u201cHydrothermal Vents and the Origin of Life.\u201d Nature Reviews. Microbiology 6 (11): 805\u201314.Orgel, L. E. 1998. \u201cThe Origin of Life\u2013a Review of Facts and Speculations.\u201d Trends in Biochemical Sciences 23 (12): 491\u201395.Pearce, Ben K. D., Ralph E. Pudritz, Dmitry A. Semenov, and Thomas K. Henning. 2017. \u201cOrigin of the RNA World: The Fate of Nucleobases in Warm Little Ponds.\u201d Proceedings of the National Academy of Sciences of the United States of America 114 (43): 11327\u201332.Rosas, Juan Carlos, and Jun Korenaga. 2021. \u201cArchaean Seafloors Shallowed with Age due to Radiogenic Heating in the Mantle.\u201d Nature Geoscience 14 (1): 51\u201356.\nAbout the Author:\nAlexa Jeanne Loste is a first-year prospective Molecular Biophysics & Biochemistry major in Ezra Stiles College. In addition to writing for YSM, she is a project head for GREEN at Yale, a member of the Environmental Education Collaborative, the STEM Panel Chair for the Conference Committee of the Women\u2019s Leadership Initiative, and a copy desk staffer at the Yale Daily News.\nAcknowledgments:\nThe author would like to thank professor Jun Korenaga for his time and enthusiasm in sharing his research.\nExtra Reading:\nRosas, Juan Carlos, and Jun Korenaga. 2021. \u201cArchaean Seafloors Shallowed with Age due to Radiogenic Heating in the Mantle.\u201d Nature Geoscience 14 (1): 51\u201356.\nPearce, Ben K. D., Ralph E. Pudritz, Dmitry A. Semenov, and Thomas K. Henning. 2017. \u201cOrigin of the RNA World: The Fate of Nucleobases in Warm Little Ponds.\u201d Proceedings of the National Academy of Sciences of the United States of America 114 (43): 11327\u201332.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/out-of-the-blue-islands-of-life/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Up in Flames: Retrieving Clues About Air Pollution from Forest Fires",
            "author": "Anavi Uppal",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fire-Forest-500x332.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Orange skies and choking smoke covered California last summer. Wildfires aren\u2019t rare in this state, but climate change has been making them increasingly severe\u20142020 was the worst Californian wildfire season on record. Recent research on wildfire patterns can offer insight into what kinds of pollutants they release into the atmosphere and may tell us more about how they impact our health and our planet.\u00a0\nResearchers from the Department of Chemical and Environmental Engineering at Yale University found that forest fire emissions evolve in surprising ways over time. Associate professor Drew Gentner and his lab focus on studying air quality and atmospheric chemistry, particularly the chemical transformations that organic compounds undergo in the atmosphere, and what their ultimate impact might be. The Gentner lab collaborated with Environment and Climate Change Canada to take part in a flight campaign that focused on studying oil sands emissions in Canada.\u00a0\nThe team\u2019s goal was to sample a forest fire\u2019s emissions to study how the composition of its smoke plume evolved over time and distance. \u201cForest fires are an important factor in global air quality and the air quality of local regions, so the field is conducting more and more projects to study wildfire smoke,\u201d Gentner said.\nCatching Fire\nThe flight campaign\u2014an airplane-based measurement program\u2014was initially focused on studying oil sands emissions and not forest fires. But when a forest fire coincidentally erupted during the campaign, a plane was quickly dispatched to sample its emissions. \u201cI think it was in the back of their mind that, if this happens, we\u2019re going to go, and once they heard about it they capitalized on the opportunity,\u201d said Jenna Ditto, a former doctoral student at Yale in the Gentner lab. \u201cThis type of sampling definitely needs quick thinking, and you have to be ready.\u201d\nThe aircraft flew in zig-zag lines called transects along the emission plume as it traveled downwind and sampled it in five different places. Sample one was taken closest to the fire, while sample five was the farthest. The farther that the sample was from the wildfire, the older those emissions were.\u00a0\nThe plane was outfitted with instrumentation that measured gases, particles, and weather conditions in real time, while also collecting offline samples for later laboratory analysis. These offline samples were collected on small filters or glass tubes filled with absorbent materials that trap a mixture of compounds from the atmosphere.\nOnce collected, the samples were frozen at around negative thirty degrees Celsius to prevent chemical reactions from altering them during storage. When the team did an initial compound class analysis to see what materials they were dealing with, they found a surprising result: the quantity of compounds called CHONS\u2014which contain carbon, hydrogen, oxygen, nitrogen, and sulfur\u2014increased in particle-phase samples taken the furthest from the forest fire. \u201cWe saw that\u00a0and thought: that\u2019s very interesting, we\u2019ve never seen this before. Why is that happening? Let\u2019s look more into the functional groups,\u201d Ditto said. Compound class analysis is usually done as just a first step to get a sense for what the data looks like, but it fortuitously led the team to some interesting results.\nThey also found that the quantity of CHO (carbon, hydrogen, oxygen) compounds decreased from samples one to four, moving away from the fire\u2014the fifth sample was contaminated by emissions from a nearby oil sands facility, and was not considered. This seemed to indicate that these CHO compounds were the precursors for the CHONS compounds that were increasing in quantity. \u201cIt\u2019s interesting because we previously didn\u2019t really know about the formation of these CHONS compounds,\u201d said Megan He, a current junior and Environmental Engineering major at Yale College who co-authored the study.\u00a0\nHuman Health\nThe discovery that CHONS compounds are a major component of forest fire emissions is important for future studies on how biomass burning affects human health. For forest fires in particular, understanding what compounds form as emissions evolve downwind helps us determine exactly what we are breathing in. \u201cIf you\u2019re a couple hundred miles downwind of a fire, you\u2019re not really exposed to the same type of chemical components as you would be if you were ten miles away from the fire,\u201d Ditto said.\u00a0\nHowever, the results of this study are not just limited to wildfires. They could also apply to developing areas that burn biomass for fuel. Biomass burning emits nitrogen species and fossil fuel combustion emits sulfur species, which are similar to those that were present in this particular forest fire plume. Therefore, the chemical reactions that created CHONS in the forest fire could be representative of similar chemical processes that occur in developing regions.\nGetting a better picture of what compounds are being formed when something is burned can help create better models that in turn help to inform environmental policies. \u201cIf you were a part of the government, it would be helpful to know what the health impacts of the different compounds are,\u201d He said.\nLooking to the Future\nMoving forward, the team believes that more studies should be done on how the compounds they observed in the fire plume affect the environment. Looking at their light absorption properties could yield important results, since having a lot of light-absorbing particles in the air changes how incoming solar radiation interacts with the planet\u2013\u2013which, in turn, affects the climate.\nLooking at oil sands emissions, such as those that contaminated the fifth sample, could also be an insightful next step. This was not only the original purpose of the flight campaign, but is also the focus of He\u2019s current research. Oil sands are untapped sources of petroleum fuel in Canada, and the facilities built on top of them drill down to extract and then process that oil. In addition to the natural evaporations from the sands, this process releases a lot of emissions. \u201cPrevious studies have shown that the enhancement of secondary organic aerosol formation from these emissions is at a similar magnitude to those that are downwind of major cities, such as Houston or Toronto,\u201d He said. \u201cThis remote area where it\u2019s just trees and oil sands facilities has emissions that are comparable to major megacities, so that just shows how important they are in the grand scheme of things.\u201d\nUndergraduate Researchers Blaze Forward\nThis study was particularly special in that it involved undergraduate students in frontline air pollution research. In addition to He, Tori Hass-Mitchell, a former Yale undergraduate and current Yale Ph.D. student, contributed to this research. \u201cI was really excited about the chance to involve undergrads in research that\u2019s at the forefront of the field, and for them to interact with leading scientists from places like Environment and Climate Change Canada,\u201d said Gentner.\nAs someone who is passionate about air quality research, He emphasized how much she enjoyed the rigor of the research process and the opportunity to apply what she had learned inside the classroom to the real world. \u201cAs we saw last year with Australia, forest fires in general are increasing, and they\u2019re just going to keep becoming more frequent,\u201d He said. \u201cThere\u2019s so much of a mystery surrounding what is burned and what\u2019s in the air, so I just want to keep figuring out what it is that we\u2019re breathing right now, and what\u2019s coming into our bodies. I guess long story short, it\u2019s just the mystery of it that I love, and we have the tools to actually solve those mysteries.\u201d\u00a0\nClimate change is worsening, and it\u2019s more urgent than ever that we find ways to mitigate humanity\u2019s negative impacts on the environment. The research that is done in labs can have a powerful impact on current worldwide problems, and new voices\u2014such as He\u2019s and Hass-Mitchell\u2019s\u2014on topics like air quality can get us closer to finding solutions for them.\u00a0\nFurther Reading:\nDitto, J. C., He, M., Hass-Mitchell, T. N., Moussa, S. G., Hayden, K., Li, S., . . . Gentner, D. R. (2021). Atmospheric evolution of emissions from a boreal forest fire: The formation of highly functionalized oxygen-, nitrogen-, and sulfur-containing organic compounds. Atmospheric Chemistry and Physics, 21(1), 255-267. doi:10.5194/acp-21-255-2021\nAuthor Bio: Anavi Uppal is a first-year student and prospective Astrophysics major in Pierson College. In addition to writing for YSM, she is one of Synapse\u2019s outreach coordinators, and teaches science to elementary schoolers through Yale Demos.\u00a0\nAcknowledgements: The author would like to thank Drew Gentner, Jenna Ditto, and Megan He for their time and enthusiasm about their research.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/up-in-flames-retrieving-clues-about-air-pollution-from-forest-fires/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Shutting Down the IRE1\u03b1 Complex",
            "author": "Ryan Bose-Roy",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2-1-500x377.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "There are more than twenty thousand different proteins in your body, and each one plays some role in your life. If you travel to another time zone, clock proteins in your brain regulating circadian rhythm are briefly overexpressed and make you tired. If you get sick, proteins called antibodies are faithfully produced by your immune system to identify the foreign particles in your body. And if you are ever so lucky enough to fall in love, then protein hormones like oxytocin and vasopressin, produced in your pituitary gland, help give you the feeling of being happy and safe.\u00a0\nThe plethora of proteins within us are produced by a cellular structure that, if not for its intricate folding, would be ten to twenty times larger than the outer surface of the cell itself. Its name is the endoplasmic reticulum (ER), and it serves as the production facility where proteins are assembled, folded, and secreted. Seeing how crucial proteins are in maintaining metabolism, it is no surprise that the ER works very hard to keep us alive.\u00a0\nUnfortunately, things don\u2019t always run smoothly: the ER sometimes over-exerts itself. If you get sick, for instance, each day, the mature B-cells of your immune system will secrete up to their own weight in antibodies, which are all processed in the cells\u2019 ERs. Glucose deprivation and calcium regulation also affect processes in the ER by triggering responses that interfere with protein folding. The imbalance between supply and demand of properly shaped proteins produced by the ER leads to a phenomenon called ER stress, which may lead to type 2 diabetes, atherosclerosis, and liver disease.\u00a0\nFortunately, our cells have a set of proteins that sense ER stress and respond to stop it. These proteins, collectively called unfolded protein response (UPR) proteins, play a major role in cellular life and death decisions\u2014this feature has garnered an intense interest in the role of UPR proteins in many diseases. However, there is a lot we do not know about these proteins and their roles.\u00a0\nThe most common of these proteins is IRE1\u03b1. Initially, IRE1\u03b1 calls for molecular chaperones that guide misfolded structures along the proper pathways for folding, helping the ER return to its normal functioning conformation. However, if activated for too long, IRE1\u03b1 starts to initiate apoptosis, or programmed cell death, through the signal-regulating kinase 1 (ASK1) protein and through proteins called caspases. It makes sense that activity is tightly regulated, but how this happens is unclear. Unveiling the molecular mechanisms that govern IRE1\u03b1 activity could help us understand how UPR proteins are regulated across all eukaryotic cells, as well as how a number of human diseases develop.\nResearch conducted by Malaiyalam Mariappan and Xia Li at the Yale School of Medicine has helped shed light on this intricate process. Their work describes how UPR proteins are regulated. \u201cWe identified the mechanism that actually turns off the IRE1\u03b1 sensor molecule so that cells can get back to normal, rather than going into cell death,\u201d Mariappan said.\u00a0\nThe key, they found, was a protein called sec63, which actively recruits a protein chaperone called binding immunoglobulin protein (BIP) to stick to IRE1\u03b1 like a cap. This capping prevents IRE1\u03b1 from binding to itself and forming long, active, peptide chains. Thus, it forces IRE1\u03b1 to exist in an inactive state as singular proteins.\u00a0\nUnder normal conditions, there is plenty of BIP for sec63 to pick up. During ER stress, BIP preferentially sticks to misfolded proteins instead of IRE1\u03b1, and this lack of capping allows IRE1\u03b1 to bind to itself and activate. Active IRE1\u03b1 chains initiate cell transcription pathways that produce more BIP, and it is this self-regulating negative feedback mechanism that keeps IRE1\u03b1 in check.\u00a0\nThe discovery of sec63 as an inhibitor of IRE1\u03b1 clustering is an addition to the Mariappan lab\u2019s long line of important findings on regulators of proteins such as IRE1\u03b1. \u201cInitially it was thought that IRE1\u03b1 was an independent protein that sensed ER stress and sent signals to the nucleus\u2026 but we were the first to report that it\u2019s actually part of a big complex with protein translocation channels,\u201d Mariappan said.\u00a0\nElucidating the role of sec63 as a recruiter for BIP opens up a host of new questions. \u201cStill in this field, there\u2019s a lot of mystery, especially in ER stress and the unfolded protein response field,\u201d Li said. \u201cI just want to know how it all works.\u201d\nCitations\nCarter, C. S. (2017). The Oxytocin\u2013Vasopressin Pathway in the Context of Love and Fear. Frontiers in Endocrinology, 8. doi:10.3389/fendo.2017.00356\u00a0\nKatsube, H., Hinami, Y., Yamazoe, T., & Inoue, Y. H. (2019). Endoplasmic reticulum stress-induced cellular dysfunction and cell death in insulin-producing cells results in diabetes-like phenotypes in Drosophila. Biology Open, bio.046524. doi:10.1242/bio.046524\u00a0\nLi, X., Sun, S., Appathurai, S., Sundaram, A., Plumb, R., & Mariappan, M. (2020). A molecular mechanism for turning off IRE1\u03b1 signaling during endoplasmic reticulum stress. Cell Reports, 13(33). doi:10.1101/2020.04.03.024356\nLin, J. H., Walter, P., & Yen, T. S. B. (2008). Endoplasmic Reticulum Stress in Disease Pathogenesis. Annual Review of Pathology: Mechanisms of Disease, 3(1), 399\u2013425. doi:10.1146/annurev.pathmechdis.3.121806.1514\nMilo, R., & Phillips, R. (2016). Cell biology by the numbers. New York, NY: Garland Science, Taylor & Francis Group.\nPonomarenko, E. A., Poverennaya, E. V., Ilgisonis, E. V., Pyatnitskiy, M. A., Kopylov, A. T., Zgoda, V. G., \u2026 Archakov, A. I. (2016). The Size of the Human Proteome: The Width and Depth. International Journal of Analytical Chemistry, 2016, 1\u20136. doi:10.1155/2016/7436849\u00a0\nXu, C. (2005). Endoplasmic reticulum stress: cell life and death decisions. Journal of Clinical Investigation, 115(10), 2656\u20132664. doi:10.1172/jci26373\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/shutting-down-the-ire1%ce%b1-complex/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Lab Grown Meat: Valid Concern or Unfounded Disgust?",
            "author": "Frances Cheung",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/FirstDraft_Cheung-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Culturing meat from animal cells is an alternative to factory farming, a practice that raises ethical, social, and environmental issues. However, culturing meat remains controversial, with \u201cunnaturalness\u201d frequently cited as a concern. Yale researchers led by Matti Wilks conducted a study to better understand psychological motivators of these negative perceptions. \u201cWe were trying to understand who was rejecting cultured meat and what kinds of personality traits were associated with disliking it,\u201d Wilks explained.\u00a0\nAfter examining correlations between naturalness and acceptability for several processes\u2014for example, growing an apple\u2014researchers observed that culturing meat scored around the average. Next, they found that people with higher disgust sensitivity and conspiratorial ideation levels tended to view cultured meat more negatively. Researchers also examined attitudes and unnaturalness ratings for specific beliefs about cultured meat, such as the perception that it is highly processed. Interestingly, the view most correlated with unnaturalness was related to safety, not naturalness. Meat grinding\u2014the only step shared with farm meat production\u2014was rated to be the least natural step of cultured meat production.\u00a0\nThese findings suggest that emotion, rather than logic, may play a big role in the perception of cultured meat as unnatural. This may be problematic, as current strategies to ameliorate such negative opinions focus on rationally educating the public. \u201cI think the question we should be asking is how can we make people feel more comfortable with cultured meat,\u201d Wilks said. In the near future, the researchers hope to find causal evidence for the role of emotion in cultured meat perception.\u00a0\nSources\n1. Wilks, M., Hornsey, M., & Bloom, P. (2021). What does it mean to say that cultured meat is unnatural? Appetite, 156, 104960. https://doi.org/10.1016/j.appet.2020.104960.\n2. Wilks, Matti. Personal communication. February 8, 2021.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/lab-grown-meat-valid-concern-or-unfounded-disgust/",
            "captions": [
                ""
            ]
        },
        {
            "title": "From Cells to Thermodynamics: Measuring the Entropy Production of Living Matter",
            "author": "Elisa Howard",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Howard_Figure1-500x320.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "A human being is composed of about 37.2 trillion cells, seven octillion atoms, sixty thousand miles of blood vessels, three billion DNA base pairs, and thirty thousand genes. Yet, despite this profound intricacy, a person originates from a single cell that splits via the mitotic process of the first cell division. After DNA replication and the separation of chromosomes, proteins called microfilaments form a cytokinetic ring, which divides the cytoplasm and generates two daughter cells. But before the first cell division, waves within the cellular fluid disseminate for proper formation of the ring. Such patterns of wave oscillations allow for the application of thermodynamic principles to measure the metabolic costs dictating the development of your very being.\nIn the Laboratory of Living Matter at Yale University, Michael P. Murrell, Benjamin B. Machta, and Daniel S. Seara introduced the entropy production factor (EPF) to quantify the irreversibility of biochemical oscillations, the propagation of signals in various biological processes, and the associated energetic expense. \u201cThe entropy production factor is a quantity that correctly measures irreversibility in order to give a total amount of energy consumed or, equivalently, how much entropy is being produced,\u201d Seara said. The EPF builds upon the second law of thermodynamics, which states that the universe tends toward disorder and that entropy\u2014the measure of energy unavailable for mechanical work\u2014increases over time.\nThe second law lends itself to a discussion of irreversibility and time-reversal symmetry, which form the basis of Murrell, Machta, and Seara\u2019s research. Irreversible processes increase the entropy of the universe and thus proceed only in the forward direction, as the reverse direction would contradict the second law. Furthermore, irreversible processes break time-reversal symmetry, such that the forward direction is distinguishable from the reverse direction and that time points unidirectionally. A recording of an explosion, for example, looks noticeably different when played in the forward versus the reverse direction. The researchers introduced the EPF to effectively measure the evolution of a system and its likelihood of returning to an initial state. \u201cWe are using a precise statistical measurement of, for example, how likely a particle is to move to the right or left at the next time point. By quantifying this, it intuitively gives you the irreversibility and also the shortcut to how much energy is being dissipated,\u201d Seara said.\nIn full, the EPF quantifies the breakage of time-reversal symmetry that is characteristic of irreversible processes. Thus, the EPF provides a measure of how much entropy is produced, or how much energy is dissipated and unavailable for work. \u201cThe statistical measure of how hard it would be to distinguish if the movie is being played forward or backward is exactly how much energy is being wasted,\u201d Machta said.\u00a0\nApplying this method, the team used their EPF to quantify phase transitions of the Brusselator, a model of biochemical oscillations. With the EPF, they not only measured irreversibility but also the energetic costs of the Brusselator\u2019s spatiotemporal waves\u2014waves with both space and time characteristics.\nThe EPF is a breakthrough in the field of nonequilibrium thermodynamics, as previous measures of entropy production only measured changes in single quantities without recognition of the spatial dimension. \u201cThis method is far more inclusive of the degrees of freedom and information in the system,\u201d Murrell said. The EPF is particularly extraordinary in its applicability to biological systems and insight regarding the energetic costs of metabolic processes. \u201cWe are interested in applying this method to relate energetic principles to fundamental biological events,\u201d Murrell said.\u00a0\nThe Yale Laboratory of Living Matter is currently researching an organism\u2019s first cell division by quantifying the energy dissipation of biochemical oscillations necessary to form a cytokinetic ring. \u201cThere are traveling waves of proteins for cell division that propagate across the surface of the cell and are implicated in properly locating the equator of the cell to divide in a healthy and robust way,\u201d Seara said. By quantifying irreversibility, the EPF has the power to unearth the metabolic costs of an organism\u2019s first cell division. Thus, it may provide insight into human development from a single zygote to an individual composed of about 37.2 trillion cells, seven octillion atoms, sixty thousand miles of blood vessels, three billion DNA base pairs, and thirty thousand genes.\nCitations\nAfework, B., Hanania, J., Stenhouse, K., & Donev, J. (2018, June 25). Entropy. Energy Education. Retrieved February 14, 2021, from https://energyeducation.ca/encyclopedia/Entropy\nBailey, B. (2014). Entropy and the second law of thermodynamics: Disorder and the unavailability of energy. In J. Rittenbach (Author), Concepts of physics with linear momentum and DC circuits. https://cnx.org/contents/UfumKqbv@12.12:jcBmTbgj@1/Entropy-and-the-Second-Law-of-Thermodynamics-Disorder-and-the-Unavailability-of-Energy\nClegg, B. (2013, January 23). 20 amazing facts about the human body. The Guardian. Retrieved February 14, 2021, from https://www.theguardian.com/science/2013/jan/27/20-human-body-facts-science\nEveleth, R. (2013, October 23). There are 37.2 trillion cells in your body. Smithsonian Magazine. Retrieved February 14, 2021, from https://www.smithsonianmag.com/smart-news/there-are-372-trillion-cells-in-your-body-4941473/\nSeara, D. S., Machta, B. B., & Murrell, M. P. (2021). Irreversibility in dynamical phases and transitions. Nature Communications, 12(1), 392. https://doi.org/10.1038/s41467-020-20281-2\nSpakovszky, Z. S. (n.d.). Some overall comments on entropy, reversible and irreversible processes. Thermodynamics and Propulsion. Retrieved February 14, 2021, from https://web.mit.edu/16.unified/www/FALL/thermodynamics/notes/node51.html\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/from-cells-to-thermodynamics-measuring-the-entropy-production-of-living-matter/",
            "captions": [
                "www.mantis.cz/mikrofotografie"
            ]
        },
        {
            "title": "Nanoparticles for Treating Sick Babies in the Uterus",
            "author": "Viola Lee",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Lee_Figure1-476x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Is it possible to treat babies with congenital lung conditions before they are even born? Yale surgeons and biomedical engineers are collaborating on a novel way to use nanoparticles to deliver therapeutic agents to fetuses in utero. Nanoparticles can enhance delivery through a variety of mechanisms, such as protecting drugs until they reach their targets, improving their bioavailability, or enhancing their cellular uptake.\u00a0\n\u201cWe were looking at how to optimize targeting the fetal lung using different nanoparticle chemistries, injecting at different gestational time points, and trying several injection methods,\u201d said Sarah Ullrich, the lead author of the study and a general surgery resident at Yale. The study found that to help nanoparticles reach the lungs of fetal mice, delivery via fetal intravenous injection is superior to delivery via the amniotic sac.\u00a0\nNanoparticles provide a potential solution for one of the diseases Ullrich studies, congenital diaphragmatic hernia. In this condition, the diaphragm does not form properly, resulting in the abdominal organs of a developing fetus being pushed up against the lungs. Many babies born with congenital diaphragmatic hernia need the help of a machine that takes over the normal function of the heart and lungs. \u201cOur goal with that project is to allow the lungs to grow enough to have full function while the baby is in utero, by injecting nanoparticles that deliver therapeutic agents that promote lung growth,\u201d Ullrich said. Knowing the optimal particle type and injection method for maximal fetal lung delivery is therefore essential for this ongoing project.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/nanoparticles-for-treating-sick-babies-in-the-uterus/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A New Frontier of Atomic Scale Replication",
            "author": "Emilia Oliva",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/image1-1-500x428.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Science now allows us to replicate designs on the atomic level, thanks to a team of Yale researchers led by Udo Schwarz and Jan Schroers, professors of mechanical engineering and materials science. By using a technique called sputter deposition, this breakthrough could be practical and desirable for mass industrial use.\u00a0\nAn efficient way to reproduce nanostructured surfaces could have a huge impact on areas of technology such as high-density data storage, photonic devices, water filtration, and electrodes in fuel cells. Imprinting doesn\u2019t require the use of a clean room\u2014a tightly regulated space of filtered air that minimizes possible contaminants\u2014which typical nanomanufacturing requires. The material used to imprint, metallic glass, also has useful properties of durability and strength. \u201cWe had the question: What\u2019s the limit of this?\u00a0If I can do this to thirty\u00a0nanometers, is there anything that stops us?\u201d Schwarz said.\u00a0\nThe key to atomic scale replication is the use of bulk metallic glass, also known as amorphous metal\u2014a material made by cooling a liquid metal alloy so quickly that the atoms don\u2019t have time to arrange themselves in a crystalline structure and instead lie jumbled together. Without a crystalline structure, the researchers found that the only factor limiting the size of what they could replicate was the size of the atoms and the distance between them. The random configuration of atoms in a metallic glass gives it a viscous quality, allowing it to be blown just like glass, or molded onto nanostructured surfaces. It can be processed as plastic, but unlike plastic, it is very hard, resistant to wear and tear, and able to conduct electricity.\u00a0\nOnce the researchers had shown that there was no limit to the size of replication except the atoms themselves, they turned their attention to scaling up the process and making it more efficient. Instead of pressing the metallic glass to the mold in a process called thermoplastic forming, the researchers used a technique called sputter deposition, which doesn\u2019t require high heat or pressure. They shot argon ions at a metal plate, which loosened the surface atoms and sent them falling onto the mold below. As single atoms, they cooled immediately upon hitting the room-temperature mold to form a metallic glass on the surface.\u00a0\n\u201cIf you use, for instance, just gold, then it will still crystallize, so you still need the right combination of different metals,\u201d Schwarz said. \u201cThe trick is to basically have small atoms and large atoms together so they don\u2019t line up nicely in a crystal, and [since] they don\u2019t know what to do, they just stick in the glass.\u201d\nSputter deposition makes it possible to use many more metallic alloys than thermoplastic forming can for nanoscale imprinting. The researchers theorize that hundreds of millions of different combinations of metallic elements could be possible when using sputter deposition, while thermoplastic forming only allows hundreds.\u00a0\n\u201cIf you want to do thermoplastic forming, there are some restrictions on the mold, on the alloy that you can choose, and some specific conditions that you have to achieve\u2014[like] the temperature or the pressure to do the thermoplastic forming,\u201d said Zheng Chen, a graduate student who worked on the study.\nBecause sputter deposition doesn\u2019t require high heat and pressure, any material that doesn\u2019t react with the metallic glass could potentially be replicated. For example, biomaterials acting as molds are a potential application for this technology. \u201cWe think you can now duplicate anything you really want at the atomic scale,\u201d Schwarz said.\nSchwarz hopes to pursue a project to find a way to keep sand and dirt off of solar panels by reproducing the structure of snakeskin, which has unique nano-scale patterns that force sand to slide off. To do this, Schwarz wants to first make a mold with metallic glass, then copy the pattern onto plastic. Another possible project is to use nanoimprinting with metallic glass to reproduce nanostructured surfaces that can act as catalysts for clean energy reactions. These reactions can be applied to areas like jet fuel.\u00a0\n\u201cMaybe it never goes\u00a0anywhere, maybe metallic glasses are totally bad. But because people haven\u2019t tried yet, there are a lot of intriguing things that could happen because of the disorder [of the atomic structure],\u201d Schwarz said.\nWorks cited\n1. Zheng Chen, Amit Datye, Georg H. Simon, Chao Zhou, Sebastian A. Kube, Naijia Liu, Jingbei Liu, Jan Schroers, and Udo D. Schwarz. (2020). Atomic-Scale Imprinting by Sputter Deposition of Amorphous Metallic Films. ACS Applied Materials & Interfaces\u00a012(47), 52908-52914. DOI: 10.1021/acsami.0c14982.\n2. Chao Zhou, Amit Datye, Zheng Chen, Georg H. Simon, Xinzhe Wang, Jan Schroers and Udo D. Schwarz. (2020). Atomic Imprinting in the absence of an intrinsic length scale. APL Materials 8(11), 111104. DOI: 10.1063/5.0027982\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/a-new-frontier-of-atomic-scale-replication/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Colossal Effect of Grains: A new model explains how tectonic plates weaken prior to subduction",
            "author": "Yu Jun Shen",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Shen_Figure2-500x254.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Tectonic plate movements drive many geologic processes on Earth, from earthquakes to volcanos, yet how tectonic plates start sinking beneath one another is not well understood. Yale researchers David Bercovici and Elvira Mulyukova have proposed a new model in which tiny mineral grains in rocks mix and shrink at passive margins\u2014inactive regions where sea floor meets continent\u2014weakening the tectonic plates and causing sinking known as subduction.\nAs the near-surface layer of Earth\u2019s mantle cools, it becomes denser, promoting subduction, but also becomes stiffer, opposing subduction. On most planets, subduction either does not occur or stiffening wins out, and plates do not sink. In contrast, Earth is unique and has a geologically active surface. Explaining how subduction initiates has attracted many theories. \u201cThe mystery for any rocky planet is if and when its surface will dive into the mantle,\u201d Mulyukova said.\nBy developing a new theoretical model that spans three scales, from massive tectonic plates to individual rocks and microscopic grains, Bercovici and Mulyukova showed that tiny mineral grains could determine tectonic plate weakness. Bercovici and Mulyukova propose that at passive margins, mineral grains mix and shrink due to the tectonic stress, which, over a period of one hundred million years, weakens the plates, making them susceptible to subduction.\n\u201cThese weak zones don\u2019t heal. They don\u2019t vanish quickly,\u201d Bercovici said. \u201cWe have a mechanism for how to transform passive, inactive places on Earth into long-lived active plate boundaries.\u201d By focusing on the action of tiny grains, the motion of tectonic plates may be predicted, revealing where their subduction zones form.\nCitations\nBercovici, D., & Mulyukova, E. (2021). Evolution and demise of passive margins through grain mixing and damage.\u00a0Proceedings of the National Academy of Sciences,\u00a0118(4).\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/the-colossal-effect-of-grains-a-new-model-explains-how-tectonic-plates-weaken-prior-to-subduction/",
            "captions": [
                "Rocks are made of different grains, which themselves set the strength of tectonic plates."
            ]
        },
        {
            "title": "The Molecular Nature of PTSD: The Transcriptomic Landscape of PTSD in Postmortem Tissue",
            "author": "Georgia Spurrier",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/YSM_Figure2-500x357.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "In studying psychiatric disorders, researchers must account for both the environmental and biological components that may play into a condition\u2019s presentation. In post-traumatic stress disorder (PTSD), the environmental component is written into the name\u2014trauma. But much still needs to be uncovered surrounding the biological mechanisms, which was the goal of an article published in Nature Neuroscience in January of this year, led by researchers in the Department of Psychiatry at the Yale School of Medicine. Researchers dove into the transcriptomic organization of postmortem tissue in the PTSD-diagnosed brain, meaning they analyzed the collection of messenger RNA (mRNA) transcripts present in a cell\u2014known as the transcriptome\u2014to understand the molecular mechanisms underlying this disorder. This investigation illuminated sex differences in PTSD expression, unexpected correlations with other disorders, and several genes of interest in the pathophysiology of PTSD.\nThe paper homed in on four subregions of the prefrontal cortex (PFC), a region of the brain highly implicated in emotion regulation, chosen because of previously observed differences between PTSD patients and healthy patients in this area. Not unlike other psychiatric conditions, PTSD does not have a clear-cut cause. A range of trauma types can contribute to its emergence and may even have an impact at the molecular level. \u201cWe would predict differences in molecular profiles for different traumas,\u201d said Matthew Girgenti, a research scientist at the Yale School of Medicine. \u201cI do think that the trauma type has an effect on how and when you develop PTSD,\u201d Girgenti said, bringing to light the complex interplay of environmental and biological factors. This interplay may also be present in sex differences in PTSD, as the traumas that most often lead to PTSD diagnoses in men and women are vastly different, the former being combat trauma and the latter being sexual trauma.\u00a0\nResearchers found that sex, in fact, had the greatest effect on molecular variance in PTSD. All subregions of the PFC displayed transcriptomic differences between men and women, with women additionally showing more differentially expressed genes (DEGs) between the PTSD and control groups. The identified genes are involved in GABAergic signaling, which is significant given that GABA serves as a major inhibitory neurotransmitter implicated in traumatic stress. One of these genes, ELFN1, was identified as a key player in the observed sex differences. ELFN1 was significantly downregulated, meaning there was significantly less of the transcript in PTSD patients in females but not in males. Another key gene, UBA7, also showed sex differences and was downregulated in multiple subregions. This gene is involved in inflammatory and immune processes, which have been implicated in the pathophysiology of many psychiatric disorders.\nAnother goal of this research was to explain on a molecular level the high comorbidity, or simultaneous presence, of PTSD and major depressive disorder (MDD). Surprisingly, despite nearly fifty percent of newly diagnosed PTSD patients having comorbid MDD, their transcriptomic profiles were found to be quite dissimilar. While there were a high number of DEGs present in the PFC regions of MDD brains, the overlap with PTSD was minimal. The researchers identified one gene, GADD45B, that PTSD and MDD brains had in common across both sexes; GADD45B therefore serves as a molecular intersection between these two disorders. Overall, however, the results indicate a non-significant overlap, and the researchers concluded that these disorders are more dissimilar than previously thought.\u00a0\nSo, what can explain the high tendency for PTSD and MDD to occur together? \u201cPTSD is still stress, and any amount of stress can lead to some type of depression,\u201d Girgenti said. \u201cHaving PTSD makes you prone to many comorbidities including depression.\u201d Interestingly, the PTSD transcriptome did significantly correlate with other neuropsychiatric disorders, such as schizophrenia, bipolar disorder, and autism spectrum disorder, implicating that the molecular pathologies of these disorders overlap to some degree.\u00a0\nThis research demonstrates important progress in our understanding of the molecular mechanisms involved in PTSD and how these may interact with sex and other diagnoses. Unfortunately, there are currently no medications specifically designed to treat PTSD. However, the gene networks identified here may play an important role in developing a treatment. \u201cTherapeutically targeting those systems [GABAergic and inflammatory] is most likely to succeed,\u201d Girgenti said. \u201cWe hope to identify genomic targets that are changing in PTSD and find current drugs we can repurpose to target those.\u201d The genomic landscape of the PTSD brain brought to light by this research may have important implications for therapeutic interventions as well as for gaining a deeper understanding of the impact of traumatic stress on the brain.\u00a0\nReferences\nGirgenti, M. J., Wang, J., Ji, D., Cruz, D. A., Alvarez, V. E., Benedek, D., Brady, C., Davis, D. A., Holtzheimer, P. E., Keane, T. M., Kowell, N., Logue, M. W., McKee, A., Marx, B., Mash, D., Miller, M. W., Scott, W. K., Stein, T., Ursano, R., \u2026 Duman, R. S. (2021). Transcriptomic organization of the human brain in post-traumatic stress disorder. Nature Neuroscience, 24(1), 24\u201333. https://doi.org/10.1038/s41593-020-00748-7\nNational Human Genome Research Institute. (2020, August 17). Transcriptome fact sheet. Retrieved from https://www.genome.gov/about-genomics/fact-sheets/Transcriptome-Fact-Sheet\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/the-molecular-nature-of-ptsd-the-transcriptomic-landscape-of-ptsd-in-postmortem-tissue/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Extracting Arsenic: Purging of Stubborn Contaminants Using Earth-Abundant Materials",
            "author": "Shudipto Wahed",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wahed_Figure1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Drinking water containing arsenic is linked to serious health issues such as cancer and diabetes. Unfortunately, millions of people around the world are at risk of water-related arsenic poisoning. While it is relatively easy to remove arsenic from otherwise pure water, natural water sources contain other competing anions, negatively charged molecules. Yale chemists Lauren Pincus and Predrag Petrovi\u0107 investigated the ability of various transition metal chitosan complexes (TMCs) to selectively adsorb\u2014stick to\u2014arsenate and arsenite over phosphate, their biggest competitor.\nTMCs are complexes of metal bound to chitosan, a waste product of the shellfish industry. Previous research demonstrated that copper(II)-chitosan selectively adsorbs arsenate, but not arsenite. This study found that iron(III)-chitosan had the highest rates of selectively adsorbing arsenate and arsenite, reducing concentrations below World Health Organization benchmarks.\nThe key is the TMC\u2019s molecular structure: iron(III) and chitosan formed a less rigid bidentate complex\u2014two bonds holding iron, as opposed to monodentate\u2014than other studied transition metals. X-ray spectroscopy data showed that this diffusion of iron\u2019s positive charge allowed iron(III)-chitosan to bind more tightly to negatively charged arsenic, whose electron cloud is more easily distorted than phosphorus\u2019s.\nThe researchers\u2019 findings address the global need for efficient water purification systems. \u201cThere aren\u2019t many adsorbents that are selective for arsenic over phosphate,\u201d Pincus said. Importantly, the scientists are furthering the incorporation of computational techniques in green chemistry, helping save time and resources. \u201cWe can do a lot of good things by combining computational and experimental work,\u201d Petrovi\u0107 said. Their research advances an environment-friendly approach while solving environmental problems.\nCitations\nPincus, L. N., Petrovi\u0107, P. V., Gonzalez, I. S., Stavitski, E., Fishman, Z. S., Rudel, H. E., \u2026 Zimmerman, J. B. (2021).\u00a0\nSelective adsorption of arsenic over phosphate by transition metal cross-linked chitosan. Chemical Engineering Journal, 412, 128582. https://doi.org/10.1016/j.cej.2021.128582\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/extracting-arsenic-purging-of-stubborn-contaminants-using-earth-abundant-materials/",
            "captions": [
                "Drop of water as a colorful illustration (Science and Technology) water,drop,mirror,science,reflection,pure,blue,vivid"
            ]
        },
        {
            "title": "Black Mirror, Discriminatory Design, and \u201cThe New Jim Code\u201d",
            "author": "Selma Abouneameh",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/RaceAfterTech_Cover-319x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "If you\u2019ve ever watched the Netflix series Black Mirror, you\u2019re well acquainted with the on-screen consequences of artificial intelligence gone rogue, invasive medical technologies, and intrusive surveillance methods. The show acts as a satirical commentary on both the role that technology plays in our society and the role society plays in creating technologies that have unintended, often destructive outcomes. After all, whose problems are technologies meant to solve, and whose problems do \u201cinnovative solutions\u201d exacerbate?\u00a0\nThis is just one question that Ruha Benjamin, sociologist and associate professor of African American Studies at Princeton University, posed to students in her course, \u201cBlack Mirror: Race, Technology, and Justice,\u201d taught in Fall 2020. The course drew its inspiration from her most recent book, Race After Technology: Abolitionist Tools for the New Jim Code.\u00a0\nIn her work, Benjamin analyzes how the history of racial coding\u2014a system that facilitates white supremacy\u2014is deeply intertwined with discriminatory design. She walks readers through examples of discriminatory design\u2014beauty algorithms that favor whiteness, soap dispensers that fail to recognize dark skin, and rating systems used to track social standing\u2014prompting us to think about the social systems that allow these technologies to exist in the first place. Benjamin gives a name to the employment of technologies that, regardless of intent, amplify racial hierarchies: \u201cThe New Jim Code.\u201d\u00a0\n\u201cThe New Jim Code\u201d isn\u2019t simply defined by the existence of discriminatory technologies. Benjamin structures her book around four major components that describe this era: engineered inequity, default discrimination, coded exposure, and technological benevolence. The strongest part of her analysis is her reliance on storytelling to engage readers and stress the tangible consequences of discriminatory design.\u00a0\nWhen asked what message she hoped her students took away from her course, Benjamin articulated the importance of human experience. \u201c[W]e have to take stories as seriously as we do statistics\u2026 speculation is not just what happens in books, films, and science fiction, but\u2026 the technologies that we use and build are the materialization of someone\u2019s imagination,\u201d she said. Through her analysis of lived experience and pop culture references, readers are able to recognize the racialized social hierarchy that decides whose problems get solved.\u00a0\nBenjamin concludes her book with an important chapter describing ways to fight the New Jim Code. We must both recognize the oppressive social systems that have led to a \u201cdefault\u201d of discriminatory design and act to dismantle them. A large part of this responsibility lies with students: the future leaders of STEM fields that have been defined by long histories of racism. Benjamin is an advocate for STEM education reform in this regard. \u201cI\u2019d love more STEM students to understand that their disciplines are located in a hierarchy of knowledge, where some ways of codifying and understanding the world\u2026 trump and displace other humanistic and experiential ways of knowing,\u201d Benjamin said. \u201cPart of working in solidarity with people and communities who are most harmed by unjust systems means engaging in the varied forms of knowledge they bring to the table.\u201d\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/black-mirror-discriminatory-design-and-the-new-jim-code/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Into the Newsroom: Teaching Through TikToks",
            "author": "Ann-Marie Abunyewa",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/AsapSCIENCE-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Ever wondered what our appendix actually does? Or why you feel like sneezing when you pluck your eyebrows? How about why the spider in your bathroom only has six legs? Well, Hank Green has an answer for that. You might have encountered Hank on his CrashCourse channel, which he co-founded with his brother John, while you were cramming for that high school biology test. Now he\u2019s migrated to TikTok, where he shares some of his hot takes and answers some of the scientific questions that may (or may not) be on your mind\u2014all while maintaining his ever-familiar eccentric personality between two of his largest platforms.\nHank Green is one of many creators on TikTok who use their platforms to talk about science. In his most popular TikToks, his followers submit videos asking any question on their minds, and Hank directly posts his responses on his page. The TikToks with the most views match his high-energy YouTube persona and use lightheartedness and sarcasm to point out that he is not always right and should not be the only scientific authority his viewers consult.\nYou might also remember the aesthetic whiteboard illustrations and the infamous \u201cPeriodic Table Song\u201d from AsapScience\u2019s YouTube channel. Well, Greg and Mitch, the channel\u2019s creators, have also brought their platform from YouTube to TikTok. Still, their style of disseminating information is a little different. Some of their most popular videos are reminiscent of the illustrative visuals they are known for on their YouTube channel. But others involve social commentary on STEM, dance breaks with captions calling attention to our reckless destruction of the planet, and Greg and Mitch\u2019s everyday thoughts and hot takes.\nHank, Greg, and Mitch never seemed to have sacrificed their personas on TikTok. Of course, their long-form content on YouTube can\u2019t necessarily be translated onto TikTok. Instead, TikTok allows their audiences to see a more personable side that may not have been portrayed in the same way on their main YouTube channels. TikTok\u2019s sixty-second time limit better accommodates short tidbits than complex concepts. This allows them to focus more on aspects that enable them to better connect with their audience\u2014for example, Q&As or talking about their personal lives.\nAs for creators that have built their platforms solely on TikTok, Darrion Nguyen (@lab_shenanigans) and Hailey Levi (@chaoticallyscience) are worth checking out. Many of Darrion\u2019s TikToks use sounds from reality shows to help playfully illustrate concepts helpful for studying biochemistry, while others showcase some of his after-hours antics as a research technician. One of Darrion\u2019s most popular videos shows him pasting images of James Watson, Francis Crick, and Maurice Wilkins in his\u00a0Mean Girls-inspired Burn Book. He alludes to how they snubbed Rosalind Franklin of her deserved recognition for identifying the double helix of DNA. The humor and classic references that Darrion incorporates are starting points for a social commentary on science and science history.\nMeanwhile, Hailey is a Ph.D. student who creates videos to prove that science isn\u2019t as dull or out-of-touch as it is sometimes portrayed to be. Her most recent posts showcase her having fun during her after-hours, whether she is switching on the vortex mixer to Gloria Estefan and Miami Sound Machine\u2019s \u201cConga\u201d or doing the Perfect Match trend with her lab mates. But she also puts out advice on starting graduate school and uses her platform to talk about being a person of color in STEM. Periodically, she educates viewers on prominent black women in STEM. She empowers her audience based on the importance of seeing other black women making significant strides in field in which they\u2019re underrepresented. From Hailey\u2019s content, you feel like you\u2019re connecting with a supportive peer mentor and easy-going friend.\nWhat do all of these creators have in common? They have all found ways to make attention-grabbing videos that promote science\u2014but not exactly in a format that is as high-stakes as your nine AM chemistry class or as passive as your asynchronous math class. Because these creators only have sixty seconds, the points that they communicate must be incredibly concise and clear. Moreover, they sprinkle in their personalities and humor to make STEM learning more engaging and more fun. Maybe Hank\u2019s status as a Gen-X member makes his TikToks more entertaining as he attempts to understand the questions coming from his majority Gen-Z audience. Meanwhile, Darrion\u2019s use of pop culture helps boost his relatability in his videos. It is no wonder that TikTok has become a popular destination for access to science and scientific news.\nCitations\nBrown, G. & Moffit, M. [@asapscience] (n.d.) AsapSCIENCE [TikTok profile]. TikTok. Retrieved February 24, 2021\nGreen, H. [@hankgreen1] (n.d.) Hank Green [TikTok profile]. TikTok. Retrieved February 24, 2021, from https://www.tiktok.com/@hankgreen1?lang=en\nLevi, H. [@chaoticallyscience] (n.d.) Hailey [TikTok profile]. TikTok. Retrieved February 24, 2021, from https://www.tiktok.com/@chaoticallyscience?lang=en\nNguyen, D. [@lab_shenanigans] (n.d.) Darrion Nguyen [TikTok profile]. TikTok. Retrieved February 24, 2021, from https://www.tiktok.com/@lab_shenanigans?lang=en\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/into-the-newsroom-teaching-through-tiktoks/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: The Surgeon\u2019s Cut",
            "author": "Tejita Agarwal",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/The-Surgeons-Cut-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "It is not easy to sit with a pregnant woman while monitors all around you tell you her fetus\u2019s heart is slowing; her child is dying.\nThis is the situation fetal surgeon Kypros Nicolaides of King\u2019s College Hospital found himself in. His own heart racing, he pushed blood directly into the fetus\u2019s heart just in time, saving its life. Over the course of four episodes, Netflix\u2019s The Surgeon\u2019s Cut follows and humanizes Kypros and three other surgeons, each revolutionaries of their fields. Like life, the show starts with pregnancy and birth, where Kypros works his miracles.\u00a0\nWhen he performs surgeries, Kypros asks his patients to hold his arm so they feel they are on a team with him. He says his role as a surgeon is to serve as a guide, leading the parents through complex operations, some of which he developed himself.\nThe second episode follows Mayo Clinic neurosurgeon Alfredo Quinones-Hinojosa, fondly referred to as Dr. Q. While Kypros is enthralled by the beginning of life, Dr. Q says the brain holds our humanity. He compares surgery to a dance: the brain dances with the rhythm of the heart and his body dances as his feet and hands control careful surgical movements. In these moments, when he commits the sacred act of opening someone\u2019s skull, he feels intimately connected to his patient\u2019s soul.\u00a0\nDr. Q sees each surgery as an obstacle, and his past empowers him to face these obstacles with determination. Dr. Q left Mexico at nineteen and became a farm worker, a cleaner, then a welder, all while learning English at night school. Seven years after leaving the farm, he began medical school at Harvard University.\nWhile the brain holds our humanity, the liver is where our souls are\u2014at least according to Nancy Asher, a transplant surgeon at the University of California San Francisco. She is artful, impatient, and in constant pursuit of excellence. \u201cI think you have to have fearlessness tempered by fear of failure,\u201d Asher says while describing the job of a surgeon. Her impact extends beyond the operating room: she invests in mentorship for women in surgery, she is an activist to prevent organ trafficking, and she has published a large body of research.\nA surgeon\u2019s greatness depends on something beyond solely technical skill, and like Asher, Devi Shetty\u2019s impact is immeasurable. Devi Shetty is a heart surgeon in India. Describing his work as Mother Teresa once did, Shetty says that when God created babies who had holes in their hearts, He saw the mistake and sent Shetty to help them. Devi has worked hard to develop a relationship with rural India, and the hospital he created can now offer operations to thousands of patients who otherwise could not afford them.\u00a0\nThe Surgeon\u2019s Cut gives us a glimpse into the trials and excitements of surgery\u2014from birth to death, from fetus to brain to liver to heart. The show reveals who these surgeons are at their cores: creators, visionaries, and artists.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/science-in-the-spotlight-the-surgeons-cut/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Counterpoint: Are We There Yet?",
            "author": "Dilge Buksur",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Screenshot-2021-04-27-144748-500x280.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Since December 31, 2019, when COVID-19 was first reported to the World Health Organization, the world has been waiting to hear positive news about a COVID-19 vaccine. At last, we have more than three successful vaccines. But success as described by the news may not tell the full story. Surprisingly, Yale professors Jason L. Schwartz and David Paltiel, along with professors from Harvard University, found that the real success of these vaccines can only be determined by the efficiency of their implementation. Their research considered specific issues related to vaccine distribution using a mathematical simulation that accounted for various factors, like the speed of manufacturing and distribution and the extent of vaccine delivery.\nThe SEIR model they used is one of the simplest mathematical models of the possible progression of an infectious disease. It illustrates the infectious spread through different stages. Initially, researchers used a population size of one hundred thousand people, where they assumed 0.1 percent of the people would be exposed to the virus and another nine percent recovered. To better reflect the parameter of vaccine efficacy in this model, the researchers took into account differing vaccine types, such as a preventative vaccine, a disease-modifying vaccine, and a composite vaccine that bears the features of both. To account for pace, researchers assumed 0.5 percent of the population could be vaccinated in a single day, since this was the daily percentage reached during influenza vaccination efforts in the US.\u00a0\nResearchers also used alternative values to achieve a more nuanced modelling. For example, coverage is a parameter that is concerned mainly with the more social side of the vaccination process. It measures public acceptance of the vaccine as well as the availability of the vaccine. For this parameter, researchers\u2019 base-case value was fifty percent, which led to the conclusion that, under these assumptions for pace, it would take one hundred days to reach the fifty percent target coverage. Additionally, the model included epidemic severity scenarios (total number of infections, deaths, and intensive care unit use) and the natural history of the COVID-19 virus\u2014which relates to the biological structure of the virus and how it is predicted to spread over time.\u00a0\nData from the study can significantly pave the way for future public health measures. They exhibited that the efficacy of the vaccines displayed in clinical trials plays a less significant role when compared to implementation and the epidemiological environment into which it is introduced. Rt can be defined as the \u201ceffective reproductive number of the virus.\u201d The results suggested that if Rtis lower, a low-efficacy vaccine can have a greater impact on the decrease in infections than a high efficacy one. When this rate is higher, implying that the public health measures are not properly followed, even the most successful vaccines fall short in decreasing infections.\u00a0\nThe results also displayed another significant conclusion regarding the social reality of vaccination. \u201cLogistics of infrastructure\u2014such as getting the proper amounts of freezers and doses to the exact places they need to be\u2014has a vital role in accelerating the effectiveness of the vaccines,\u201d Schwartz said on Newsmakers, a podcast series by the journal Health Affairs. He highlighted that the governments should put ample time and effort into helping educate the public and inform them about the importance of these vaccines. Educational messaging should rely heavily on communicating why vaccination is beneficial, as well as finding strategies to gather states, local administrations, healthcare providers and scientists to spread information on vaccine safety. This way, we can get past the social reality dilemma.\u00a0\nThough we have a long way to go in achieving flawless vaccine production, distribution, and deployment processes, Schwartz stressed in his podcast interview that we have reached historic progress with promising vaccines in record time. He also expressed positivity on governmental efforts to invest in production and distribution of vaccines. Now, all we need to do is to put more energy towards public education and transportation of the vaccines. With attentive governmental endeavors and continuous efforts to follow public health measures, we will defeat this pandemic that has turned our lives upside down.\u00a0\u00a0\nWorks Cited\u00a0\nPaltiel, A. D., Schwartz, J. L., Zheng, A., & Walensky, R. P. (2021). Clinical Outcomes Of A\u00a0 \u00a0 COVID-19 Vaccine: Implementation Over Efficacy. Health Affairs, 40(1), 42\u201352. https://doi.org/10.1377/hlthaff.2020.02054\nSchwartz, J. L. (2020, November 24). \u201cAll hands on DECK\u201d \u2013 preparing for the distribution of \u00a0 \u00a0 \u00a0 COVID-19 Vaccines Health Affairs Podcast\u00a0 https://www.healthaffairs.org/do/10.1377/hp20201202.663555/full/.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/counterpoint-are-we-there-yet/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Undergraduate Profile: Anna Zhang (DC \u201923)",
            "author": "Lauren Chong",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Anna-Zhang-3-Photo-with-camera-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Anna Zhang (DC \u201923) is well known for her accomplishment as a Forbes 30 under 30 honoree on the Art & Style list, but her combination of artistry, innovation, and creativity extends to the personal as well as the professional in life. From creative photography to inspiring app ideas, Zhang has photographed for Keds and Fujifilm, started a publication to share the stories behind youth leaders, and designed a mobile gaming app that advocates kindness in games, rather than violence.\u00a0\nZhang credits her passion for photography for the start of her journey in all of her projects. First experimenting with landscape photos, she soon decided to try her hand at concert photography. After cold-emailing over forty artists\u2019 management and record labels, Zhang finally received a photo pass to photograph Magic Man. Soon after, she was approved to photograph other concerts, and grew her portfolio from there.\u00a0\n\u201cI started a music blog on which I shared my concert photography, and this blog ultimately transformed into my magazine, Pulse Spikes. I founded Pulse Spikes because there weren\u2019t many publications at the time that spotlighted young people\u2019s work, and as a photographer, I was particularly interested in people\u2019s stories,\u201d Zhang said. \u201cTo bring Pulse Spikes to life, I had to create a website, which is what prompted me to learn how to code.\u201d\u00a0\nPulse Spikes has featured artists and entertainers including notable names such as Lana Condor, the star of the Netflix movie To All the Boys I\u2019ve Loved Before, and Riverdale actress Lili Reinhart. With over twenty thousand readers per issue and fifteen million social media impressions, Pulse Spikes is a well-established publication made by youth for youth.\n\u201cIt\u2019s definitely a lot of work, but I just love hearing the stories of different people around the world. I also get to collaborate with other incredible young artists and writers who are passionate about Pulse Spikes and sharing these stories to the rest of the world,\u201d Zhang said.\u00a0\nDuring the COVID-19 pandemic, Zhang decided to rebrand Pulse Spikes and expand its mission. Rather than focusing on arts and entertainment as the publication has done in the past, she hopes to highlight the voices of young people around the world, whether it\u2019s an interdisciplinary artist sparking conversations around environmental justice or an author celebrating women of color.\n\u201cIt\u2019s easier in some way to do entertainment stories because there are managers, publicists who reach out to you with pitches and story ideas. But there are also incredible people who don\u2019t have publicists to reach out on their behalf or advocate for them. We want to try to uplift the voices that are not traditionally heard in the media, rather than those that are already heard,\u201d Zhang said.\u00a0\nZhang hopes to find an intersection between the arts and computer science. She\u2019s already well on this path, having ideated the award-wining game Brightlove. As the winner of the 2019 Google Play Change the Game Challenge, she served as the Creative Director of Brightlove when bringing the game to life. Brightlove aims to award players for positive actions, and all the objectives circle back to kindness and standing up against injustice.\u00a0\nWith over ten thousand downloads on the Google Play store and a spot in an exhibition at the National Museum of American History, Brightlove is a product of her spontaneity.\u00a0\n\u201cI just thought of it one day when I realized the number of games that reward violence. I don\u2019t think innovation necessarily has to come from a \u2018I\u2019ve never seen this before\u2019 sort of an idea\u2014I think it can come from elements that have existed separately in the past and combining them in a different way,\u201d Zhang said.\u00a0\nZhang hopes to continue her creative weaving of multiple fields in one by majoring in Computing and the Arts at Yale. While she is still exploring her potential career interests, she ultimately hopes to put innovative ideas into the world that bring people together.\u00a0\n\u201cI\u2019m just in the same boat as everyone else. I don\u2019t really know what I want to do career-wise, but my general interests are in the intersection between technology and art. I\u2019m not too sure what the future holds, but I am excited about all of the possibilities.\u201d\nWorks cited:\u00a0\nAnna Zhang. (n.d.). Retrieved February 16, 2021, from https://www.forbes.com/profile/anna-zhang/?sh=76b9a1e210c4\nInterview with Anna Zhang [Online interview]. (2021, February 6).\nZhang, A. (n.d.). Pulse spikes. Retrieved February 16, 2021, from https://pulsespikes.org/\\\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/undergraduate-profile-anna-zhang-dc-23/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Just How Badly Has COVID-19 Affected College Students?",
            "author": "Sherry Wang",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-3-500x319.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Nithyashri Baskaran\nJust about every college student can relate to memes and TikToks ranting about online school, what with the huge workload, lack of social interaction, and accompanying Zoom fatigue. But amidst increased pressures and challenges to academic success, few students have had time to pinpoint just how badly the pandemic has affected them mentally. Now, a study published in PLOS provides some answers.\nDuring the first lockdown, an online questionnaire was administered to students at seven different universities nationwide to capture the pandemic\u2019s toll. Results showed that among college students, certain risk factors were associated with increased psychological impact: being a woman, being eighteen-to-twenty-four years old, possessing below-average general health, experiencing prolonged screen time, and knowing someone infected with COVID-19. In contrast, the data suggested that those who were of White or Asian ethnicity, had higher income, or spent large amounts of time outside were less susceptible. This allows college students to better understand how vulnerable they are to the pandemic\u2019s impact in relation to their peers, and to what extent they need to prioritize their mental stability over academic life.\nThe study ultimately proposes ways for universities to reach out to the large percentage of the student body with increased mental health concerns by maintaining healthy mindsets, supporting safe social interactions, and providing more personalized approaches to learning. By supporting the mental health and educational success of students\u2014especially those who are more vulnerable\u2014universities can circumvent possible long-term consequences of college students sacrificing their health and education during these troubling times.\u00a0\nCitation:\nBrowning, M. H. E. M., Larson, L. R., Sharaievska, I., Rigolon, A., McAnirlin, O., Mullenbach, L., Cloutier, S., Vu, T. M., Thomsen, J., Reigner, N., Metcalf, E. C., D\u2019Antonio, A., Helbich, M., Bratman, G. N., & Alvarez, H. O. (2021). Psychological impacts from COVID-19 among university students: Risk factors across seven states in the United States. PLOS ONE, 16(1). https://doi.org/10.1371/journal.pone.0245327\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/just-how-badly-has-covid-19-affected-college-students/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Can We Reverse Aging?",
            "author": "Christopher Ye",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure1_Ye-500x251.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "When humans find the Fountain of Youth, it may ultimately come in the form of a protein shake. Researchers studying the effect of OSK, a protein cocktail of \u201cYamanaka factors\u201d that converts mature cells back into embryonic stem cells, recently demonstrated that neurons can be reprogrammed to a more youthful state. This allows for improved survival and even regeneration of neurons.\nThe researchers injected viruses to deliver OSK into mice retinal ganglion cells (RGCs), neurons with projections from the retina that form the optic nerve. After crushing these axonal projections, they observed that axons regenerated, RGCs survived, and sight was restored with no adverse effects like tumor development. Notably, although regeneration treatment often fails in older individuals, OSK was beneficial in both younger and older mice. In addition, though no current treatment can induce regeneration after neurons sustain damage, the researchers demonstrated that OSK induction even after crush injury resulted in significant regeneration. The researchers recovered vision in mice with glaucoma, a leading cause of human blindness, as well as in mice with vision loss caused by aging. OSK expression also enhanced regrowth in human neurons in the lab.\u00a0\nFinally, the researchers investigated epigenetic noise, such as the change in methyl groups on DNA known as methylation. Accelerated methylation mimics aging, but OSK expression counteracted this acceleration. As additional evidence, reduction of TET enzymes that reverse methylation blocked OSK\u2019s beneficial effects. Further research into how cells store epigenetic information will take humans closer to the reversal of aging.\nCitations\nHuberman, A. D. (2020). Sight restored by turning back the epigenetic clock. Nature, 588(7836), 34-36. doi:10.1038/d41586-020-03119-1\nLu, Y., Brommer, B., Tian, X. et al. Reprogramming to recover youthful epigenetic information and restore vision. Nature 588, 124\u2013129 (2020). https://doi-org.yale.idm.oclc.org/10.1038/s41586-020-2975-4\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/qa-can-we-reverse-aging/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Owen Garrick (MD \u201998): Precision Medicine and Health Disparities",
            "author": "Xiaoying Zheng",
            "authorLogo": "",
            "date": "April 27, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Xu_2.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Growing up in a majority Black and minority neighborhood, Owen Garrick (MD \u201998, MBA) had always been aware of the health disparities that disproportionately affects minority communities. When he began college, Garrick began to deepen his interest in medicine, in hopes that he would play a role in addressing these disparities. As Garrick continued exploring the intersections between medicine, public health, and business, he began exploring different avenues to make healthcare more equitable, merging his diverse interests to make a difference for his family and community in their access to quality healthcare.\u00a0\nFascinated by people and social sciences, Garrick majored in psychology at Princeton. Although he describes his undergraduate experience as typically pre-med, it is clear that he diverged from the traditional route. During these years, he began to develop a broad interest in the business side of healthcare, gravitating toward summer analyst positions outside traditional research and clinical experiences. After college, Garrick opted to take two gap years to work as a financial analyst in New York City and then at his cousin\u2019s construction company while living in the Caribbean.\u00a0\nIt wasn\u2019t until medical school when Garrick\u2019s interest in business became more central to his medical career. Between his first and second year at the Yale School of Medicine, Garrick found an intersection between medicine and business as an intern at Merck in the Vaccine Division, where he helped write the first commercial analysis for the human papilloma virus (HPV) vaccine. As Garrick met doctors who were working on marketing strategies for pharmaceutical companies, he started seeing a clearer path for himself. \u201cHelp launch a drug that cures two million people, right? That\u2019s the inflection point I had in terms of my career, away from clinical practice more toward the business side of healthcare,\u201d Garrick said. \u201cIt made me realize that I can do something a little different and still make an impact on healthcare.\u201d\u00a0\nAt the time, medicine and business functioned relatively independently of one another. Although Garrick met physicians at Merck who worked on marketing and business, he said very few had both an MD and an MBA. Garrick would attend events at the Yale School of Management before the combined MD/MBA program existed. But this did not stop Garrick from pursuing his passion for utilizing business to impact healthcare. When asked about the difficulties that pursuing this path entailed, Garrick responded simply, \u201cI just decided, I\u2019m going to make this work.\u201d\nToday, Garrick has struck a balance between his interests in medicine, business, and public health while staying true to his original goals. He dedicates his time to bridging health disparities among underserved ethnic and racial groups through his work with Stanford Precision Health for Ethnic and Racial Equity Center (SPHERE) and as CEO of Bridge Clinical Research, a contract research organization that specializes in research and development in a variety of therapeutic areas.\u00a0\nRecently, Garrick has launched a collaboration between Bridge Clinical Research and SPHERE, which is one of five National Institutes of Health centers focused on using precision-medicine to address health concerns specific to underserved racial and ethnic groups. Recognizing that health disparities that affect certain racial and ethnic groups result from environmental as well as genetic differences, the study focuses on the enrollment of sickle cell disease patients in precision health research, as well as the effects of the race of the physician on a patient\u2019s view on the research.\u00a0\nSickle cell disease (SCD) is a hereditary blood disorder that primarily affects populations in Mediterranean, the Middle East, the Caribbean, and South and Central America. When groups uniquely being affected by a disorder such as SCD are not participating in precision health research, it negatively impacts the potential of new treatment options and innovations. The study hopes to address the issue of historical underrepresentation of demographic groups in clinical and biomedical research. Through merging his interest in business and passion for bridging healthcare disparities, Garrick has become a leader in cutting-edge research that brings to light systematic barriers in biomedical research today.\u00a0\nGarrick believes in the importance of taking initiative to explore new avenues in hopes of addressing the problems he is passionate about. \u201cIf you see something wrong in the world, or missing in the world, the opportunity to create the solution is really, really fascinating, right?\u201d Garrick said. \u201cIt\u2019s fun, it\u2019s fulfilling. And you might fail at it a few times, but you have to get comfortable with to failing, and learn how to fail fast. The successes will come.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/owen-garrick-md-98-precision-medicine-and-health-disparities/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Understanding the Potential of Neural Stem Cells: An analysis of cell migration for neural tissue regeneration",
            "author": "Krishna Dasari",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nEvery year, nearly eight hundred thousand Americans experience a stroke, each with a possibility of brain damage or death. Following such brain injuries, the body attempts to repair the damaged tissue, beginning with neural stem cells (NSCs). Once signaled, NSCs proliferate and migrate as a cluster to the olfactory bulb in the brain to differentiate and repair damaged tissue. However, the mechanisms triggering NSC clustering were hidden in relative obscurity.\nThat was until a team of Yale researchers led by recent graduate Rita Matta and professor Anjelica Gonzalez in the Department of Biomedical Engineering decided to investigate how endothelial cells (ECs), which constantly exchange signals with NSCs because they line the blood vessels along which they move, may contribute to NSC clustering and migration.\u00a0\nBy studying cell cultures, the team established that ECs promote NSC clustering and migration. However, clustering itself must be actuated by something else. The culprits behind that were leader cells, special NSCs that sense the microenvironment and guide the cluster to areas of neural injury by extending cell arms. Their presence opened a new avenue for exploration.\nIn collaboration with professor Michael Murrell and post-doctoral associate Sulaiman Yousafzai Muhammad, migration and clustering were observed using multiple sophisticated engineered systems, including microfluidic chambers, traction force microscopy, and laser ablation. Ablation of the leader arm resulted in no migration of NSC clusters, even in the presence of ECs.\u00a0\n\u201cWhat if there is a mutation that leads to significantly less leader arm formation? We know these clusters are crucial for neural stem cell migration. By looking at the different phenotypes, we could have an incredible therapeutic investigation,\u201d Matta said.\u00a0\nThe team next sought to observe if the effects of vascular cells held true in a substrate similar to brain tissue. However, the common substrate for studying cell migration was unsatisfactorily stiff relative to brain tissue, so Gonzalez\u2019s team was compelled to create a more accurate substrate, a porous biomimetic hydrogel. With the addition of zinc oxide salts to template pores and two abundant brain proteins\u2014fibronectin and laminin\u2014for adherence, the team was able to design a remarkably more brain-like substrate, which allowed for confirmation of their previous results in a pseudo-brain-tissue context.\u00a0\n\u201cOur different materials and different systems that we created specifically for brain migration are novel and can be used for diseases other than stroke and organs other than the brain,\u201d Matta said. \u201cSo we really opened up a door for cell migration.\u201d\nHaving confirmed the pro-clustering behavior of ECs in a brain-like substrate, the team sought to offer a molecular explanation as to why ECs promote NSC clustering. They discovered that ECs secrete an enzyme, matrix metalloproteinase-2, that triggers a protein signaling cascade ultimately leading to cleavage of the cell-cell adhesion protein N-cadherin, a prerequisite for clustering.\u00a0\nThe researchers hope that the mechanistic understanding of NSC clustering and migration will help further research on neural tissue regeneration, not just for stroke injuries, but also for other neurological disorders, whose repair mechanisms often feature NSC migration.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/understanding-the-potential-of-neural-stem-cells-an-analysis-of-cell-migration-for-neural-tissue-regeneration/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Wait, What Was I Doing Again?: Newfound insight into transient forgetting",
            "author": "Matthew Fan",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/29009784253_a68a0c459f.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nEvery student has been there\u2014you\u2019ve prepared for a big exam, but when you read over a question, you blank on the correct answer. It isn\u2019t until after you turn in your test that the answer suddenly comes to mind. This is a prototypical example of a transient memory lapse, and neuroscientists at Scripps Research are currently trying to unravel this phenomenon by studying Drosophila melanogaster, or fruit flies.\nLed by graduate student John Martin Sabandal, the team from Scripps Research was curious about whether dopamine neurons play a role in modulating the expression of long-term memory. They proceeded to test the effect of stimulating the dopamine neurons in fruit flies and found that memory retrieval was impinged. Sabandal and his colleagues identified a single pair of dopamine neurons, PPL1-?2?\u20192 in flies, and observed that even though stimulation caused memory suppression, the memory spontaneously recovered within the next hour. Thus, they called this type of forgetting transient forgetting.\nPrevious research in experimental psychology focused on a tip-of-the-tongue state, in which interfering stimuli or distractors cause a recall failure. In an effort to elucidate the mechanism for transient forgetting, Sabandal and his colleagues modeled this experience in fruit flies. They used classical olfactory conditioning to create an association between a particular odor and an electric shock, which served as a negative reinforcer, and another association between a different odor and the absence of shock. When flies were presented with the two odors, they went to the one that was not paired with a shock. When a distractor, such as blue light or airflow, was applied, the fruit flies forgot these associations. However, the memory was restored within the next hour.\n\u201cIn nature, when fruit flies are looking for food, they go to a food source, and they rely on prior experiences\u2014or memory\u2014for this behavior,\u201d Sabandal said. \u201cPerhaps they may encounter a predator suddenly or experience gusts of wind, for example, that could distract them and cause transient forgetting. This could, in turn, cause the flies to briefly forget the memory of the food source, and come back at a later time when the memory becomes accessible again.\u201d\nThrough these experiments, Sabandal and his colleagues determined a pathway through which transient forgetting occurs. In Drosophila, memories are primarily stored in clusters of mushroom body neurons. Within these neurons there exists a dopamine receptor known as DAMB, which is downstream of the PPL1-?2?\u20192 neuron. When DAMB is functioning normally, it mediates transient forgetting, but when it is mutated, memory is enhanced. These findings demonstrated that DAMB transduces the transient forgetting signal.The implications of this research are far-reaching. Although this particular study looked at olfactory memories in Drosophila, the findings could potentially translate to other types, including visual, auditory, and episodic memories. This research has possible implications in humans, too, with potential contributions to studies about memory enhancement. Ronald Davis, the senior author of the paper, suggests that if a pharmacological inhibitor of this particular forgetting gene can be found, then perhaps memory can be improved. \u201cUnderstanding the molecular and cellular biology of forgetting is brand new, and there\u2019s an enormous amount to learn in the fly,\u201d Davis said.\nCitations:\u00a0Sabandal, J. M., Berry, J. A., & Davis, R. L. (2021). Dopamine-based mechanism for transient forgetting. Nature. doi:10.1038/s41586-020-03154-y\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/wait-what-was-i-doing-again-newfound-insight-into-transient-forgetting/",
            "captions": [
                "Brains of sleep-deprived and well-rested fruit flies"
            ]
        },
        {
            "title": "Post-Operative Painkiller Patches: A Promising Alternative to Opioid Prescription",
            "author": "Sydney Hirsch",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-1-1-500x333.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "After surgery, effective pain management is one of the most critical aspects of patient recovery. Treatment requirements can vary from person to person, leading to high variability in management strategies. As a result, physicians may prescribe analgesic (pain-relieving) drugs in excess, allowing patients to take them \u201cas needed.\u201d While this method is effective, it also increases the rate of unauthorized distribution, furthering risk of opioid addiction. In addition, drugs administered systemically\u2014orally or intravenously, as opposed to locally\u2014pose a higher risk for adverse effects, such as fatigue and cardiovascular dysfunction.\nTo combat these issues, a team of scientists at Duke University led by professor Matthew Becker, alongside graduate student Natasha Brigham, created a potential solution: bio-resorbable poly(ester urea) films (PEUs). These synthetic polymer films contain etoricoxib, an inhibitor for COX-2, an enzyme involved in inflammation. They are designed to deliver pain-management at the site of operation. After the drug has been released, the biomaterial breaks down into components safely tolerated by the body.\nBecker and his team are not the first to create a film for surgical-site pain relief. Synthetic polymers are physically and chemically tunable, and resorbable ones are particularly appealing as they are considered temporary devices. In fact, poly(lactic-co-glycolic acid) films (PLGAs) have previously been used for analgesic delivery. However, this material presents some problems that result in non-linear release of the active pharmaceutical ingredient (API). For one, the PLGAs can be semi-crystalline, a structure that excludes the API. Additionally, the biomaterial degrades through various mechanisms that result in acidic byproducts, causing tissue inflammation and damage to the API.\nIn contrast, the etoricoxib PEU films created by Becker\u2019s team circumvent all of these problems. The structure is amorphous (non-crystalline) due to powerful hydrogen bonding and flexible diol connections. \u201cIn the PEUs\u2026 the drug interacts strongly with the polymer, and allows for more uniform distribution of the drug,\u201d Becker said. As the release profile of the API is nearly constant, the elution is likely only dictated by one mechanism and does not involve polymer degradation.\nBesides the benefits of their general structure, these films can be customized from the polymer itself to different thicknesses and drug saturations. The scientists first tested two drug-loads, twenty percent and forty percent, in two types of amino acid-based polymers. They found that the higher-loaded film releases more API per time point; thus, films with greater drug loads could be used as longer-acting implants. Additionally, they discovered that different polymer compositions, while maintaining a continuous release profile, exhibit various release percentages due to how etoricoxib interacts with the polymer. Finally, film thickness affects diffusion, in that thicker films release the API at the same rate but for a longer duration.\nThe theoretical efficacy of these films was proven in rat models, in which a PEU wrapped around the sciatic nerve restored normal pain threshold for up to five days. All of these factors promise a more predictable and controllable drug diffusion, which would provide patients with prolonged pain relief. \u201cThis is another tool in the toolbox for physicians to offer their patients,\u201d \u00a0\u00a0\u00a0\u00a0\u00a0Becker said. \u201cIt wouldn\u2019t feel different [than an oral drug], you can control it locally\u2026 and it doesn\u2019t face the challenges of illegal distribution since it\u2019s sewn in.\u201d With time and refinement, local drug delivery systems have the potential to transform the standard of care for post-operative pain management.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/post-operative-painkiller-patches-a-promising-alternative-to-opioid-prescription/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How Effective is Yale\u2019s Twice-Weekly Testing Schedule?",
            "author": "Hannah Huang",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/YasmineHalmane_covidtesting2-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Yasmine Halmane.\nDefying the pessimists who doubted the ability of Yale students to follow COVID-19 safety protocols, the Yale student body conducted itself in a safer manner than expected last semester. To put a number on it, the R0 value, or the number of secondary cases generated by an initial case, of the student body last semester was 1.85\u2014compared to the 2.3 that experts set as the maximum value that could still keep student infections under control. Yale researchers Joseph Chang, Forrest Crawford, and Edward Kaplan calculated this number and devised the twice-weekly testing plan implemented among Yale College\u2019s on-campus student body last semester.\u00a0\nAfter building a model that took into account multiple factors, such as test sensitivity, imported infections from outside of campus, and the time delay from a positive test to relocation, the team recommended a twice-weekly testing schedule to the administration. \u201cThere was a lot of hard swallowing,\u201d Kaplan said. \u201cThe original idea, before people had done much analysis, was that we might just be able to test a couple people every week to kind of keep some background information. But very quickly we realized that the purpose of a repeat testing program in the university setting isn\u2019t to do surveillance. It\u2019s to prevent the spread of infection.\u201d\u00a0\nIntensive repeat screening is the first step in reducing COVID-19 transmissions; the team\u2019s calculations showed that once-weekly testing likely wouldn\u2019t be enough to keep infections low. The second step is mandated isolation. \u201cPeople always think of testing as the prevention program, but testing tells you who needs to be isolated. That\u2019s what really prevents the spread of infection,\u201d Kaplan said. He pointed out the University of Illinois as an example\u2014a school that provided regular testing but didn\u2019t initially enforce isolation for those who tested positive. \u201cPeople who had knowingly tested positive were skipping out and going to parties,\u201d Kaplan said. The result was a large spike of cases at the beginning of the year, after which the university reinforced isolation.\u00a0\nThanks to the existence of strong testing and quarantine programs from the beginning of the school year, Yale never experienced a spike to the severity of the University of Illinois\u2019s. A total of 191 students living in New Haven (including undergraduates and graduates, living both on- and off-campus) tested positive last semester, far under the goal that the administration set at the outset of the fall semester: less than three hundred students\u2014five percent of the approximately six thousand students regularly tested\u2014testing positive.\nAs the spring semester gets underway, a new development is the sizable number of first years living off-campus in New Haven. Chang and Kaplan call them \u201cghost students\u201d\u2014students who don\u2019t officially have access to campus but will likely still mingle with both on- and off-campus students. Testing services are still available to them, but it is probable that not all students will continue to get tested twice a week. \u201cYoung people themselves won\u2019t have serious medical consequences, but they will continue to transmit the virus if they\u2019re not careful,\u201d Kaplan said. \u201cIt\u2019s one of these collective action problems where everyone acting together will collectively keep us safe, but if we have enough people who are shirking on that responsibility, that\u2019s just going to keep the engine [of COVID transmission] running.\u201d\nCitations:\nChang, J.T., Crawford, F.W. & Kaplan, E.H. Repeat SARS-CoV-2 testing models for residential college populations. Health Care Manag Sci (2020). https://doi.org/10.1007/s10729-020-09526-0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/how-effective-is-yales-twice-weekly-testing-schedule/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The New Social Robot: Deep Learning with DANTE for automatic group detection",
            "author": "Cindy Kuang",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/49997851407_9d4568d415_b-385x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nImagine you\u2019re at First Year Formal. You\u2019re talking in a circle, and your belly is full of the mini hot dogs. When the room gets crowded, your friends instinctively shuffle closer together to form a smaller circle, without even a hitch in the conversation.\u00a0\nNot that exciting, right? But upon deeper thought, that non-verbal group movement and maintenance of a shared focus of attention during a conversation are crucial aspects of human social awareness\u2014aspects that robots have yet to master. In robotics, this field of research is called conversational group detection, and it is precisely what the Vazquez lab at Yale University and the Savarese lab at Stanford University are working on.\n\u201cThere\u2019s all these tiny social cues that we as humans are conditioned to understand, but robots don\u2019t come with these baked in\u2014 \u00a0 \u00a0 you have to teach them,\u201d said Sydney Thompson, a Yale Ph.D. student. \u201cThe way that I see it, group detection is one of the fundamental social skills and without it, you can\u2019t really have a conversation; you can\u2019t really be a social agent.\u201d\nThe conversational group detection method proposed by Thompson, Marynel Vazquez\u2014an assistant professor of computer science at Yale\u2014and other researchers at the Vazquez and Savarese labs is a novel neural network called Deep Affinity Network for clustering conversational interactants, or DANTE.\nDANTE receives visual images of social scenes as inputs: each person is labeled with a unique identifier and a feature vector, a mathematical representation of the characteristics of an individual, with spatial information such as their 2D position and orientation in the room. The scene is then represented as a graph with the people as nodes connected by edges. DANTE\u2019s main job is to predict the affinity scores for each edge, or how likely it is for the two agents connected by that edge to be engaged in the same conversation.\nWhile previous approaches have required brittle heuristics and subsequent ad-hoc steps to verify the detected groups and account for context, DANTE is primarily data-driven and evades these issues, making it more easily generalizable to future applications. DANTE\u2019s groundbreaking accuracy largely stems from how it reasons around two types of information: not only the spatial information of the dyad (two individuals) of interest connected by an edge, but also global spatial information of the other people in the room. The final affinity score is computed by concatenating\u2014combining\u2014the dyad information with context information.\u00a0\nHowever, there is still a lot more work to be done. \u201cWhen you start working on a research project, the more you know, the more you know what you don\u2019t know,\u201d Vazquez said. Researchers at the Vazquez lab are curious about introducing temporal dependency between the visual input into DANTE, addressing how physical elements and occlusions may disrupt DANTE\u2019s function, and even using this approach to study how people\u2019s spatial interactions may change post-COVID. Vazquez is hopeful that someday, granting robots this social intelligence will allow them to integrate into our world seamlessly, as effective collaborators and social agents in our increasingly complex, dynamic environment.\nCitation:\u00a0Swofford, Mason, et al. \u201cImproving Social Awareness Through DANTE: Deep Affinity Network for Clustering Conversational Interactants.\u201d Proceedings of the ACM on Human-Computer Interaction, vol. 4, no. CSCW1, May 2020, pp. 1\u201323., doi:10.1145/3392824.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/the-new-social-robot-deep-learning-with-dante-for-automatic-group-detection/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Why Aren\u2019t There North American Lions?",
            "author": "Lucas Loman",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-3-1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nAfrica and Asia are home to some of the largest land animals alive. Grasslands and rainforests conjure up images of massive elephants, hippos, and giraffes. Yet while these large animals, called megafauna, are widespread in Africa and Asia, they no longer roam Europe, Australia, and the Americas. Researcher Advait Jukar from the Yale Institute for Biospheric Studies offers a new, key explanation for this disparity.\nJukar\u2019s research, based on his investigation of fossil sites in India, aimed to verify the coevolution hypothesis. This hypothesis, first proposed by Paul Martin in the 1960s, argued that large animals persisted in Africa and Asia due to the species\u2019 ability to evolve and cope with the pressures of humans moving into their habitats. Martin explained that this coevolution was not present in other parts of the world, where humans drove other megafauna to extinction through hunting and habitat alteration.\nJukar\u2019s team studied fifty-one fossil sites in India to determine the magnitude of megafauna extinction. They found areas with low magnitudes of extinction when humans were present, corroborating the importance of coevolution for species survival. \u201cIf you have different species of humans, including our own, that have interacted with these species of large animals and their ancestors, then these lineages potentially evolved strategies to cope with humans,\u201d Jukar says.\nWhile the study provides compelling evidence for the coevolution hypothesis, the exact reason megafauna withstood human contact in Africa and Asia when they failed to survive in other parts of the world is still unclear. Jukar\u2019s team plans to collect more information in the form of bone surveys and chemical analysis. Although many of these large animals successfully evolved to survive our arrival in their ecosystems, we must still strengthen conservation efforts to safeguard their continued presence in the wild.\nCitations:\u00a0\nJukar, A., Lyons, S., Wagner, P., & Uhen, M. (2021). Late Quaternary extinctions in the Indian subcontinent. Palaeogeography, Palaeoclimatology, Palaeoecology, 562, 110137. doi:10.1016/j.palaeo.2020.110137\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/why-arent-there-north-american-lions/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Higher Levels of Air Pollution Linked to Increased Demand for Mental Health Services",
            "author": "Victoria Ouyang",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-2-1-500x346.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nHigher levels of air pollution are linked to an increased use of mental health services, according to a new study conducted by the Yale School of Public Health.\nThe findings are based on six years\u2019 worth of data collected from two major hospitals within Nanjing, China, where air pollution is high. The researchers monitored daily levels of air pollution and recorded the daily number of mental health outpatient visits. They found that there tended to be more mental health visits at the hospitals on days with higher air pollution.\nThe results showcase a potential need for more mental health services than are currently available. \u201cAs pollution is projected to increase, we would need a better and strong[er] mental health infrastructure to meet growing demands,\u201d said Sarah Lowe, first author of the study and assistant professor of social and behavioral sciences.\u00a0\nAlthough this study shows a link between air quality and demand for mental health services, more research is needed to show why air pollution might lead to a higher demand for mental health services. For example, people may simply be more likely to stay in town and show up to appointments when air pollution is particularly bad. Alternatively, individuals could have worsened physical symptoms from asthma or a lung condition, leading them to seek out mental health services in order to cope.\u00a0\nLowe\u2014who collaborated with Kai Chen in the Department of Environmental Health Sciences\u2014hopes that further research will look at how air pollution affects people at a personal level rather than at a city level. \u201cThe ideal next step would be to get more fine-grain data on an individual\u2019s exposure to air pollution, along with their mental health over time and what else is going on in their lives, whether it be biological or social processes,\u201d Lowe said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/higher-levels-of-air-pollution-linked-to-increased-demand-for-mental-health-services/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The New Energy Farm: Physicists find a new way of extracting energy from black holes",
            "author": "Nicole Rodriguez",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-7-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nWith their mind-bending metaphysical properties, black holes appear to be objects taken straight out of a science fiction film. But underneath their seemingly fictional characteristics may be the future of energy. Since Einstein proposed his general theory of relativity, which predicted that black holes possess vast amounts of energy, many physicists have sought ways of extracting it. Such methods include those of Roger Penrose and Stephen Hawking, who proposed that energy could be drawn through particle disintegration and quantum mechanical emission, respectively.\u00a0\nRecently, physicists Luca Comisso from Columbia University and Felipe Asenjo from Universidad Adolfo Ibanez in Chile, have theorized a new way to extract energy from black holes through a magnetic reconnection process occurring in the plasma surrounding black holes.\nPlasma is a highly ionized state of matter containing electromagnetic fields that exist around black holes\u2019 high levels of electrical current. Asenjo explained that under these conditions, interactions between plasma can cause magnetic field lines to break and reconnect. \u201cField lines are attached with the plasma, like the beads in a necklace,\u201d Comisso said. Generally, these magnetic field lines cannot directly interact with each other, but there are small regions with a very strong electric current density where this can occur. In these regions, rather than moving with the plasma, field lines tend to break and reconnect. This accelerates plasma in two directions: towards the black hole and away from it.\u00a0\nThis process of magnetic reconnection mainly occurs in the ergosphere, the area near the event horizon of a black hole. There, spacetime is accelerated by the gravitational pull of the black hole, dragging plasma with it. \u201cThe plasma surrounding a black hole needs to travel at almost relativistic speeds in order to maintain its proper orbit,\u201d Comisso said. He explained that inside the ergosphere, there is no way to move in the opposite direction of the rotation of a black hole. But when plasma is accelerated in two directions by the breaking and reconnecting of field lines, one is pushed in the opposite direction against the spin of the black hole. Instead of rotating against the spin, plasma gains negative energy and falls into the event horizon. The plasma accelerated in the direction of the spin gains positive energy and escapes the ergosphere.\u00a0\nComisso and Asenjo theorized that these high energy escaping particles could be captured and used as a source of energy. But, the technology needed to make this a reality is in the distant future. \u201cIn order to extract energy from a black hole, you would have to build something around the black hole\u2014far enough so that its gravity does not draw you into it,\u201d Asenjo said.\u00a0\nAccording to Comisso, the laws of physics allow for the extraction of energy from black holes, but technology must advance much farther in order for this to become a reality. \u201cThe time scale of a million years is what seems most realistic at the time,\u201d Comisso said.\u00a0\nIn the meantime, until these theories can become reality, the wonders of black holes will be explored through science fiction.\nSources:\nColumbia University. (2021, January 13). Could we harness energy from black holes? A new study indicates energy can be extracted from black holes through reconnection of magnetic field lines. ScienceDaily. Retrieved March 20, 2021 from www.sciencedaily.com/releases/2021/01/210113100829.htm\u00a0\nComisso, L. & Asenjo, F. A. (2020). Magnetic reconnection as a mechanism for energy extraction from rotating black holes. Physical Review D, 103(2), 023014.10.1103/PhysRevD.103.023014\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/the-new-energy-farm-physicists-find-a-new-way-of-extracting-energy-from-black-holes/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Why Am I Irritable?",
            "author": "Van Anh Tran",
            "authorLogo": "",
            "date": "April 25, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/wiresimage__whyamIirritable-1-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nIrritability is defined as having a higher tendency to experience anger in response to frustration. In the field of child psychiatry, the symptom of irritability appears in multiple disorders, including autism, ADHD, anxiety disorders, depressive disorders, and conduct disorders. Targeting the neural mechanisms of irritability, something relatively unclear and unexplored, raises the opportunity to better understand the pathophysiology of these various youth disorders.\nA study conducted by the Yale School of Medicine in conjunction with the National Institutes of Health (NIH) sought to analyze the functional connectivity between brain networks when a person was irritated. Functional connectivity measures the statistical relationship and dependence between two spatially independent regions of the brain. The study used functional MRI scans of sixty-nine youths who had to complete frustrating and non-frustrating cognitive flexibility tasks. With the aid of a machine learning tool called connectome-based predictive modeling, the study used spatiotemporal patterns from the brain activity data in order to predict differences in irritability behavior.\u00a0\nThe study identified 266 edges that measured the functional connectivity between nodes and predicted irritability in the study subjects. Many of the edges were found in the left cerebellum, left parietal region, motor-sensory cortex, and right thalamus. \u201cOne of the most important [edges] is the motor network to the frontal parietal network,\u201d said Dustin Scheinost, a professor at the Yale School of Medicine and a member of the team conducting the study.\u00a0\nThese results indicate that youths may experience a larger activation of the motor and frontal parietal network during irritability. This study expands our prior knowledge on how functional connectivity, which is affected by both genetics and the environment, can help predict the differences in irritability in youth.\nCitations\nScheinost, D., Dadashkarimi, J., Finn, E.S.\u00a0et al.\u00a0Functional connectivity during frustration: a preliminary study of predictive modeling of irritability in youth.\u00a0Neuropsychopharmacol.\u00a0(2021). https://doi.org/10.1038/s41386cn-020-00954-8\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/why-am-i-irritable/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Harmony and Discord: The Brain Activation in Social Interactions",
            "author": "Georgia Woscoboinik",
            "authorLogo": "",
            "date": "April 24, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/ysm-1.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Oxford University Press Blog.\nA team of Yale researchers led by Joy Hirsch has utilized a revolutionary technology known as functional near-infrared spectroscopy (fNIRS) to illuminate differences in brain activation patterns between pairs of people discussing a topic on which they agree and pairs of people discussing a topic on which they differ.\u00a0\nfNIRS is a portable method by which neuroscientists can noninvasively monitor changing hemoglobin levels\u2014and thus activation\u2014across the brains of multiple participants while they engage in a wide array of activities. This is an important development in the field of social neuroscience because it allows researchers to directly study what they have thus far only been able to simulatez: social interaction.\nHirsch and her team found major brain activation differences between disagreeing and agreeing partners. Firstly, the location of the activity differed. When partners were in agreement, activity occurred in regions involved primarily in social perception, while when they were in disagreement, activity occurred in regions responsible for higher order executive functions. Recruitment of such distinct structures suggests that agreeing and disagreeing are not merely opposites of one another, but are in fact entirely separate processes. Secondly, when the team looked at the relationship between activation patterns within pairs, they found that agreeing partners\u2019 brains exhibited synchronous activation while disagreeing partner\u2019s brains did not. Hirsch and colleagues are now setting out to explore the meaning of this synchrony\u2014where it comes from, how it can be modified, and what it means about social connectedness.\n\u201cSocial interactions are the most important functions that we as humans have,\u201d Hirsch said. \u201cBecause of the lack of technology to investigate those functions in dyadic, real-life modes, we know very little about them.\u201d Through her lab\u2019s revolutionary work with fNIRS, Hirsch is on her way towards filling that knowledge gap in the field of social neuroscience.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/harmony-and-discord-the-brain-activation-in-social-interactions/",
            "captions": [
                "Image representing neural harmony in agreement."
            ]
        },
        {
            "title": "The Sugar Code: Instructions for the Earliest Stages of Cardiovascular Development",
            "author": "Elizabeth Wu",
            "authorLogo": "",
            "date": "April 24, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Screen-Shot-2021-04-24-at-2.58.41-PM-500x424.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "The molecular instructions involved in building an embryo are complex and beautiful, but not fully understood. Through studying zebrafish embryogenesis in the Nicoli Lab at Yale, postdoctoral fellow Dionna Kasper recently discovered a new pathway that regulates the early development of the cardiovascular system in embryos. This provides exciting possibilities for improving therapies, such as bone marrow transplants for blood disorders.\nIn vertebrate embryos, the cardiovascular system first begins to form when some endothelial cells, which are the internal lining of blood vessels, turn into precursor cells responsible for blood production. Those special endothelial cells are known as hemogenic endothelial cells (hemECs), and the precursor cells are called hematopoietic stem and progenitor cells (HSPCs). The process by which the hemECs turn into HSPCs is known as the endothelial-to-hematopoietic transition (EHT). After the EHT, the HSPCs delaminate from the lining of the blood vessels and enter circulation to give rise to all the blood cell types in the body.\u00a0\nThe factors that regulate the EHT process are not completely understood. However, Kasper uncovered the previously unknown role of miR-223, a molecule that belongs to a family of small, noncoding RNAs that silence gene expression. Kasper explained that this study was focused on embryonic development because that is the only window of time when HSPCs are produced from scratch.\u00a0 When she deleted the gene coding for miR-223 in mutant zebrafish and mice embryos and observed elevated levels of hemECs and HSPCs, Kasper concluded that miR-223 inhibits the production of those types of cells.\nSpecifically, miR-233 affects the EHT by repressing expression levels of N-glycoenzymes alg2 and st3gal2. N-glycoenzymes are proteins involved in N-glycosylation, a process by which sugars are added to proteins. These sugar chains are crucial to protein folding, function, and signaling. The sugar modifications that alg2 and st3gal2 add to proteins limit EHT and cell proliferation. Fascinatingly, there has not yet been past research associating N-glycosylation with EHT, so this exciting discovery about the role of a \u201csugar code\u201d in cardiovascular cell development provides novel information about the growth of cells responsible for cardiovascular system development.\u00a0\nOne challenge that Kasper encountered was the amount of material needed to analyze the sugars in endothelial cells. She was unsure whether she\u2019d be able to see the sugars or find proteins modified by N-glycosylation. Ultimately, though, she was able to do both, thus finding a new pathway involving N-glycan sugars that regulate the production of HSPCs.\u00a0\n\u201cThese cells have incredible therapeutic potential for patients with leukemia or other blood disorders to help them regenerate their blood system, but there\u2019s a shortage of ways to get hematopoietic stem cells,\u201d Kasper said. With the new information about how HSPCs are generated in embryos, researchers can improve strategies for producing the stem cells needed for these therapies.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/the-sugar-code-instructions-for-the-earliest-stages-of-cardiovascular-development/",
            "captions": [
                ""
            ]
        },
        {
            "title": "From Bacteria to Glacier Melting",
            "author": "Bella Xiong",
            "authorLogo": "",
            "date": "April 24, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/IMG_2129-500x344.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Sasha Leidman.\nWho knew microscopic organisms could have huge impacts on climate change? \u201cBacteria\u201d and \u201cglacier melting,\u201d two seemingly unrelated terms, were recently found to be deeply linked. Led by graduate student Sasha Leidman, a group of scientists from Rutgers University traveled to Greenland to collect sediment samples and drone images of glaciers. Previous research on supraglacial sediment existed, but it had never been quantified. There was little knowledge on how much cyanobacteria grew in the sediments or how they impacted the glaciers. \u201cWe didn\u2019t even collect measurements of the bacteria at first, just because we had no indication that there was anything living in these sediments when we were first going out there,\u201d Leidman said.\nThen, these hydrologists made their discovery: the cyanobacteria in the sediments led to an increased glacier melting rate. The majority of this sediment was blown onto the ice sheet, then consolidated into what is known as cryoconite holes. When these cryoconite holes flood, all the sediment flows into streams and is deposited in floodplains. The cyanobacteria clump up on the sediment, which likely decreases albedo, the amount of light being reflected off the surface. Unable to reflect light off the surface, the glacier absorbs more heat from the sun and thus melts faster.\nStudying these cyanobacteria may help scientists predict the level of glacier melting in the future. Correlating cyanobacteria growth with changing temperatures and hydrology will help Leidman and his team make glacier melting predictions as accurate as possible. For example, as these scientists examine how the bacteria in the sediment will change in the future, they can further evaluate the amount of flocculation\u2014the clumping of bacteria\u2014in supraglacial streams to produce more precise predictions of albedo. These scientists hope to use these climate models, incorporating the effects of cyanobacteria in the sediment, to predict how much melting there is tens to hundreds of years from now.\nDue to COVID-19, the team was not allowed to travel to Greenland last summer, and this summer, it is still up in the air as to whether or not they can continue their research there. However, they are always ready. They are currently in the planning process and will head to Greenland as soon as possible. The team hopes to determine the biological constraints on cyanobacteria in streams and examine how these supraglacial streams affect atmospheric currents and weather patterns in Greenland and the polar regions.\nGlobal warming is increasing temperatures, changing the sky\u2019s cloudiness, and transforming ocean currents. \u201cGreenland is melting at a scale that\u2019s kind of hard to wrap your head around,\u201d Leidman said. \u201cJust during the past season, it lost 280 billion tons of ice.\u201d Small changes in climate have a huge impact on Greenland\u2019s surface mass balance and its contribution to the world\u2019s rising sea level. These scientists are trying to use bacteria to quantify exactly how much glaciers are melting and to make that number as accurate as possible so that our society can plan for rising seas and climate change in the future.\nCitations:\u00a0\nLeidman, S. Z., Rennermalm, \u00c5. K., Muthyala, R., Guo, Q., & Overeem, I. (2021). The Presence and Widespread Distribution of Dark Sediment in Greenland Ice Sheet Supraglacial Streams Implies Substantial Impact of Microbial Communities on Sediment Deposition and Albedo.\u00a0Geophysical Research Letters,\u00a048(1), 2020GL088444.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/04/from-bacteria-to-glacier-melting/",
            "captions": [
                "Researchers Sasha Leidman and Rohi Muthyala stand in a supraglacial stream to collect drone images of the ice sheet, GPS measurements, and sediment samples. Courtesy of Sasha Leidman."
            ]
        },
        {
            "title": "\u201cLike-Dissolves-Like\u201d: Updating theories on miscibility",
            "author": "Veronica Brooks",
            "authorLogo": "",
            "date": "June 21, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Brooks_Figure1-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nMiscibility, or the ability for liquids to mix, is often determined by the \u201clike-dissolves-like\u201d rule, which is largely qualitative. It remains difficult to quantitatively determine how \u201calike\u201d two substances are. But by using the dielectric constant, Bilin Zhuang, an assistant professor at Yale-NUS, developed a model that accurately predicts the miscibility of two liquids using their permanent dipole moments, which arise from differences in electronegativity across a molecule.\u00a0\nThe dielectric constant is a number assigned to a substance based on how polarized it becomes in an electric field. A molecule with a high dielectric constant has higher polarity and a greater ability to stabilize charges in an electric field. Materials with similar dielectric constants often mix well. Zhuang\u2019s model also uses the free energy of mixing to predict miscibility of two liquids. This model accurately fits experimental data when compared to previous theories that use a similar number of parameters.\nHowever, these new equations are unable to account for hydrogen bonding, which leads certain liquids to adopt conformations that the dielectric constant does not predict. Zhuang\u2019s next steps will focus on developing miscibility predictors for hydrogen bonding liquids and polarizable liquids, substances with no permanent dipoles.\u00a0\u00a0\nUltimately, these new equations will be particularly useful for predicting the miscibility of newly synthesized molecules. It also saves time at the bench when one studies multi-component mixtures. \u201cWe can just plug in the number and roughly see what the dielectric constant is [and] its miscibility,\u201d Zhuang said.\nSources:\nZhuang, B., Ramanauskaite, G., Koa, Z. Y., & Wang, Z.-G. (2021). Like dissolves like: A first-principles theory for predicting liquid miscibility and mixture dielectric constant. Science Advances, 7(7), 1\u20137. https://doi.org/10.1126/sciadv.abe7275\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/like-dissolves-like-updating-theories-on-miscibility/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Identifying Deafness Mutations",
            "author": "Kelly Chen",
            "authorLogo": "",
            "date": "June 21, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Chen_Figure1.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nHearing loss is a commonly overlooked sensory disorder, even though it occurs all over the world. One type of deafness is autosomal recessive nonsyndromic deafness (ARNSD), a comparatively prevalent type of deafness in Iran. Working with researchers from Shiraz University of Medical Sciences, Emily Smith and Arya Mani from Yale University used DNA sequencing techniques to identify mutations that cause ARNSD.\u00a0\nThe research established that causative mutations were found in all ten Iranian families studied. Mutations were found primarily within GJB2 genes, which code for gap junction beta proteins. Novel mutations in the Iranian population were found also within the TMC1, ESRRB and MYO15A genes. These genes encode proteins involved in hearing.\u00a0\u201cThese mutations often impair the function of cochlear hair cells,\u201d Mani said. \u201cFor instance, TMC1[transmembrane channel like] is a pore-forming component of mechanosensory transduction channels in auditory and vestibular hair cells with important function in hearing.\u201d\nIdentification of common mutations allows for early diagnosis of ARNSD.\u00a0Earlier diagnosis, in turn, leads to proactive treatment plans, such as cochlear implants or speech therapy. \u201cThere are ongoing discussions in the media about people [who are] affected by deafness but are afraid of seeking help\u2026[or] they try to deny their illness, so they are not as stigmatized. But once they are treated or wear their hearing aid, they catch up with challenges, and suddenly they see the world changes for them,\u201d Mani said.\nCitations:\nDianatpour, M., Smith, E., Hashemi, S., Farazifard, M., Nezafat, N., Razban, V., & Mani, A. (2021). Identification of homozygous mutations for hearing loss. Gene,778, 145464. doi:10.1016/j.gene.2021.145464\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/identifying-deafness-mutations/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Nanoscale Nucleation: Insight into the unusual mechanism of contact freezing",
            "author": "Krishna Dasari",
            "authorLogo": "",
            "date": "June 21, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Dasari_Figure1-500x272.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nFreezing: a simple phase transition with a surprisingly complex set of mechanisms. Researchers use freezing dynamics to study the crystallization of various materials, but not all kinds of freezing are mechanistically understood. Graduate student Sarwar Hussain and professor Amir Haji-Akbari in the Department of Chemical and Environmental Engineering at Yale recently simulated contact freezing to unravel its unique mechanism.\nIn contact freezing, a water droplet that is supercooled\u2014below freezing temperature but still liquid\u2014collides with an external particle that promotes nucleation, the initiating step in the process of freezing. This results in unusually rapid ice formation. However, why exactly freezing proceeds so quickly remains unclear. Previous studies have suggested two key points. First, the rate of contact freezing is related to the liquid\u2019s tendency to surface freeze\u2014that is, to rapidly freeze its surface relative to the interior. Second, the nucleating particle doesn\u2019t necessarily have to directly disrupt the liquid-vapor interface to increase the freezing (nucleation) rate.\u00a0\nThe researchers\u2019 results ruled out the prevailing theories on its mechanism. \u201c[These findings] were not necessarily explained by the previous mechanisms which said that there has to be some sort of mechanical disturbance in the free interface between the liquid and the vapor for the increased freezing rate to take place,\u201d Hussain said.\u00a0\nFurther experiments into this nucleation mechanism are hindered by the limits of technology. Freezing events occur on the nanosecond timescale and create ice nuclei containing only hundreds to thousands of molecules. They cannot be observed with sufficient resolution, so the mystery of high nucleation rates during contact freezing is difficult to approach experimentally.\nWhat can\u2019t yet be accomplished in a physical lab, though, can now be done computationally. Two major advancements allowed for the accurate simulation of contact freezing. The first was the mW model, a water-like tetrahedral model liquid that enables rapid simulation while still considering interactions like hydrogen bonding. The second was the development of jumpy forward flux sampling, a novel sampling technique conceptualized by Haji-Akbari to address the shortcomings of the original forward flux sampling method. The original method could be used to estimate the likelihood of freezing events progressing toward complete freezing, but Haji-Akbari\u2019s version accounts for the jumpiness of freezing progression caused by the coagulation of ice particles. \u201cIf you do not take into account these jumps, you can underestimate the nucleation rate by several orders of magnitude,\u201d Haji-Akbari said.\nWith these advancements, the researchers were able to simulate the nanoscale dynamics of contact freezing for two mW-based liquids, one that had a surface freezing propensity and one that did not. By simulating supported nanofilms of the liquids, they were able to exclusively investigate the effect of the proximity of the nucleating particle to the vapor-liquid interface on the nucleation rate.\u00a0\nFrom their simulations, they observed that only the surface freezing liquid\u2019s nucleation rate was affected by proximity to the nucleating particle, increasing the nucleation rate by orders of magnitude. Moreover, they discovered that in such a case, freezing proceeds through the formation of hourglass-shaped nuclei, a unique property that mechanistically explains the increased nucleation rate. Compared to the spherical cap-shaped nuclei of classical models, hourglass-shaped nuclei have a smaller surface area exposed to the liquid. According to classical nucleation theory, the smaller liquid-exposed surface area lowers the nucleation barrier, allowing nucleation to proceed faster.\nTheir findings have implications for understanding contact freezing of water in the atmosphere, a phenomenon important for predicting weather patterns. These results support the theory that water may be capable of surface freezing, giving it access to rapid nucleation through contact freezing. However, the authors also note that other agents in the atmosphere may also contribute to nucleation rate, making it difficult to conclude that the proximity effect of surface freezing liquids is necessarily the main cause for atmospheric nucleation rates.\u00a0\nMore broadly, their discovery of this non-classical nucleation mechanism provides a roadmap to study other non-classical processes. For example, scientists may investigate nucleation in the vicinity of surfaces with different ice-forming properties, such as a protein with hydrophilic and hydrophobic patches. \u201cThe question is, if you put that protein inside supercooled water, what will happen? How will the critical nucleus look like, and how will the rate be sensitive to temperature, for example? These are all questions that our work gives a good conceptual framework to pursue,\u201d Haji-Akbari said.\nReferences:\nHussain, S., & Haji-Akbari, A. (2021). Role of Nanoscale Interfacial Proximity in Contact Freezing in Water. Journal of the American Chemical Society, 143(5), 2272\u20132284. https://doi.org/10.1021/jacs.0c10663\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/nanoscale-nucleation-insight-into-the-unusual-mechanism-of-contact-freezing/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Soft, Stretchy, and Reliable: The Discovery of Biphasic Ga-In as a Solution to Strain Sensitivity in Electronics",
            "author": "Gonna Nwakudu",
            "authorLogo": "",
            "date": "June 21, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Nwakudu_Figure1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nWith an increased demand for wearable technology, soft and stretchable circuits have become an essential component to commercial electronics. This demand creates a growing need for electronics that not only conduct high amounts of electricity but also survive wear and tear over time. Professor Rebecca Kramer-Botteglio and her research team, known as the Faboratory, works on developing stretchable, multilayer electronics that can create complex patterns and allow for more advanced nanoprinting techniques. In 2021, she alongside researchers Shangliangzi Liu and Dylan Shah published a research paper investigating biphasic Ga-In and its potential for accomplishing these feats at a smaller size.\u00a0\nBiphasic Ga-In (bGaIn), builds on Gallium-Indium eutectic alloy (eGaIn), a gallium-based liquid metal that, once exposed to oxygen, allows for high conductivity. However, eGaIn\u2019s high surface tension prevents it from being completely flexible, whereas bGaIn combines liquid particles with crystalline solids, allowing for the same amount of conductivity with a greater degree of stretchability.\nKramer-Botteglio\u2019s group formed bGaIn by applying eGaIn onto silicon and then heating and cooling the film until it became hard. Then, to test the features of this new material, they interconnected bGaIn with rigid electrical devices (resistors, microcontrollers, LED lights, etc.) as well as other soft, stretchable surfaces (latex balloons, paper, etc.). In both studies, bGaIn proved to be able to maintain the same level of electrical conductivity as untampered eGaIn under higher amounts of mechanical strain.\nAlthough the full extent of bGaIn\u2019s utility have not been studied yet, the results from the Faboratory show a promising future for various stretchable technology innovations, from the wearable health monitor to the soft robots.\nLiu, S., Shah, D.S. & Kramer-Bottiglio, R. Highly stretchable multilayer electronic circuits using biphasic gallium-indium.\u00a0Nat. Mater.\u00a0(2021). https://doi.org/10.1038/s41563-021-00921-8\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/soft-stretchy-and-reliable-the-discovery-of-biphasic-ga-in-as-a-solution-to-strain-sensitivity-in-electronics/",
            "captions": [
                ""
            ]
        },
        {
            "title": "News Byte: Stem Cell Therapy for Spinal Cord Injuries",
            "author": "Jerry Ruvalcaba",
            "authorLogo": "",
            "date": "June 21, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Ruvalcaba_Figure1-500x402.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nSpinal cord injury treatment without surgery\u2014the work of science fiction or a soon reality? Spinal cord injuries continue to be a challenging medical issue: they commonly cause disability, yet have limited viable treatments. Discovering such remedies has been one of the drivers behind the long-standing relationship between researchers at the Sapporo Medical University of Japan and the Yale School of Medicine. Building on their focus on pre-clinical work with stem cells, this collaboration has led to the implementation of a clinical trial utilizing intravenous injection of stem cells.\u00a0\nIn the study, patients\u2019 stem cells were isolated from their bone marrow and grown using their serum. \u201cIt\u2019s a completely closed system\u2026 it\u2019s personalized medicine,\u201d said Jeffery D. Kocsis, professor of neurology and neuroscience at Yale. Following the cells\u2019 injection, the researchers monitored the patients and reported neurologic improvements in twelve of the thirteen patients under the ASIA Impairment Scale for sensory and motor levels. Researchers did not detect adverse effects after injection. \u201cThe studies are, I think, quite exciting and give us great hope that we can push on with this,\u201d Kocsis said.\nWhile these results are promising, Kocsis notes that they are only anecdotal. \u201cThe study that was done in Japan was not blinded; it was observational and the paper [described the tests] as case studies,\u201d he said. With this, Kocsis is cautious to declare the results conclusive and is looking forward to a future, blinded study performed in New Haven for more definitive answers.\nWorks Cited\nBangalore, L. (2021, February 22). Yale scientists repair injured spinal cords using patients\u2019 own stem cells. YaleNews. https://news.yale.edu/2021/02/22/yale-scientists-repair-injured-spinal-cords-using-patients-own-stem-cells\nKocsis, J. (2021, March 30). Personal interview [Personal interview].\nHonmou, O., Yamashita, T., Morita, T., Oshigiri, T., Hirota, R., Iyama, S., Kato, J., Sasaki, Y., Ishiai, S., Ito, Y. M., Namioka, A., Namioka, T., Nakazaki, M., Kataoka-Sasaki, Y., Onodera, R., Oka, S., Sasaki, M., Waxman, S. G., & Kocsis, J. D. (2021). Intravenous infusion of auto serum-expanded autologous mesenchymal stem cells in spinal cord injury patients: 13 case series. Clinical Neurology and Neurosurgery, 203, 106565. https://doi.org/10.1016/j.clineuro.2021.106565\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/news-byte-stem-cell-therapy-for-spinal-cord-injuries/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Stereochemistry Selection: The catalytic synthesis of stereopure oligonucleotides",
            "author": "Shudipto Wahed",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wahed_Figure1-500x331.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image generated using ChemDraw.\nNucleotides, the building blocks of DNA and RNA, can be synthetically designed to mimic their biological counterparts and interact with the cellular environment. An important class of nucleotide molecules are cyclic dinucleotides (CDNs), two single nucleotides that bind to form a ring. For example, cGAMP is a naturally occurring CDN that can drive immune response by activating the stimulator of interferon genes (STING) protein. Because interferon genes are critically involved in immune cell signaling, STING pathways are being extensively evaluated in cancer immunotherapies, and CDNs such as cGAMP may serve as promising new drugs. Synthetically manufacturing them represents an important step in bringing these drugs to mass market.\nA powerful method of increasing metabolic stability and therapeutic potential of CDNs is to modify their native phosphodiester linkages into phosphorothioate (PS) double-bonds. However, doing so introduces an additional layer of complexity by rendering the central phosphorus (P) atoms stereogenic (chiral), meaning different spatial orientations\u2014stereoisomers\u2014of the same connected groups are possible. An analogy for stereoisomers is a pair of baseball gloves in which one is left-handed and the other is right-handed\u2014although otherwise indistinguishable, the right-handed glove will not fit on a left hand, and vice versa.\nEach CDN stereoisomer, despite possessing identical atomic connectivities, displays markedly different physical properties and biological activities. The importance of stereochemistry is best highlighted by the infamous case of thalidomide, a drug developed in the 1950s that was marketed to treat morning sickness in pregnant women. One of its stereoisomers has sedative effects, whereas the other caused birth defects. As a result, thousands of children whose mothers took thalidomide during pregnancy had severe birth defects, since both stereoisomers were present in the medicine.\nMost synthetic methods for preparing PS-derived CDNs are nonselective in stereochemical outcome, relying on intensive purification techniques or large quantities of auxiliary reagents to produce stereopure products. In a recent study published in Science, the Scott Miller lab at Yale\u2019s Department of Chemistry, in collaboration with Takeda Pharmaceutical Company, reported the first catalytic, stereocontrolled synthesis of dinucleotides. Lead author Aaron Featherston, along with a team of academic and industrial researchers, sought to address the aforementioned problem using asymmetric catalysis. Catalysts, which are regenerated throughout the course of a reaction, could ideally be used in small amounts to facilitate the stereoselective assembly of PS compounds.\nThe first step of oligonucleotide synthesis is often achieved using excess amounts of an acid activator. Symmetric chiral phosphoric acids (CPAs) have proven to be powerful catalysts in several asymmetric transformations that isolate one stereoisomer. Recently, the Miller lab developed an additional class of CPAs containing a modified amino acid, phosphothreonine (pThr). Their rationale was that the amino acid, a building block of proteins, could conceivably help impart selectivity on par with enzymes, the ultra-specific protein catalysts of nature.\nAccordingly, Featherston and the team assessed the ability of these two classes of CPAs to asymmetrically couple two select nucleotides, guanosine and adenosine. They found that several pThr-derived catalysts greatly biased coupling towards one product stereoisomer. Alternatively, the symmetric CPA catalysts were highly selective for the other stereoisomer. The researchers thus demonstrated two distinct, complementary catalyst frameworks, allowing for the synthesis of either stereopure isomer.\nThe researchers then evaluated the ability of these catalysts to asymmetrically couple a broader range of representative nucleotides, finding that their stereoselective catalyses could be applied to other base pairs beyond the guanosine-adenosine coupling initially tested. Although selectivity decreased for certain nucleotide couplings, the chemists demonstrated that their approach is generalizable and can potentially yield a universal catalyst. Finally, the group applied their method to the synthesis of PS-modified cGAMP, showing that the pThr and symmetric CPA catalysts could allow for an efficient, stereocontrolled preparation.\nThe researchers found, for the first time, a stereocontrolled synthesis of dinucleotides using two catalyst frameworks. Oligonucleotide syntheses have long struggled with controlling P-stereogenicity, which reduces the efficacy of nucleotide-based therapeutics. This new approach both provides efficient access to a dinucleotide P-stereoisomer and enables preparation of stereopure analogs of cGAMP, a CDN of great biological significance.\nIn the future, the Miller lab may dive deeper into the catalysts\u2019 mechanism of action. A longer-term ambition would be to develop a more universal catalyst framework that can facilitate the asymmetric synthesis of all possible nucleotide couplings. Their current findings will prove vital to the field of oligonucleotide chemistry, as synthetically modified nucleotides continue to grow in importance. \u201cIt was a great collaboration, and I think we were able to make a significant impact by developing some really cool chemistry,\u201d Featherston said.\nCitations:\nFeatherston, A. L., Kwon, Y., Pompeo, M. M., Engl, O. D., Leahy, D. K., & Miller, S. J. (2021). Catalytic asymmetric and stereodivergent oligonucleotide synthesis. Science, 371(6530), 702\u2013707.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/stereochemistry-selection-the-catalytic-synthesis-of-stereopure-oligonucleotides/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Racial Disparities in COVID-19 Mortality",
            "author": "Bella Xiong",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-4.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Getty Images.\nIt has been frequently reported that racial disparities persist in COVID-19 mortality rates, but how large are these disparities, and what factors create them? Exactly one year after the World Health Organization (WHO) declared COVID-19 a pandemic, a team of researchers from the Yale School of Public Health, led by graduate student Alyssa Parpia, published a study evaluating how the pandemic has reflected systemic racism in the United States. The study looked at the disproportionate burden borne by Black Michiganians in the COVID-19 pandemic relative to their White counterparts.\u00a0\nSpecifically, the team studied mortality attributable to COVID-19. While only 14.1 percent of the Michigan population is Black, Black Michiganians experienced about thirty-five percent of COVID-19 deaths in the entire state as of November 2020. The researchers compared the demographic characteristics\u2014such as age, sex, and total number of comorbidities (presence of more than one illness or disease in one patient)\u2014of White and Black individuals. Even after accounting for these factors, Black individuals were still at higher risk of COVID-19 mortality than their White counterparts, indicating that race is a driving factor behind the disproportionate mortality burden in Michigan.\nThese results shine a light on systemic racism in the United States. The team\u2019s research demonstrated that chronic conditions alone are not responsible for the increased mortality rate among Black individuals, especially for those who are younger. Systemic racism, for one, has created racial disparities in socioeconomic status. And even when socioeconomic status is not a factor, biases and stereotypes have a serious impact on how doctors treat people of color, especially Black individuals. For example, a study conducted by the National Institutes of Health reported that between 2005 and 2016, the admission rate into hospitals was ten percent lower for Black individuals compared to their White counterparts. This can lead to misdiagnosis of illnesses, a lack of proper pain management, and increased health risks in general. Histories of systemic racism have created a lack of trust between medical personnel and racialized populations.\u00a0\nParpia\u2019s study helps us quantitatively identify racial disparities in the United States, a crucial step toward addressing systemic racism. Stopping the pandemic will not stop the inequalities built by hundreds of years of racially discriminatory and oppressive policies. Parpia noted that there are many other important factors linked with systemic racism that we should continue to explore. Racial inequality in employment presents one such example. As \u201cessential workers,\u201d grocery store or transit employees\u2014positions disproportionately held by Black Americans\u2014have less access to personal protective equipment compared to hospital employees. Many who do not have access to higher paid positions are also excluded from health insurance. In addition, essential workers might not have access to paid sick leave and are less likely to socially distance because of the nature of their jobs.\u00a0\nRace-based socioeconomic inequities and inaccessibility of healthcare have heightened chances of COVID-19 exposure and lowered overall survival rate. \u201cThe pandemic magnified many existing issues we had in the U.S., and we should use it as an impetus to change our entire healthcare structure,\u201d Parpia said. Even as the spread of the COVID-19 dies down, it is imperative to examine underlying reasons why certain populations are more at risk of contracting and dying from COVID-19 than others. These communities will continue to be more at risk if we maintain the status quo.\nParpia suggested solutions such as providing paid sick leaves, living wages, and universal healthcare, as well as restructuring the U.S. prison system. These supports would help ensure that people are able to adhere to the stay-at-home guidelines put in place to control disease transmission. This, in turn, could have compounding effects. For example, providing paid sick leaves would allow for people to avoid exposure to others when sick, thus decreasing the spread of the virus.\u00a0\n\u201cThese should be seen as basic rights, and for some reason, they are not,\u201d Parpia said. And while the proposed solutions center on just one aspect of systemic racism, according to Parpia, they \u201cwill have wide-reaching implications on the ability of racialized populations to be able to approach a semblance of equity with White populations in the United States.\u201d\nWorks Cited\u00a0\nParpia, A. S., Martinez, I., El-Sayed, A. M., Wells, C. R., Myers, L., Duncan, J., \u2026 & Pandey, A. (2021). Racial disparities in COVID-19 mortality across Michigan, United States. EClinicalMedicine, 33, 100761.\u00a0\nZhang, X., Carabello, M., Hill, T., Bell, S. A., Stephenson, R., & Mahajan, P. (2020). Trends of racial/ethnic differences in emergency department care outcomes among adults in the United States from 2005 to 2016.\u00a0Frontiers in medicine,\u00a07, 300.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/racial-disparities-in-covid-19-mortality/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Curious Salmonella Protein: SopD\u2019s stimulation and inhibition of inflammation",
            "author": "Christopher Ye",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Ye_Figure1-500x419.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nThe bacterial pathogen Salmonella typhimurium causes intestinal inflammation. S. typhimurium injects effector proteins such as SopD that stimulate a signaling cascade, ultimately leading to inflammation. However, researchers from Yale and Shandong University discovered that SopD is bifunctional and can alternatively stimulate or inhibit inflammation. \u201cIt contains the \u2018Yin and Yang\u2019 elements of the Salmonella/host interaction within the same protein\u2026 a remarkable piece of evolution,\u201d said Jorge Gal\u00e1n, lead researcher of the study and chair of the Department of Microbial Pathogenesis at Yale School of Medicine.\n\u201c[Inflammation is] essential for [S. typhimurium] to colonize the intestinal tract, since it allows Salmonella to [compete] with the resident microbiota and secure nutrients that are otherwise not accessible in the uninflamed intestine,\u201d Gal\u00e1n said. Rab8 is a regulatory protein that is central for an anti-inflammatory signaling pathway that helps the host recover homeostasis after inflammation. Therefore, by inhibiting Rab8, SopD stimulates inflammation and helps the pathogen replicate within the intestine.\u00a0\nWhen the researchers solved the SopD-Rab8 complex\u2019s crystal structure, they identified SopD\u2019s unexpected second function: SopD can activate Rab8 and stimulate an anti-inflammatory response. In other words, opposing enzymatic activities are present within the same protein. Rab8 normally binds to GDI2, an inhibitor that blocks Rab8 activity. However, SopD can displace GDI2 to activate Rab8 and inhibit inflammation. By doing so, S. typhimurium sacrifices virulence to preserve host stability, maximizing its ability to continue replicating.\n\u201c[This research is] providing major insight into the pathogenesis of chronic intestinal inflammatory diseases such as Crohn\u2019s disease,\u201d Gal\u00e1n said. Understanding Salmonella has implications in the development of novel therapeutic strategies.\nCitations:\nLian, H., Jiang, K., Tong, M. et al. The Salmonella effector protein SopD targets Rab8 to positively and negatively modulate the inflammatory response. Nat Microbiol (2021). https://doi.org/10.1038/s41564-021-00866-3\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/a-curious-salmonella-protein-sopds-stimulation-and-inhibition-of-inflammation/",
            "captions": [
                ""
            ]
        },
        {
            "title": "What\u2019s in the Mariana Trench? A Robot May Have the Answer: Self-powered soft robot withstands high pressure depths",
            "author": "Frances Cheung",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Image-1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Courtesy of Guorui Li.\nThe intense pressures of the deep ocean cause it to remain Earth\u2019s largest unexplored territory. Currently, mechatronic machines with rigid vessels and pressure-compensation systems are commonly used to explore these high-pressure terrains. However, to protect against extreme pressures, these machines are often bulky and inflexible, which make them highly susceptible to structural failures. Inspired by the hadal snailfish, a deep-sea creature native to the Northwest Pacific Ocean, a Chinese research team from Zhejiang University developed the first untethered self-powered soft robot that is fully functional in the deepest parts of the ocean.\nStructural failure under high pressures remains a prevalent challenge when constructing deep-sea exploration systems. In order to combat this issue, underwater soft body robots inspired by soft-bodied sea creatures were developed. These robots are designed with soft actuators, or components responsible for mechanical motion, and are structurally flexible for efficient swim performance, often utilizing propulsive movements like flapping or jetting. However, these robots are still incapable of overcoming extreme hydrostatic pressures without bulky vessels. To solve this issue, the researchers incorporated bodily features of the hadal snailfish, such as its distributed skull and flapping pectoral fins.\u00a0\u00a0\nThe snailfish\u2019s distributed skull led the researchers to a decentralized design in the robot\u2019s soft body. They found that electronic components densely packed onto the same printed circuit board (PCB) often led to pressure-induced shear stresses at the interfaces between components. This often resulted in pressure test failures. However, they were able to lower the average shear stress when direct contact between components were decreased and distances between microchips were increased through wire connections and separations into several smaller PCBs. Pressure tests comparing the centralized and decentralized designs confirmed that there was greater pressure resilience when adopting the latter design.\u00a0\nThe researchers used soft actuators to model their robot after the snailfish\u2019s joints and fins. Mirroring the snailfish\u2019s thin pectoral fins, they incorporated silicone film flapping fins that were supported by elastic frames and stiff leading edges. They also included dielectric elastomer muscles between the frames and the fins that were similar to the snailfish\u2019s joint muscles. When in action, the muscles flapped the robot\u2019s fins, propelling it forward and allowing it to swim. The electronics were encapsulated in a soft silicone matrix, which, when combined with the robot\u2019s decentralized system, resulted in a low-density design that was beneficial for deep-sea swimming.\u00a0\nSeveral field tests and experiments in a pressure chamber confirmed the robot\u2019s excellent swimming ability and pressure tolerance. The robot was fully operative in the Mariana Trench at a depth of 10,900 meters and in the South China Sea at a depth of 3,224 meters. The last known robot capable of similar depths in the Mariana Trench was Nereus, which in 2009, dove to a depth of 10,902 meters. Swimming speeds and performances were tested in a pressure chamber by attaching the robot to a rotatable rod and allowing it to swim. Free-swimming ability was further tested in a deep lake by measuring the robot\u2019s speeds at various depths. Results from these tests verified its robustness for field explorations.\u00a0\nThe researchers have shown that soft robotics may be a more effective avenue for deep sea studies. In the future, they hope to focus on developing new machinery that can enhance efficiency, intelligence, versatility, and maneuverability.\nSources:\u00a0\nLi, G., Chen, X., Zhou, F., Liang, Y., Xiao, Y., Cao, X., Zhang, Z., Zhang, M., Wu, B., Yin, S., Xu, Y., Fan, H., Chen, Z., Song, W., Yang, W., Pan, B., Hou, J., Zou, W., He, S., \u2026 Yang, W. (2021). Self-powered soft robot in the Mariana Trench. Nature, 591(7848), 66\u201371. https://doi.org/10.1038/s41586-020-03153-z\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/whats-in-the-mariana-trench-a-robot-may-have-the-answer-self-powered-soft-robot-withstands-high-pressure-depths/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Future of Personalized Medicine and Cancer Treatment: The promise of whole genome sequencing",
            "author": "Mehana Daftary",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Photo-1-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Andrew Armstrong.\nWhole genome sequencing\u2014reading all three billion letters of a person\u2019s genome\u2014was first accomplished by the Human Genome Project in 2003 after more than a decade of research. But now, with the advent of massive parallel sequencing methods, the human genome can now be sequenced in a matter of days.\u00a0\nA recent case study conducted by Yale and the Duke and Weill Cornell Schools of Medicine is one of the first to publish the completed whole genome sequence of a patient to inform future personalized medicine treatment for prostate cancer. In the near future, the patient hopes to create a page that shares his motivation for self-identification, his germline, and his somatic sequencing information. This creates a \u201cunique case where clinical and genetic information are linked\u201d and \u201c[sets] the stage for further patients to share and link their own data,\u201d said Andrew Armstrong, co-first author of the study.\u00a0\nTargeted gene panels, which sequence only the most commonly mutated genes in cancers or other conditions, are used more frequently in medicine due to their lower cost. They operate within a smaller pool of known genes whose mutations have been shown to drive cancers. Whole genome sequencing, in contrast, looks at every letter in the entire genome, so it remains quite expensive and is not generally a viable clinical option. However, examining whole genome sequencing enables researchers to analyze the potential effects of noncoding sequences\u2014which do not produce protein and comprise over ninety-eight percent of the genome. The function of these non-protein-coding sequences in the genome is \u201cnot well understood,\u201d said Xiaotong Li, a co-first author and the study\u2019s bioinformatician.\nIn this case, the whole genome sequencing was not integral to finding a cancer driver mutation, which would have been found with targeted sequencing. However, the patient\u2019s whole genomic information was useful for inferring the aging and clock-related mutational signatures that may have caused his cancer-related mutation over time.\u00a0 \u201c[Future] whole genomic approaches may speed the discovery of cancer causes and prevention as well as treatment by more fully using this information and processing it with clinical outcomes to broaden the impact of personalized medicine,\u201d Armstrong said. He hopes this is the first of many cases in which genomic sequencing data becomes available and tied to clinical outcomes.\u00a0\nArmstrong and Li formed close relationships with the patient. Li described this journey as a \u201cuniquely rewarding experience.\u201d \u201cI was impressed by how genomics analysis can help us better understand cancer treatment and benefit personalized medicine,\u201d Li said.\u00a0\nIf possible, Armstrong encourages patients to seek out whatever sequencing options they might have access to, whether that be targeted gene panels or another method. \u201cBy empowering patients to ask their doctors about sequencing options, we can help inform treatment and genetic counseling in ways that will continue to facilitate discovery,\u201d Armstrong said.\nSources:\u00a0\nArmstrong, A. J., Li, X., Tucker, M., Li, S., Mu, X. J., Eng, K. W., \u2026 & Gerstein, M. (2021). Molecular medicine tumor board: Whole-genome sequencing to inform on personalized medicine for a man with advanced prostate cancer. Prostate Cancer and Prostatic Diseases, 1-8.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/the-future-of-personalized-medicine-and-cancer-treatment-the-promise-of-whole-genome-sequencing/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Magnetism in Small Planets",
            "author": "Rayyan Darji",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2-1-1-500x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nWithin the expansive solar system, there are bodies of numerous types and sizes, and our understanding of them is far from complete. However, a key tool toward furthering our understanding of our own planet Earth and other bodies in the solar system is the study of magnetic fields. In general, the magnetization of a body in space can tell us something about how it formed, what it is made of, and how it has cooled and evolved through time.\nLarger bodies like planets are believed to have been formed from the collisions and eventual conglomeration of smaller bodies called planetesimals. By studying planetesimals, scientists can apply those findings to larger planets, which are far more difficult to directly study. Building upon existing models, researchers from Yale\u2019s Department of Earth & Planetary Sciences developed a new model to understand magnetism in planetesimals.\u00a0\nThere is evidence that the planetesimals are magnetized based on the analysis of meteorites, which are fragments of planetesimals that made it to the Earth\u2019s surface. Magnetization of planetesimals implies they were already segregated (or differentiated) like mini-planets into a metallic core (in which the magnetic field is generated) and rocky mantle and crust, even before they accreted to make bigger planets.\nCertain conditions must be present for a body to be able to generate a magnetic field. \u201cTo get a magnetized body, you need an electrically conductive fluid\u2014like molten iron in the core\u2014and the fluid needs to be moving at a fast enough rate to generate a magnetic field,\u201d said Elvira Mulyukova, a co-author of the paper published in Physics of the Earth and Planetary Interiors. This motion is referred to as dynamo activity. \u201cThere also needs to be a solidifying, cooling crust at the surface that can record that induced magnetic field,\u201d Mulyukova said.\u00a0\u00a0\nThe top of metallic cores in planets and planetesimals will crystallize over time to a solid material, making that region heavier and causing it to sink downward\u2014a process known as delamination. When the solid material drops off, it tends to do so in big blobs, and when these blobs disconnect, they form geological intrusions known as diapirs. That delamination can cause the fluid in the core to stir fast enough to generate dynamo activity and ultimately a magnetic field.\u00a0\nIn deducing how magnetization occurs in small planetesimal cores, a primary obstacle is the inability of the smaller bodies to sustain sufficient dynamo activity. \u201cWhen the solid outer shell delaminates, the falling of those solid bodies is so fast and sporadic that it would require a lot of them to be falling at the same time to induce vigorous motion of the fluid and thus generate a dynamo; moreover, they need to be falling over a long period of time for the induced magnetic field to get recorded,\u201d Mulyukova said.\u00a0\nInstead, by analyzing various factors influencing dynamo activity, the researchers proposed the nature of planetesimal cores may be the cause of its magnetism. Because planetesimal cores are not pure iron, the diapirs formed are probably porous, like iron snowballs. \u201cFor a sinking porous diapir, the motion of the liquid in the surroundings and the motion of the liquid through the pores will generate enough velocity of the liquid to induce a magnetic field,\u201d said David Bercovici, the second co-author of the paper.\nMuch research is left to be done to fully understand magnetism in planetesimals and how it relates to larger planets. \u201cThe presence of magnetization in an object tells us something about its differentiation history and composition, which in turn allows us to understand the types of planetesimals that likely have created our own planet,\u201d Mulyukova said. Although bound by certain limitations and assumptions, the theoretical model produced from this study paves the way for promising future research, including developing a model for multiple diapirs, and ultimately understanding the magnetic and thermal histories of planetesimals \u2013 the building blocks of our planet.\nSource:\nBercovici, D., & Mulyukova, E. (2021) Magnetization of sinking porous diapirs in planetesimal cores. Physics of the Earth and Planetary Interiors, 313, 106678. https://doi.org/10.1016/j.pepi.2021.106678\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/magnetism-in-small-planets/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Curing Soil with Cover Crops",
            "author": "Ivy Fan",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/1-cereal-rye-field-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nSummer is for squashes, and autumn is for apples. But what happens during the winter? In fields left empty between crop seasons, wind and rain can erode away the soil, depleting nutrients and depositing it into water sources. Cover crops such as cereal rye\u2014which are planted not to be harvested, but to cover the soil\u2014can help protect the land. Yale researcher Stephen Wood and Soil Health Partnership researcher Maria Bowman investigated how planting cover crops could affect soil health on farms in the US over the course of five years.\u00a0\nWood and Bowman wanted to see how cover crops would fare on real-world farms, where farmers whose livelihoods depend on the fields are already actively farming. They measured soil health with six different metrics, including how well wet soil sticks together, and the activity levels of bacteria that live in the soil. After five years, soil planted with cover crops improved in four of the six metrics\u2014active carbon, aggregate stability, respiration, and total organic matter\u2014 as compared to soil with nothing planted during the off-season. Though the changes were small, they accumulated over the course of the study, suggesting that as farmers continue to plant cover crops, their soil could grow healthier year by year. \u201cI think it confirms what a lot of farmers observe on their farm, which is that they\u2019re seeing changes in the soil,\u201d Bowman said.\nHowever, these findings themselves likely won\u2019t spark widespread use of cover crops just yet. Researchers are continuing to evaluate how measures of soil health are tied to crop yield, and in the case of cover crops, some farmers might not find the improvements in soil health worth the added work of planting during the off-season. More research is needed to explore the benefits of cover crops beyond soil health.\nSources:\nWood, S. A., & Bowman, M. (2021). Large-scale farmer-led experiment demonstrates positive impact of cover crops on multiple soil health indicators. Nature Food, 2(2), 97-103.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/curing-soil-with-cover-crops/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Are Artificial Intelligence Models Ready for Clinical Use?",
            "author": "James Han",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/2-500x400.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nAs machine learning algorithms continue to increase in accuracy, their clinical applications have gained more and more interest, as machine learning models are able to learn from massive amounts of data and recognize patterns that humans are unable to comprehend. Often, these algorithms can perform with equal or greater accuracy than experienced clinicians. However, in a study published in Nature Digital Medicine, a group of researchers from UCSF caution against just how ready such algorithms are and stress the importance of rigorous testing before real-world clinical use of artificial intelligence models.\nThe team of researchers, led by Michael Keiser, a professor at the Institute for Neurodegenerative Diseases, and Maria Wei, a professor and dermatologist at the UCSF School of Medicine, developed and trained a machine learning model to identify melanomas, then exposed the model to a variety of stress tests to mimic real-world conditions. To Albert Young, a medical student at UCSF and the first author of the paper, the project was a culmination of ideas he developed from reading the computer science literature and talking to members within the lab. \u201c[We wanted] to evaluate these tools in ways to gauge how clinic-ready they are and what the barriers are to actually using them to help patients, and I think that\u2019s where the project came about,\u201d Young said.\u00a0\nWhile the model matched or exceeded dermatologist-level classification on conventionally reported metrics with curated datasets, it performed worse than dermatologist-level classification on non-curated datasets, which included lower-quality images that had been excluded from the curated datasets. In addition, the group found that model performance on images of the same lesion with different settings (such as angles, magnifications, or tools) and performance after image augmentations, such as rotations or changes in brightness and contrast, became less robust and often yielded inconsistent predictions.\nThe study highlights the importance of rigorously testing AI algorithms before they are adopted for clinical use. \u201cThere have been no clinical trials that I know about or real-world applications so far; they\u2019ve all been done with datasets that have been retrospectively collected, and a lot of them have been curated,\u201d Young said. \u201cThe very challenging conditions one might encounter in real life [should] also be replicated when testing these algorithms.\u201d\u00a0\nYoung also stresses the magnifying effect AI models can have on healthcare disparities once they are integrated in a clinical setting. \u201cOne can imagine that if you were to implement AI tools without really thinking about who might be using them, then those who have the most access to technology\u2014the most privileged in the healthcare system\u2014are going to benefit more, and even if this is a good tool, it\u2019ll only serve to widen existing healthcare disparities.\u201d\u00a0\nDespite the challenges of incorporating AI models into healthcare pipelines and clinical settings, Young remains excited about the future of AI. He hopes to continue to stay involved in AI, especially as he looks beyond his final year of medical school towards residency. \u201cI see myself as being a bridge between physicians who will be using these [AI tools] and the people who are developing them, asking the right questions as to how they were developed, what kind of biases might they have, as well as the technical and practical challenges of actually getting them to patients.\u201d\nSources\nYoung, A.T., Fernandez, K., Pfau, J. et al. Stress testing reveals gaps in clinic readiness of image-based diagnostic artificial intelligence models. npj Digit. Med. 4, 10 (2021). https://doi.org/10.1038/s41746-020-00380-6\u00a0\nEsteva, A., Kuprel, B., Novoa, R. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115\u2013118 (2017). https://doi.org/10.1038/nature21056\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/are-artificial-intelligence-models-ready-for-clinical-use/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Kelp\u2019s Future in Renewable Energy",
            "author": "Sydney Hirsch",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/giantkelp-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nThe environmental threats posed by fossil fuels, such as their rapid depletion and the climate change threats posed by their emissions, have made the need for renewable energy sources more and more apparent. Biofuel, fuel derived from plants, could supplement our current energy paradigm and could one day replace fossil fuels. However, biofuels from certain feedstocks, such as corn-based ethanol, pose significant disadvantages: they compete for land and fresh water, the pesticides and fertilizers used to grow them pollute surrounding waterways, and they may be carbon-intensive.\u00a0\nThe ocean\u2019s giant kelp, Macrocystis pyrifera, circumvents these issues. Not only does it have the potential to be a carbon-neutral energy source, but it does not require land nor disrupt habitats. As a bonus, kelp fits into the existing energy infrastructure. However, the limited nutrients in the photic zone (near the ocean\u2019s surface) limits the growth of this seaweed, thus hampering the large-scale development of M. pyrifera as a biofuel. To optimize the growth process, a team of researchers, including USC\u2019s Diane Young Kim, recently developed a solution that allows the seaweed both sufficient sunlight and nutrients. They deemed their novel technology the \u201ckelp-elevator.\u201d\nThe scientists hypothesized that, using this kelp-elevator, they could maximize growth with a depth-cycling approach: raising and lowering the kelp to provide it with the proper nutrients depending on the time of day. At 7:00 PM, the elevator would lower the kelp to eighty meters deep, where the water is rich in the necessary nitrates; at 5:00 AM, the kelp would be raised back to nine meters, allowing it a full day of sunlight.\u00a0\nThe researchers, in addition to growth, also took note of the plant\u2019s morphology and chemical composition after undergoing this process for ninety days. Compared to a control group, the depth-cycled kelp produced up to four times as much biomass. Additionally, its pneumatocysts, seaweed blade-attached bladders that are usually air-filled) were surprisingly fluid-filled, impacting buoyancy. This morphological difference may cause the seaweed fronds to shade each other, affecting the engineering parameters in furthering this research.\u00a0\nThe depth-cycled kelp further showed distinct levels of \u03b415N and \u03b413C, stable nitrogen and carbon isotopes. This revealed that the kelp successfully assimilated nutrients from the deeper water. \u201cWhile the nitrogen and protein content demonstrated that the depth-cycled kelp were not nutrient deficient, it was also important to show that the nitrogen the kelp acquired was from deep water,\u201d Kim said. \u201cIf nutrients were acquired from the surface of the ocean, that defeats the purpose of depth-cycling,\u201d The isotopic signature matched that of the deep ocean, confirming the source of the seaweed\u2019s nutrition.\u00a0\nThis research provides the first step towards utilizing giant kelp as a widespread biofuel. \u201cThe broader context is big\u2026 it holds great promise and potential to diversify the alternative energy portfolio,\u201d Kim said. She also explained that kelp may fill a niche in the current energy landscape. Electric vehicles, for instance, are another part of the solution, but are not yet suitable for long distances; kelp-based biofuel could fill in here to fuel planes and long-range trucks.\u00a0\nBefore considering the larger implications, however, the immediate steps to further this research lie in fine-tuning the procedure: changing the depth-cycling parameters, finding the sweet-spot of nitrate levels, and selectively breeding kelp for desirable traits. If seaweed meets its full potential, it offers a stepping stone on the pathway to eliminating fossil fuel usage.\u00a0\nCitations\u00a0\nNavarrete, I. A., Kim, D. Y., Wilcox, C., Reed, D. C., Ginsburg, D. W., Dutton, J. M., Heidelberg, J., Raut, Y., & Wilcox, B. H. (2021). Effects of depth-cycling on nutrient uptake and biomass production in the giant kelp Macrocystis pyrifera. Renewable and Sustainable Energy Reviews, 141, 110747. https://doi.org/10.1016/j.rser.2021.110747\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/depth-cycled-kelp-a-promising-addition-to-the-renewable-energy-paradigm/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Expected Parenthood: Fathers vs. Mothers",
            "author": "Cindy Kuang",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-1-1-500x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of the New York Times.\nPregnancy is widely understood to be a time of neurophysiological and psychological change for the mother in preparation for caregiving\u2014but what about for the expectant father? A recent study led by Helena Rutherford at the Yale Child Study Center compared maternal and paternal responsiveness to infant affective facial cues, seeking possible correlations between neural and psychological changes in the transition to parenthood.\u00a0\nSixty-eight expectant parents (thirty-eight mothers, thirty fathers) were recruited from the New Haven community to complete electroencephalogram (EEG) assessments while looking at photographs of distressed infant versus neutral infant faces. Using event-related potentials (ERPs) to measure a specific peak of neural response, P300, the researchers measured attention allocation to infant facial cues, which is thought to be important to future caregiving behavior. Even more interesting was their written language-based measure of psychological \u2018mind-mindedness,\u2019 in which participants were asked to prospectively think about what their baby would be like at six months of age.\u00a0\n\u201cYou\u2019re looking for evidence that [the parents recognize] the baby is a psychological agent and has thoughts and feelings and ideas of their own,\u201d Rutherford said.\u00a0\nP300 reactivity in the ERP neural measures was found to be heightened in expectant fathers, meaning fathers were more reactive to infant distress than expectant mothers. This increased paternal attention to distress was also correlated with greater levels of paternal mind-mindedness when thinking prospectively about their unborn child.\u00a0\nThese novel findings suggest sex differences in reactivity to infant facial cues, with implications for prenatal mind-mindedness and future parent-child attachment styles. It could be that mothers are exposed to constant biological and sociocultural cues during pregnancy\u2014making them less reliant on infant facial cues. Men, conversely, are more reliant and sensitive to the facial cue input.\u00a0\n\u201cIt raises more questions than it answers\u2014more next steps, more next directions,\u201d Rutherford said. She is excited to study whether these parental differences in reactivity and mind-mindedness persist longitudinally past infancy, as well as how factors such as socioeconomic background and stability of the relationship may contribute.\u00a0\n\u201cIt brings the research to life, spending time with the women\u2014just hearing their stories, and hearing the narratives around their pregnancies. The paper was accepted shortly after my daughter was born, so it was really interesting to go through that whole process along with my own pregnancy,\u201d Rutherford said.\nReference:\nRutherford, H. J., Bunderson, M., Bartz, C., Haitsuka, H., Meins, E., Groh, A. M., & Milligan, K. (2021). Imagining the baby: Neural reactivity to infant distress and mind-mindedness in expectant parents. Biological Psychology,161, 108057. doi:10.1016/j.biopsycho.2021.108057\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/expected-parenthood-fathers-vs-mothers/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Who Votes for Climate Change?",
            "author": "Tai Michaels",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/fig1-492x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Tai Michaels.\nThe majority of Americans believe that climate change is real\u2014but how important is it to their vote? A team of Yale and George Mason University researchers recently released a new study on the predictors of how important climate change is as a voting issue.\u00a0\nAnalyzing data from the long-running Climate Change in the American Mind surveys, the researchers began by identifying factors strongly associated with how important climate change is when voting. They identified many contributing factors, including social norms, media exposure, and political party alignment. The factors related to climate change being someone\u2019s first voting priority, however, were much more unexpected. Interestingly, discussing climate change with family and friends was the only significant predictor across all survey waves analyzed. Several other factors, such as worry and mainstream media exposure, were significant in at least one survey, but none were significant in all surveys.\u00a0\nThese results stand as a testament to the power of personal connections on climate change voting and advocacy. \u201cEnding the idea of climate silence and cultivating discourse\u2026 [so that] it\u2019s something that people talk about with others\u201d is crucial, according to lead researcher Eryn Campbell. These findings could be important for climate advocacy work\u2014particularly in strategizing on how to motivate people to communicate to friends and family the importance of voting for politicians that support climate change policies.\u00a0\nIn the future, Campbell plans to evaluate groups of cognitive, experiential, and sociocultural factors separately before examining their combined contributions to voting issue importance. The research team plans to dig deeper into significant factors such as discussing with family and friends\u2014as well as into typically important factors that were not found to be consistently significant, such as exposure to conservative and liberal media.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/who-votes-for-climate-change/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Environmental Justice and Industrial Animal Farms",
            "author": "Emilia Oliva",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Image-1-1-1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nConcentrated animal feeding operations (CAFOs), or intensive animal production facilities, minimize the space necessary to produce the greatest number of livestock possible. These facilities also produce high concentrations of waste and pollution, which pose significant environmental threats to local water systems and air quality, and they have been linked to increased respiratory dysfunction, lower immune health, and lower mental health for workers and for the people of nearby populations. According to a recent study by Ji-Young Son, associate research scientist, and Michelle Bell, professor of environmental health at Yale\u2019s School of the Environment, CAFOs are disproportionately distributed near communities of color and impoverished communities. The Bell Research Group hopes to address this environmental injustice in collaboration with Arizona State University and Rice University by developing more accurate models of CAFO exposure to inform communities and policymakers.\u00a0\nThe researchers studied North Carolina, home to the second largest hog industry in the US, and estimated CAFO exposure across the state. Consistent with results of previous studies, they found a high density of CAFOs close to racial/ethnic minority communities and areas of poverty. However, their model\u2014an advancement of previous work\u2014showed larger areas of risk compared to more traditional methods.\n\u201cOur study suggested that more refined exposure assessment from CAFOs is very important,\u201d said Son, lead author and a member of the Bell Research Group. Previous studies analyzed CAFO exposure by counting the CAFO facilities within a given area\u2014such as within each ZIP code of a state\u2014or by assessing the distance of different populations to nearby CAFOs.\u00a0The Bell Research Group developed a more advanced approach that addresses several limitations of earlier work. In their approach, exposure to CAFOs accounted for proximity of a community to multiple CAFO facilities. Their data was able to show that a CAFO near a ZIP code boundary impacts more than one ZIP code region.\u00a0\nThe researchers also analyzed the racial residential isolation and the educational residential isolation of North Carolina in relation to CAFOs. The researchers used these more complex metrics to evaluate the segregation of communities by race and education level, instead of simply measuring the percentages of different demographic groups within a community.\u00a0\nAccording to Son, determining the relative segregation of different populations is crucial for understanding the environmental justice implications of CAFO pollution. The disparities in CAFO exposure were starker under the team\u2019s newly developed exposure approach compared to earlier more simplistic methods, which suggests that the earlier work underestimated the environmental justice issue of CAFOs.\nThe Bell Research Group hopes to expand their study to include other regions of the country and metrics that will account for CAFO size and intensity. \u201cCAFO-produced pollution may have a substantial impact on health,\u201d Son said. \u201cOur next step is to look at associated health disparities in nearby communities, especially in communities of minorities and low socioeconomic status.\u201d\nSon, J. Y., Muenich, R. L., Schaffer-Smith, D., Miranda, M. L., & Bell, M. L. (2021). Distribution of environmental justice metrics for exposure to CAFOs in North Carolina, USA. Environmental Research, 195, 110862.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/environmental-justice-and-industrial-animal-farms/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Sensing Colors: How Blind Worms See",
            "author": "Hannah Ro",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fig1-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nFor many animals, color guides foraging decisions. In the same way a yellow inverted triangle signals us to yield or a shape outlined in red alerts us that something may be hazardous, environmental colors also help animals learn avoidance. Canonically, colors are detected and processed by specialized photoreceptors and opsin molecules in our eyes. But what about animals without eyes?\nDipon Ghosh, Yale PhD graduate and now MIT researcher, explored this question in Caenorhabditis elegans, a transparent, eyeless roundworm that typically resides in decomposing matter. When Ghosh read that harmful bacteria like those native to the worm\u2019s environment secrete pyocyanin, a blue-pigmented toxin, he decided to test whether the worms could sense the color of the pigmented toxin. His study reported that light affected worms\u2019 avoidance of harmful pigmented bacteria and that colors of incident light that mimic spectral properties of pigment-altered light can influence avoidance behavior in worms. In other words, worms can sense colors despite lacking eyes and opsins. \u201cOpsin molecules were previously thought to be required for color detection,\u201d Ghosh said. \u201cOur work tells us that we have so much more to learn and explore about how animals sense light.\u201d\nFurthermore, Ghosh and members of the Nitabach and Horvitz laboratories at Yale and MIT identified two evolutionarily conserved genes\u2014jkk-1 and lec-3\u2014required for the worms\u2019 color sensitivity. \u201cMany discoveries made in simple organisms have unexpected parallels in human biology, with the potential for biomedical applications. Perhaps by better understanding color sensitivity in the worm, we might find similar patterns in how other organisms respond to light,\u201d Ghosh said.\nSources:\nGhosh, D.D., Lee, D., Jin, X., Horvitz, H.R, Nitabach, M.N. (2021). C. elegans discriminates colors to guide foraging. Science, 371, 1059-1063.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/sensing-colors-how-blind-worms-see/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Mice with Human Blood: A new way to study blood disorders",
            "author": "Van Anh Tran",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2-2-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nHistorically, in vivo mice models have fallen short of simulating human erythropoiesis, or the production of mature red blood cells (RBCs), because of mice\u2019s immune response. As a result, human blood disorders such as sickle cell anemia have been mostly studied with murine RBCs from mice, which does not allow as much flexibility in experimentation. Recently, however, researchers from the Yale Department of Immunology and Yale Cancer Center have developed a murine model that displays enhanced human erythropoiesis and mature RBC survival.\u00a0\nThis model relies on cytokine and liver humanization\u2014the adoption of human genes and tissues\u2014in order to extend the lifespan of circulating human RBCs in the mice. Without humanization, engrafted human RBCs can be detected by the mices\u2019 immune systems and subsequently destroyed by immune cells.\u00a0\nThrough the deletion of the fumarylacetoacetate hydrolase (Fah) gene and transplenic injection of adult human hepatocytes, the researchers succeeded in liver humanization. Fah gene deletion allowed the engrafted human hepatocytes to repopulate in an immunodeficient liver. Essentially, the researchers grew a human liver in mice.\u00a0\nLiver humanization reduced the production of a protein called mucin 3A by mice hepatocytes. Mucin 3A, when attached to human RBCs, mediates the adherence to mice phagocytes, which results in the destruction of the human RBCs. \u201cCombining a humanized liver with a humanized blood system increased RBC count drastically,\u201d said Richard Flavell, Yale professor and one of the study\u2019s corresponding authors.\u00a0\nYale researchers also succeeded in cytokine humanization by utilizing MISTRG mice, which carry human genes that encode cytokines such as interleukin-3, granulocyte-macrophage and macrophage colony-stimulating factor, and thrombopoietin. These cytokines, in addition to a protein called signal-regulatory protein alpha, regulate innate immune cell development and human blood cell development in mice. Liver and cytokine humanization therefore enhances the survival of engrafted human RBCs by preventing the mice\u2019s immune responses from targeting the foreign human cells.\nThis mouse model saw success in simulating sickle cell disease as well. Sickle cell anemia in humans causes red blood cells to contort into a sickle shape, which can block blood flow and restrict oxygen and nutrient supply to the body. The researchers observed that after engraftment of hematopoietic stem and progenitor cells from sickle cell patients, the mice started producing sickle-shaped human RBCs. Furthermore, they started displaying signs of sickle cell anemia in their lungs, liver, kidneys and spleen, such as alveolar hemorrhage, thrombosis, and vascular occlusion. The sickle cell studies in mice showed that this model can be adapted to studying other RBC disorders, including thalassemia, and even hematopoietic stem cell diseases like myelodysplasia and erythroleukemia.\u00a0\n\u201cWe also like to think of this model as one that potentially addresses health disparities. We hope that it will allow us to advance treatments for sickle cell disease, a disease predominantly affecting African Americans in the US,\u201d said Yale professor and corresponding author Stephanie Halene. \u201cNow that we\u2019ve succeeded in growing mice with human blood, future research may make huge breakthroughs in studying blood disorders that disproportionately affect groups of people.\u201d\nCitations:\u00a0\nSong, Yuanbin, et al. \u201cCombined Liver\u2013Cytokine Humanization Comes to the Rescue of Circulating Human Red Blood Cells.\u201d Science, vol. 371, no. 6533, 2021, pp. 1019\u20131025., doi:10.1126/science.abe2485.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/mice-with-human-blood-a-new-way-to-study-blood-disorders/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Comet Catalina: Delivering the Ingredients of Life",
            "author": "Anavi Uppal",
            "authorLogo": "",
            "date": "June 20, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-1-500x400.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Michael S.P. Kelley, University of Maryland / Discovery Telescope Observatory.\nBefore our solar system came into existence, in its place was only a metaphorical lump of clay, spinning on a cosmic potter\u2019s wheel. As this lump of gas and dust spun and spun, it flattened out to eventually become the disk from which our Sun and planets formed. Researchers from the University of Minnesota, NASA Ames Research Center, the University of California at San Diego, the University of Maryland, and the Aerospace Corporation recently discovered that comets may have played an important role in the formation of Earth from this protoplanetary disk.\nAs the solar system formed, the young Sun heated up the inner protoplanetary disk, causing carbon in the inner portion of the disk to heat up to such high temperatures that it became gaseous. Rocky planets like Earth formed in this carbon-depleted region, while gas giants like Jupiter formed in the colder carbon-retaining regions that were farther away. But these rocky planets clearly have carbon in abundance today\u2014Earth wouldn\u2019t be able to support carbon-based life if it didn\u2019t. So where did all that carbon come from? Comets, the researchers found.\nIn 2016, gravity briefly nudged Comet Catalina from its home in the Oort Cloud to the inner parts of our solar system. The Oort Cloud is a spherical cloud of icy objects located in the farthest reaches of our solar system. \u201cThere\u2019s a handful of [Oort Cloud] comets that come by every couple of years, and they\u2019re spectacularly interesting to see visually, but also scientifically really interesting to study,\u201d said Charles \u201cChick\u201d Woodward, an astrophysicist at the University of Minnesota and the lead author on the paper.\nThe Oort Cloud\u2019s composition is representative of the ingredients that our planetary system was made from long ago, so studying Oort Cloud comets can tell astronomers a lot about our solar system\u2019s formation. \u201cIt\u2019s kind of like [\u2026] taking a pot pie and [\u2026] seeing how many carrots are in it, or how many onions and things like that, and then trying to figure out how the cook actually created that dish,\u201d Woodward said.\nThe researchers used the NASA Infrared Telescope Facility in Hawaii and the Stratospheric Observatory for Infrared Astronomy (SOFIA) to study Comet Catalina. SOFIA is a mobile 2.5-meter telescope carried into the stratosphere\u2014where there is less water vapor to block infrared light coming in from objects like Comet Catalina\u2014by a specially modified Boeing 747 airplane. Next, the researchers used spectroscopy, a method that allows astronomers to figure out what elements an object is made of by analyzing the light that a telescope receives from it. Through spectroscopy, they found that Comet Catalina was carbon rich and realized that other comets like it may have delivered carbon to the young Earth and other rocky planets. Without these deliveries, carbon-based life may never have evolved on Earth.\n\u201cIt took quite a few months\u2014like about forty-eight months\u2014to really get our heads around how to interpret the spectra that we observed,\u201d Woodward said. However, Woodward says that this difficult work is all a part of the scientific process\u2014and that it takes collaborations of many different people from all around the world to make new discoveries like this one possible every day.\nSources:\nWoodward, C. E., Wooden, D. H., Harker, D. E., Kelley, M. S., Russell, R. W., & Kim, D. L. (2021). The coma dust of Comet C/2013 Us10 (Catalina): A window into carbon in the solar system. The Planetary Science Journal, 2(1), 25. doi:10.3847/psj/abca3e\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/comet-catalina-delivering-the-ingredients-of-life-to-earth/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Breakthrough Therapy For Diabetes: Could teplizumab lead us to a cure for type 1 diabetes?",
            "author": "Alex Dong",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Finally-a-Cure-for-Type-I-Diabetes-Sophia-Zhao-383x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Sophia Zhao.\nBefore insulin was discovered in 1922 by Sir Frederick Banting and Charles Best, type 1 diabetes\u2014an autoimmune disease that renders the body unable to convert blood sugars to energy\u2014was often a death sentence. Patients with diabetes rarely lived for more than two years after disease onset. This discovery of the insulin treatment was revolutionary: for the first time, patients could survive and manage their illness.\u00a0\nNearly a century later, a new breakthrough in the field of type 1 diabetes has been achieved. A clinical trial analysis published in Science Translational Medicine, co-authored by Kevan Herold, C.N.H. Long Professor of Immunology and of Internal Medicine at Yale University, and Emily Sims, Assistant Professor of Pediatrics at Indiana University, reported compelling evidence for teplizumab\u2014a drug granted FDA \u2018Breakthrough\u2019 status in January 2021. The breakthrough aspect comes from the fact that this drug doesn\u2019t simply address symptoms; it could be able to preemptively delay, or even prevent, type 1 diabetes altogether.\nThe journey towards teplizumab has been a long and arduous one. \u201cLiterally for the past thirty years I\u2019ve been working on this, from doing the pre-clinical mouse work, to doing the early investigator-initiated clinical trials, to eventually leading clinical trials that were done by NIH consortia like the Immune Tolerance Network or TrialNet,\u201d Herold said.\u00a0\nA long and winding road\nEven after insulin started to be used as treatment, Herold witnessed the drastic effects that the disease had on the quality of life of patients. \u201cDiabetes is with you twenty-four-seven,\u201d he said. \u201cThere\u2019s literally nothing that you do that is not impacted by having the disease, whether it\u2019s deciding to eat or not, whether it\u2019s exercise, whether it\u2019s sleep, whether it\u2019s going to class.\u201d\nFor Herold, the prospect of conducting research had been appealing since his undergraduate years. Throughout his research trajectory, he has always strived to understand the basic mechanisms, causes, and treatments of type 1 diabetes. Herold\u2019s decades-long commitment to the pursuit of scientific advancement in this area began even before the invention of many essential research techniques scientists often rely on today, such as polymerase chain reaction. \u201cAt that time, a lot of what we take for granted now hadn\u2019t even been discovered,\u201d he explained. \u201cImmunology was still in its infancy.\u201d\nThe research leading up to this breakthrough drug began in 1990 for Herold and his colleague, Jeffrey Bluestone, Professor of Metabolism and Endocrinology at UCSF. In his earlier research, Herold had studied autoreactive T cells\u2014a group of immune white blood cells that turn against our own cells and tissues. By looking at them in mouse models with diabetes, he was led to believe that they could cause type 1 diabetes in humans. With researchers at Johnson & Johnson, Bluestone then developed a human drug, teplizumab, that modifies a certain population of autoreactive T cells that play an important role in killing beta cells\u2014the cells that produce insulin in the pancreas. CD3, a T cell receptor, is involved in activating this population of autoreactive T cells. Teplizumab is an anti-CD3 antibody that binds competitively to CD3\u2014an action thought to prevent the receptor from binding to and activating the autoreactive T cells. Teplizumab thus serves as a regulatory immunosuppressant for an overactive immune system, protecting against the depletion of beta-cells that is characteristically seen in type 1 diabetes.\nFrom gold, to dirt, and back\nTeplizumab showed early success in Herold\u2019s first clinical trial in 2002 and was later acquired by biotechnology company MacroGenics. It was also supported by the pharmaceutical company Eli Lilly in phase III clinical trials to evaluate its safety and efficacy. However, this large-scale trial did not end up meeting its target efficacy endpoint, the necessary threshold to move forward. \u201cWhen that happens in the pharma field, it\u2019s a disaster,\u201d Herold explained. \u201cYou\u2019ve basically turned gold into dirt.\u201d\nMacroGenics and Eli Lilly both abandoned the project in 2010, and teplizumab was considered a failure. \u201cThere was nobody willing to pick it up, and we had no support,\u201d Herold said. Knowing that the drug development process requires substantial resources, Herold and his colleagues traveled across the country and even flew internationally to Germany in pursuit of funding and support. Despite teplizumab having favorable mouse and human trial data, every company, foundation, or potential investor declined\u2014for eight years.\u00a0\nFinally, in 2018, Provention, a biotechnology company founded just two years prior, decided to take on teplizumab anew. Herold cites his belief in the promising science behind the mechanisms of the drug in humans as a large motivating factor in his persistence over the eight long years. \u201cThis was literally dead,\u201d he said. \u201cIt just goes to show you that if you think something is really worth doing, you [have] got to stick with it no matter how bad it seems, because one turn of the tide could make all the difference in the world.\u201d\nIn 2019, Herold led a phase II clinical trial, sponsored by TrialNet, testing the effectiveness of teplizumab. He found that it successfully delayed the onset of type 1 diabetes in high-risk patients by approximately two years. Herold then proposed a new question: how does teplizumab affect beta-cell function? \u201cWe ask this question all the time in people who have diabetes, but we really never had the opportunity to answer it in people at risk for diabetes,\u201d he explained. \u201cThey don\u2019t yet have the disease, but we know that they\u2019re going to develop it.\u201d\nDelaying the onset of diabetes\nFor Sims, conducting research was not always a priority. \u201cI always thought I wanted to be a doctor, and I always loved kids, so I thought I was going to be a pediatrician,\u201d Sims said. She found the physiology of endocrinology interesting and intuitive, so she decided to specialize in pediatric endocrinology. She was first exposed to basic science research during these years.\nAlmost immediately, the inherent cross-applications of research and medicine became apparent. \u201cWorking in the lab gave me this really cool opportunity to ask questions that were relevant to what you see in the patients you\u2019re treating,\u201d she said. Referencing a line from Aaron Burr in the musical Hamilton, she explained that research is like \u201cbeing in the room where it happens.\u201d In Sims\u2019 many interactions with children diagnosed with type 1 diabetes, she witnessed the toll of this disease on her patients and their families. \u201cWhen you get that diagnosis, your life changes,\u201d she said.\nHerold and Sims are both involved in the NIH consortium TrialNet. Sims\u2019 expertise studying beta-cells and analyzing metabolic data drew her to join Herold in pursuit of a better understanding of the effects of teplizumab on beta-cell function.\u00a0\nIn their 2021 study, published in Science Translational Medicine this March, Sims and Herold suggested that there is progressive depletion of beta-cells in the years preceding type 1 diabetes diagnosis. During this period, the level of metabolic dysfunction, which is a sign of autoimmunity, defines the stages of the disease. Stage 1 consists of the period before glucose abnormalities arise; stage 2 makes these abnormalities more evident; and stage 3 is the typical definition of diabetes\u2014the phase defined by clinical presentation of high blood sugar.\u00a0\nSims and Herold investigated whether teplizumab would delay stage 3 clinical diagnosis in seventy-six individuals at stage 2 of the disease. They found that a single fourteen-day teplizumab treatment program could have enduring effects: the teplizumab group had a median time of five years before stage 3 onset compared to just two for the placebo group. Moreover, eighteen percent of teplizumab-treated individuals treated were not diagnosed with stage 3 at all in more than five years, which is the time during which follow-up data was being collected, compared to just six percent for the placebo group. The study also found that teplizumab improved beta-cell function, even in individuals who did not develop diabetes. The drug could also reverse declines in insulin secretion.\nSims and Herold\u2019s paper outlined that teplizumab led to an improvement in metabolic responses and delay of diabetes. It is the first drug of its kind to ever do so. \u201cIf you\u2019re eight years old and get treated for the disease, you\u2019re not going to develop it for five years until you\u2019re thirteen,\u201d Herold said. \u201cThe maturation of a child during that period of time is extensive, and you\u2019re probably better able to manage the disease when [you\u2019re] older. Same thing if you\u2019re going into middle school and you\u2019re not going to get it until after graduating high school. That\u2019s a big deal!\u201d\nA game-changer\nThe Food and Drug Administration (FDA) has recently granted teplizumab \u201cBreakthrough Therapy Designation,\u201d which bodes well for its approval this summer. If the drug is approved, an important next step is to identify those who are eligible for and could benefit from the treatment. Sims explained that TrialNet screens the relatives of patients with diabetes, but most people who develop diabetes do not actually have family members with the disease. \u201cWe have to think big: now we have a reason to screen people at risk for diabetes, because there is something we can do about it,\u201d Herold stated.\nCurrent insulin treatments act as retroactive \u201cband-aids,\u201d making it possible for diabetes patients to manage their symptoms and survive. Teplizumab, on the other hand, targets the underlying mechanisms of type 1 diabetes before its onset. This means that it could modify the disease\u2019s trajectory. With teplizumab, the playing field for type 1 diabetes has completely shifted\u2014what was once a waiting game now holds options for delay, or even prevention, of the disease.\nAbout the Author:\nAlex Dong is a first-year student from Canada in Benjamin Franklin college interested in studying Biomedical Engineering and The Humanities on the pre-med track. On YSM, Alex is a copy editor, staff writer, layout designer, photographer, and artist. Outside of YSM, Alex is a Senator for the Yale College Council and a poet for the Yale Layer.\nThe author would like to thank Dr. Kevan Herold and Dr. Emily Sims for taking the time to discuss their experiences and research with him.\nFurther Reading\nHerold, K. C., Bundy, B. N., Long, S. A., Bluestone, J. A., DiMeglio, L. A., Dufort, M. J., \u2026 & Greenbaum, C. J. (2019). An anti-CD3 antibody, teplizumab, in relatives at risk for type 1 diabetes. New England Journal of Medicine, 381(7), 603-613.\nSims, E. K., Bundy, B. N., Stier, K., Serti, E., Lim, N., Long, S. A., \u2026 & Type 1 Diabetes TrialNet Study Group. (2021). Teplizumab improves and stabilizes beta cell function in antibody-positive high-risk individuals. Science Translational Medicine, 13(583).\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/a-breakthrough-therapy-for-diabetes-could-teplizumab-lead-us-to-a-cure-for-type-1-diabetes/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Radio Station at the End of the Universe: Chasing the axion to unravel the mystery of dark matter",
            "author": "Brianna Fernandez",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Dark-Matter-Axions-Alex-Dong-500x347.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Alex Dong.\nThe matter we interact with on a daily basis is known as normal matter. Counterintuitively, this normal matter makes up only about five percent of the universe. Physicists think the rest is composed of two other constituents: dark energy, the force thought to be speeding up the expansion of the universe, and dark matter, an unknown type of matter that only interacts strongly with gravity. Though neither of them can be detected directly, the role that dark energy plays in the rate of the universe\u2019s expansion, as well as the effect that dark matter has on galactic structure, make physicists confident in these hypothesized substances.\u00a0\nSome people wonder how galaxies rotate at a seemingly impossible rate; in theory, they simply could not maintain such high speeds given the masses we detect from Earth. From the perspective of astronomers, galaxies\u2019 low masses could not generate enough gravity to hold them together. Something is giving them extra mass\u2014something undetectable. This is what we have designated dark matter. But what is dark matter, really? What is it made of? Enter the axion.\nResearchers at the Yale Department of Physics\u2019s Wright Laboratory have come together in pursuit of the axion. By looking for this hypothetical particle\u2014which is thought to comprise dark matter\u2014they think it could be possible to find dark matter. Led by fifth-year graduate student Kelly Backes, this group recently published a paper in Nature that reports the use of vacuum squeezing to double the search rate for axions. This process enabled them to circumvent the quantum limit that many dark matter searches can barely approach. By breaking through this limit, rather than merely approaching it, they are ushering in an age in which searches for fundamental physics are less hindered by noise, bettering the chances of the axion\u2019s discovery.\nHiding in Plain Sight\nThis question of missing galactic mass has been pondered by physicists since the 1930s, resulting in a variety of potential candidates for what dark matter could be. \u201cBecause there are so many different options for what could be dark matter, a lot of the well-motivated theories are particles or theories that solve multiple problems,\u201d Backes said. \u201cThere are very few things in physics that just exist for one weird purpose.\u201d One promising dark matter candidate is the axion\u2014a hypothetical particle that was first proposed in 1977 by Roberto Peccei and Helen Quinn. Named after a laundry detergent, the axion was theorized to solve the strong charge-parity (CP) problem of quantum chromodynamics\u2014a problem within the Standard Model of particle physics, in which two fundamental nuclear forces act differently. Later, researchers Steven Weinberg and Frank Wilczek suggested that the axion could also be what makes up dark matter.\u00a0\nAlthough axions are theorized to be infinitesimally small and extraordinarily light, they completely pervade the space which they occupy, existing everywhere and all the time. Their omnipresence makes it more convenient to imagine each axion as a sea of particles that oscillate together rather than as individual ones. With this knowledge in hand, the detectors searching for axions aim to sense them as waves.\u00a0\nWhile we generally think of dark matter in the context of its interactions with gravity, since this is the only way in which we know it exists, dark matter seems to have feeble interactions with other fundamental forces. As a result, some scientists looking for axions do so by detecting their extremely weak interactions with electromagnetism. \u201cIf you supply a magnetic field, the axion field and this magnetic field interact and produce a tiny [bit of] excess electric field that is actually then detectable, and that\u2019s the interaction that we center our detector around,\u201d Backes said. Essentially, axions are detected as excess power in a detector. They react with magnetic fields, yielding small traces of electric field. It is Backes\u2019s job to amplify this electric signal and, from there, detect these evasive axions.\nThe Great Cosmic Radio\nBackes\u2019s research group has spent years searching for this dark matter candidate, analyzing excess power that could be produced by axion waves and a large magnetic field in the hopes of finding the answer to this long-held mystery. \u201cEssentially what we\u2019re doing is operating a really, really, really sensitive radio,\u201d Backes said. The interactions they measure occur inside of a microwave cavity, or a resonator, and when the resonator frequency matches that of the axion field, the interaction is enhanced, amplifying the signal.\u00a0\nWhen you\u2019re flipping through radio stations in the car, you\u2019ll tune to a station, listen to hear if that\u2019s what you want, and tune to the next station until you find what you\u2019re looking for. However, your radio will only pick up a station if it is tuned to the same frequency as the incoming radio waves. In this case, the detector functions similarly to the car radio, and the axion is the station to be detected.\nBut where exactly is the axion station located? As it turns out, it is hard to tell. \u201cYou\u2019re tuning through frequency space, and you\u2019re looking for the only station in the universe, and you have no idea where it is,\u201d Backes said. For now, Backes\u2019s group is searching for axion frequencies at around four or five gigahertz, but the axion could be hiding anywhere on the range of hertz to terahertz\u2014where a frequency of one hertz is one cycle per second, and one terahertz is a trillion times that.\u00a0\nThough the range Backes and her colleagues are investigating is small relative to the orders of magnitude of potential frequencies that surround it, it is strongly grounded in theory. Some groups of theorists have done large-scale calculations that indicate that the axion\u2019s location is likely around the range they are exploring. Experimentally, this range is favorable because the low gigahertz range makes for a nicely sized detector: resonator size is proportional to desired frequency, so a much lower frequency would require an inconveniently large detector. A higher frequency, conversely, would necessitate an exceptionally smaller one.\nThe Coolest Part: Vacuum Squeezing\nThe vacuums physicists use are nothing like the loud cleaning appliances with which most people are familiar. In physics, a vacuum is the absence of matter and energy. It is the ground state of all fields in quantum mechanics, and its energy fluctuates in quantum fluctuations, creating temporary random changes of energy in a point in space. Vacuum squeezing redistributes these fluctuations, enhancing or repressing them along different time intervals. \u201cI think I\u2019m biased, but this is the coolest part of what I\u2019ve done,\u201d Backes said.\u00a0\nWhen conducting any experiment, data is likely to come with noise, which is a result of random variations that interfere with the signal. Like radio static, the electronic noise in axion experiments doesn\u2019t have any specific frequency or phase preference. Since that noise is made of components with different phases, one could mathematically decompose it into terms of more traditional sine and cosine wave patterns. The amplitudes of these sine- and cosine-like components of these fluctuations don\u2019t commute, which is why the noise exists in the first place. \u201cLike the traditional uncertainty relationship between position and momentum, you can\u2019t measure all fluctuations at once without adding noise to your system,\u201d Backes explained. \u201cThat\u2019s where these quantum vacuum fluctuations come in.\u201d\nHowever, it does not matter whether all the phases can be precisely measured in the detector\u2014the way that axion signals are measured does not necessitate it. Instead, physicists squeeze the noise into one \u201cquadrature,\u201d like position and momentum in the previous example, meaning that the sine- and cosine-like fluctuations would be two measurement quadratures.\u00a0\nIf we were to think of noise as a malleable ball, squeezing it would involve taking a round noise state that lacks phase preference and processing it with an amplifier so that it is squeezed into an oblong blob of a noise state\u2014one that has a phase preference. The resonator\u2019s power has no phase preference, so when the newly squeezed state is guided into its cavity, the axion is measured until it no longer has a phase preference either. Essentially, one axion arrives, displacing the squeezed state in one direction, and another follows, displacing it in a different direction. This process molds the squeezed state, and the pattern continues until it is broadened by the displacement.\u00a0\nOnce the squeezed state is slightly fattened, it is read out of the microwave cavity and squeezed in the opposite direction. Flattening the squeezed state amplifies the hypothetical axion signal along the newly shaped quadrature, which is the same quadrature that originally had the squeezed noise. Ultimately, this allows Backes and her team to measure an amplified signal against subquantum limited noise, making it easier to detect axions.\nThis work is revolutionizing the field, which should make the search for axions more efficient. \u201cI think the big impact of this specific paper and this work is it shows for the first time that quantum squeezing can be used as a tool to speed up a full-scale fundamental particle search,\u201d Backes said. As the first experiment to show that one can look for new fundamental particles against a noise background that is below the standard quantum limit, this work is at the forefront of the search for dark matter.\u00a0\nDark matter has eluded physicists for decades, but Backes and her team might have unearthed a faster path to find it with their novel approach to detecting the axion. They have not had luck yet, but their research takes time. For now, they can only continue flipping through galactic radio channels, hoping to find the station at the end of the universe.\nAbout the Author\nBRIANNA FERNANDEZ is a sophomore in Pierson College studying astrophysics. In addition to writing for YSM, she is one of the magazine\u2019s copy editors. Outside of YSM, she researches exoplanets with Professor Debra Fischer and advocates for free prison phone calls with the Yale Undergraduate Prison Project.\nTHE AUTHOR WOULD LIKE TO THANK Kelly Backes for her time and enthusiasm to share her research.\u00a0\nFurther Reading\nBackes, K. M., Palken, D. A., Al Kenany, S., Brubaker, B. M., Cahn, S. B., Droster, A., \u2026 & Wang, H. (2021). A quantum enhanced search for dark matter axions. Nature, 590(7845), 238-242.e\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/the-radio-station-at-the-end-of-the-universe-chasing-the-axion-to-unravel-the-mystery-of-dark-matter/",
            "captions": [
                "Dark Matter Axions. Art courtesy of Alex Dong"
            ]
        },
        {
            "title": "Generating Randomness: A Laser-Based Scramble for Random Numbers",
            "author": "Alexa Jeanne Loste",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Random-Number-Generator-Elaine-Cheng-466x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Elaine Cheng.\nWhen you play the violin, you can trace back its sound to the vibration of its strings. These energy vibrations\u2014the sound waves\u2014transfer from the strings to the violin\u2019s bridge, and then to its body, eventually vibrating the air before reaching our ears as sound. The hollow wooden body serves as a resonator for acoustic waves. Its shape is tailored to resonate with many acoustic frequencies, producing the rich, resonant quality of sound that we appreciate as music.\nThis is how Hui Cao, John C. Malone Professor of Applied Physics and of Physics at Yale, explained the design of a new laser developed in her lab. Her team is leveraging this innovative technology to generate random numbers at revolutionary speeds.\nIn an article published in Science on February 26, Cao and her collaborators wrote about their new laser design with a random bit generation (RBG) rate of two hundred fifty terabits per second\u2014faster than existing versions by more than a hundredfold. Functioning by a completely different mechanism, their laser uses many different channels to generate random numbers in parallel, while increasing the RBG rate of each individual channel.\nLike the sound waves produced by a violin string that are amplified in the wooden body, the laser produces light waves that are amplified in an optical resonator, which Cao designed in a bow-tie shape. This shape allows the laser to resonate with many optical modes of different frequencies, analogous to the multiple tones of a violin string. \u201cThe breakthrough is a different mechanism,\u201d Cao said. Whereas conventional lasers only have one or a few modes, the many modes of this new laser can interfere with each other to create complex spatio-temporal patterns\u2014which is where the randomness originates.\nLeveraging Lasers for Cybersecurity\nDoing basic research in understanding complex laser behaviors opens up the possibility for a multitude of applications, some of which come in unexpected forms. \u201cThe original goal was not generating random numbers, but just changing the shape of the cavity and studying the laser dynamics,\u201d said Kyungduk Kim, a graduate student in Cao\u2019s group. Cao explained that by working with more complex laser designs, her lab is tapping into potential new functions of lasers. \u201cLasers are probably one of the most important inventions in science and technology in the last century,\u201d Cao said.\u00a0\nAmong all the potential applications of lasers, random number generation represents a particularly important one. In a world increasingly dependent on digital communication and exchange, random number generation is integral to ensuring online security. One ubiquitous example is in the creation of encryption keys\u2014used to scramble private information such as passwords, banking information, or messages to prevent them from being intercepted when sent through online channels, like emails. The random quality of the selected key is integral to preventing potential attackers from breaking into messages and stealing information. Predictable keys, or even keys based on sophisticated algorithms whose pattern can be uncovered, could leave sensitive private data vulnerable.\nAdditionally, random numbers have a variety of applications in scientific research. The modelling of stochastic processes that involve random probabilities, such as the spreading of viruses or fluctuations in the stock market, relies on streams of random numbers that can simulate the unpredictability of these systems. Statistical analysis also relies on random number generation to choose random samples from a population in order to prevent biases that may make the analysis less reliable.\nLaser-to-Randomness Fundamentals\nNot even the most powerful supercomputer can generate true random numbers on its own. This is because computers run on algorithms, and any finite algorithm will eventually loop back and repeat itself, yielding a specific pattern of outputs. To generate true randomness, one has to rely on external physical sources of entropy, or naturally occurring disorder in the universe. Through monitoring systems that have dynamics that cannot be predicted, they can be used as a source of randomness. One way that scientists have done this is by using lasers.\nLight waves in the lasers that the researchers work with, called broad-area semiconductor lasers, often naturally experience irregular fluctuations from the interaction of light with the lasing medium. Previously, researchers leveraged this property of light as a source of randomness, translating fluctuations of light intensity into zeros and ones. The randomness comes from the chaotic pattern of the stream of bits generated. However, there is a limit on how quickly those lasers can generate random number streams. This depends entirely on how fast the fluctuations occur. To increase the RBG rate of a laser beyond that limit, one would need to either increase the number of bit streams generated in parallel or use a new mechanism as a source of randomness that has faster dynamics. The Yale team\u2019s new laser does both.\nImprovements in Quantity and Quality\nPreviously implemented lasers had flat edges. With this conventional shape, laser intensity fluctuations were correlated with both time and space, limiting the lasers\u2019 effectiveness: correlations over time decrease the quality of the randomness sampled from a single location, and correlations over space decrease the number of different locations one could measure to get random numbers.\nBy curving the edges of the laser cavity, Cao and her collaborators were able to substantially increase the number of lasing modes (think: violin string tones). \u201cWhen you have this curved edge, the light can come out at many different spatial locations,\u201d Cao said. \u201cWhen you measure the intensity at each spatial location, these intensities will fluctuate in time.\u201d By recording output from multiple positions simultaneously, they could use the laser to generate multiple random number streams in parallel.\nIn addition to inducing multiple RBG streams at once, the new laser also enhances the random bit generation rate of every individual stream by using a new mechanism. Whereas conventional chaotic lasers rely on the irregular fluctuations on a time scale set by their response time to extract randomness, the research team\u2019s laser uses a different source of randomness: the interference of the multiple lasing modes.\u00a0\nSince the light waves in each mode have different frequencies, by summing them up at different points in space and time\u2014that is, their spatio-temporal interference\u2014the researchers could use the variation in interference intensity as a source of randomness. Because the interference pattern fluctuates much faster than the emission from chaotic lasers, it can generate random numbers at a much faster rate.\nBreaking into a New Field\nCao mentioned that this project was her lab\u2019s first venture into the field of random number generation, and they did not have any previous experience or connections to other researchers in the field. Having realized that her work could be applied to a new mechanism for random number generation, she assembled an interdisciplinary team to study techniques including translating measured intensities into digital bits and quality testing random numbers. \u201cWe learned a lot through this adventure, and I think that is how scientific research gives us a lot of surprises. And sometimes, we also get some reward,\u201d Cao said.\nTo get published in a scientific journal, every article must undergo a thorough review process in which peer researchers in the field must provide feedback on the work. \u201cThe reviewers of our papers \u2026 were very critical and made sure we did everything right,\u201d Cao said. \u201cOn the other hand, they really helped us by suggesting the additional tasks we need to do to convince people our method works.\u201d Cao cited the support received from the random number generation community, which was helpful to her team as they broke into the field.\nKim also attested to the important role of collaboration in the project. \u201cIt was very lucky that I met good collaborators,\u201d Kim said. Researchers from Nanyang Technological University in Singapore built the lasers that the Yale team designed, which are cutting-edge chip-scale lasers fabricated on a semiconductor wafer. Kim also emphasized that his work directly built upon the work of previous researchers in the lab, highlighting the cumulative process of building knowledge in the scientific field.\nScaling Down to Scale Up\nLooking forward, the next challenge facing this new laser is integrating the system into a smaller medium, such as a chip. In this study, to measure the spatiotemporal interference of the light waves (the source of randomness), a special camera was used. This streak camera measured the light emission at an extremely rapid rate, recording an image of the emission every picosecond, resulting in one image produced per every trillionth of a second. A resolution this high comes with a steep cost, so the camera is primarily used by researchers. Additionally, its bulkiness presents a hurdle to wide-scale adoption. Taking the new laser forward would require engineering laser chips with integrated photodetectors.\u00a0\nNevertheless, the work done by the Yale researchers takes the field of random number generation a step forward\u2014or in this case, two whole orders of magnitude forward. For Cao, the potential of basic research to be leveraged into concrete applications inspires the team to continue studying the complex physics of laser dynamics.\nAbout the Author:\nAlexa Jeanne Loste is a first-year prospective Molecular Biophysics & Biochemistry major in Ezra Stiles College. In addition to writing for YSM, she is a project head for GREEN at Yale, a member of the Environmental Education Collaborative, the STEM Panel Chair for the Conference Committee of the Women\u2019s Leadership Initiative, and a copy desk staffer at the Yale Daily News.\nAcknowledgments:\nThe author would like to thank Kyungduk Kim and Dr. Hui Cao for their time and enthusiasm in sharing their research.\nExtra Reading:\nKim, Kyungduk, Stefan Bittner, Yongquan Zeng, Stefano Guazzotti, Ortwin Hess, Qi Jie Wang, and Hui Cao. 2021. \u201cMassively Parallel Ultrafast Random Bit Generation with a Chip-Scale Laser.\u201d Science 371 (6532): 948\u2013952.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/generating-randomness-a-laser-based-scramble-for-random-numbers/",
            "captions": [
                "Random Number Generator - Elaine Cheng"
            ]
        },
        {
            "title": "Tracking Down Lethal Mosquitoes: Machine learning to map the genetic connectivity of A. aegypti in the southern United States",
            "author": "Elizabeth Wu",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Tracking-Mosquitos-Noora-Said-500x311.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Noora Said.\nWith global temperatures reaching record highs over the last few years, climate change has expanded the ranges of disease-carrying animals. Even tiny insects, such as Aedes aegypti mosquitoes, which are native to Africa, are not exempt from this trend. Because of their highly invasive nature, recent increases in global temperatures have allowed the range of A. aegypti to continue expanding worldwide, throughout tropical and temperate regions. In the United States, they can be found in the southern states, most notably in Texas, Florida, and California. They prefer warm, humid areas close to humans who can serve as sources of bloodmeals for female mosquitoes. Feasting on our blood provides not only a means for A. aegypti to nourish themselves, but also allows them to transmit infectious diseases like yellow fever, Zika, dengue, and chikungunya.\u00a0\nCurrent climate trends could result in the exposure of one billion additional people to these diseases. The fact that, with the exception of yellow fever, there are no reliable and widely used vaccines for these diseases creates an urgent need for improved tracking and management of A. aegypti populations. Two scientists at the Yale School of the Environment\u2014Evlyn Pless, a postdoctoral researcher at UC Davis who completed her graduate studies in ecology and evolutionary biology at Yale, and Giuseppe Amatulli, a research scientist in geocomputation and spatial science\u2014collaborated on a recent study to tackle this pressing environmental issue. Their goal was to map North American landscape connectivity for A. aegyti mosquitoes.\nOld Limitations in Landscape Genetics\nLandscape genetics, which is the study of organisms\u2019 population genetic data alongside landscape data from their habitats, provides scientists with helpful information that could be used to control invasive species, such as A. aegypti. Classical models of population genetics relate increased genetic differentiation to increased geographical distance, but these models do not account for environmental limitations on dispersal, such as geographic barriers, or for landscape variables that facilitate connectivity, like favorable climate.\nA common approach to incorporate environmental data into a model of genetic connectivity is \u201cresistance surface mapping.\u201d In this technique, a map of pixels is created where each pixel represents the hypothesized resistance of an organism\u2019s movement. These hypotheses consider environmental variables. But although the resulting map of resistance surfaces allows for extrapolation of genetic distributions across the region, this method involves substantial subjectivity, as it relies on the hypothesized effect of an environmental factor on population mobility.\u00a0\nPrior studies attempted to circumvent the subjectivity of resistance surface mapping by modelling genetic connectivity directly from environmental data and iteratively refining the model using least cost path analysis, a mathematical technique that estimates the least resource-intensive route along which an organism could travel. However, according to Amatulli and Pless, this model was limited because it employed a mathematical method known as maximum likelihood estimation, which establishes a relationship between environmental variables and genetic distances before the model is built. The model produced by this methodology can therefore \u201coverfit\u201d the data: while it may have been optimized to match the data, it does not necessarily make accurate ecological estimations.\nA New Approach to Modeling\nTo improve upon these previous models, Pless and Amatulli took a groundbreaking approach towards determining the relationship between landscape variables and genetic distance. First, they sampled mosquitos from thirty-eight sites across North America and calculated the genetic differences between mosquitoes in each of those sites. Open-source data for twenty-nine different environmental factors, such as daily temperature ranges and accessibility to major cities, served as variables meant to explain and predict genetic distances. For every pair of sites in the set of thirty-eight sampling sites, the researchers calculated average values describing each of the twenty-nine environmental factors that lay in between.\u00a0\nUsing those values on genetic distances and environmental factors, Pless and Amatulli employed a fascinating strategy to predict the effects of landscape conditions on genetic connectivity: they used a machine learning method called a random forest (RF)\u2014a predictive model based on aggregations of possible effects of different factors\u2014to create landscape resistance maps. In doing so, they generated a map representing landscape resistance, which measured the difficulty of mosquito migration at any particular point based on all of the twenty-nine environmental factors combined.\nUsing the resistance map built by RF, least cost paths were drawn between each pair of thirty-eight sampling sites. These paths describe the least energetically expensive routes between sites that could be taken by mosquitoes over a particular landscape. Then, multiple iterations of this process were conducted by generating more resistance maps via RF and subsequently re-calculating least cost paths. As a result, the model refined itself with each subsequent iteration, producing increasingly accurate predictions of mosquito genetic connectivity based on landscape data.\u00a0\nCompared to previous landscape genetic models, one distinct advantage of RF is its resistance to overfitting\u2014the model produced by RF is not overly sensitive to noise in the data that it was trained on. To test if their model overfit the data, Pless and Amatulli conducted \u201cleave-one-out cross-validation,\u201d meaning that the model was run thirty-eight times, each time leaving out one of the thirty-eight genetic data points.\u00a0\nResults generated by this cross-validation process were comparable to the results from a model based on a full data set, demonstrating that the model was not overfitting the data. In fact, leave-two-out cross-validation was also conducted, which further demonstrated that the model did not overfit the data and could accurately predict genetic distances.\nBut while this novel iterative approach combined with RF did, in fact, prove to be effective, it was initially time-consuming. To address this, the researchers decided to use GRASS\u2014a geographic information system software\u2014in addition to R, a statistical computing environment. \u201cWe wrote everything first in R, but it was not fast enough to do all the iterations, so then we used GRASS to build cost paths analysis\u2026 and we conducted the machine learning part in R, allowing us to speed up the process from twenty-four hours to one or two,\u201d Amatulli said.\nThe researchers had successfully constructed a model that predicted genetic distances based on landscape data more accurately than previous models. This meant that they could track the movements of A. aegypti mosquitoes based on the idea that landscapes facilitating the animal\u2019s movements allow for greater genetic connectivity. Inversely, they could also consider the possibility that landscape barriers result in greater genetic distances due to lower movement.\u00a0 Interestingly, of the twenty-nine environmental variables tested, the researchers discovered that maximum temperature was the most important in predicting genetic connectivity, followed by slope, barren land cover, and human density.\nA Tool for Ecological Intervention and Protection\nThe novel model of A. aegypti landscape genetics is important because it accurately predicts the genetic connectivity\u2014and thus the mobility\u2014of mosquitoes in regions where samples were not taken and genotyped.\u00a0\nThe broader implications of tracking mosquitos with such accuracy involve recently developed methods of disease control. A prime example of this is releasing genetically modified mosquitos that will prevent wild mosquito populations from reproducing. This kind of model provides valuable knowledge about where the mosquitoes should be released and how far the intervention will spread. Another potential application is demonstrating the effects of pesticide application, which would cause natural selection of mosquitoes with pesticide-resistant genes. In theory, the model could be used to predict where those genes would prevail.\nBeyond mosquitoes, this study\u2014with its iterative RF methods\u2014is an innovative step forward in the field of landscape genetics. The novel strategies that were employed could help protect corridors for vulnerable animal populations. \u201cWe hope this paper will be inspiring to people, more broadly, who are trying to control invasive species or who are trying to protect endangered species,\u201d Pless said.\nAcknowledgements: The author would like to thank Evlyn Pless and Giuseppe Amatulli for their time and enthusiasm about their research.\nElizabeth Wu is a freshman in Saybrook College. In addition to YSM, she is an intern for the New Haven Public School Advocates through Yale\u2019s First Years in Support of New Haven.\nBibliography:\nPless, E., Saarman, N. P., Powell, J. R., Caccone, A., & Amatulli, G. (2021). A machine-learning approach to map landscape connectivity in\u00a0A. aegypti\u00a0with genetic and environmental data.\u00a0Proceedings of the National Academy of Sciences of the United States of America,\u00a0118(9), e2003201118. https://doi.org/10.1073/pnas.2003201118\nExtra Reading:\u00a0\nBishop, A., Amatulli, G., Hyseni, C., Pless, E., Bateta, R., Okeyo, W. A., \u2026 & Saarman, N. P. A machine learning approach to integrating genetic and ecological data in tsetse flies (Glossina pallidipes) for spatially explicit vector control planning. Evolutionary Applications. https://doi.org/10.1111/eva.13237\u00a0\nZhao N, Charland K, Carabali M, Nsoesie EO, Maheu-Giroux M, Rees E, et al. (2020) Machine learning and dengue forecasting: Comparing random forests and artificial neural networks for predicting dengue burden at national and sub-national scales in Colombia. PLoS Negl Trop Dis 14(9): e0008056. https://doi.org/10.1371/journal.pntd.0008056\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/tracking-down-lethal-mosquitoes-machine-learning-to-map-the-genetic-connectivity-of-a-aegypti-in-the-southern-united-states/",
            "captions": [
                "Tracking Mosquitos - Noora Said"
            ]
        },
        {
            "title": "2D Solutions to 3D Problems: Studying the electrical properties of altered 2D materials",
            "author": "Catherine Zheng",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/2D-Solutions-for-3D-Problems-Sophia-Zhao-386x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Electronics are ubiquitous in our everyday lives\u2014they are in the cars we drive, the microwaves that heat up our food, and the computers we use. This omnipresence is due to technology\u2019s constant evolution. Currently, unbelievably complex technologies can be found in even common devices, such as our cell phones. The creation of materials that are elaborate in their complexity but simple in their design\u2014and can thus be implemented into many technological devices\u2014sits at the intersection of electrical engineering and materials science.\nJudy Cha, Yale Professor of Mechanical Engineering and Materials Science, has led her lab in important work within these fields. Her team focuses on discovering new layered materials that can be used in electronics. Through manipulating their electrical properties, they seek to understand more about the materials themselves and how they can be used. The team hopes to elucidate which materials might be particularly ideal for a certain electronic device, as well as how the materials\u2019 performance can be improved by altering electrical properties.\nIn the beginning of 2021, Cha\u2019s group and its collaborators published two studies: one focusing on the mechanical properties of graphene with lithium between its layers, and the other on molecular doping\u2014the addition of small molecules to materials to activate them for use in electronics.\nLithium-Ion Batteries\n2D materials are usually approximately one to three atoms thick. They come from layered materials that are exfoliated down to a single layer. The properties of 2D materials normally change when their layers are isolated. Graphite, commonly found in pencil lead, is a classic example of this: graphite consists of layers of graphene, and the individual graphene layers have properties that differ substantially from those of graphite as a whole. To harness such materials for device applications, it is important to understand these thickness-dependent changes.\u00a0\nLithium intercalation into graphite\u2014or, the insertion of lithium between layers of graphene that are held together by van der Waals (vdW) forces\u2014is essential to create lithium-ion batteries, which power many of our modern electronics. Staging, or structural ordering, minimizes electrostatic repulsions within graphite\u2019s crystal lattice, allowing lithium to order itself between the van der Waals gaps of graphene. Initially, lithium is randomly distributed throughout the graphite, but as the lithium concentration increases, there\u2019s a phase transition where lithium moves laterally to form intercalated regions that are vertically separated by unintercalated regions. The kinetics of lithium moving between the sheets of graphene are directly related to how well the battery performs.\nThis staging process is well understood for bulk graphite, which is thick. But on a nanoscale, the way lithium and graphene are confined so closely together affects the overall structure. As lithium makes its way between vdW gaps, these gaps expand to accommodate the new atoms. However, anchoring graphene sheets by clamping the edges down changes the way lithium interacts with the graphene. This constrains how much the graphene is able to open, and it requires more work for lithium to squeeze into those gaps. The kinetics of lithium diffusion are also slowed down, since it becomes more difficult for lithium to move between the graphene sheets.\nThe effect of this mechanical strain sparked the interest of Cha\u2019s group. To investigate it further, they used thin sheets of graphene\u2014between four and fifteen layers thick\u2014with gold electrodes on top that acted as a clamp. Although these electrodes were only one-hundred nanometers thick, each layer of graphene was even thinner: one-third of a nanometer. The difference in size allowed the gold to act as a source of pressure and hold down the ends of the graphene sheets.\nBut as they observed this configuration, the group realized that, while the edges of the graphene sheets stayed still, the center would expand freely, stretching in both the x and y directions and causing strain in the graphene. \u201cInterestingly, what we found is this strain can delay the lithiation kinetics of graphene,\u201d said Josh Pondick, a PhD candidate in Cha\u2019s lab and one of the lead researchers for this experiment\u2014lithiation referring to the process by which a lithium ion replaces hydrogen atoms.\nThe team looked at these properties in different thicknesses of graphene with in situ Raman spectroscopy, a method that provides molecular-level information about material surface structures based on light scattering. They found that, as the thickness of graphene increases, staging is delayed, requiring more electrochemical voltage to be induced.\u00a0\u00a0\nA major obstacle in this study arose while dealing with lithium, since it is a rather flammable chemical. Lithium-ion batteries are typically assembled in glove boxes filled with an inert, unreactive gas. However, to experimentally monitor things like electrical properties, the lithium had to be taken out of the glovebox. \u201cWe spent quite a bit of time trying to devise device geometry and architecture that would allow us to contain all of these volatile chemicals inside a small pouch while we could still safely take it out and do the types of measurements that we wanted to do,\u201d Cha said. But even with these tricky chemical properties under control, simply handling these materials was a challenge due to their small size. The flakes of graphene are on the order of ten to thirty microns\u2014about the real-life size of a white blood cell. Thus, techniques in lithography, a special form of printing, were required to add the gold electrodes.\nWith the push for new kinds of batteries that use metals like magnesium and sodium rather than lithium, there are plans to see the results of these different kinds of atoms being intercalated in graphene. These atoms are bigger and will undoubtedly provide a larger mechanical strain. Given how strong graphene is, researchers are also considering looking into new materials\u2014notably heterostructures that consist of multiple layers of different 2D materials. Adding intercalants could allow scientists to tune the electrical and chemical properties of these structures to be used in many different devices, from optoelectronic to logic devices.\nMolecular Doping\nAlongside the research on lithium-ion batteries and graphene, Cha\u2019s group also published a study on molecular doping. An example of molecular doping is adding boron or phosphorus to silicon, which activates silicon so that it can be used in electronics. This is particularly useful for transistors, which are an important component of computers.\nAdding impurity atoms to a 2D material like molybdenum sulfide (MoS2) is not as simple as doing so to a single layer of inactive atoms. The method used in this study involved sprinkling molecules on top of the 2D material. The molecules readily gave away electrons to the material, slightly altering its properties. For this particular study, a synthetic organic molecule known as DMAP-OED was added to MoS2. To evaluate the effect of this compound on the 2D material, the number of electrons donated from it to the material was investigated.\nFinding the proper technique to do this proved to be an arduous process. Given the small size of the molecules, optical microscopes would be useless. Although electron microscopes have higher resolution, they would also be ineffective, since they would burn through all the molecules. Alternative spectroscopy techniques were also considered, but they were too crude to properly count the number of molecules. In the end, Cha\u2019s group landed on atomic force microscopy. This method, which uses a sharp tip to scan a surface by interacting with it and tracing its topography, allows for high resolution of small objects.\nUltimately, Cha\u2019s group found that DMAP-OED donates 0.63 to 1.26 electrons per molecule to MoS2\u2014record molecular doping levels.\u00a0\nThis work represents one of the first experiments of such a nature done with an organic electron donor. Thus, it will likely lead to the development of more organic electron donors beyond DMAP-OED for this purpose. Moving ahead, Nilay Hizari, Yale Professor of Chemistry and the collaborator involved in the making of DMAP-OED, looks forward to better understanding molecular doping levels in the context of other molecules and materials. \u201cNow, there\u2019s a whole range of small molecules we could try on [those] 2D materials to get some kind of desired property,\u201d he said.\u00a0\nAbout the Author:\nCatherine Zheng is a sophomore BME major in Pauli Murray College.\u00a0 In addition to writing for YSM, she\u2019s involved in research and other organizations on campus like WGiCS.\nAdditional Reading:\nPondick, J. V., Yazdani, S., Yarali, M., Reed, S. N., Hynek, D. J., & Cha, J. J. (2021). The Effect of Mechanical Strain on Lithium Staging in Graphene. Advanced Electronic Materials, 7(3), 2000981. doi:10.1002/aelm.202000981\nYarali, M., Zhong, Y., Reed, S. N., Wang, J., Ulman, K. A., Charboneau, D. J., . . . Cha, J. J. (2020). Near\u2010Unity Molecular Doping Efficiency in Monolayer MoS 2. Advanced Electronic Materials, 7(2), 2000873. doi:10.1002/aelm.202000873\u00a0\nAcknowledgments:\nThe author would like to thank Professors Judy Cha, Nilay Hizari, and Josh Pondick for their time and enthusiasm in sharing their research.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/2d-solutions-to-3d-problems-studying-the-electrical-properties-of-altered-2d-materials/",
            "captions": [
                "2D Solutions for 3D Problems - Sophia Zhao"
            ]
        },
        {
            "title": "ASIA: Assessing Social Identities",
            "author": "Tejita Agarwal",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/ASIA-scimag_-Malia-Kuo-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Malia Kuo.\nThe various groups we belong to are at the heart of our human identities. These social identities shape who we are and influence everything from our individual actions to our shared interactions. We behave in accordance with the norms of the groups we identify with, with group memberships that are dynamic. This means that our social identities are context-dependent; at any moment, the group membership that is psychologically salient for a person can change. In other words, our actions and interactions often conform to the norms of the group we identify with at a particular instance.\u00a0\nThis prompts questions about our social identities: what factors determine which groups we identify with? How do we switch between our different identities, and how do we deal with competing identities? The major roadblock to studying these concepts is that social identity salience is difficult to assess, especially in a natural setting. Researchers face obstacles and uncertainties in determining which identity is guiding someone\u2019s actions and interactions at a given moment.\u00a0\nIn a creative attempt to address this, researchers from the University of Exeter in the United Kingdom recently developed an analytical protocol, ASIA (Automated Social Identity Assessment), that uses linguistic indicators in text to infer salient group membership at a particular moment.\u00a0\n\u201cSalience is a very dynamic thing, so it can switch very quickly,\u201d said Miriam Koschate-Reis, the lead researcher for this project. \u201cIf my little girl runs through here, then I can very quickly switch to being a parent and back to being an academic. It\u2019s very fast switching, and we haven\u2019t really looked much at these switches.\u201d (Ironically, seconds after she said this, her little girl did run through the room.)\nIn the past, researchers have attempted to use self-reporting as a way of assessing salient social identity. However, self-report measures are not very useful for studying temporal dynamics of social identities in natural settings, nor are they reliable for studying long periods of time, because they provide relatively limited datasets. Additionally, if someone is asked to self-report their \u201cmain\u201d social identity at a particular moment, they may lack the introspection to actually answer the question. For example, take a moment now to try to identify your salient social identity\u2014student, feminist, daughter, etc. It is quite difficult.\u00a0\nIn contrast, ASIA relies on computational linguistics and uses a binary classification model in order to determine which of two social identities is salient in a person at a particular moment. ASIA makes use of linguistic indicators, because sociolinguistic theories assert that both vocabulary and stylistic choices are affected by social variables and groups. Linguistic information has been established as a reliable way to determine group classification and identification. Additionally, there is a wide availability of useful data in the form of written text in online forums, which makes models that focus on linguistic styles convenient and desirable.\u00a0\nHowever, this data use doesn\u2019t come free of concerns. While developing the ASIA protocol, the researchers made sure to center ethical considerations\u2014mainly the ethical implications of assessing specific social identities in the first place, as well as of using online data to train and validate the model.\u00a0\n\u201cIt\u2019s quite tricky when you\u2019re almost looking into people\u2019s minds. \u2026. . .\u00a0 that\u2019s why we really felt strong about writing and putting ethics first to say, if you want to develop this tool, please think carefully about the ethics of it,\u201d Koschate-Reis said.\nKoschate-Reis and colleagues concluded that researchers have a responsibility to consider any foreseeable harm to individuals, especially those whose identities may expose them to discrimination and ostracism. They explained that public online forums are perhaps a more ethical source of data than social media platforms where users face difficulty or confusion in selecting appropriate privacy settings. Public online platforms generally have anonymous users with little personal identifying information.\u00a0\nAfter training and testing their program, the researchers concluded that ASIA provides a mechanism to assess salient social identities using naturally occurring data at a scale large enough to investigate salience within a person over time. This step is essential in investigating how people switch between different identities and when those identities come about. For example, consider: when does someone start to identify themselves as a parent? Is it when they become aware of pregnancy, when they are buying child-raising materials, or when the baby is actually born? The ASIA protocol gives researchers a reliable way to seek answers to these questions, furthering the general effort to learn about our social identities in natural social settings.\u00a0\nCitation:\nKoschate, M., Naserian, E., Dickens, L., Stuart, A., Russo, A., & Levine, M. (2021). ASIA: Automated social identity Assessment using linguistic style. Behavior Research Methods. doi:10.3758/s13428-020-01511-3\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/asia-assessing-social-identities/",
            "captions": [
                "Art courtesy of Malia Kuo"
            ]
        },
        {
            "title": "Beauty is in the Eye of the Beholder",
            "author": "Lauren Chong",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/beauty_in_the_eyes_of_the_b-Cecilia-Lee-386x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Cecilia Lee.\nLeft. Right. Left. Right. We\u2019re swiping on Tinder, a social network dating app where users swipe left on users they find unattractive and right on users they find attractive. During these split- second glances at pictures, we know instantly when we find someone good-looking. Generally, when we make these judgements about others, we do not think about the specific attributes that make them attractive. Our individual preferences for beauty all come down to subtle subconscious preferences in our minds shaped by sociocultural influence, background, age, and gender. How, then, do we define beauty?\nResearchers at the University of Helsinki designed an innovative method at the intersection of computer science and psychology to investigate the human brain and its interpretation of attractiveness. With novel generative brain-computer interfaces (GBCI) technology, psychologist Michiel Spape and computer scientist Tuukka Ruotsalo studied the computer\u2019s potential to identify facial features that participants consistently found attractive, as measured by spikes in brain signals. With this data, the computer then generated new images of faces that the participant was likely to find attractive, thus interpreting each individual\u2019s personal preference based on brain signals.\u00a0\n\u201cThe point is that most of computer vision and AI is busy with the question of detecting what is in a picture: who\u2019s the person, what kind of person is it, and so on. Our work is focused on how humans respond to the picture, what feelings are evoked in them, and what kind of subjective perceptions do different individuals get from looking at the picture. So, by feeding this information back into the AI, we teach train the machine about what it is like being human, while at the same time, we gain a unique insight into what being human even means,\u201d Spape said.\u00a0\nIn a session with thirty participants, the researchers formulated a setup similar to Tinder, in which the participants were shown a series of images derived from a generative adversarial neural network (GAN) that used a dataset to create zillions and zillions of different images that looked like they could be of celebrities. These images were artificially engineered from real celebrity images. Instead of having participants swipe right as Tinder users normally would when faced with an attractive image, researchers simply used brain activity measuring caps to track brain activity, which was then analyzed by electroencephalography (EEG). The EEG was connected to the GAN: every time the participants\u2019 brains demonstrated a positive reaction towards a specific image, the GAN generated more images that the participant was likely to find attractive.\nIn the second half of the experiment, the participants were invited back for a double-blinded controlled experiment and instructed to rate their GAN-generated photos in terms of attractiveness. The participants found that around 80% of the photos generated suited their personal preferences, significantly far above control conditions.\u00a0\nInterestingly enough, the participants would not be explicitly rude about the faces generated when asked about their attractiveness, despite knowing they were AI-generated images and not real ones. Generally, the negative responses fell into one of three categories: participants often blamed their personal preference for their lack of attraction to the face (clarifying that they might not find it attractive but others might), associated the face with negative personality traits (for example, stating, \u201cHis smile . . . too bossy\u201d), or blamed the source material for their lack of attraction. These interviews were conducted after the big reveal, ensuring its blind procedure.\u00a0\nNevertheless, while the participants downplayed their unattraction towards certain images during the second half of the experiment, they generally reacted positively to the GBCI-generated images. Overall trends showed a general preference for blonde hair and youthful faces for male participants. Female participants often linked age with facial features. For example, a lack of a beard was associated with a youthful appearance and a lack of hair was associated with age.\u00a0\n\u201cThe interview tells us that while obviously they explain their attractiveness decisions first as a pretty objective process of checking against readily identifiable [physical] features, like hair color, age, and so on, they continue in more psychological explanations of their preference\u2014\u2018This person looks kind.\u2019 This ascribing of humanity continues all the way to the extent that they even expressed resistance in saying anything rude to an image,\u201d Spape said.\u00a0\nThe ability of the GAN to recognize implicit preferences within the human brain demonstrates the advances of computer technology. AI can potentially model individual human behavior, including latent mental functions, meaning those that do not require conscious thinking. In this way, computer technology can potentially decode the inner workings of the human brain, diving deep into our deepest thoughts and perceptions.\u00a0\nSpape hopes to move the study beyond its current application to reveal insights into other core human behaviors, such as implicit biases or stereotypes. Since the computer has shown the capability to \u201cdecode\u201d attractiveness, a mental process people themselves do not fully understand, its potential to analyze implicit biases and stereotypes\u2014other mental processes we do not explicitly think about\u2014is huge.\u00a0\nFrom the computer science perspective, Ruotsalo strongly believes that the ability of the computer to recognize human perspectives can be used to add a touch of creativity to technology.\u00a0\n\u201cIt\u2019s very exciting to see that computers can actually capture something much more complex than a command. We can make them understand something that is subjectively important for people, and allowing this generative loop takes this [technology] towards something that could support creativity, rather than just transmitting a command,\u201d Ruotsalo said.\u00a0\nHowever, there are some limitations to the study that may not exactly replicate results in real life. Ruotsalo recognizes the limitations of using a database of celebrities for generating the images. \u201cI think it has both pros and cons. The training data is made up of supposedly generally attractive-looking people, which makes it more challenging to personalize. . . . it\u2019s not representing the overall population,\u201d Ruotsalo said. Additionally, the data set does not account for a diverse array of ethnicities due to the inherent limitations of the celebrity dataset.\u00a0\nSince the study focuses on the intersection between humans thinking and computer science, Spape also recognizes the limitations of applying computer-based thinking to real-life applications. \u201cAs a psychologist, it would be great if we could say that [what] we are finding is actually a perfect match for a mental model. We know that to some extent we are finding something certainly related to a mental \u2018picture,\u2019 but that might also be some sort of local optimum. Another question is, of course, whether we can get further than just attractiveness, and study also other aspects of social perception as well,\u201d Spape said.\u00a0\nNevertheless, with the potential to decipher other aspects of human preference, the GBCI technology reveals more about the human psyche than ever. In the future, the technology could lead to the advent of other new innovations, including artificial intelligence to find implicit biases behind behavior and psychology.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/beauty-is-in-the-eye-of-the-beholder/",
            "captions": [
                "Art Courtesy of Cecelia Lee."
            ]
        },
        {
            "title": "Migratory Strategies: Past, Present, and Future",
            "author": "Madison Houck",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/migratory-strategies_AL-AnMei-Little-375x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of AnMei Little.\nIn the coldest depths of winter, many of us spend our hours wishing we could move somewhere warmer. Luckily for them, many species of birds have perfected this process. Birds\u2019 seemingly intrinsic ability to navigate has always left us with more questions than answers, especially now as climate change threatens the migration routes and survival of many avian species. To investigate the formation of migratory patterns across thousands of years, and to demystify the relationship between climate and migration, a research team from the Chinese Academy of Sciences collected migratory data to model the effects of rising global temperatures on migratory strategies in years to come.\u00a0\nThe peregrine falcons studied here typically live and breed in the Arctic, but every September they embark on a month-long journey to find solace (and warmth) during the winter. These \u201cwintering locations\u201d are mostly located in tropical or temperate areas. In order to study current migration patterns of these falcons, the team strapped satellite trackers to the backs of forty-one peregrine falcons and sent them on their way, monitoring their locations for an entire year. Birds that were tracked for more than this one-year period returned to the same migratory route year after year, settling in the same location each October. Additionally, it was determined that birds from the same population migrated using similar pathways, but not all peregrine falcons wound up in the same wintering areas. This is referred to as \u201cindividual migration\u201d\u2014different populations of peregrine falcons have their own unique migration strategies that depend on a variety of factors. Such behavior offers valuable insight into the influence of seemingly tiny changes in climate on overall migration behavior.\u00a0\nScott Yanco, an incoming postdoctoral researcher at the Max Planck Yale Center for Biodiversity, Movement, and Global Change, praised the methods that the research team used, citing that the transmitters had a spatial error of only a few meters. \u201cWe really know where that bird was,\u201d he said, laughing. \u201cWe\u2019re in a golden age for that.\u201d\u00a0\n\u201cOne of the big holy grails, at least in my opinion for migration, is: why does it happen? There\u2019s all these different adaptations that organisms show to seasonality, and migration is just one of them,\u201d Yanco said.\u00a0\nTowards this question, the team also studied the intrinsic, genetic component of migration. After studying a wide variety of falcon populations with observably different migration patterns (long versus short migratory paths), it was suggested that the ADCY8 gene had a large effect in directing migration of peregrine falcons. An epigenetic modification actually results in over-expression of the ADCY8 gene in falcons that must travel long distances, leading the research team to believe that the gene is directly related to long-term memory. This indicates that migration is a combination of intrinsic ability to remember pathways and learned behavior from other falcons or previous experience. This is also supported by the fact that the level of expression of the ADCY8 gene correlates with the length of the migratory journey.\u00a0\nYanco thinks this kind of research touches on a question that has been ever-present in the field of migration. \u201cWhat they\u2019ve been able to do here,\u201d he said, \u201cthat is relatively new and I think very few authors are working on, is the sort of ultimate drivers. Why do it? How does it happen? How does something like this emerge in the first place in deep evolutionary time? How is it maintained?\u201d These questions will propel the field forward to looking at the underlying why in migratory patterns.\u00a0\nThe research team then set out to determine the history of migration and how it was impacted by large scale climate changes in history, such as the melting of the ice caps. By modelling historical migration paths, they were able to determine that as the ice caps melted, northern falcon populations decreased due to disruptions to their breeding grounds. Breeding grounds shifted north in order to maintain a similar temperature environment for the falcons, lengthening the falcons\u2019 migratory path. As discussed above, the length that a falcon can travel is at least partially genetically determined, meaning that only birds that were genetically predisposed to remember and travel long distances were likely to survive long journeys. This particularly brutal bout of natural selection resulted in a dramatic decrease in the population of peregrine falcons.\u00a0\nIn addition to impacting the duration of the migratory journey, changing temperatures and melting glaciers also impacted the directional orientation of migration routes. During the last Ice Age, or the Last Glacial Maximum, there were many more accessible wintering locations to the west, whereas now, there are a relatively equal number of western and eastern locations.\u00a0\nBoth of these changes demonstrate that global climate can have a marked impact on migratory routes and relative survival of the peregrine falcon species, and likely other species of Arctic birds as well. The findings offer a grave perspective on the impact of current rising global temperatures on Arctic avian populations.\u00a0\nHaving studied how climate change has impacted migration in the past, as well as migratory routes in the present, the research team then directed their attention towards the future. To study how present-day climate change would impact future survival of the peregrine falcon species, they used ecological niche modelling simulations to predict how rising global temperatures would affect potential breeding grounds and wintering areas.\u00a0\nThe results were striking. Some groups of peregrine falcons could lose between ninety and one hundred percent of all suitable breeding grounds, a development that would be devastating to those populations. As a result, populations with short migratory routes would see a decrease in migration distance, eventually reaching the point where they wouldn\u2019t migrate at all, while populations with long migratory journeys would see further increases in distance. Longer migration routes are more closely correlated with mortality, so lengthening an already long and harrowing journey could devastate the population size substantially.\u00a0\nAccording to data from the team, these shifts have already begun. Retroactive analysis of peregrine populations found that population numbers have been declining for the past twenty-five generations: the future doesn\u2019t look bright for peregrines.\u00a0\nWhat does this mean for the rest of us? While some might hesitate to understand how a peregrine falcon can represent the world, this work has done nothing if not convey how interconnected our planet is. The same climate changes that impact these falcons will undoubtedly have similarly intricate impacts on our ways of life, especially if no steps are taken to slow rising temperatures in the coming years.\u00a0\nThe Chinese team\u2019s study is unique in that it focused heavily on one species, using a wide variety of tools and research methods to create a complete and almost definitive picture of the migration patterns of peregrine falcons.\u00a0\n\u201cOne of the cool things in this study was that they integrated approaches that are often quite siloed. And I think that this makes a compelling case for putting together teams that can do that stuff\u2014that you\u2019re looking at things behaviorally, environmentally, ecologically, and [with] molecular tools,\u201d Yanco said. \u201cI mean, I think there\u2019s a broad trend in science, that it\u2019s becoming more interdisciplinary and [with] larger teams. As we reach the limits of what we can infer with any given tool, it becomes important to start expanding out.\u201d\u00a0\nReferences:\u00a0\nGu, Z., Pan, S., Lin, Z., Hu, L., Dai, X., Chang, J., \u2026 & Zhan, X. (2021). Climate-driven flyway changes and memory-based long-distance migration. Nature, 591(7849), 259-264.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/migratory-strategies-past-present-and-future/",
            "captions": [
                "Art courtesy of AnMei Little"
            ]
        },
        {
            "title": "Memories of a Brainless Slime Mold",
            "author": "Malia Kuo",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Mold.Anasthasia.Shilov-Anasthasia-Shilov-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Anasthasia Shilov.\nLet\u2019s talk about slime.\u00a0\nAnd no, not the kind that went viral on ASMR TikTok. Today, we\u2019re diving deep into the world of Physarum polycephalum, an intelligent unicellular eukaryote with the ability to solve complex problems, and how it is changing our perception of memory one tube at a time.\nThe concept of memory is often associated with complex organisms: humans reminiscing about failed family picnics or those heartfelt videos of dogs jumping into the arms of their owners after years of separation. We love to see it. But it turns out that the conceptualization of memory may be different from what most expect. Researchers Mirna Kramar and Karen Alim at the Max Planck Institute for Dynamics and Self-Organization and the Technical University of Munich recently investigated Physarum and the way it encodes memory of food sources through rapid communication between its tube systems.\u00a0\nSpoiler alert\u2014and apologies to the viral military dog reuniting clips\u2014Physarum is coming for your brand.\nPhysarum is a network-shaped organism that explores its environment with a vast array of tubes, rapidly and constantly reorganizing its body plan to pin down a food source, all while maintaining the ability to find the shortest possible path between nutrients. Yet, even though Physarum seems like just another slime mold, Kramar chuckles at the memory of working with the organism.\n\u201cPhysarum is extremely dynamic and very, very moody. It really doesn\u2019t like being under the microscope. It will run away, actually physically run away. It\u2019s hilarious,\u201d Kramar said.\u00a0\nKramar began working with Physarum years ago at the beginning of her PhD, carrying out various exploratory projects and recording observations about this capricious creature. During one of these observatory studies, she noticed that Physarum was running to the edge of the petri dish. Not wanting the experiment to conclude with Physarum committing scientific death through a heroic escape, Kramar attempted to lure it back down with a food source.\u00a0\nIt worked. After Physarum consumed the food source and began moseying elsewhere, Kramar noticed that a circular arrangement of big tubes had formed exactly where the food source was. And this tube imprint didn\u2019t fade, even after Physarum continued its journey around the petri dish. \u201cObserving this I had two questions: how does this imprint come around in the first place, and is it useful?\u201d Kramar said.\nThe researchers began observing the changes in tube diameter before and after the addition of a food stimulus, finding that there was an internal redistribution of mass: tubes closer to the food got much larger, whereas peripheral tubes became smaller. And even long after the stimulus had been consumed, the larger tubes remained enlarged. But how did this happen?\nThey found that the propagation of tube dilation across the network was mediated through a cytoplasmic flow, which carried a chemical agent that softened the tube walls. This cytoplasmic flow is critical to Physarum, transmitting both nutrients and information through chemical signaling.\u00a0\nAfter determining that the propagation was due to cytoplasmic flow, the researchers asked the second main question: does the observed imprint constitute memory?\u00a0\nHypothesizing that the tubes could represent Physarum\u2019s memory, given that they remained as an imprint even after the stimulus disappeared, the researchers analyzed three large tubes in a sample of Physarum. One tube was directly connected to a group of tubes arranged in fan shape to forage towards the bottom of the microscopic window. When Kramar placed a food stimulus towards the top of the sample, that tube attached to the fan got increasingly small whereas the two tubes closer to the stimulus increased in size. This was critical evidence for the memory of Physarum. \u201cThe selection of which big tubes are important shows something more than just an imprint or a remnant of the stimulus,\u201d Kramar said.\nRuminating on the impact of this discovery, Kramar discussed the potential implications of Physarum on primitive memory. \u201cThis reminded us of synaptic plasticity and synaptic facilitation, creating long-term memories from short-term memories. That\u2019s very interesting because Physarum has some kind of very primitive membrane potential going on that we don\u2019t know much about,\u201d Kramar said.\nOf course, the implications of Physarum\u2019s memory don\u2019t end with this project. Kramar predicts potential impacts on fields such as soft robotics. Although the concept is still in its beginning stages, she proposes that Physarum\u2019s self-navigation based on attraction to chemical stimuli could be used to guide technological advances in arterial surgeries. For example, robots could be designed to crawl and adapt to the arterial environment, following a chemical stimulus that the condition creates.\nSo yes, maybe we can all have a little bit of Physarum within us someday.\nCitation: Kramar, M., & Alim, K. (2021). Encoding memory in tube diameter hierarchy of living flow network. Proceedings of the National Academy of Sciences of the United States of America, 118(10), e2007815118. https://doi.org/10.1073/pnas.2007815118\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/memories-of-a-brainless-slime-mold/",
            "captions": [
                "Art courtesy of Anasthasia Shilov"
            ]
        },
        {
            "title": "Gynecology for Guys: Male Birth Control",
            "author": "Angelica Lorenzo",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/GUYNECOLOGY-Noora-Said-500x429.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Noora Said.\nOral birth control, commonly referred to as \u201cthe pill,\u201d is prescribed to millions of women in the United States as a convenient and effective way to prevent pregnancy, treat acne, regulate periods, and more. While the pill in the 1950s marked a triumph for women\u2019s reproductive rights, the history of birth control is one deeply rooted in injustice. From the propagation of eugenics ideology to the mass sterilization of Puerto Rican women during the Rio Piedras clinical trials, the development of oral contraception directly targeted impoverished Black and Brown communities in the United States.\u00a0\nEven today, the economic and health-related burdens associated with preventing pregnancy fall predominantly on women. This has long been due to the lack of birth control options available to men. While women have over ten birth control options including barrier (condoms, diaphragms, and sponges), hormonal (pills, patches, shots, and rings), and long acting, reversible contraceptive methods (IUDs and implants), men only have two: condoms and vasectomies.\u00a0\nAfter twenty years of studying sperm formation, researchers at the Lundquist Institute at Harbor-UCLA Medical Center have recently discovered that triptonide, a compound purified from the Chinese herb Tripterygium wilfordii Hook F, can demonstrate reversible contraceptive abilities in men. With this finding, a reversible non-hormonal male contraceptive may be on the horizon, making equitable reproductive health a possibility.\nFor over five decades, researchers have been working on developing contraceptive pills for men with no success. Previously, the mainstream approach for developing male contraceptives involved blocking sperm production. The belief was that if sperm counts were reduced to zero, there would be no sperm available to fertilize eggs and, therefore, pregnancy would be prevented. The problem with this approach, however, is that it requires depletion of sperm precursor cells, which is hard to achieve and tends to cause significant side effects.\u00a0\nWei Yan, principal investigator of the study, explored a new, innovative approach for developing male contraceptives. Instead of depleting all sperm cells, Yan sought to disable sperm by causing deformation during spermiogenesis, the maturation process of spermatids (immature male germ cells) into sperm. By disrupting the final steps of sperm assembly, Yan theorized that sperm would become incompetent, or unable to fertilize eggs, due to their malformation, while sperm count and testis size would be largely preserved.\u00a0\u00a0\u00a0\u00a0\nTowards this goal, the researchers combed databases containing thousands of drug candidates with documented side effects in search of a compound with sperm deforming effects. Tripterygium wilfordii Hook F, sometimes called thunder god vine, has long been used in traditional Chinese medicine to treat autoimmune and inflammatory diseases like rheumatoid arthritis and lupus. Ever since the first reported cases of infertility in men after taking this herbal medicine, researchers have spent years isolating and purifying different compounds of this herb in an effort to identify which specific compound caused deformed sperm. However, many of these purified compounds caused severe liver toxicity or had limited reversibility of contraceptive ability. In hopes of isolating a compound of the herb that demonstrated reversibility in male fertility without serious side effects, the researchers persisted in their testing and ultimately observed that triptonide displayed the desired contraceptive properties.\u00a0\nAfter administering triptonide at different doses to adult male mice, the researchers found that between three and four weeks, daily oral consumption of triptonide at a dose of 0.8mg/kg body weight (BW) induced deformed sperm with limited forward motility, successfully causing infertility. Repeating this experiment with cynomolgus monkeys, the researchers similarly observed that daily intake of triptonide at 0.1mg/kg BW for five to six weeks led to male infertility due to disabled sperm. In both mice and monkeys, the induced infertility was found to be fully reversible, meaning that fertility was regained between four to six weeks after stopping consumption of the contraceptive. This reversibility in contraceptive effects is essential in granting the consumer more flexibility over his own fertility.\u00a0\nThe testes of both mice and monkeys maintained normal morphology without any severe cell depletion, meaning sperm counts remained relatively normal during triptonide treatment. The difference between triptonide-treated and control animals was that the former displayed deformed sperm, particularly a \u201chead-bent-back\u201d phenotype with complete inability of forward motility.\u00a0\nTo understand what this looks like, picture sperm as a tadpole, containing both a head and a tail. Spermatids, the precursors to sperm, are round and do not have a tail. In order to mature into sperm, spermatids undergo an elongation process in which the head becomes compacted and the tail forms through gradual elongation. This coordinated process is controlled by the gene SPEM1, which allows the tail and head to grow proportionally.\u00a0\nNormally, SPEM1 interacts with a protein called junction plakoglobin; however, in the presence of triptonide, this interaction is blocked due to junction plakoglobin\u2019s higher binding affinity to triptonide. When SPEM1 and junction plakoglobin are unable to bind, the elongation process of spermatids is disrupted. \u201cThe consequence [of inhibiting the SPEM1 gene] is that you\u2019re going to have a head that is all bent back and sometimes the tail actually starts wrapping around the head,\u201d Yan said.\u00a0\nDeformed sperm are unable to fertilize eggs because of their inability to swim vigorously to meet the egg and because defective sperm tails are not strong enough to penetrate the egg during fertilization. With the inhibition of SPEM1, spermiogenesis lacks a checkpoint mechanism to eliminate deformed spermatids. Importantly, this missing \u201cquality control\u201d is advantageous to birth control safety because normal sperm counts are preserved.\u00a0\nBecause two abundant compounds of the Chinese herb\u2014triptolide and triptochloride\u2014are known for causing liver toxicity, many grant reviewers rejected Yan\u2019s applications because of the herb\u2019s notorious reputation.\u00a0\n\u201cAt a certain point, I wanted to give up because [the project] just didn\u2019t go anywhere without funding,\u201d Yan said. \u201cI was lucky enough to secure private funding.\u201d\u00a0\nNow that triptonide has successfully displayed reversible contraceptive effects in both male mice and monkeys without side effects, when can it be used by human men? Before any clinical trials, the Food and Drug Administration (FDA) must approve the drug\u2019s Investigational New Drug (IND) status. Before that, pharmacokinetics and toxicology studies must be conducted to further assess safety and metabolism of the drug in the body. Ultimately, securing further funding is the prerequisite to move this project forward.\u00a0\u00a0\u00a0\nSo why has it taken so long to make progress in developing male contraceptives? While funding poses a challenge, Yan believes the underlying reason is because of lack of success with popular methodologies. As described previously, the standard research approach for inducing male infertility has historically been sperm depletion. Finding a chemical that can deplete all sperm cells without causing adverse effects has proven difficult.\u00a0\n\u201cA popular joke in the field is that male contraceptives have been five years away for fifty years,\u201d Yan said. With the success of treating animals with triptonide, Yan hopes that he can find enough financial support to bring triptonide drugs onto the market. Not only will this achievement allow for shared contraceptive responsibility between men and women, but it will also provide men with more autonomy over their reproductive health. After all, according to Yan, \u201cto control your own fertility is a basic human right.\u201d\nReferences\nChang, Z., Qin, W., Zheng, H., Schegg, K., Han, L., Liu, X., \u2026 & Yan, W. (2021). Triptonide is a reversible non-hormonal male contraceptive agent in mice and non-human primates. Nature communications, 12(1), 1-14.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/gynecology-for-guys-male-birth-control/",
            "captions": [
                "GUYNECOLOGY - Noora Said"
            ]
        },
        {
            "title": "Bridging the Quantum Gap",
            "author": "Yu Jun Shen",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Michaels_quantum-3-Tai-Michaels-500x330.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Tai Michaels.\nQuantum computers may one day solve difficult problems, but currently they still face many hardware limitations. Quantum physics\u2014the science of the very small, such as electrons and photons\u2014 allows for \u201cqubits\u201d that can represent \u201c0\u201d and \u201c1\u201d at the same time, a concept known as superposition. This gives them exponentially faster processing speeds than traditional computers, which use binary electrical bits assigned a fixed value of either \u201c0\u201d or \u201c1.\u201d\nHowever, today\u2019s quantum processors can only work with a few qubits, compared to the billions of transistor bits in traditional computers. To increase the number of qubits involved, researchers from the Max Planck Institute of Quantum Optics in Germany have demonstrated a distributed quantum logic gate that can connect multiple quantum processors. Severin Daiss, Gerhard Rempe, and colleagues set up two qubits, located sixty meters apart in two labs, to interact using an additional photon sent between them. Quantum logic gates like this are the quantum version of classical logic gates, performing specific operations to input qubits. Researchers hope having a distributed setup\u2014where the quantum logic gate is not necessarily in one location only\u2014provides a more flexible, modular approach towards achieving larger quantum computing power.\u00a0\nUsing the distributed gate, the German researchers produced pairs of maximally entangled qubits known as Bell states. Entangled qubits can be highly correlated even though they are physically apart. Such \u201cspooky action at a distance,\u201d as Einstein remarked, actually provides quantum computers with their potential power. If one element in a pair of Bell state qubits is measured, the other qubit\u2019s condition is also fixed, no matter how far away.\u00a0\nIn an ordinary computer, billions of transistors work in unison to perform logical operations\u2014such as addition, multiplication and information processing\u2014on electrical bits. Quantum researchers have adopted a similar approach to quantum computing (among other methods) to design \u201cquantum circuits.\u201d Quantum circuits manipulate qubits, which, in contrast to electrical bits, are not a fixed \u201c0\u201d or \u201c1.\u201d The circuits therefore require quantum logic gates instead of the silicon chips found in ordinary computers.\u00a0\nAs an example of a nonlocal operation, Daiss and Rempe performed a quantum controlled-NOT (CNOT) gate in their experiments. The CNOT gate uses the input of one qubit to determine whether or not to invert the input of a second qubit. In many quantum circuits, CNOT gates are used to achieve the superposition necessary for any potential quantum advantage over classical computing.\u00a0\nDaiss and his colleagues placed two optical cavities containing a rubidium atom in two separate rooms within a building at the Max Planck Institute. In order to perform a quantum logic gate between the two devices, the researchers first launched a photon towards the first optical cavity along an optical fiber, then directed the reflection to the second cavity (in the other room). The reflection caused an interaction between the photon state and each atomic qubit state. Following the photon measurement, with the addition of a Z-gate\u2014a type of quantum logic gate\u2014on the first cavity controlled by a classical communication channel, Daiss and his team completed a CNOT gate.\u00a0\n\u201cOur experiment is the first that does such a gate between qubits residing in completely independent laboratories,\u201d Daiss said.\u00a0\nThe team reported results of up to eighty-five percent accuracy for the CNOT operation, at a computation rate of one kHz. While this is low compared to current state-of-the-art quantum hardware, the approach holds promise for a modular approach to scaling up quantum computers. Qubits are much more fragile than electrical bits; the slightest measurement by environmental disturbances (dust, air, stray light) could break the trance. As qubits typically reside in dilution fridges or vacuum chambers\u2014which have limited space\u2014increasing qubit number requires denser packing. This can cause problems like crosstalk noise and limited access to each individual qubit, complicating manipulation and measurement. Thus, in the future, instead of just increasing just the number of qubits in a single processor, researchers may connect multiple quantum devices using distributed quantum gates to improve computational power. \u201cSuch a modular approach might open a new development path for larger quantum computers,\u201d Daiss said.\u00a0\nThe researchers believe that their protocol with the use of a separate photon may be applied to other quantum operations and gates between distant qubit modules. In a future quantum computer, it is likely that many quantum gates\u2014such as the CNOT\u2014will be involved, each with its own chance of failure. Thus, the photon\u2019s ultimate arrival would signal a successful quantum operation, before subsequent operations proceed.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/bridging-the-quantum-gap/",
            "captions": [
                "Art courtesy of Tai Michaels"
            ]
        },
        {
            "title": "Science in the Spotlight: The Nocturnists",
            "author": "Ann-Marie Abunyewa",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/healthcareworkers-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Canva.\nJust as Charon ferried souls post-death across the River Styx to receive their fate, death too propelled Jenny Tiskus into her journey with medicine. In \u201cThe River Styx,\u201d an appropriately named episode of the podcast The Nocturnists, Tiskus explores gallows humor and how physicians process death. She reflects on the deaths of her father and grandmother and her initial hesitance to go into medicine. Her wandering back between a life with and without medicine feels reminiscent of the wandering souls of the Greek Underworld river, who anticipate the moment when their afterlife fates become clear.\nThe Nocturnists is a podcast in which healthcare workers share their experiences in the field. Integral to each episode is the art of storytelling. The anecdotes that each guest shares are raw: listeners feel as though they have a special insight into healthcare without having to enter the hospital or clinic themselves. They learn about healthcare professionals\u2019 joys and vulnerabilities while working in the field.\nMarch 2020 marked the beginning of The Nocturnists\u2019 \u201cStories from a Pandemic\u201d series. This season is particularly moving; though our one-year anniversary since the beginning of the COVID-19 pandemic has passed, all the initial emotions and reactions are still incredibly tangible. The hope, exhaustion, and cynicism that listeners have in common with storytellers grounds the healthcare workers as people like us, rather than sacrificial heroes the media glorifies. \u201cIt\u2019s not bad yet. It\u2019s a whole lot of unknown,\u201d recounts a trauma nurse as she marvels at her colleagues\u2019 smiles despite their surging anxious emotions. \u201c[The hospital] sent me home early today because I\u2019m getting too much overtime. Apparently being willing to make sure that our patients get their stuff is too expensive,\u201d reports a Durable Medical Equipment truck driver.\nThis season, the producers have expanded the podcast to make it a nationwide, collaborative effort. They created an interactive map where each destination features a story from a healthcare worker into which listeners can tune. Usually, the podcast uses music by composer Yosef Munro to open and close episodes. However, the only music featured this season is that provided by the diarists. At the end of \u201cStories from a Pandemic: New World,\u201d an internal medicine resident details that she picked up music again because it gives her the comfort that uncertainty has often taken away; she closes out the episode playing Dvorak\u2019s New World Symphony on her violin. By incorporating these collaborative components, the producers have elevated this season\u2019s storytelling power, authenticity, and connectedness\u2014an important mission now that we have been so apart.\nLooking back on her journey into medicine, Tiskus worries about the \u201cemotional desiccation\u201d that could ensue as her profession exposes her to more death. To combat this, she says it\u2019s important to discuss how to stay in touch with her humanity when gallows humor seems to strip it away. Storytelling through The Nocturnists is how she can more fully emphasize the gravity of the deaths that shaped her path to medicine.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/science-in-the-spotlight-the-nocturnists/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Alumnus Profile: Dr. C. Brandon Ogbunu (PhD \u201910)",
            "author": "Anna Calame",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Brandon-Ellie-Gabriel-500x464.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Ellie Gabriel.\nTen minutes into my conversation with Dr. C. Brandon Ogbunu (PhD \u201910), I knew that no 750-word profile could fully do him justice. Throughout his life, Ogbunu has consistently pushed boundaries and rejected dichotomy, making for an impressive career that resists abridgement. Ogbunu is a scientist, yes, but he is also a prolific writer, storyteller, and educator. His nontraditional, interdisciplinary path has led him to the Ecology & Evolutionary Biology Department at Yale, where he is an assistant professor and the principal investigator for the Ogbunu Lab for Genetics, Ecology, Evolution, and Quantitative Science (GEEQs) research.\nDespite being a self-described \u201clate bloomer\u201d academically, Ogbunu emphasizes that he has always harbored a deep love of learning. He credits his mother, a teacher, with imparting to him this proclivity for scholarship, which blossomed during his undergraduate years at Howard University. There, Ogbunu studied chemistry, explored the intersections between various scientific disciplines, and developed an interest in disease. After graduating from Howard in 2002, Ogbunu studied malaria in Kenya on a Fulbright scholarship, an experience that confirmed his preference for research over clinical practice. \u201cIt was when I got to Kenya that I said, if I can be doing this kind of work as a grown-up, this is the career that I want: the producing and engaging of scholarship,\u201d Ogbunu said. \u201cScience is a type of scholarship; it\u2019s a manner through which a person creates knowledge and offers it to the world.\u201d\nUpon returning to the US, Ogbunu followed his curiosity to Yale, where he worked in Paul Turner\u2019s virology lab. He completed his PhD in microbiology in 2010 and, subsequently, a postdoctoral fellowship at Harvard. Ogbunu spent two years working at Brown University before returning to Yale in the fall of 2020, this time as a faculty member.\nOgbunu, a computational biologist trained in chemistry, mathematics, genetics, evolution, and microbiology, approaches research in a way that reflects the diversity of his interests and abilities. His GEEQs lab conducts \u201cremix science,\u201d drawing on concepts from various scientific fields to gain insight into disease. Ogbunu considers research questions on two levels: the molecular scale, comprising technical knowledge of genetics and biology, and the population scale, involving modeling and data analysis. Together, they have brought him great success and an enduring love for his work. \u201c[The multidisciplinary approach] is just more fun\u2014I can talk to more people, I can engage more people,\u201d Ogbunu said. \u201cOn one end, these two lenses allow me to comment on and think about very practical things. On the other, they let me ask broad questions about society or evolution or ecology.\u201d\nOgbunu is a staunch believer in the importance of collaboration. Throughout our discussion, Ogbunu was quick to credit the positive influences that others, particularly his mother, his college friends, and Turner, have had on his life and career. When asked how his passion for community informs his approach to teaching, Ogbunu described the ability to craft an engaging and supportive lab environment as an incredibly exciting aspect of being a principal investigator. \u201cI do a self-care symposium in my lab, where every year you have to present on the ways you\u2019re going to take care of yourself, and answer questions,\u201d Ogbunu said. \u201cI can work my value system into the ways my lab interacts.\u201d\nConsistent with his lifelong love of learning and creating scholarship, Ogbunu is also an impressive communicator, having written numerous blog posts, contributed to WIRED, and appeared on podcasts. \u201cI\u2019ve always been connected to writing\u2014I\u2019ve read comics all my life. Writing and art and being creative have always been a part of my identity,\u201d he said. Rather than seeing his creative pursuits as separate from his dedication to science, Ogbunu considers his writing, his scientific process, and his teaching to be complementary. Through his writing, Ogbunu skillfully explores questions at the intersection of science and society: the limitations of analogizing infectious disease and white nationalism, the potential of network science to make sense of our increasingly interconnected world, and the insidiousness of scientific racism and the legacy of James Watson. Moreover, he presents his thoughts on these complex and technical topics in ways accessible to the average reader.\nOgbunu\u2019s success serves as a reassuring reminder to my fellow students, anxious over seemingly binary decisions between disciplines and unsure of how to appropriately navigate the professional world. Prioritizing a dedication to one\u2019s values\u2014in Ogbunu\u2019s case: community, scholarship, and creativity\u2014over an adherence to previously-trodden paths is not only possible, but highly rewarding.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/alumnus-profile-dr-c-brandon-ogbunu-phd-10/",
            "captions": [
                "Brandon - Ellie Gabriel"
            ]
        },
        {
            "title": "Undergraduate Profile: Phyllis Mugadza (\u201922 BS/MPH)",
            "author": "Eamon Goucher",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Phyllis-Ellie-Gabriel-478x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art courtesy of Ellie Gabriel.\nIn a normal year, you can find Phyllis Mugadza (\u201922 BS/MPH) hanging out in the Silliman courtyard, giving tours of Yale\u2019s campus, or working as a recruitment coordinator in the admissions office. In between classes and work, Mugadza, a mechanical engineering major, spends her free time innovating the world around her.\nThis past winter, Mugadza was selected as one of the winners of the 2020 Reimagine Challenge, a scholarship competition that aims to identify innovative solutions that will help spark global movements and build back from COVID-19. For her proposal, Mugadza focused on the growing waste mismanagement crisis in several developing nations. Despite the serious public health problems they pose, waste sites have become unique spaces of creation in which grassroots innovators repurpose discarded materials into art and commodities. Mugadza, inspired by the creative superpower of these creators, proposed a novel method of addressing the waste mismanagement crisis: opening makerspaces to support grassroots creators, bolster local economies, and repurpose waste.\nMugadza\u2019s passion for innovation first blossomed out of a desire to help her home community in Harare, Zimbabwe. \u201cThe biggest challenge I found was that a lot of women around me were missing school\u2014my friends would miss work when they were on their period because of dysmenorrhea, or menstrual pains,\u201d she said. The inaccessibility of medicine, sanitary products, hygienic facilities, and education on menstruation created ubiquitous barriers to everyday life. \u201cWhen I committed to Yale, I wanted to commit my entire engineering journey to finding a solution for this problem,\u201d she said. Over the past four years, Mugadza has collaborated with OB-GYNs at the medical school, conducted surveys with menstruators of all identities, and iteratively designed a device that can effectively collect menstrual blood and treat dysmenorrhea.\nListening to Mugadza feels liberating; her passion is palpable. Over the course of our conversation, I realized that Mugadza\u2019s unique perspective comes from a belief in the potentiality of objects and people to build a happier, safer, and more equitable world. For her Reimagine Challenge proposal, Mugadza emphasized breaking out of a functional fixedness mindset\u2014using everyday materials in new and exciting ways. Mugadza is inspired by the work of architects Kevin Kimwelle and Ashis Paul, who have built plastic bottles in their designs as storage hooks and as naturally cooling air filters. Mugadza wanted to center this kind of ingenuity in her project proposal. She believes that in order to solve this problem, we must empower local creators: \u201cThey possess a gift and a talent that the world needs right now,\u201d Mugadza said.\nAs she described the process of designing a menstrual device, I started to understand Mugadza\u2019s experience in reimagining a better world. \u201cI would say that a lot of my inspiration and motivation come from studying engineering at a university that is rooted in the liberal arts,\u201d she said. Especially at first, Mugadza leaned heavily on Tsai City and her mentors for both guidance and support. She points to Alyssa Siefert, Christina Mainero, and Anjelica Gonzalez as some of the people who have helped her get to this place. \u201cMentorship has been extremely important, especially being a woman of color in engineering at Yale and all that comes with that,\u201d she said. \u201cMy mentors have really uplifted me, connected me to resources, have pushed me to take up space, and always push me constantly to achieve.\u201d Still, Mugadza is very transparent about her experiences being a woman of color in engineering and entrepreneurship: \u201cI\u2019ve had to put in a lot of extra work to make my voice heard in a lot of spaces. I felt like I was constantly being sheltered and limited by what I could achieve,\u201d she said. In times like these, Mugadza turns to her mentors\u2014particularly her female mentors of color\u2014to help her get back to doing what she loves: building a better world.\nMugadza will graduate from Yale College in May, before moving to the School of Public Health full-time to complete her MPH. She hopes to launch her menstrual device startup Sprxng by the end of the year and plans to resume work on her makerspace project within five years. I walked away from our conversation feeling inspired and excited about the future. We often tend to feel like very small cogs in a very big machine\u2014everything we do is a drop in the bucket. But Mugadza has demonstrated the power that each person has in creating a happier, safer, and more equitable world.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/undergraduate-profile-phyllis-mugadza-22-bs-mph/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Why do fragments spin after a nuclear fission split?",
            "author": "Meili Gupta",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/molecules-500x251.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "In 1938, chemists Otto Hahn and Fritz Strassmann bombarded a uranium nucleus with a neutron. To their surprise, they discovered that barium and krypton were produced. This division of heavy nuclei was termed \u201cfission,\u201d and since its discovery it has deeply intrigued physicists. For decades, physicists have puzzled over why the resulting fragments spin after nuclear fission. A recent study between scientists from France, Germany, the UK, and other European countries offers clear answers.\nAt the IJC Laboratory in Orsay, France, scientists used high-resolution spectroscopy to inspect the fission of 232Th, 238U, and 252Cf. They specifically used a method from the University of Manchester to measure the average spin of the fission fragments. They discovered that the fragment spin appeared to depend only on the fragment mass, not the mass of the original nucleus or the mass or charge of its partner fragment. Their results deny hypotheses that the spin is generated before the nucleus splits (pre-scission), as these hypotheses predict equal magnitude spins for partner fragments. The large asymmetries in the angular momentum between the spins of heavy and light partner fragments support a post-scission hypothesis and the idea that each of the fragments should be treated as independent quantal\u2014discrete\u2014systems.\nBeyond deepening a fundamental understanding of fission, these findings have important applications for nuclear energy, since fragment spins influence the heating effects of reactor gamma rays. This research may help unlock the full potential of nuclear fission.\nSources:\nWilson, J.N., Thisse, D., Lebois, M.\u00a0et al.\u00a0Angular momentum generation in nuclear fission.\u00a0Nature\u00a0590,\u00a0566\u2013570 (2021).\u00a0https://doi.org/10.1038/s41586-021-03304-w\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/qa-why-do-fragments-spin-after-a-nuclear-fission-split/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: Vivek Murthy\u2019s Together",
            "author": "Hannah Huang",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/vivek_murphy-500x331.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Whether it be walking into a room of strangers or standing alone at recess, everyone has felt lonely at some point. Vivek Murthy (SOM \u201903), the nineteenth and twenty-first Surgeon General of the US, built his platform on combatting loneliness after realizing how insidious its long-term effects are. In his book Together: The Healing Power of Human Connection in a Sometimes Lonely World, Murthy explains that because loneliness is the root cause of many societal problems, combating loneliness ultimately bolsters our collective health.\u00a0\nMurthy\u2019s childhood role models were his parents. Physicians themselves, they built relationships with their patients by taking time to listen to their needs. When Murthy began his first stint as Surgeon General, he took his parents\u2019 example to heart and embarked on a listening tour across America to identify the most pressing health issues Americans were facing. Between those listed\u2014addiction, violence, anxiety, and depression\u2014there was a common connector. \u201cTo be at home is to share a sense of common ground, common interests, pursuits, and values with others who truly care about you. In community after community, I met lonely people who felt homeless even though they had a roof over their heads,\u201d Murthy said.\nThe link between loneliness and physical health, though surprising when first discovered, is nonetheless an established one.\ufeff Psychologist Julianne Holt-Lunstad found that loneliness is a stronger risk factor for reduced life span than obesity, alcoholism, and lack of exercise. In fact, lack of social connection is as detrimental to one\u2019s health as smoking fifteen cigarettes a day. \u201cIf neglected, loneliness can have long-term health implications, yet it is not a state that can be fixed with a pill or a procedure. It is a human condition that reminds us of our need for the love, compassion, and companionship of fellow human beings,\u201d Murthy said.\u00a0\nGiven the current state of social distancing and mandated isolation, it\u2019s likely that loneliness is more prevalent than ever. However, Murthy insists that physical solitude doesn\u2019t necessarily translate to loneliness. \u201c\ufeffLoneliness is the subjective feeling that you\u2019re lacking the social connections you need. Solitude, by contrast, is a state of peaceful aloneness or voluntary isolation. It is an opportunity for self-reflection and a chance to connect with ourselves without distraction,\u201d Murthy said.\nMurthy believes that even in the current pandemic, we can find ways to combat loneliness while finding peace in solitude. He lays out four strategies: 1) spending time each day with those you love, even if it\u2019s fifteen minutes on a video call; 2) giving other people your full, undivided attention when conversing; 3) performing acts of service to be reminded of how we can support each other; and 4) embracing solitude through nature, meditation, and art.\n\u201cDeveloping comfort with solitude is an essential part of strengthening our connection to ourselves, and by extension, enabling our connection with others. Solitude, paradoxically, protects against loneliness,\u201d Murthy said. Even in the despair of this past year, there may be a hidden blessing if one ascribes to Murthy\u2019s teachings.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/science-in-the-spotlight-vivek-murthys-together/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Into the Newsroom: A Conversation with Carl Zimmer",
            "author": "Sophia Li",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/author-carl-zimmer-superJumbo-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Carl Zimmer\u2019s award-winning science journalism regularly features in the New York Times. A Yale alum (\u201987) and professor adjunct, Zimmer has also authored fourteen books. His most recent, Life\u2019s Edge: The Search For What It Means To Be Alive, was published in March of this year.\u00a0\nHow did you become interested in communicating/disseminating scientific information through scientific writing? Where did this interest come from?\nI was very lucky to get a job a couple of years out of college as an assistant copy editor at a science magazine called Discover. I graduated from Yale as an English major; I really loved to write and wanted to do something with writing but wasn\u2019t sure what. I was then given the opportunity to do fact-checking, which was not only very important for the articles but also very good to learn how to be a science journalist. Then, I started to learn how to write articles about complicated things for a broad audience and I went from there.\nHow did you get into covering for the New York Times and what has that process been like?\nI worked at Discover for ten years in total (the last four years I was a senior editor). And then I decided I just wanted to work on my own writing for a variety of publications. I left the staff of Discover and started writing for places like National Geographic or Wired, and in 2004, I decided to pitch an idea to the NYT just as a freelancer. The editor who read my pitch had read one of my books, so he was happy to talk about ideas and we started off with a story on why leaves change color in the fall. And after that, I started contributing stories to them on a somewhat regular basis. Eventually, about eight years ago my editor said, let\u2019s just make this a weekly column. Let\u2019s make it official and that\u2019s been the timeline. I balance that with writing books and other projects.\nAnd that\u2019s your Matter Column on the NYT?\nYeah.\nI saw that you have some really interesting articles ranging from topics regarding pythons, algae, ant zombies, singing mice and was curious about how you came up with these topics to write about?\nLike other science writers, I try to keep up with the new research that\u2019s coming out. If there\u2019s something that\u2019s particularly significant, eg. medical advances, or something that\u2019s fascinating in showing us something about how the world works, then I\u2019ll talk to my editor as that being my topic for the week. I write about biology, sort of broadly speaking. What I love about that is that every week there can be something new about singing mice or jellyfish or about plants fighting against insects, or what have you. But there\u2019s this underlying unity: the same processes you see in one species, you\u2019ll find it in the evolution of another. There\u2019s this mix of variety and unity that is very satisfying to me as a writer.\nWhat is the research process for your column and COVID-19 updates? Where do you get scientific information from, and how do you begin to dissect it and make it understandable to a broader audience?\nWhen I start working on a story, I will read a number of papers\u2014maybe one new study I\u2019ll focus on in particular\u2014but I\u2019ll look and see, get familiar with the research that was important to make the new research possible. Then I just have long conversations. I\u2019ll talk to scientists about the work that they\u2019ve done. I might talk to outside scientists to get an expert opinion on whether or not the research really lives up to its claims. If it\u2019s the kind of research that affects people\u2019s lives, I will talk to those people.\u00a0\nFor example, there are ancient skeletons of people who lived in the Caribbean before Columbus arrived. And comparing their DNA to living people shows you some interesting things about how people came to Caribbean islands and settled on them before moving from island to island. So, I talked to people who identify as Ta\u00edno, which is one of the groups that was there when Columbus arrived, about what these findings mean to them or [how they] fit in with their own experiences of their identities as Caribbean peoples. I try to hear as many voices as I can in the time that I have.\u00a0\nIn terms of writing the articles, I always remind myself that I have spent several days or maybe weeks immersed in this subject, whereas my readers are coming to it completely fresh, so I can\u2019t assume they live inside my head. I have to put everything that they need onto the page in order for them to follow the story. This requires constant reminding, that you have to tell a story that is clear and compelling enough that people who aren\u2019t experts in the particular research will want to read it and will keep reading it and will understand it.\u00a0\nThis is definitely reflected in the narrative aspect of your articles, where it\u2019s not just about the discovery but it\u2019s also about the people behind the discoveries. Some of your articles are in Spanish and can cater to different populations of people/less scientific understanding.\nYeah, that\u2019s part of the NYT\u2019s efforts to reach a number of audiences. They have had Chinese translations, Spanish and other languages, so they will pick certain articles to translate. And I think that they have been particularly interested in some of the COVID-19 stories that I\u2019ve been writing, because I have been collaborating with a designer named Jonathan Corram on basic visual explanations of things. So how does the coronavirus hijack our cells/how do these vaccines work? How does the Pfizer vaccine work? AstraZeneca? We are trying to present pretty brief explanations of things that run through the key points of vaccination and how the immune system responds\u2014something you can look at on your phone as well as your computer. Those things are of great interest to people not just in English-speaking countries but also people who speak other languages as well.\u00a0\nAfter these articles come out, how do you engage with your audience? Do you read reviews/feedback on articles and how have you adapted?\nWhen I have the time, I will try to look around for reactions. Like everyone, I spend time on social media, so if I share something on Twitter, LinkedIn, Facebook, there will typically be some comments in response. The NYT will sometimes enable a comment function on articles so I\u2019ll try to read through those and respond to some questions that I feel I can help with. It is useful to get a sense of what people take from my stories. Sometimes the thing that I thought was really interesting turns out to not get a lot of attention. But people might be really interested in some other aspect of a story that I haven\u2019t thought about as much. It\u2019s good to know what things people find meaning from.\nWhere did the idea of the book, your inquiry about life, come from?\nI think it\u2019s one of these basic questions that I can\u2019t remember when I first wondered it. I think a lot of people, even when they\u2019re kids, wonder, \u201cWell what is life, exactly, and what does it mean that we\u2019re alive?\u201d If you ask your parents, you might not get a satisfying answer, and it turns out if you ask scientists, you might also not be satisfied because everyone seems to have a different definition of it, and no one seems to be able to agree. It\u2019s puzzling but also fascinating.\u00a0\nI talked with scientists and philosophers and spent time looking at particularly weird and amazing forms of life, whether it\u2019s hibernating bats or slime mold or just a maple tree, and talk with the researchers who are studying these things. It grew into what I consider a journey. I start the book in the familiar heartland of life, thinking about things no one would really argue are alive\u2014like ourselves or a snake or a tree\u2014and then move out to the borderlands, where it suddenly gets much harder to decide whether things are alive or not\u2014whether they are synthetic life or protocells which may have first evolved four billion years ago. Even viruses. These are the things that are very much a part of our world, but we\u2019re not sure what to call them.\nYou write in your book, \u201cAll life gives way to half-life and then to no life at all.\u201d Do you think we fundamentally characterize life wrong, or through your investigation do you have a different way of characterizing life?\nSomething like a virus shows you how shaky the whole edifice of the definition of life is. Definitions, as we think of them, are kind of arbitrary lists or hallmarks. The hallmarks you think are important might not be the ones other people think are important. You don\u2019t really get at something fundamental about nature. So, I don\u2019t think it\u2019s really possible to define life. We can have some sort of rough and ready definition, which is fine, but in Life\u2019s Edge, I compare it to asking an alchemist in the 1500s to define water:\u00a0\nThey would probably say: It\u2019s wet, it\u2019s transparent, it\u2019s liquid, and if I make it cold it gets hard. But then you say: Okay well, the stuff it becomes, is that water too? Then they would say: No that\u2019s ice because water as I just told you is liquid.\u00a0\nSo, it\u2019s kind of a meaningless exercise to ask an alchemist to define water. What you really want is a theory of chemistry. You can say: According to your theory you call that stuff water. What\u2019s in it are these molecules, and I can tell you what molecules are, and I can tell you how this particular substance has molecules that contain oxygen and hydrogen. It\u2019s still water when it freezes because the molecules just arrange in different shapes. So suddenly I\u2019ve told you something deep and profound about water because I have a theory of it. However, we don\u2019t have a theory of life that everyone agrees on yet.\nCould you tell me about the timelines of the book and whether the COVID-19 pandemic shaped the outcome of your book/the direction the book was going?\nI was working on this through much of 2019. I was making plans on doing the last few trips into May and June of 2020. But by February it was pretty clear I was going to have to cut things short. I had this one last trip at the end of February where I went to an abandoned mine in the Adirondacks to go with some biologists who study hibernating bats. We have these super insulated waders, basically climbing through this icy stream to get into this mine with these bats that are spending the winter\u2014great experience\u2014but drove home, and pretty soon after that everything shut down.\u00a0\nSo, I wasn\u2019t able to do those last few trips, but it was okay. I realized that I actually had enough to work with. I started wrapping up the book and at the same time started ramping up my work for the NYT for the COVID coverage. I went from writing about anything to writing about this one virus. I\u2019ve been writing like crazy about vaccines and about variants, so in the meantime, the book was working its way through the publication process. But I had a chapter already written about viruses and whether viruses were alive. And over the summer I updated that and focused on the coronavirus. I said, okay so here is this new virus that is taking control of the world and scientists don\u2019t agree if it\u2019s alive or not.\u00a0\nWhen people go to books/websites/journals, they almost expect to come out with something that they\u2019re sure of/better informed. As scientists, we have to exist in this realm of uncertainty. So as someone who serves as the medium through which this information is being spread to the public, how do you deal with the uncertainty and explain that to your readers in a way that doesn\u2019t induce severe panic?\nIt\u2019s hard. It\u2019s hard because you want to give people the best understanding that scientists have, and there\u2019s a wide range of uncertainty. But just because scientists are unsure about something doesn\u2019t mean that they don\u2019t know anything at all\u2014you have to find a way to balance those things. How much you should be afraid of the virus? Well, that\u2019s a difficult thing and it\u2019s not entirely a scientific question. These variants that have sprung up, we\u2019ve only really become aware of them in January, and they\u2019ve been a dominant concern ever since. We as reporters need to write about these variants and the new research that comes up about them. If there\u2019s evidence that they could be transmitting faster, we have to share that. If they\u2019re possibly evading vaccines, we have to share that. But we also don\u2019t want to give people a sense that it\u2019s all hopeless and that these new variants will destroy our efforts to reign it in. We don\u2019t know for sure what\u2019s going to happen with variants, but we have reason to be hopeful. The lesson to take from the variants is that we just have to be vaccinating as fast as we can.\u00a0\nDo you have any advice for Yalies who want to engage with scientific writing?\nIt takes a lot of practice, so nobody should expect to do a spectacular job of science writing their first time out. It\u2019s a big challenge to learn about complicated things and write about them in a way that is exciting and comprehensible. We\u2019re writing things that people don\u2019t have to read. We\u2019re writing things that people can just skip over, so the challenge is how you keep people reading and give them a story that is as accurate and as close to the truth as you can make it. An important thing to remember is to try to write it the way you actually talk. Don\u2019t try to show how smart you are when you\u2019re writing about science; that\u2019s not a fun thing to read. Tell us a good story about science and we\u2019ll want to read it!\nDo you have any mentors you particularly look up to? What do you do in your free time?\nI had a couple of great teachers at Yale. One was a writer named Peter Matthiessen, who wrote about nature, and the other was a poet and an essayist named Vicky Hearne. I feel very fortunate to have been able to start trying to write with their guidance; that was a very lucky experience.\nI\u2019ve been writing so much, so other things\u2014it\u2019s hard to think about. I have to say, I live in Guilford, and we\u2019re lucky that there are huge amounts of forests, hills, and trails here. I try to get out a few times a week at least to explore what we have here, and that\u2019s definitely kept my sanity intact this past year.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/into-the-newsroom-a-conversation-with-carl-zimmer/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Counterpoint: Not-So-Identical Twins",
            "author": "Eva Syth",
            "authorLogo": "",
            "date": "June 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure2-500x332.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nThe classic scientific debate on \u201cnature vs. nurture\u201d asks: to what extent do genetics shape our characteristics, and to what extent do our environments shape our characteristics? In pursuit of the answer, scientists historically studied identical twins, or monozygotic twins, who were widely believed to share the same DNA. To isolate differences associated with nature as opposed to nurture, these studies assumed that any differences in identical twins must have been due to the environment, as their genetic material would be the same.\nHowever, new research from Hakon Jonsson and Erna Magnusdottir, as well as collaborators at deCODE genetics, the University of Iceland, and Reykjavik University, suggests otherwise. The team recently found that identical twins on average differ by 5.2 mutations from early in the life cycle. The study, which involved the genetic sequencing of almost fifty thousand people, further showed that, in fifteen percent of identical twins, one of the twins has a substantial number of mutations that the other does not have.\nBeyond quantifying the average mutation differences between monozygotic twins, this study also looked into when the mutations occurred during development. Jonsson and the research team cleverly used information on early development, coupled with genetic sequencing of identical twins along with their parents, spouses, and children, to draw inferences surrounding the timing of mutations during development.\u00a0\nSo, how exactly can researchers use the genetic sequences of these close contacts to decipher when mutations occurred? The answer relies on the very beginnings of the human life cycle. When an egg cell is fertilized, it becomes a single-celled zygote, composed of genetic material from both parents. Over time, the zygote divides and embeds itself into the uterine lining to form the blastocyst. After several weeks, some of the cells are designated to be germ cells, or sex cells. Sex cells are involved in passing genetic material on to offspring.\u00a0\nTwinning occurs when the single mass of developing cells splits into two identical masses, which eventually become the two twins. This process generally occurs early in development, much before the designation of germ cells.\nThe researchers used the development process coupled with genetic information from relatives of identical twins to determine at what point mutations occurred in development. For example, the researchers identified mutations in an identical twin and their offspring, but not in the twin\u2019s spouse or twin counterpart. Of these mutations, the researchers then found that some were also present in somatic body cells of the twin. From the life cycle, the researchers could extrapolate that the mutation occurred after twinning, because the twin\u2019s monozygotic counterpart didn\u2019t have the mutation. Additionally, because the mutation was present in both somatic cells and germ cells, investigators inferred that the mutation likely occurred before the germ line cells were designated. If this wasn\u2019t the case, the mutation would have been found in either somatic cells or germ cells, not both. The researchers used similar logic to identify at what point in development a variety of mutations likely occurred.\nIn addition to identical twins, the researchers also investigated a family with identical triplets in order to learn more about genetic variation. Specifically, this case study proved crucial in exploring cell allocation. Cell allocation is concerned with the designation of different cell types. For example, twinning may occur when a group of cells is designated and begins developing independently of existing cells. In the case of the triplets, researchers found that two of the triplets shared more mutations with each other than the third. The study pointed to cell lineage as a potential explanation: two of the triplets were likely \u201cdescended\u201d from the same cell whereas the third triplet came from another set of cells that was allocated separately.\nSo where does this leave identical twin studies, which assume that these mutations are insignificant compared to environmental factors? Jonsson and the research team caution that the effects of these mutations have likely been underestimated when it comes to the development of certain diseases. However, even if nature vs. nurture identical twin studies are eventually retired from the field, studies involving twins still have their place: further work can be done with identical twin genetics to better understand early stages of human development.\u00a0\nSources:Jonsson, H., Magnusdottir, E., Eggertsson, H.P. et al. (2021). Differences between germline genomes of monozygotic twins. Nat Genet, 53, 27\u201334. https://doi.org/10.1038/s41588-020-00755-1\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/06/counterpoint-not-so-identical-twins/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Ramp to the Photon Highway",
            "author": "Yu Jun Shen",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/IBMQ_Dilution_Refridgerator-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nIt is difficult to vibe on different wavelengths, especially in a quantum regime. In a recent paper published in Nature Communications, Yale researchers from the School of Engineering and Applied Science developed a thin-film lithium niobate-based device that converts photons between microwave and telecom optical frequency suitable for future quantum computing.\u00a0\nThe need for efficient bidirectional conversion between optical light and microwaves arose out of two technology trends. First, a leading contemporary approach to quantum computing is via superconducting qubits that use microwave photons on electronic chips at low (mili-kelvin) temperatures. Such microwave-based superconductor devices are suitable for scaling up quantum computers, and industry giants like Google and IBM have taken this approach. However, communication between quantum computers is best done using optical light instead of microwaves\u2014interlinked quantum computers then enjoy greater overall computational performance. A Yale group led by Professor Hong Tang has been actively researching methods to convert between microwave and optical photons at high efficiency.\n\u201cThe superconducting qubits utilize microwaves at extremely cold temperatures inside a cryogenic fridge, but sending these microwaves directly on a cable from one quantum computer to another will cause high loss and significant thermal noise,\u201d explained lead authors Yuntao Xu and Ayed Al Sayem. \u201cSo, we want a kind of transductor [an energy converter] between the waves, similar to how an Internet link forms between your PC and submarine cables.\u201d\u00a0\nThe team developed and tested a superconducting cavity electro-optics device that reached a high level of bidirectional efficiency at a classical, non-quantum level. They selected thin-film lithium niobate as the material and designed a compact resonator-based structure for it. Lithium niobate displays a high level of nonlinearity among non-linear crystals and is currently commercially available. The device is then tuned at resonance to allow gigahertz electrical signals to convert into optical frequencies and vice versa.\u00a0\n\u201cThin-film lithium niobate is an exciting new material, but it comes with a big problem of instability from the photorefractive effect,\u201d Sayem said. In the past, the photorefractive issue drastically limited the performance of lithium niobate in nanophotonics despite its good nonlinearity. The effect is more prominent at low temperatures, particularly hindering its use for transductor and quantum applications. Xu and Sayem resolved this challenge by integrating the thin-film lithium niobate resonators with a superconductor in an air-cladded structure, thus yielding conversion efficiencies of over one percent\u2014three orders of magnitude improved from comparable past results. This was not an obvious solution. \u201cThere are many steps in the fabrication process, and we had to determine which step plays the dominant role boosting the photorefractive effect. It turned out adding a dielectric coating layer\u2014instead of air layer\u2014would actually worsen the effect,\u201d Sayem added.\u00a0\u00a0\nThe team intends to continue development of bidirectional converters, including studying the effects of device packaging and sustaining the microwave resonance quality factor. Their long-term aim is to work with quantum signals, which would introduce stricter temperature and performance requirements. If successful, this development may pave the way for connecting many future quantum machines.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/ramp-to-the-photon-highway/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Food Insecurity in Honduras",
            "author": "Himani Pattisam",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/BeanFarm-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\u00a0\nWhen households go hungry, their members experience a range of effects, including stunted growth, a higher risk of developing chronic diseases, and lowered mental health. In a recent study, Sanjeev Kumar, a researcher at the Yale School of Public Health, sought to understand household food insecurity in a high-migration area in rural Honduras. Kumar was interested in exploring food insecurity as a critical factor influencing people\u2019s mental and overall health. \u201cPeople can explore local opportunities in the neighborhood when their basic needs are being met. When people lose their health, they are more risk-seeking,\u201d Kumar said, discussing the high level of migration from the Central American region.\u00a0\nThe study, conducted in collaboration with Yale professors Nicholas Christakis and Rafael P\u00e9rez-Escamilla, surveyed respondents about how often they worried about their household running out of food and how often their household had actually run out of food in the last three months. Respondents who had a larger social network or who lived in multi-generational families in the same village tended to be more food secure, likely because they could rely on others for support in times of need. Interestingly, affiliation or non-affiliation with a religious community network did not have a significant difference in the probability of experiencing food security, even though those social networks could theoretically provide support like that of an extended family.\u00a0\nThe researchers\u2019 findings also shed light on groups of people who have been historically excluded from studies on household food insecurity. For example, Indigenous people and those intending to migrate were found to have higher odds of experiencing food insecurity. Widows were also twenty-five percent more likely to be severely food insecure.\u00a0\nThere is still much more work to be done to improve global food security, especially in rural communities like those in the study. Though food insecurity is designated as a sustainable development goal by the UN, less than one percent of global aid is allocated toward improving undernutrition. Kumar\u2019s goal is to understand how focusing on nutritional security as a critical part of the healthcare policy initiatives can better support people living in rural villages\u2014to know \u201cwhat it will take for all of us to live in a more sustainable world,\u201d Kumar said.\u00a0\nKumar has a novel approach to this: deepening our understanding of the biological mechanisms behind the propensity to commit acts of violence within communities. He plans to further this research by investigating how household food insecurity affects early childhood breast-feeding practices\u2014and in turn, their long-term effects on the structure of social networks and the propensity for violence. \u201cIt is critical to create a convincing, cohesive narrative to improve awareness of household food insecurity around the world,\u201d Kumar said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/food-insecurity-in-honduras/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Staying Alive: How Plants Prepare for Winter",
            "author": "Saachi Grewal",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Saachi_Figure-1-375x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Melissa Askew on Unsplash.\nNew Haven\u2019s first red leaves have spun to the ground and the promise of autumn nears. Though it may seem like the plants are easing into the dormancy of winter, there\u2019s a lot going on beneath the surface. Yale researchers have identified a gene in Arabidopsis, a small flowering plant, that regulates the plant\u2019s physiological response to winter-like seasons.\u00a0\nThe expression of this gene, PP2-A13, is triggered by a metabolic response to a change in daylength. As light wanes, a plant produces less photosynthetic outputs, like sucrose. These sucrose levels indicate to the plant that it is either summer or winter, and PP2-A13 is respectively repressed or expressed. The PP2-A13 gene is lifesaving for a plant in the wintertime. It ensures cellular health, prevents vegetative growth, and breaks down cellular components for storage. \u201cThese plants aren\u2019t dormant; they\u2019re racing to save. It\u2019s like the harvest before a long winter,\u201d said Joshua Gendron, professor of molecular, cellular, and developmental biology and an author of the study published in Developmental Cell.\u00a0\nThough the humble Arabidopsis was the subject of this study, it may have far-reaching consequences. \u201cMy thought is that this is going to be pretty fundamental to all plants,\u201d Gendron said. If so, this newfound understanding of plant growth during wintertime processes can inform genetic editing for agricultural applications and result in longer growing seasons.\u00a0\nPP2-A13\u2019s universality would also make many native plants equally susceptible to climate change. If the duration of seasons changes as a result of global warming, the plants\u2019 predictive mechanism breaks down, alters growing seasons, and diverges reproductive cycles from the habits of pollinators. Global warming has a disproportionately large effect on winter, making it important that we expand our knowledge of wintertime processes in plants and related ecological implications.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/staying-alive-how-plants-prepare-for-winter/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Quenched Galaxy Leaves Astronomers Thirsty for More",
            "author": "Julia Levy",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Levy_Figure-1-500x240.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Polzin et al.\u00a0\nGalaxies, like humans, can be quenched\u2014not in the way that humans drink water, but in the way that galaxies form stars.\nThink of a galaxy as a lightbulb factory. Imagine you walked into this factory immediately after it stopped operating. You would see all the newly manufactured light bulbs and could conclude the factory must have recently stopped its production. A recently quenched galaxy is a recently dysfunctional star factory that still contains newly formed stars even though there is no active star formation.\u00a0\nAva Polzin\u2014a Yale graduate student working in the lab of Pieter van Dokkum, professor of astronomy\u2014researched a recently discovered galaxy known as COSMOS-dw1. COSMOS-dw1 is a dim, small, low-mass, isolated dwarf galaxy that lies far outside the gravitational influence of our local group of galaxies\u2014including the Milky Way\u2014at a distance of approximately twenty-two megaparsecs (Mpc). Before starting her research, Polzin already believed the galaxy to be quenched, but after examining its properties, including its stars and spectroscopy, she concluded the galaxy had only recently stopped its star formation, defining it as \u201crecently quenched.\u201d Finding an isolated quenched galaxy in this mass regime is rare. And to find one at this pivotal point of its lifespan and outside of the local group was a first. \u201cCOSMOS-dw1 deserved its own paper,\u201d Polzin said.\nCOSMOS-dw1 is fascinating for how it stopped producing stars\u2014in other words, how it became quenched. Other well-studied quenched galaxies have been assumed to discontinue their star formation due to their passing through a more massive galaxy. COSMOS-dw1 is at such a great distance from any large galaxy that Polzin concluded an internal occurrence must have ended its star formation. This exact occurrence, however, still requires further research. Currently, stellar explosions known as supernovae and other forms of energy released from stars are thought to drive quenching for low mass galaxies. Thus, Polzin hypothesizes that the young, blue stars in the galaxy might be remnants of the event that halted COSMOS-dw1\u2019s star formation.\u00a0\nCOSMOS-dw1\u2019s low luminosity combined with its far distance made the study immensely difficult. Since low mass galaxies have low luminosities, the only well-studied low mass galaxies are less than three Mpc away from our local group of galaxies, compared to COSMOS-dw1\u2019s significantly farther twenty-two Mpc. Several sky surveys initially overlooked the potential interest of COSMOS-dw1 due to its challenging characteristics. According to Polzin, the designs of most of these surveys are \u201cbiased\u201d against quenched galaxies due to their generally older and less luminous stellar populations.\nAs new wide-field surveys and instruments are developing, we must understand the flaws in our current methods. Polzin\u2019s study exemplifies the need for improved surveying techniques and analysis of survey data. Galaxies like COSMOS-dw1 may not be that rare in actuality\u2014just difficult to find with our current approaches.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/quenched-galaxy-leaves-astronomers-thirsty-for-more/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Dollar General Health Interventions",
            "author": "Noor Nouaili",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/2008-10-07_Dollar_General_in_Durham-1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "A study conducted by the Yale School of Management analyzed the impacts of using Dollar General stores as COVID-19 vaccine distributors. Originally, the U.S. focused vaccination efforts on commercial retail distribution partners through the Federal Retail Pharmacy Program (FRPP). However, lower-income households and populations living in rural areas face many barriers to receiving the vaccine, including access to transportation or scheduling technology.\u00a0\nProfessor Judith Chevalier and Assistant Professor Jason Schwartz concluded that adding Dollar General stores as vaccination sites would create proximity advantages for low-income households, populations living in rural counties, Black Americans, and Hispanic Americans in regions across the U.S.\u00a0\nChevalier and Schwartz used the Social Vulnerability Index (SVI) created by the Centers for Disease Control (CDC) to assess the relationship between vaccination accessibility and social vulnerability. The SVI uses factors such as socioeconomic status, access to special services and transportation, and household composition to determine which communities would require additional support during public health emergencies such as COVID-19. The higher the SVI calculation, the more vulnerable the population in that area. These areas are referred to as tracts. small subdivisions of a county or equivalent entity for which the census collects statistical data. \u201cThe SVI Index has been used a fair bit during COVID-19 to talk about whether people in low SVI areas are getting fewer or more vaccines than people in high SVI areas,\u201d Chevalier said.\u00a0\u00a0\nChevalier and Schwartz found that, even though higher SVI tracts have a lower number of retail pharmacies, they have a higher density of Dollar General stores. The addition of Dollar General stores as vaccine distributors would therefore increase the percentage of low-income households that are less than one mile from a pharmacy partner from 48.9 percent to 60.5 percent, significantly reducing the transportation barrier. \u201cWhile we may have missed our chance to use Dollar General stores in the first round of COVID-19 vaccines, I am hopeful that for the booster program they can consider it,\u201d Chevalier said.\u00a0\nDollar General stores, moreover, may hold potential in distributing resources beyond the COVID-19 vaccine. \u201cThere is also a whole variety of health interventions, social assistance programs, et cetera for which Dollar General stores are so perfectly located,\u201d Chevalier stated.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/dollar-general-health-interventions/",
            "captions": [
                "Dollar General variety shop at 800 Broad Street in Durham, North Carolina. Image courtesy of Wikimedia Commons."
            ]
        },
        {
            "title": "Decrypting Dinosaurs of the East: Uncovering records of eastern North American tyrannosaurs",
            "author": "Anavi Uppal",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fig.-1-500x339.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Millions of years ago, long before any of us existed, dinosaurs roamed the Earth. What might have stood where you are right now? Maybe a T. rex or a Triceratops?\u00a0\nIf you are somewhere in eastern North America, the dinosaurs that lived near you long ago might be unique. Chase Brownstein, a Yale College junior pursuing the Ecology and Evolutionary Biology major, recently conducted research showing that eastern North American dinosaurs were probably very different from the famous species of the American West. His work sheds light on the possibility of multiple paths to evolutionary success.\nDinosaur Island\nDuring the Mesozoic Era, when dinosaurs like the T. rex existed, the Earth looked very different from how it does today. Surrounded by oceans and seaways, eastern North America was isolated from the rest of the world for about thirty million years, constituting an island landmass named Appalachia. But since the 1800s paleontologists have largely neglected the study of what kinds of life once inhabited Appalachia.\nWhen organisms evolve on an isolated landmass, it\u2019s considered more likely for them to develop in ways that differ substantially from their relatives elsewhere. This has caused researchers like Brownstein to ask: was this true for dinosaurs isolated in Appalachia, and if so, what unique characteristics did they have? Poor fossil-forming conditions and other factors, however, have made this question difficult to answer.\u00a0\nFirstly, Appalachia has smaller mountain ranges compared to western North America. This means that the shorter rivers created by these mountains don\u2019t flow as far and therefore cannot accumulate as much sediment as their longer counterparts in the West. This accumulation of sediment is what creates fossil-forming regions. Shorter rivers generate fewer of these regions; thus, fewer fossils formed on Appalachia to begin with, making it difficult to know what kinds of dinosaurs lived there.\u00a0Additionally, the fossils that did form had a high chance of being destroyed later by glaciers. The same glaciers that carved out the Great Lakes dug up much of the fossil-containing sediment in eastern North America.\u00a0\nFinally, it\u2019s difficult to even access the fossils that did survive the glaciers, as the eastern coast of North America is much more densely populated than the West. Most of the land is privately owned. \u201cNobody wants you to make a giant hole in their backyard,\u201d Brownstein said. Many of the major fossil discoveries that are now in museums like the Yale Peabody Museum of Natural History were therefore made in the 19th century, when populations were less dense and eastern fossils more accessible.\nUncovering Clues\nIn 2015, while browsing collections at the Yale Peabody Museum, Brownstein elucidated connections between two different tyrannosaurs\u2014Dryptosaurus and the Merchantville tyrannosauroid\u2014to answer the question of whether distinct dinosaur species evolved on the once-isolated eastern North America. \u201cThis research is the culmination of several years of work into the question of eastern North American biogeography,\u201d Brownstein said.\u00a0\nIn 1866, West Jersey Marl Company workers discovered the enormous fossil of a dinosaur that lived approximately sixty-seven million years ago in modern-day New Jersey. Yale Professor of Paleontology Othniel Charles Marsh named the dinosaur Dryptosaurus in 1877. Brownstein had the opportunity to study the Dryptosaurus fossil at the New Jersey State Museum. The fossil revealed distinct anatomical features distinguishing Dryptosaurus from other tyrannosaurs like the T. rex. In particular, Dryptosaurus had an elongated skull and hands ranking among the proportionally largest for any dinosaur. Furthermore, it had massive claws reaching up to six inches long and an unusually shaped foot with three bones.\nWhile at the Peabody Museum, Brownstein noticed that the foot of a tyrannosauroid found in\u00a0the Merchantville Formation in Delaware displayed similar features to that of Dryptosaurus. To investigate, he used the Tree Analysis Using New Technology (TNT) program to conduct a phylogenetic analysis of the Merchantville tyrannosauroid and Dryptosaurus. The program incorporated the skeletal features of the two dinosaur species to determine evolutionary relationships.\nFrom this computational analysis, Brownstein discovered that the Merchantville tyrannosauroid and Dryptosaurus evolved from a common ancestor and are part of the same clade. That clade, known as Dryptosauridae, is a distinct group of tyrannosaurs that existed solely in Appalachia. For over a century, paleontologists have hypothesized the existence of a distinct set of tyrannosauroids native to the once-isolated eastern North America. With Brownstein\u2019s research, we now have evidence supporting that hypothesis.\nThough factors such as poor fossil records still constitute obstacles to our knowledge of the dinosaurs that inhabited the east, Brownstein\u2019s research underscores the rise of anatomical differences in the dinosaurs of eastern and western North America. In a broader context, such discoveries highlight the profound interplay between geographical isolation and the evolution of species.\nSearching for History\nEvolutionary biologists and paleontologists often develop \u201cjust-so stories,\u201d speculative explanations for the origins of a biological trait. The term comes from Rudyard Kipling\u2019s 1902 \u201cJust So Stories for Little Children.\u201d The book includes a collection of animal tales such as \u201cHow the Rhinoceros Got His Skin,\u201d in which the rhinoceros developed wrinkles after rubbing against a tree. In the context of dinosaurs, there are many speculative hypotheses that tyrannosaurs evolved a specialized skull, superior sight, or other specific traits to achieve supremacy. The T. rex\u2014the \u201cKing of the Dinosaurs\u201d that lived in western North America\u2014boasted hallmark features of dinosaur superiority, such as a gigantic skull, forceful jaw, powerful hindlimbs, and muscular physique. Yet, whether those features are indeed necessary for biological success remains up for debate.\nThe eastern North American Dryptosaurus, for example, differed from the T. rex and other tyrannosaurs: it had larger hands, extensive claws, and a distinctive unit of foot bones. \u201cEastern North American tyrannosaurs were really big, were probably predators, and had a different set of features than western North American tyrannosaurs,\u201d Brownstein said. \u201cThis may cause us to rethink the hypothesis that there was only one way that tyrannosaurs got so big and successful.\u201d In this way, Brownstein\u2019s discoveries point towards the possibility that tyrannosaurs achieved success through the evolution of differing features.\nAs Brownstein emphasized, his research raises broader questions of evolution that demand further research and contemplation\u2014the prevailing one among them being: how many paths could there be to evolutionary success?\u00a0\nTo find out more about eastern North American dinosaurs, the next step would be to discover a more complete skeleton of these species. Currently, research is limited to the fossils that have already been found, which do not include the body part that paleontologists consider to be the most informative: the skull. However, looking at living things today could also shed light on the nature of extinct species. Analyzing the characteristics of dinosaur descendants can sometimes help us learn more about their ancestors.\nBehind the Discoveries\nBrownstein\u2014who has an impressive research history, having published about twenty peer-reviewed articles in journals including Royal Society Open Science, the Journal of Paleontology, Scientific Reports, and the Zoological Journal of the Linnean Society\u2014intends to go forward with other research while he waits for more fossil discoveries. He is currently studying fishes with Yale Professor and Chair of Ecology and Evolutionary Biology Thomas Near. \u00a0\nBrownstein said that he was fortunate to have access to fossil collections like those at the Peabody Museum and described his appreciation for those who have provided support and advice in his research endeavors. \u201cI have been very fortunate to have people who gave me a chance,\u201d Brownstein said.\nBrownstein has a genuine passion for the field of research. \u201cI have always been really fascinated with nature, time, what lived before, and how we got here,\u201d he said. Research simply makes him happy. \u201cIf I want to do something that I enjoy, I will do research, write, and study things,\u201d he said. Based on this passion, Brownstein described science in the larger context of the human desire for exploration. \u201cIt is a human thing to constantly explore. The urge to discover is a motivator in science, and it\u2019s a beautiful thing,\u201d he said.\u00a0\nJust like we push the boundaries of our universe with space travel, we are now pushing the boundaries of time by uncovering our planet\u2019s incredible history. In Brownstein\u2019s case, we now understand that the geographical isolation of eastern North America over the course of thirty million years likely provided the means for the evolution of distinct dinosaur species.\nAs we continue to uncover our planet\u2019s incredible history, what will we discover next?\nAbout the authors: \nElisa Howard is a sophomore neuroscience major in Berkeley College. In addition to writing for YSM, she volunteers at CT Hospice and Yale Community Kitchen, constructs 3D-printed limb devices through Yale e-ENABLE, and helps organize blood drives for the American Red Cross at Yale. During the summer, she researches neural repair in the Strittmatter Lab at the Yale School of Medicine.\nAnavi Uppal is a sophomore astrophysics major in Pierson College. In addition to writing for YSM, she is one of Synapse\u2019s outreach coordinators, and she teaches science to elementary schoolers through Yale Demos. She\u2019s also a fall social media intern at NASA Ames Research Center.\nAcknowledgments: \nThe authors would like to thank Chase Brownstein for his time and enthusiasm about his research.\nExtra reading:\nDoran Brownstein, C. (2021). Dinosaurs from the Santonian\u2013Campanian Atlantic coastline substantiate phylogenetic signatures of vicariance in Cretaceous North America. Royal Society Open Science, 8(8), 210127. https://doi.org/10.1098/rsos.210127\nMarsh, O. C. (1896). The Dinosaurs of North America. Govt. Print. Off.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/decrypting-dinosaurs-of-the-east-uncovering-records-of-eastern-north-american-tyrannosaurs/",
            "captions": [
                "A painting detailing the hypothesized appearance of Dryptosaurus. Image courtesy of Wikimedia Commons."
            ]
        },
        {
            "title": "An Unexpected Reason for COVID Outcomes: The presence and role of autoantibodies in patients with COVID-19",
            "author": "Sophia David",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/David_Fig1-500x281.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "As the COVID-19 pandemic rages on, researchers have puzzled over several mysterious viral outcomes. Infections are severe in some people yet mild or even asymptomatic in others, and many have reported long COVID, in which COVID-19 related health problems last four or more weeks after infection. Yale undergraduate Eric Wang (YC \u201921) worked alongside members of the Ring and Iwasaki labs to study the relationship between autoantibodies and COVID-19.\u00a0\nGenerally, we consider antibodies to be illness protectors. Autoantibodies, in contrast, may cause harm. \u201cThey are antibodies that target proteins expressed by your body\u2019s own cells,\u201d Wang said. They can trigger the killing of specific helpful immune cells and disrupt general immune system communication.\u00a0\u00a0\nUsing samples from Yale New Haven Hospital patients and healthcare workers, Wang and the research team tested blood reactivity with 2,770 human extracellular secreted proteins. They selected a few examples of autoantibodies and performed in vitro signaling assays, later assessing their effect on disease progression in mice. They found that autoantibodies targeted cytokines, chemokines, and various cell surface protein receptors, potentially altering disease trajectory.\u00a0\n\u201cA lot of the symptoms and reasons people go to hospitals are due not to the virus itself, but the body\u2019s response to the virus. For example, an overactive immune system has been implicated in a lot of COVID-19 hospitalizations,\u201d Wang said. These autoantibodies may also be linked to long COVID symptoms.\nWith this new knowledge that autoantibodies may be risk factors for more serious COVID-19 outcomes, physicians may incorporate autoantibody screening in their practice.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/an-unexpected-reason-for-covid-outcomes-the-presence-and-role-of-autoantibodies-in-patients-with-covid-19/",
            "captions": [
                "Realistic COVID-19 virus. Image courtesy of Google images, creative commons."
            ]
        },
        {
            "title": "Alumnus Profile: Eric Y. Wang (YC \u201921)",
            "author": "David Zhang",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/DONG1-500x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "For Eric Y. Wang (YC \u201921), photography has always been about seeing things you would normally miss in daily life. And throughout his four-year research career at Yale, Wang always approached scientific problems the same way, looking for things other people would normally miss. The approach has led him to countless successes. Earlier this year, Wang was first author in a Nature paper on autoantibodies and is now on his way to an MD/PhD at Weill Cornell.\nComing into Yale, Wang knew he wanted to pursue both research and photography. Having done both in high school, Wang immediately joined a lab as well as the Yale Daily News (YDN) during his first year. Although his very first research project didn\u2019t go as planned, Wang used these experiences as valuable learning moments. \u201cIt was a good experience because in science, things are bound to go wrong, even in the best projects, and having that early experience of things not working reinforced my desire to do research,\u201d Wang said. \u201cThe fact that I still wanted to do research after going through this experience probably means I am really interested in it.\u201d\u00a0\nDuring his sophomore year, Wang joined Aaron Ring\u2019s (YC \u201908) lab, hoping to have the opportunity to take on his own project. \u201cFor me, what I really wanted from a lab was the ability to lead my own project and take on something for myself,\u201d Wang said. With the support and encouragement of Ring, Wang quickly translated his passion for research into meaningful work, taking charge of a project that would later become the foundation for his autoantibody publication. Wang would spend two years tirelessly developing novel technology capable of detecting autoantibodies, something seen in many autoimmune diseases as well as in patients with COVID-19.\u00a0\nWhen COVID-19 forced all the labs to close, Wang was able to make the most out of his situation, remotely analyzing his screened COVID-19 patient samples, which eventually led to his publication. \u201cEric had a totally fearless and gung-ho mindset where he got completely absorbed in an interesting scientific question and was willing to take any approach he could to address that question,\u201d Ring said.\u00a0\nWang\u2019s drive was not only seen in the laboratory, but also in the photojournalism work he did for YDN. Wang quickly rose through the ranks, from contributing photographer his first semester to photo editor by the beginning of his sophomore year. For Wang, photojournalism was a completely different type of photography than what he was used to. \u201cI came from a really quiet suburb. Our [high] school didn\u2019t really have a newspaper, so I never really had that exposure,\u201d Wang said. Nonetheless, Wang used photojournalism as one of his ways to stay connected to the Yale community. Wang documented a diverse array of events at Yale, from the opening of Benjamin Franklin and Pauli Murray Colleges to the protests against a shooting that involved the Yale Police Department in 2019. \u201cIt was really cool seeing your photos being spread online,\u201d Wang said. \u201cThis was particularly true in the case of protests. Photos from protests can be very powerful and moving and can call people to action.\u201d\u00a0\nAlthough photography and research might not immediately seem to involve overlapping skills, the ability to see the things others normally wouldn\u2019t has helped Wang get to where he is today in both of his passions.\u00a0\nWhen asked about his future plans and why specifically he chose to pursue a MD/PhD, Wang mentioned the unique perspective he will gain on human diseases as a physician scientist. \u201cWhen you talk about things in science, you don\u2019t really talk about the patients as much. It\u2019s very easy to get disconnected from what actually matters\u2014which for me is being able to help patients,\u201d he said. Research-wise, Wang hopes to continue growing as a scientist, formulating important scientific questions and ideas so that one day, he can start his own lab. Wang also hopes to continue his love for photography and to take advantage of all the unique features that New York has to offer through street photography.\u00a0\nHis biggest advice for aspiring scientists? \u201cNot to stress about things like publications\u2026 it\u2019s much more important to focus on developing yourself as a scientist,\u201d he said. Living by that advice, Wang has been able to broaden his scientific knowledge and gain a unique way of thinking that has helped him find success.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/alumnus-profile-eric-y-wang-yc-21/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: Fuzz by Mary Roach",
            "author": "Norvin West",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/elephant-picture-500x360.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Jeff Bergman on Flickr.\nAnimals\u2014they are the lovable beings that are generally seen as allies to humans, bringing joy and perspective to our lives. But what happens when there is trouble in paradise\u2014when animals and humans begin to have conflict? And does nature handle it, or do we take it into our own hands? Mary Roach, in her new book Fuzz: When Nature Breaks The Law, analyzes this issue from a humorous and first-person point of view.\nRoach demonstrates a beautiful case of nature facilitating cohabitation between animals and humans in Aspen, Colorado. We\u2019ve all seen animals snooping for food, but according to Roach, the bears of this mountainous town take it to another level. Here, residents don\u2019t just find bears dumpster-diving; they find bears snatching food off dinner tables and hiding in the rooms of houses. There is hope for the future though: laid-back bears, like an infamous one nicknamed \u201cFat Albert,\u201d are favored by natural selection because they calmly carry out their food operations in such a suave manner that homeowners can tolerate it. They are therefore more likely to get away, survive, and pass on their calm temperaments to their offspring.\u00a0\nRoach finds a contrasting example in India\u2019s more lethal, man-eating leopards. Expert animal handlers have tried relocating them, but particularly aggressive species are even more dangerous after being moved. Moreover, relocation would likely create a dilemma over whether it is ethical to remove animals from their natural habitats. To address this ostensibly unsolvable problem, scientists attempt to control the density of these populations, rather than remove them altogether.\u00a0\nElsewhere, Roach writes, humans are using molecular biology and chemistry to alter the animals around them. Aaron Shiels, a wildlife biologist, is working on an escape-proof habitat for mice, which would be genetically modified to only produce male offspring. This would be done with CRISPR technology, which targets a gene and cuts it out or replaces it. In isolation, Shiels\u2019s work would eventually lead to a less dense population of mice. Additionally, a few US cities are trying a contraceptive on rats called Contra-Pest, which uses 4-vinylcyclohexen diepoxide and triptolide, two components that impact the reproductive viability of certain species.\nPeople can also shift their mindsets when it comes to wildlife. On an individual level, perceiving interactions with nature as an inherent part of life rather than a burden could give people peace of mind. Perhaps we should remove ourselves from animals\u2019 natural habitats rather than the other way around. According to Roach, people have invaded Bengali forests and turned elephant habitats into their own, forcing the elephants to aggressively come into villages looking for refuge. Indeed, sometimes we as people are our own worst enemies, villains to the very animals we love and cherish. We mustn\u2019t maliciously take advantage of our manpower and intellect, but rather use it to facilitate human-animal coexistence in a way that is mutually beneficial.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/science-in-the-spotlight-fuzz-by-mary-roach-the-future-of-peaceful-human-animal-coexistence/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: Breaking Boundaries",
            "author": "Chris Esneault",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/49449072528_1876ce3416_b-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of House of Lords.\nLying in my bed on a Saturday morning, I hesitantly opened my laptop to begin watching David Attenborough\u2019s latest documentary, Breaking Boundaries: The Science of Our Planet. I say \u201chesitantly\u201d because, while I am a huge proponent of sustainable living and learning about how climate change affects us, I\u2019m honestly not a big documentary guy. While I have, no doubt, seen my fair share of An Inconvenient Truth-esque films, sooner or later, they all begin to meld into one big, urgent, overwhelming, ominous mess. However, after watching this riveting documentary, I can say with full confidence that if you are someone who wants to learn more about the ways in which humans have, quite literally, broken the boundaries of Earth\u2019s climate, biospheres, oceans, and atmosphere, then this is the perfect Netflix quick-fix for you.\nTaking a much more climate-forward approach to education than his past documentaries, David Attenborough starts off by introducing Swedish climate scientist Johan Rockstr\u00f6m. Rockstr\u00f6m and his colleagues gained fame within the scientific community recently when they hypothesized that there are nine boundaries humans need to respect in order to keep Earth sustainable for human life. While we currently live within the safe zones for five of the boundaries (freshwater use, ocean acidification, aerosol pollution, ozone layer depletion, and novel pollutants like nuclear waste), we have already surpassed four of the boundaries: climate change, land use, biodiversity integrity, and biogeochemical flows of nitrogen and phosphorus.\u00a0\nThe effects of crossing these boundaries can be seen most significantly by the melting of the ice poles. However, scientists in the documentary also point out that an increase in drought, wildfires, flooding, and even the onset of the COVID-19 pandemic can all be tied back to our unsustainable living habits.\u00a0\nTheir perspectives show us that this planetary crisis is a metaphorical asteroid coming to Earth. We are reaching a point where ignorance of this issue is simply unacceptable. Healthcare services have become overwhelmed, entire ecosystems face collapse, and novel zoonotic diseases have been transmitted to humans, all because of the climate disaster. If humans do not act with responsibility and purpose, our planet will soon be uninhabitable.\nAfter hearing about this incredibly overwhelming climate crisis, where do you begin to tackle this problem on an individual level?\u00a0\nWatching this documentary is definitely a start. You can also join a club on campus. If you\u2019re interested in assuming a leadership role, think about applying to be a Residential College Sustainability Liaison. When eating in the dining halls, maybe swap out your cheeseburger for tofu tenders every so often, since transitioning to a more plant-based diet is one of the single most important ways you can reduce your carbon footprint. When possible, buy your clothes second-hand, and walk or bike around. Continue to educate yourself about the problems facing our planet and vote for environmentally conscious politicians.\u00a0\nWith these actions in mind, we must now begin to act with a unified purpose, in search of\u2014as David Attenborough puts it\u2014the perfect home.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/science-in-the-spotlight-breaking-boundaries-a-breakdown-of-david-attenboroughs-latest-documentary/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: How Will Climate Change Progress?",
            "author": "Crystal Liu",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-3-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Hippopx.\nWildfires. Heatwaves. Strong precipitation and floods. Extreme weather has been exceedingly common this decade, destroying natural ecosystems and claiming hundreds of lives. Global warming has contributed to its increasing prevalence, according to a new report from the Intergovernmental Panel for Climate Change (IPCC). And this trend will continue in the foreseeable future.\u00a0\n\u201cIt is unequivocal that human influence has warmed the atmosphere, ocean, and land,\u201d read the report\u2019s very first finding. Skeptics of climate change prefer to blame natural factors, arguing that there is no need to change human behavior. But scientific evidence has ruled out this fantasy.\nThe goal of the Paris Agreement was to limit global warming well below two degrees Celsius. Earth is now 1.1 degrees Celsius warmer than it was in the 19th century. Under current policies, the difference will rise to 2.7 degrees Celsius by the end of this century. If rapid and massive measures are taken, however, a relatively cooler future is possible. Adopting more eco-friendly measures, like afforestation and the usage of cleaner energy sources, can cap warming at two degrees Celsius in the late-twenty-first century.\nBut in an interview with the New York Times, Robert Kopp, a climate scientist at Rutgers University, notes that we shouldn\u2019t view these standards as rigid. \u201cIt\u2019s not like we can draw a sharp line where, if we stay at 1.5 degrees, we\u2019re safe, and at two degrees or three degrees it\u2019s game over. But every extra bit of warming increases the risks,\u201d Kopp said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/qa-how-will-climate-change-progress/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Can Brains Be Fossilized?",
            "author": "Odessa Goldberg",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-2-375x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "If you consider yourself a pretty awesome human being and your brain remarkably special, wouldn\u2019t you want your brain preserved and found 310 million years into the future? Well, first you\u2019d want to find yourself in a low-oxygen environment at the time of your death. Then you\u2019d want to be covered in siderite, an iron carbonate. Your brain would start to degrade, but have no fear: kaolinite would creep in and form a perfect white mold of your brain in fifty years. And after many, many years, rock would form around your brain until you\u2019d be found, studied, and lauded.\nFossils of brains are incredibly rare because lipid-rich brains are quick to decay. But a fossil of the brain of a horseshoe crab, Euproops danae, was recently discovered at the Yale Peabody Museum of Natural History by researchers from the University of New England, Harvard University, the Natural History Museum in London, and Pomona College. The artifact was originally sourced at Mazon Creek, a fossil site in Illinois.\u00a0\nResearchers compared this preserved brain with the brains of modern horseshoe crabs and found that they were very similar. They deduced that the organisms likely had similar behavior, too. This fills a gap in the timeline of the central nervous systems of euarthopods, one of the best-preserved invertebrate animals.\nFinding a fossil of a brain like this is extraordinary: a product of many processes going exactly the right way at the right time in the right place. Before you theorize how you might fossilize your own brain, pay homage to our horseshoe crab pioneer.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/qa-can-brains-be-fossilized/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Perceptions of \u201cNatural Gas\u201d: The influence of terminology and political affiliation",
            "author": "James Licato",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Licato_Fig1-1-500x310.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Natural gas continues to be one of the most popular energy sources across the world. The largest component of natural gas is methane, a potent greenhouse gas with twenty-five times the global warming potential of carbon dioxide. Mining natural gas also results in leaks that pollute the atmosphere. However, the American public perceives natural gas and renewable energy sources, like wind and solar, similarly. This discrepancy motivated Karine Lacroix and researchers from the Yale Program on Climate Change Communication to study the American public\u2019s perception of natural gas based on differing terminology, as well as the effect of political affiliation on perception.\nThe researchers asked over three-thousand volunteers to take a survey that questioned their perceptions of one of six terms: natural gas, methane gas, natural methane gas, methane, fracked gas, and fossil gas. The team chose terms based on their prevalence in media and everyday conversation.\nLacroix and her team found that the term \u201cnatural gas\u201d was perceived most positively by a significant margin. Their findings also suggest that there is a general lack of knowledge about the ramifications of using natural gas. Partisanship also affected term perception, with Republicans holding more positive perceptions than Democrats.\u00a0\nPublic opinion is an important driver for policy initiatives. To more accurately portray the downsides of natural gas in the public sphere, \u201cclimate communicators should refer to [natural gas] as methane gas,\u201d Lacroix explained. Lacroix and her team look to continue their work in climate change communication as greenhouse gas emissions rise.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/perceptions-of-natural-gas-the-influence-of-terminology-and-political-affiliation/",
            "captions": [
                "Fracking for natural gas. Image courtesy of Daniel Foster (Flickr)."
            ]
        },
        {
            "title": "Forests of the Future",
            "author": "Tori Sodeinde",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2-Clearcut-Forest-1-500x335.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons\nTake a look around the room you\u2019re in and see if you can find any items made of wood; there are probably quite a few. While wood is an essential material in the manufacturing industry, poor harvesting methods can devastate forest ecosystems and limit long-term timber availability. A former Yale College undergraduate, Romy Carpenter, working under the supervision of Mark Asthon, investigated a chronosequence of forest harvests in the Yale-Myers forest to study how irregular shelterwood harvesting affects soil composition over time.\u00a0\n\u201cThe foundation of this paper is this chronosequence of [irregular] shelterwood harvests,\u201d Carpenter said. A chronosequence is a set of forest sites, each having similar characteristics but a different age (time since the forest has been harvested). Each section of the forest is like one frame from a time-lapse, so imagine the difficulty of waiting 25 years to watch one section of forest develop! By using a chronosequence instead, research can be performed much more quickly.\u00a0\nWhile normal shelterwood cuts leave individual parent trees standing, irregular shelterwood cuts leave groups of reserved trees standing. \u201c[These cuts] mimic a natural disturbance because there are certain stands of trees that are left remaining, and those stands of trees provide canopy shade and a seed source for regeneration,\u201d Carpenter said.\u00a0\nCarpenter took soil samples from irregular shelterwood harvest sites at all different stages of regeneration after harvesting and tracked soil nutrients such as carbon, nitrogen, calcium, magnesium, and potassium. Increased nutrient availability is common in the first years after a harvest due to decomposition of debris and less plants taking up nutrients, but after the initial uptick, soil nutrient levels usually drop for a long time. However, the study uncovered exciting trends in the soil composition of the chronosequence. \u201cThis forest type is able to re-organize and reassimilate the nutrients back within a relatively short period of time,\u201d Ashton said. All important macronutrients recovered within the twenty-five-year timespan studied.\u00a0\nCarpenter also investigated the changes in isotope composition of the soil. Elements exist in multiple isotopes (atoms of the same element with different weights), and the proportion of carbon isotope \u03b413C is closely related to the rate of organic matter cycling in an environment. \u201cThe proportion of \u03b413C changes with how quickly organic matter cycles. If \u03b413C is higher, it\u2019s indicative of a slower cycle,\u201d Carpenter said. The amount of \u03b413C decreased after the harvest, indicating that fast-cycling carbon from sources like debris from the harvest recovered quickly.\u00a0\nThese data provide evidence that irregular shelterwood harvests are a sustainable forest management technique that facilitate quick soil nutrient recovery. Carpenter also viewed the project as a starting point to begin her career; she now works as a soil chemist in Maine creating soil nutrient management plans. Carpenter\u2019s work is part of a larger study of the Yale-Myers Forest chronosequence; researchers are also investigating ecological impacts of harvesting on organisms such as birds and amphibians. Insights gleaned from these studies will hopefully steer timber production towards a more sustainable future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/forests-of-the-future/",
            "captions": [
                ""
            ]
        },
        {
            "title": "\u201cHands up, We\u2019ve Got You Surrounded!\u201d: A protein that dissolves bacterial membranes to execute immunity",
            "author": "Emily Shang",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Shang_Figure1-362x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Every society needs a group of superheroes. And as a society of proteins, organic molecules, and nucleic acids, cells are no different. To defend against pathogens, certain proteins within the cell work vigilantly to secure its safety. One group of these vigilantes hails from a set of mysterious genes termed the apolipoprotein L (APOL) family. Twenty years ago, the discovery of APOL1, which functions outside of the cell to defend against extracellular parasites, led scientists to believe that the other five APOL genes may defend against intracellular pathogens since they lack a secretion signal. Led by postdoctoral fellow Ryan Gaudet, the MacMicking lab at Yale and collaborators unearthed the function of one of these five genes, APOL3, which codes for a protein that attacks Gram-negative bacteria such as Salmonella.\nAPOL3 interacts with another host defense protein, guanylate binding protein (GBP1), which autonomously binds to the sugar-rich surroundings of Gram-negative bacteria. When GBP1 invites APOL3 to the inner membrane of Gram-negative bacteria, APOL3 kills the pathogen by dissolving the lipid membrane, essentially ripping apart the bacterial membrane in the cytosol.\u00a0\nWith great power comes great responsibility: APOL3 needs to discriminate between self and non-self-membranes. APOL3 doesn\u2019t surround lipids within the cytosol without specificity\u2014that would be dangerous. A key ingredient in host cell membranes, cholesterol, is an inhibitor to APOL3 that prevents self-destruction. \u201cCholesterol makes APOL3 less able to insert its hydrophobic component into the membrane,\u201d Gaudet said.\u00a0\nGaudet is optimistic about the many avenues of exploration for APOL3, including future work investigating the protein\u2019s role in vivo.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/hands-up-weve-got-you-surrounded-a-protein-that-dissolves-bacterial-membranes-to-execute-immunity/",
            "captions": [
                "Microscopy image of Salmonella typhimurium invading host epithelial cells. Image courtesy of Genetic Engineering & Biotechnology News."
            ]
        },
        {
            "title": "Colder and Wiser:  The impacts of aging on thermoregulation",
            "author": "Van Anh Tran",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Duality_Of_Cold_Final-Breanna-Brownson-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Babies don\u2019t shiver when they\u2019re cold\u2014at least for the first six months of their lives. Instead, they keep warm through a mechanism called non-shivering thermogenesis, in which a special type of fat called brown adipose tissue generates heat. But as babies grow older, thermogenesis is no longer their primary means of keeping warm. According to a study by researchers at multiple centers, including Yale, age-related changes in thermoregulatory control arise from changes in the body\u2019s immune system. The authors discovered that aging impairs a specific kind of immune cell called type 2 innate lymphoid cells (ILC2s), which are important for the maintenance of healthy adipose (fat) tissue.\nWe have two types of fat in our bodies: white adipose tissue (WAT) and brown adipose tissue (BAT). Aging is marked by a decline in brown adipose tissue and a shift in the distribution of white adipose tissue. As we grow older, we have an increase in white adipose tissue in our trunk and abdomen. This visceral adipose tissue is subject to enhanced inflammation and insulin resistance, which increases the risk of obesity among the elderly.\nThere also exists a third type of body fat midway between white and brown adipose tissue: beige adipose tissue, which arises from white fat parent cells but possesses similar features to brown fat cells. Beige adipose tissue also responds to cold exposure via energy expenditure and heat production.\u00a0\nThe scientists looked into ILC2s because of their role in visceral adipose tissue \u201cbrowning,\u201d the production of beige fat cells. They compared the immune compartment differences between young and old mice models and found that there was an almost complete loss of ILC2s in the visceral adipose tissue of older mice.\nILC2s are tissue-specific immune cells, meaning they stay within the visceral adipose tissue after their generation in the bone marrow. ILC2 development depends on the proliferation of IL-33, which belongs to a class of small cell-signaling proteins that regulate our immune systems. The research team found that IL-33 was produced in different cellular locations in the adipose tissue of young versus old mice. This switch in cellular source led them to believe that there is less IL-33 available to develop ILC2s. Less ILC2s means less browning, and thus a weakened cold tolerance.\u00a0\nThe authors hypothesized that if they could supplement IL-33 in old mice, the resulting ILC2 development would restore healthy cold response. They examined this through the \u201ccold challenge\u201d method, during which mice were placed alone in cages that were kept at around forty degrees Fahrenheit. Experimenters checked on the mice twice a day to monitor mortality rates, then took adipose tissue samples from mice that survived for two straight days to look for signs of a healthy cold response.\nSo, can IL-33 alone fix the immune system of older mice? In short, it can\u2019t. Actually, mice with supplemented IL-33 had a higher mortality rate than did other old mice in the cold challenge. Their response to cold and temperature regulation was still entirely dysfunctional.\nFaced with totally unanticipated results, the researchers came to realize that maybe the problem wasn\u2019t with IL-33 at all: it was with the ILC2s themselves. Using RNA sequencing, they discovered that ILC2s of old mice are pathogenic. Simultaneously, there are very few healthy ILC2s left to offset these negative effects. While the researchers were unable to determine the exact mechanism of old ILC2 lethality, it certainly seems to be a double-edged sword that leads to the dysfunction of the thermogenic response.\nThe research team tried one last experiment. ILC2s from young, healthy mice were directly transplanted into older mice. Only then did the thermogenic response increase and mortality rates in the cold challenge decrease.\u00a0\nThese results caution us that attempting to \u201cfix\u201d an immune pathway can be tricky\u2014we don\u2019t know if we could be causing more problems than we solve. \u201cWith age, the immune system has already changed, and we need to be careful how we manipulate it to restore the health of the elderly,\u201d said principle investigator Vishwa Deep Dixit, Waldemar Von Zedtwitz Professor of Comparative Medicine and of Immunobiology at Yale, in an interview with YaleNews.\u00a0\nFully understanding how to repair the immune system could be a game changer for the elderly or people with immune deficiencies. \u201cImmune cells play a role beyond just pathogen defense and help maintain normal metabolic functions of life,\u201d Dixit told YaleNews. These other functions include cold response and regulation of fat. Armed with more knowledge of why the immune system stops working, researchers like Dixit can continue to work towards solutions that will lead to a healthier population in more ways than one.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/colder-and-wiser-the-impacts-of-aging-on-thermoregulation/",
            "captions": [
                "Art Courtesy of Breanna Brownson."
            ]
        },
        {
            "title": "Birds of a Feather Color Together: Studying the structure of bird feathers could revolutionize engineering",
            "author": "Ryan Bose-Roy",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/RainbowWings.Anasthasia.Shilov-Anasthasia-Shilov1-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "From the bright Red-Necked Tanager to the deep Blue Crowned Pigeon, over ten-thousand species of birds share the planet with us. Throughout history, their colorful feathers have flickered ubiquitously into fashion and culture. But where do bird feathers get their colors from? What makes cardinals red and blue jays blue?\u00a0\nThe search for answers to these questions has led to novel discoveries in nanophotonics and soft-matter physics. A recent Yale study on how birds make blue feathers\u2014led by Vinod Saranathan, Ornithologist and Applied Physicist at Yale-NUS, and Richard Prum, William Robertson Coe Professor of Ornithology at Yale\u2014opens new avenues in many lines of research, from understanding the physics of cell biology to creating more efficient solar panels.\nPrum, who is also head curator of vertebrate zoology at the Yale Peabody Museum, explores the relationship between the phenotypic diversity of bird species and their evolutionary history. \u201cI was interested in paleontological discoveries in bird feathers, and also a sideline on pigmentation and coloration, and before you know it those two worlds connected,\u201d he said.\u00a0\u00a0\nHow Bird Feathers Have Color\nIn some birds, feather colors are produced by pigments, like brown melanins and orange carotenoids. In many other birds, however, colors are produced by the intrinsic structure of the feather. In these \u201cstructurally colored\u201d feathers, light is scattered off proteins coating secondary feather barbs\u2014microscopic comb-like fronts that doubly extend out from the stiff center of a feather and then stock together into a vane.\nSome structural colors are iridescent: light bounces off at different angles on a feather\u2019s surface creating positive and negative overlap, resulting in a feather whose color changes depending on the direction from which you look at it. Peacocks have iridescent feathers, and they change from blue to turquoise as the bird moves around. However, blue jays, blue grosbeaks, and several other birds have non-iridescent feathers: they always look blue, no matter what direction you look at them. And they never fade. \u201cBirds that were collected one-hundred years ago look just as lifelike as if they were collected today,\u201d Saranthan said.\nThe barbs of non-iridescent birds\u2019 feathers are made of a protein called \u03b2-keratin, which forms nanostructures interspaced by pockets of air that evenly scatter different wavelengths of incoming light, creating a pure single color.\u00a0\nThese structures grow by a process called phase separation, which also happens when you pour soda into a glass. In the pressurized soda can, the carbon dioxide and water are thoroughly mixed. When the can is opened, the pressure changes, and carbon dioxide rises from the liquid in the form of bubbles, which form foam on the sides of the glass. Drop a coin in the glass and you\u2019ll see bubbles form on the surface of the coin as well; bubbles need nucleation sites, or central hubs, to form and grow over time. At the nanoscale, this is what generally happens in bird feathers, except that while carbon dioxide forms spherical bubbles, \u03b2-keratin in bird feathers forms a variety of shapes.\nPreviously, using scattering patterns from super-high intensity X-rays, Prum and Saranathan had identified structures made from keratin fibrils in the surface patterns within feathers of every single bird in the ornithology collection of Yale\u2019s Peabody Museum. \u201cThere are two types of structures we thought were generated,\u201d Saranathan said. \u201cOne looked like swiss cheese, or bubbles in a beer foam. The other one looked like nano-spaghetti\u2014you get this random jumble of keratin fibrils in the air.\u201d\u00a0\nHowever, while perusing the feathers of different bird species, Saranathan and Prum found something that, as Saranathan puts it, \u201clooked very funky.\u201d In the leafbird species, found only in Asia, iridescent colors were not produced in the secondary feather barbs, but in the primary feather branches. \u201cThat was really a clue that something new was going on here,\u201d Saranathan says. Rather than the swiss-cheese or nano-spaghetti subunits lining the surface of the feather, the building blocks formed by \u03b2-keratin took the shape of a new, complex topological structure called a single gyroid.\u00a0\nGyroids: A Game-Changer\nA gyroid is an example of what mathematicians call a minimal surface, a shape that takes the least amount of surface necessary to span a given region of space. Structures with high-surface area-to-volume ratios, like a human brain, consist of lumps and folds and have a high degree of average curvature. At any given location on the gyroid surface, however, the positive bumps and negative depressions even out to zero, yielding a mean curvature of zero.\nGyroids are minimal surfaces that are triply periodic, meaning that a small piece on the surface can be repeated in three independent directions to assemble the entire surface. What gives the gyroid its characteristic shape is that it has no planes of reflectional symmetry and no straight lines at any point along its surface. Any point along its surface lies in a region that looks something like a saddle.\u00a0\nTen years ago, Saranathan had conducted X-ray analysis on iridescent green butterflies and found these same single gyroid structures. Though these structures have been modeled by scientists and mathematicians since the 1970s, Saranathan\u2019s butterfly discovery was the first time they had ever been positively identified in nature.\nThe single gyroids that Saranathan and Prum identified in birds and butterflies represent a game-changer for several reasons. For one, single gyroids are structurally distinct from the far more common double gyroid structures, which consist of two interlocking gyroid surfaces enmeshed together. Unlike the double gyroid, the single gyroid has both a full electronic bandgap as well as a full optical bandgap, which means that it completely traps all directions and polarization states of light and easily excites electrons to a conductive state. This gives single gyroids better electronic (conductive) and optical (reflective) properties than double gyroids. Thus, they could be an incredibly useful tool in solar cells for sequestering light and turning it into electricity.\nAdditionally, Saranathan and Prum\u2019s discovery could open up new ways of directly synthesizing single gyroid nanostructures, which could serve as a powerful optical tool for a variety of disciplines. Currently there is no way for engineers to make the single gyroid directly. Saranathan and Prum explained that soft-matter engineers instead embed Lego-like molecules with hydrophobic and hydrophilic components in solution, where they locally reorder into a double gyroid structure. Engineers then chemically degrade one of these components, backfill the empty space with gold, and burn away the remaining organic complement. This process leaves a single gyroid made of gold, which can then be used as a template to form single gyroids from other materials.\u00a0\nInherent limits in this double gyroid etching process make it impossible to synthesize single gyroids larger than fifty nanometers in unit size. Unfortunately, single gyroids that interact effectively with light are around five-hundred nanometers. Researchers have yet to find a way to synthesize one of that size. Both butterflies and birds, however, have figured out the process.\nMaking Single Gyroids\u00a0\u00a0\u00a0\u00a0\u00a0\nCuriously, butterflies make single gyroids the same way researchers do\u2014only somehow, they\u2019re able to make them ten-times larger than engineers can.\u00a0\nBut \u201cthe birds,\u201d Saranthan said, \u201care completely revolutionary.\u201d In contrast to butterflies, there\u2019s no templating. Birds like the blue jay seem to make single gyroids spontaneously by phase separation, as if they dropped a quarter in a glass of soda and single gyroids assembled on the coin\u2019s surface.\u00a0\nTo ascertain the spontaneous generation of single gyroids by phase separation, Saranathan used X-ray analysis to observe the \u03b2-keratin structures in other species that are sister species to single gyroid leafbirds. He found swathes of keratin nano-spaghetti, assembled through phase separation. Prum noted that it is highly likely that two species diverged from a common ancestor by way of the nanostructure formed, keeping the same general formation process.\u00a0\nCrystal structures produce more saturated colors. For that reason, Saranathan suggested that keratin structures resembling single gyroids were preferred by some female leafbirds over those resembling nano-spaghetti.\u00a0\nNevertheless, these birds somehow form single gyroid crystals without ostensibly having to form a double gyroid first. \u201cThe way they are making this is new to science, period,\u201d Saranathan said. \u201cNew to biology, new to engineering, new to physics.\u201d Birds\u2019 spontaneous self-assembly of these structures illuminates the exciting potential for humans to recreate this self-assembly in the laboratory.\u00a0\nSingle gyroids and their discovery in living systems represent a breakthrough in a vast number of scientific disciplines. The optical structures used by birds to make colors can also be used to better manipulate the flow of light. This makes them highly applicable in solar cell technology. A structural approach to creating color, rather than one based off pigments, could inspire the development of sustainable and less toxic paints, tiles, textiles, and cosmetics that resist fading over time, too. Furthermore, the formation of networks and gel matrices from large liquid-like particles, similar to how keratin forms single gyroids, is a process nearly ubiquitous in cell biology. A better understanding of single gyroid synthesis could lend insight into organelle-less phase separation\u2014a widely growing area of interest in cell biology\u2014soft-condensed matter physics, and physiological systems.\u00a0\u00a0\nIn an age where nanotechnological structures in computer chips and rapid-diagnostic tools are designed to optimally control the flow of electrons and light, learning from self-assembled structures like single gyroids could open up whole new areas of research. \u201cThis is an example of why I think bird-watching science matters,\u201d Prum said. \u201cThat tension between irregularity and specificity is something that I really enjoy, and this research is a great example of the way in which that works together.\u201d\nAbout the Author\nRyan Bose-Roy is a sophomore in Trumbull majoring in Biomedical Engineering and \u201csomething else, we\u2019ll figure out what it is.\u201d In addition to writing for YSM, Ryan works the Trumbull buttery shift on Sunday nights, where he delights in making quesadillas and regaling customers with stand-up bits while taking their orders.\u00a0\nAcknowledgements\nThe author would like to thank Dr. Prum and Dr. Saranathan for their time and willingness to be interviewed for the article. At the request of Dr. Saranathan (and at the author\u2019s own discretion), the author would like to acknowledge the Yale Peabody Museum for its existence.\nReferences\n\u200b\u200bSaranathan, V., Narayanan, S., Sandy, A., Dufresne, E. R., & Prum, R. O. (2021). Evolution of single gyroid photonic crystals in Bird Feathers. Proceedings of the National Academy of Sciences, 118(23). https://doi.org/10.1073/pnas.2101357118\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/birds-of-a-feather-color-together-studying-the-structure-of-bird-feathers-could-revolutionize-engineering/",
            "captions": [
                "Art Courtesy of Anasthasia Shilov."
            ]
        },
        {
            "title": "The Atmospheres of Mars and Titan",
            "author": "Ethan Olim",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/fig-1-500x281.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of NASA.\nScientists have long been interested in predicting weather on Earth, but in recent decades, tools developed for climate science at home have increasingly been applied to studies of extraterrestrial atmospheres. Inspired by puzzling patterns in Martian dust storms, researchers at Yale recently investigated the effects of annular modes of variability\u2014climate patterns that repeat every few weeks to a month, independently of the cycle of seasons\u2014on Mars and Titan, a moon of Saturn.\nJoseph Michael Battalio, a postdoctoral associate in Yale\u2019s Department of Earth and Planetary Sciences, noticed a few years ago that certain patterns of Martian dust activity seemed to repeat approximately every twenty sols (Martian days). This length of time didn\u2019t match the behavior of any known Martian storm instigator but was quite similar to that of the annular modes Battalio had previously studied on Earth. This led him to look for the effects of these modes on Mars.\nSupporting this hypothesis, Mars has many other atmospheric similarities to Earth: it rotates at a nearly identical speed (one sol is approximately twenty-four hours and thirty-nine minutes) and exhibits similar prevailing winds.\u00a0\nWhen Battalio began analyzing data from Mars, fluctuations in atmospheric eddy kinetic energy\u2014a quantity associated with storms\u2014and shifts in atmospheric mass showed cyclic behavior that was clearly due to annular modes.\u00a0\nSimilar results were also found on Titan, the largest moon of Saturn and a body of particular interest due to stable liquids and hydrocarbons on its surface. The moon is studied via the Titan Atmospheric Model (TAM), a numerical climate model created by Yale professor Juan Lora. \u201cTAM enables us to generate realistic simulations of Titan\u2019s global circulation,\u201d Battalio said. These pronounced effects of annular modes on Mars and Titan may suggest the ubiquity of annular modes in terrestrial atmospheres.\nThis research makes great contributions to our understanding of extraterrestrial atmospheric dynamics and may aid our exploration of Mars. Martian dust storms are notoriously brutal, and occasionally prove lethal to solar-powered missions, but this research could help protect future landers. \u201c[Annular modes on Mars] impact the overall climate and dust storm activity\u2026 [and] Mars\u2019s modes may even enable us to generate predictions of dust activity,\u201d Battalio said. Activity from annular modes on Mars tends to reliably foreshadow dust activity, so accurate current observations of the atmosphere allow prediction of storms in a few days\u2019 time.\nLooking forward, Battalio has received a grant from NASA to continue investigating atmospheric variations on planets and moons. He plans to look further into modes on Mars and Titan, particularly as they relate to weather events. For instance, Titan\u2019s methane storms are currently not well understood, but they pose a potential hazard to future landers such as NASA\u2019s Dragonfly. Other bodies, such as Venus\u2014which has atmospheric patterns similar to Titan\u2019s\u2014and Jupiter are also on the docket. Finally, his research into annular modes could prove useful to the study of exoplanets, helping to provide baseline atmospheric understanding so that more irregular winds can be spotted.\nBattalio and Lora have broken new ground in extraterrestrial atmospheric science, and their work has countless applications\u2014on Earth, in our solar neighborhood, and lightyears away.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/the-atmospheres-of-mars-and-titan/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Tracking Mercury Pollution",
            "author": "Jessica Liu",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Liu_Figure1-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nSeafood is tasty, but we are often hesitant to consume it because of the ocean\u2019s high mercury concentration. Increased human activities have released mercury into nearby rivers, where it naturally transforms to methylmercury, a potent neurotoxin associated with lowered intelligence, child developmental delays, and cardiovascular impairments. Methylmercury also bioaccumulates in our food web, making its health consequences long-lasting. Most of our exposure to methylmercury comes from coastal fish consumption. Thus, we could effectively minimize the health risks of mercury intake by mitigating pollution at the source.\nPreviously, scientists believed that atmospheric deposition is the most important contributor to coastal mercury. Yale postdoctoral researcher Maodian Liu and colleagues recently challenged this traditional view by developing a high spatial resolution dataset of global riverine mercury export. They discovered that worldwide riverine mercury export to coastal oceans is actually three-fold that of atmospheric deposition, making it an unexpected driving force of the global mercury cycle.\u00a0\nRiverine mercury measurement data has been scarce in the past, resulting in large variations in export estimates between different studies. \u201cThe greatest challenge is to verify the reasonability of our estimates because our results are three times the recommended value of the United Nations Environment Programme,\u201d Liu said. Nevertheless, Liu is confident in this estimate since it matches empirical observation. Building off this work, Liu and colleagues are developing a global model to further quantify the spatial differences of river mercury cycling in coastal oceans. Understanding the overlooked riverine process will help policymakers better regulate mercury pollution issues, targeting not only atmospheric but also aquatic releases.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/tracking-mercury-pollution/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Predicting Inaccessible Information",
            "author": "Sydney Hirsch",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Hirsch_Figure1-500x296.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nIn scientific experimentation, some information is more attainable than others, by nature of the method of retrieval. For instance, clinicians can easily gather blood pressure and other laboratory values; aptly, this type of data is called easy-to-obtain information (EI). However, other data may be too expensive, time-consuming, or both to collect on a larger scale. Flow cytometry, a laser-based technique to measure the chemical and physical properties of cells, is an example of this type of hard-to-obtain information (HI). To circumvent these limitations, a team of Yale researchers, including graduate student Matthew Amodio and associate professor Smita Krishnaswamy, developed a model called the Feature Mapping Generative Adversarial Network (FMGAN) that allows for the accurate prediction of HI given EI. Their methodology is novel\u2014in fact, Krishnaswamy\u2019s lab pioneered all of the frameworks used throughout the study, even those used as comparators to the FMGAN.\u00a0\nThe most recent study applied the neural network model in two contexts: one generated RNA sequences of cells perturbed with drugs, a form of HI, via the chemical structure of the compound, a form of EI. The second predicted the flow cytometry data (HI) of COVID-19 patients using clinical measurements (EI).\nThe FMGAN\u2019s predictive capabilities come from the addition of a condition-embedding network. This network transforms the EI into representations called manifolds that are easier to visualize, reduce redundancy, and thus simplify data extrapolation. \u201cThe condition-embedding network translates the data from how it exists naturally to a form more easily used by our model, which it gradually learns how to do,\u201d Amodio said. The manifold structure is preferable to the alternative form of data representation in ambient space, as its smooth structure produces outputs that move uniformly with changes in input. This point is especially relevant in the context of Krishnaswamy\u2019s work with chemical structure and RNA sequencing\u2014small modifications to certain portions of the input can determine molecular function, so it is important to maintain such consistency in the magnitudes of movements.\u00a0\nFurther, the scientists introduced stochastic mapping, a measure of randomness, into the model. \u201cThe drugs do not produce a single result every time,\u201d Amodio said. \u201cThe cell measurements change even in applying the same drug to the same system. There are lots of sources of randomness with respect to the data we looked at. Thus, it makes sense to use models that include randomness to accurately represent that.\u201d In other words, stochastic mapping was another deliberate addition to their neural network that further increased prediction reliability.\nIn applying the FMGAN to predict the RNA sequencing data of cells treated with drugs, the team performed four experiments. In the first two, they provided the model with preprocessed data and good manifold coordinates; the purpose was simply to show that information could be generated from the data. After demonstrating the FMGAN\u2019s success under these conditions, the researchers executed two more challenging experiments that required the full capabilities of the network in creating its own manifold coordinates. One tested the condition of drug chemical structure in the form of simplified molecular-input line-entry system (SMILES) strings, a specialized notation system. The other instead looked at image representations of said chemical structure. The latter performed better than the former, likely due to the more advanced architecture of the images compared to the strings. Both, however, demonstrated the efficacy of the FMGAN and its condition-embedding network.\nTo demonstrate the breadth of the FMGAN\u2019s applications, the researchers also tested its ability to predict future flow cytometry information from COVID-19 patients\u2019 clinical measurements upon entering the ICU. During experimentation, researchers took both clinical measurements and flow cytometry measurements from all study participants. They omitted the data of fourteen patients, training the neural network model on the remaining 115. Ultimately, the FMGAN was able to use clinical measurements to generate flow cytometry predictions for the never-before-seen patients. In practice, this data gives clinicians insight into a patient\u2019s immune function and is a predictor of mortality. Instantaneous and accurate determination of this HI would allow physicians to craft optimal courses of treatment.\u00a0\nThrough this set of experiments, Krishnaswamy and her team demonstrated the efficacy of their novel FMGAN neural network model through its applications in drug discovery and clinical inference. However, the FMGAN program is not limited to these spaces\u2014its architecture is not hardwired to address these structures specifically and can be generalized to other data. This area of quantitative computational biology is underexplored, but breakthroughs have the potential to transform how scientists leverage the information they have readily available.\n\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/predicting-inaccessible-information/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Uncovering the Role of a Microprotein",
            "author": "Hannah Barsouk",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Barsouk_Figure2-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Researchers Sarah Slavoff and Zhenkun Na of Yale\u2019s Department of Chemistry are standing up for the little guy.\u00a0\nMore than a hundred years in the making, the Human Genome Project was born from our need to understand the little parts of ourselves. With our entire genome sequenced at the turn of the century, researchers began picking proteins to study as if from a lineup during gym class. Insulin, flaunting its pharmaceutical applications, was chosen first. A blood clotting factor went second. Around twenty thousand picks later, lil\u2019 old NoBody (NBDY) microprotein is ready for its time in the limelight. Microproteins have and will continue to be master regulators in cells, even if they\u2019re not winning popularity contests.\nSarah Slavoff entered the field of proteomics\u2014the study of the proteins that make up life\u2014asking all the right questions but none of the popular ones. She began working to fill the gaps in our knowledge of what she calls \u201cthe dark matter of the genome\u201d during her postdoctoral fellowship at Harvard. Like many others taking a protein-based approach to gene discovery, Slavoff sought to separate the junk from jewel. And while it would be nice if regions of our DNA could scream to us, \u201cHey, I\u2019m important!\u201d, natural selection hasn\u2019t quite worked that kink out yet. Instead, researchers relied on a strict set of rules when identifying new protein-coding gene sequences:\n\nSlavoff\u2019s proteomic experiments, however, began producing tens of thousands of potential results that were discounted because they broke one or more of these rules. \u201cBiology is just as messy and beautiful as you would expect it to be,\u201d Slavoff noted a decade later. Through ribosome profiling and bioinformatics approaches, her lab has discovered exceptions to identifying protein-coding genes. \u201cAll of these rules are actually broken. And they\u2019re not just broken in rare exceptions, they\u2019re broken very widely,\u201d Slavoff said. After adjusting experimental parameters to account for this inconsistency, the floodgates were opened: in the world of proteomics, the mavericks and outcasts now shared a table at lunch with the jocks and socialites.\nIn an effort led by postdoctoral fellow Zhenkun Na, the lab further justified that these \u201cnew\u201d proteins aren\u2019t just sitting around. In fact, they might be serving some of the most important functions in cells. Enter: NoBody, a microprotein that is a mere sixty-eight amino acids long.\u00a0\nOne unique property of NoBody is its ability to behave like a fluid, forming liquid droplets in cells. While in this droplet state, certain modifications to NoBody, such as the addition of chemical groups known as phosphates, cause the dissociation of membrane-less organelles known as processing bodies, or P-bodies. Small like the proteins that regulate it, the complexity of P-bodies\u2019 anatomy is not to be underestimated. They serve as storage sites for enzymes that function in the processing and breakdown of RNA. Thus, NoBody\u2019s mood at any given moment\u2014in other words, its phosphorylation state\u2014can make the difference between whether or not certain RNA sequences, and the proteins they encode for, are produced by the cell.\u00a0\nWhat\u2019s even more astounding is that NoBody can regulate P-body dynamics seemingly without formal or consistent structure. It is not made of folded sequences such as alpha helices or beta sheets, which are some of the defining features of secondary structure in typical proteins. NoBody is just one of many \u201cintrinsically disordered\u201d microproteins with the power of order over our cells. The very existence of microproteins challenges everything we know about what proteins look like, what they do, and where to look for them.\nOne proteomics database, OpenProt.org, predicts the existence of over forty thousand microproteins and other proteins missing from our modern understanding of the human proteome. As of today, characterized proteins in the human body make up only half that number. With each one of these unfilled links potentially representing a new function, location, or structure in the cell, we should take a long, hard think before choosing the next protein from our lineup. \u201cIt took us over a hundred years to build up and annotate the human genome right. We don\u2019t have another hundred years to figure out what these things are doing,\u201d Slavoff said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/uncovering-the-role-of-a-microprotein/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Circa Diem: Opening the AI Black Box",
            "author": "Simona Hausleitner",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Circa-Diem-1-Kassi-Correia-364x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "The fact that the Earth rotates around its axis once every 86,400 seconds seems like a faraway explanation for the passage of time, but what if this simple concept actually relates to the most important physiological and behavioral processes in our bodies? Our internal circadian rhythm is a twenty-four-hour biological clock that influences everything from our sleep cycle and metabolism to our immune system and susceptibility to disease. Understanding the gene expression that underlies such a fundamental adaptation for life poses many challenges for scientists, but modern artificial intelligence (AI) algorithms and machine learning (ML) models provide new avenues into exploring such scientific questions. A team of researchers at the Earlham Institute in Norwich, England recently conducted a study to increase the transparency of how ML systems work, while also shining light onto the most advanced computational system we know of: the human brain.\u00a0\nCircadian rhythms depend on many factors, including environmental stimuli like light and temperature. This is one of the reasons why changing time zones can cause us to experience jet lag\u2014a misalignment between our body\u2019s expectation of the day-night cycle and the changing cues presented by a new geographical location. It has been experimentally determined that these circadian rhythms are controlled by the expression of specific genes that oscillate between on-off states during the twenty-four-hour intervals. However, past efforts to detect this circadian rhythmicity have required the generation of long, high-resolution time-series datasets, an effort that is expensive, inefficient, and time-consuming. To work with such large amounts of data, the researchers took a new approach, involving a combination of AI and ML algorithms, to predict circadian gene expression.\u00a0\nHussien Mohsen, a researcher in the Gerstein Lab at Yale who was not involved in the study, further explained the intersection between artificial intelligence and gene expression research. Mohsen focuses on interpretable machine learning for cancer genomics\u2014a field where, as in the circadian rhythm field, there has been increasing interest in deep learning algorithms (a subset of machine learning) in recent years. According to Mohsen, this is particularly due to technological advancements, which allow us to generate the immense archive of data that lies at the heart of deep learning. \u201cInterpretability of machine learning has become way more popular with deep learning for that particular reason: because you have enormous amounts of data,\u201d Mohsen said. \u201cThe models become so incredibly complex that we need to simplify them\u2014our human cognition can\u2019t really follow what\u2019s going on.\u201d\nWhen it comes to applying these data analysis tools to the field of biology, scientists must ensure that AI techniques are simultaneously efficient and reliable so that the results generated can be applied to the whole population being studied. In computing, the \u201cblack box\u201d refers to systems that are considered only in terms of their inputs and outputs, with no real understanding of their inner workings. As powerful as AI algorithms are for navigating increasingly complex issues, this lack of transparency raises concerns for future research: how is the model transforming data into results? How are the ML algorithms making decisions based only on pattern identification? And if there are any issues, how would we know?\u00a0\nTo this end, in their study of circadian rhythms, the Earlham Institute researchers formulated an approach involving three key elements: 1) developing ML models that quantify the best transcriptomic timepoints for sampling large gene sequencing datasets while reducing the overall number of timepoints required; 2) redefining the field by using only DNA sequence features rather than transcriptome time point information; and 3) decoding the \u201cblack box\u201d of ML models to explain the mechanism of how AI is used to predict circadian clock function.\nIn order to effectively analyze the expression of circadian rhythms, the researchers chose the small flowering plant Arabidopsis thaliana as a model organism. Arabidopsis was the first plant to have its entire genome sequenced, and because some of its regulatory elements were already known, the researchers used that pre-existing knowledge to validate their ML predictions. This allowed them to understand how their ML model was reaching its predictions, thereby decoding the mystery of the AI black box.\nWhen there are tens of thousands, even millions, of data points, how do we understand that data and extract their patterns and trends? Mohsen explained that we learn by finding parameters that capture what patterns exist\u2014the more sophisticated the data, the more parameters we need. But using more parameters necessitates a greater understanding of what each does. \u201cThere are multiple approaches and even definitions of what interpretability is,\u201d he said. Fundamentally, though, \u201cit is just learning how the prediction process works or which input features are corresponding to a specific prediction.\u201d\nThe Earlham Institute researchers used MetaCycle\u2014a tool for detecting circadian signals in transcriptomic data\u2014to analyze a dataset of Arabidopsis genomic transcripts. Using this information, the researchers trained a series of ML classifiers to predict if a transcript was circadian or non-circadian. They found that the AI was not just using gene expression levels, but also timepoints for its predictions. However, these predictions were not always one-hundred percent accurate, and the researchers thus set out to ascertain the optimal sampling strategy and number of timepoints needed.\nCircadian gene expression rhythms follow diverse patterns, but all share a twenty-four-hour periodicity. Having fewer timepoints is more efficient, but leads to concerns over loss of information and accuracy. The researchers aimed to find the optimal balance between a low number of transcriptomic timepoints and improved accuracy, so they started with a twelve timepoint ML model and sequentially reduced it to three timepoints.\u00a0\nThe explainablity aspect of their model comes with understanding how the model was making its predictions. The researchers needed to see which k-mers (short sequences of DNA) were the most influential in impacting the ML model\u2019s predictions, and found that the most accurate predictions resulted from a k-mer length of six.\nOverall, the study showed the possibility for reducing the number of transcriptomic timepoints while still maintaining accuracy in predicting circadian rhythmicity. Since creating datasets takes significant time and resources, a reduction in sampling could have important long-term impacts in increasing efficiency.\nThe findings of this study have major implications for the future of biomedical science and AI: recent studies have shown that disruption of clock genes is associated with sleep disorders, heightened susceptibility to infections, Alzheimer\u2019s disease, and metabolic syndrome. \u201c[Machine learning] has already reshaped a significant part of how we study the biology of disease,\u201d Mohsen said. \u201cI very much see AI playing a larger role in drug development and in terms of the way we study biology.\u201d\nMore recently, Mohsen and the Earlham Institute researchers have shifted to a new focus: advancing the clarity of how and why these powerful algorithms are providing the predictions that they do. As scientists explore foundational questions of how human physiology works, understanding the powerful tools used in probing those questions is just as crucial. According to Mohsen, having unexplainable AI poses \u201ca huge risk in medicine and elsewhere\u201d due to its prevalence in everyday life, including face recognition, surveillance, and biohealth.\u00a0\nIn illuminating the \u201cblack box\u201d for ML models that predict circadian rhythms, research merging transparent AI and genomics opens possibilities for understanding the rapidly-developing technology in our hands. Ultimately, this has implications for precision medicine, novel drug development, and decoding the genetic basis of disease in the future.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/circa-diem-opening-the-ai-black-box/",
            "captions": [
                "Art courtesy of Kassi Correia"
            ]
        },
        {
            "title": "Bioethics in the Age of COVID-19: Laundering bias and saving lives through AI",
            "author": "Risha Chakraborty",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Bioethics-in-the-Age-of-COVID-Laundering-Bias-Through-AIscan-Noora-Said-421x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Over the past year and a half, our hospitals, overwhelmed by COVID-19 patients desperate for oxygen, have been debilitated by staff and resource shortages. While many called for vaccines as a hopeful cure-all, some recognized a faster alternative: efficient and deliberate distribution of hospital resources. Fourth-year PhD candidate Amogh Hiremath and Professor of Biomedical Engineering Anant Madabhushi at Case Western Reserve University were among the bioengineers who confronted this problem. \u201cIt\u2019s particularly heart-wrenching, as a father myself, to see pediatric wards filled up\u2026 kids [who] require critical surgeries just don\u2019t have a bed,\u201d Madabhushi said. Recognizing that delayed or inaccurate risk assessments could prove fatal, Hiremath and Madabhushi developed CIAIN (integrated clinical and AI imaging nomogram), the first deep-learning algorithm to predict the severity of COVID-19 patients\u2019 prognoses based on patient CT lung scans as well as clinical factors.\u00a0\nArtificial intelligence, at its core, endeavors to mimic processes within a human brain. Similar to how humans take lessons from past experiences and apply them to novel situations, computers \u201clearn\u201d information from a training set and apply it to a testing set. In the case of a prediction algorithm like CIAIN, computers are initially fed information from existing patient data to correlate features of CT scans and clinical test results with patient prognoses. Once the algorithm is trained, it can then be applied to novel patient information\u2014the testing group\u2014and give prognoses with a high degree of precision. CIAIN is the \u201cfirst prediction algorithm to use a deep learning approach in combination with clinical parameters,\u201d Hiremath said. This makes it more accurate than algorithms using imaging alone. Another major advantage of CIAIN lies in its speed of deployability: given that accessing medical datasets is relatively difficult compared to obtaining a set of natural images, Hiremath and Madabhushi used roughly one-thousand patient scans from hospitals in Cleveland, Ohio and China to train, fine-tune, and test their model. And notably, CIAIN is the first algorithm designed for COVID-19.\nGiven that their paper only examined unvaccinated patients, Madabhushi and Hiremath now want to investigate if they can find the risk of hospitalization for vaccinated individuals. \u201cAs we hear about new breakthrough infections, the question is if we need to run the analysis retrospectively on patients who have been vaccinated,\u201d Madabhushi said. However, while it is one thing to create predictive algorithms retrospectively, it is another to apply such algorithms to novel patient data without prior physician evaluation. A prospective study\u2014a study that follows patients before their ultimate outcomes are known\u2014would employ a dual-pronged approach. First, the researchers would evaluate the algorithm in the pilot phase of a prospective non-interventional trial, where radiologists would upload a CT scan and the algorithm would generate a risk score for a patient. In a few months, if the tool performed well, the study could then transition into a prospective interventional form, and the researchers could propose the algorithm to the FDA for clinical approval.\nDespite anticipating the usage of CIAIN in the emergency room, Madabhushi was careful to emphasize the limited role even very advanced algorithms can play in clinical settings. The vast majority of AI algorithms in the foreseeable future are intended to be decision support tools; they merely augment and complement the physician\u2019s interpretation by aggregating data and prognosticating patient outcomes more accurately. Ultimately, only physicians interact with patients and thus, are the best individuals to make treatment decisions. Madabhushi likened the role bioengineers like himself and Hiremath play in healthcare to the role aircraft engineers play in improving functionalities on the console of an airplane. Ultimately, the physicians are the pilots in the cockpit.\nNo discussion on novel AI technology is complete without considering possible biases in the model and the effects of such biases. Imagine an algorithm trying to classify whether or not an object is ice cream. If, in training the algorithm, one only feeds it images of vanilla ice cream in a cone, the algorithm is likely to reject images of any other flavor, since it is not used to classifying anything but vanilla ice cream cones as ice cream. Simply put, algorithms are biased if the correlations they have learned from a certain training set (vanilla ice cream cones) can\u2019t be extrapolated to the testing set (ice cream of all types).\u00a0\nWhile this example may be innocuous, biases in models used in healthcare can have life-or-death consequences. This year, the American Society of Nephrology finally updated their model for calculating glomerular filtration rate, which was originally based on assumptions derived from Caucasian patients. Their old model was found to make inaccurate calculations for African Americans, culminating in frequent misdiagnoses of chronic kidney disease.\u00a0\nEven if AI just provides a single data point for physicians to use in decision-making, AI predictions are often given precedence over other data points due to the complex methodology by which models aggregate information. Hence, ensuring that AI predictions are as accurate and unbiased as possible is crucial.\nEven without prompting, Madabhushi and Hiremath highlighted the methods by which they attempted to avoid introducing biases to CIAIN. \u201cWe were very deliberate and purposeful in making sure the data was collected from a few different sites,\u201d Madabhushi said. Diversifying the source of data generalized the algorithm and also reduced the likelihood of a \u201cleakage problem,\u201d a known biasing factor AI models face when data is poorly separated between the training set and testing set. The resulting overlap means the algorithm will learn the training set well and accurately classify the testing set, but will demonstrate poor accuracy in classifying a new \u201cvalidation\u201d testing set because it hasn\u2019t learned enough variation. Both Hiremath and Madabhushi expressed the need for further validation to verify CIAIN is sufficiently generalizable.\nWhile generalizing models might help decrease bias, it is not a fix-all. With African American patients three-times more likely to die from COVID-19 than Caucasian patients, an algorithm trained on a mixed-race group may fail to accurately predict prognoses for either group. Scientists must integrate how social determinants of health\u2014including ethnicity, race, and socioeconomic status\u2014play a role in disease manifestation and prognosis. \u201cWhile we haven\u2019t explicitly explored these factors with our methodology and platform yet, it is definitely something we want to look at,\u201d Madabhushi said, who is of the strong belief that scientists need to get away from the idea that \u201cone model fits all.\u201d In fact, Madabhushi and Hiremath have compared the accuracy of models specific to different ethnic groups for breast, uterine, and prostate cancer\u2014in each case, the model designed for the subpopulation yielded more accurate predictions than a more general model. Madabhushi expresses hope that \u201c[scientists] will get to the point where there is a buffet of models and a physician can selectively invoke a model based on the ethnicity or other attributes of their patient. Otherwise, we are doing a disservice to underrepresented populations.\u201d\nIn theory, the future of AI in healthcare seems clear: scientists must identify differences among populations and incorporate them into increasingly specific algorithms to minimize bias. But its implementation remains challenging: one of the biggest hindrances scientists face is a lack of data from underrepresented populations. Until this data can become readily available via drastic institutional and structural change, it is up to scientists like Hiremath \u201cto improve the current prediction models in a step-by-step manner, improve the biases that are involved, and create a usable product.\u201d\nAs AI becomes increasingly ubiquitous in healthcare, there are fears that biased and over-generalized algorithms are being put into practice faster than refined and population-specialized algorithms are being created. We must remember that the personalized aspect of medicine\u2014the conversations, interactions, and human observations\u2014are just as, if not more, important than an algorithm\u2019s score. AI can be a fantastic passenger-seat navigator to a physician driver. But society must be careful not to let AI take the wheel, lest the tool meant to improve patients\u2019 survival endangers it instead.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/bioethics-in-the-age-of-covid-19-laundering-bias-and-saving-lives-through-ai/",
            "captions": [
                "Art courtesy of Noora Said"
            ]
        },
        {
            "title": "Counterpoint: What Makes a Habitable Planet?",
            "author": "Nathan Wu",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "We all know how the story goes.\u00a0\nA mysterious spaceship is detected in the atmosphere. Humans try to communicate with the aliens on it. Aliens are hostile and attempt to conquer Earth. Pandemonium ensues.\nThe \u201calien invasion\u201d trope and extraterrestrial beings in general have been parts of movies, books, and other media for decades, from H. G. Wells\u2019s The War of the Worlds to the cult classic film Independence Day to everyone\u2019s favorite quarantine video game, Among Us. The idea of encountering aliens has captured our imaginations. However, in scientific communities, the search for extraterrestrial life has yet to find success.\nTraditionally, scientists have looked towards planets with conditions like ours in their search for life. Whether a planet has appropriate conditions for liquid water has been a primary concern. These planets can neither be too close nor too far from the star they orbit: this famed \u201cGoldilocks\u201d region is usually considered to be the habitable zone for a star. An additional constraint is that the models used to predict the bounds of this region assume a small, rocky planet with an Earth-like atmosphere filled with nitrogen gas, oxygen gas, and carbon dioxide. However, two recent studies tell us that we may not be looking in the right places.\nNikku Madhusudhan and his team at the University of Cambridge proposed a new type of potentially habitable planet. These planets, known as \u201cHycean worlds,\u201d are composed of massive oceans with surrounding atmospheres made mostly of hydrogen gas. Madhusudhan\u2019s team first explored the range of masses and radii that Hycean worlds can take on and then determined the range of temperatures (and, by extension, distances from various stars) that allow for habitable Hycean surfaces.\u00a0\nMadhusudhan\u2019s team found that Hycean planets offer several advantages over Earth-like ones when it comes to the search for life. Hycean worlds can be much larger than rocky, terrestrial ones, and their thick atmospheres provide insulation that allows for liquid water far away from a star: some \u201cCold Hycean\u201d planets may not need any stellar irradiation at all, with their only heat source being internal. The increased range of sizes and distances from a star that Hycean planets have could mean that scientists can broaden their search for extraterrestrial life.\u00a0\nMeanwhile, Noah Tuchow and Jason Wright of Penn State questioned the habitability of planets in the traditionally defined habitable zone. They noted that, while the traditional definition considers whether liquid water could exist under current conditions, a planet\u2019s habitability is dependent on whether it has existed in the habitable zone ever since life there began. Planets currently observed in a star\u2019s habitable zone may have entered the zone relatively recently, either due to changes in a star\u2019s luminosity or planetary migration. These \u201cbelatedly habitable\u201d planets are unlikely to gain the ability to host life: if Venus somehow took Earth\u2019s spot in our solar system, entering the \u201chabitable zone,\u201d it would never regain liquid water.\u00a0\nIdentifying the \u201cbelatedness\u201d of a planet\u2019s habitability is a difficult task. It requires knowledge of both a star\u2019s life history as well as when and how planetary formation occurs. However, while no simple model can tell us which planets we can ignore, Tuchow and Wright\u2019s research will guide future extraterrestrial exploration. Considering belated habitability for planets may change how we approach future mission design, as many planets found in habitable zones will merely be belatedly habitable.\nThese two studies are challenging our traditional ideas of what makes a planet habitable. Our current definition of the habitable zone, centered around the possibility of finding liquid water on Earth-like planets, ignores other types of potentially habitable planets and fails to consider the impact of stellar history on habitability. These studies teach us that our initial conceptions about science are often false: life in the universe need not look like life on Earth. Our current definition for \u201chabitable zone\u201d may be less useful than we once thought, and it may be time to reconsider it. Perhaps applying a new definition will help us find those aliens we\u2019ve fantasized about for so long\u2014let\u2019s just hope they aren\u2019t as hostile as those in all the movies.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/counterpoint-what-makes-a-habitable-planet/",
            "captions": []
        },
        {
            "title": "Into the Newsroom: David Pogue (YC \u201985)",
            "author": "Dhruv Patel",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Pogue-photo-1-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "David Pogue (YC \u201985) is not your average CBS Sunday Morning science and technology correspondent. He\u2019s written or co-written more than 120 books, given five TED Talks, and has hosted twenty NOVA science specials on PBS. All of this makes him uniquely qualified to provide insight into what it\u2019s like to communicate with the larger public through media.After graduating summa cum laude from Yale with a degree in music, Pogue conducted and arranged Broadway musicals for ten years. But on the side, he taught computer lessons. Over a decade, his hundreds of hours of teaching clients\u2014including celebrities\u2014about to use computers gave him a good sense of what the average adult can grasp and how quickly they can grasp it, a skill that would prove useful later in his career.\u00a0\nPogue also wrote technology review articles on the side. An impressed outgoing tech columnist at the New York Times recommended Pogue to fill his position, where he remained from 2000 to 2013. Pogue got his first break into covering science and the environment when he was approached about hosting a NOVA science special on PBS while at a talk he was giving. \n\u201cWe had fun working together, so I started doing more shows for them. The areas that they let me cover began to expand: first it was tech, then it was tech and science, then it was tech, science, and environment. So I gradually started doing more stories on plastic in the ocean, and fracking, and the environment. It gradually became part of my portfolio,\u201d Pogue said.\nPogue is now a CBS Sunday Morning science and technology correspondent. What he loves particularly about this position is the creative control and liberty he has when presenting a story. \u201cBeing able to choose my own story ideas, the ability to write my own script, the ability to comment on the story as it\u2019s being edited\u2014these are all luxuries you don\u2019t get in other television,\u201d Pogue said.\nTo cater science for the audience at home, Pogue relies on his experience teaching computer lessons and writing books, six of which have been of the popular For Dummies series. \u201cI like to imagine that it\u2019s me from twenty years ago\u2014before I had gotten into the world of science and technology\u2014in the audience,\u201d Pogue said. Keeping that thought in mind, Pogue is cautious not to under-explain a concept. \u201cI would much rather be accused of over-explaining than shooting over the heads of the audience. If the latter happens, the audience learned nothing and the segment can be considered a failure.\u201d\u00a0\nIn Pogue\u2019s mind, explaining key concepts, regardless of how trivial they may seem, is a win-win situation: it allows those who already know the concepts to feel smug about their knowledge, but it also allows those who didn\u2019t know this concept to learn something new. This approach of building a segment while keeping the audience\u2019s perspective in mind, including their ability to understand certain ideas, allows Pogue and his team to effectively and adeptly convey scientific information to viewers.\u00a0\nPogue acknowledges that there is still room for science writers and reporters to improve. We are, after all, living in a world where more and more people are becoming hesitant to accept scientific findings. According to Pogue, there are two causes of this suspicion. One is that recent scientific findings are new and unfamiliar to many people; the second is that modern science phenomena cannot be seen or observed by the naked eye (e.g., the transmission of the COVID-19 virus from person to person). As Pogue explains, the way to overcome this fear is by relentlessly explaining the facts and significance of these new findings with humor and entertainment value. Importantly, Pogue mentions that science reporters and writers must maintain empathy as well\u2014because a person\u2019s mind will not be changed by facts, but by empathy and understanding. As one of his favorite sayings goes, \u201cPeople don\u2019t care what you know\u2014unless they know that you care.\u201d\nPogue doesn\u2019t have a specific plan on what he\u2019d like to do in the future. He likes it when life presents a new opportunity. After all, he didn\u2019t plan anything that has happened in his career; he simply said yes to the opportunities presented to him.\u00a0\nAs for his advice to today\u2019s scientific writers, Pogue mentioned the necessity of pursuing your passion and trusting that things will turn out all right. \u201cDon\u2019t wait. Don\u2019t think that because you\u2019re young, you can\u2019t do or become or start whatever you want,\u201d Pogue said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/into-the-newsroom-david-pogue-yc-85/",
            "captions": [
                "Image courtesy of David Pogue"
            ]
        },
        {
            "title": "The Tug-of-War Between Plasticity and Stability: The science of learning languages",
            "author": "Hannah Han",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-Neuronal-Network-500x279.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixaby.\nM\u0101. M\u00e1. M\u01ce. M\u00e0. These sounds, though phonetically identical, represent four Chinese characters with drastically different meanings: \u201cmother,\u201d \u201chemp,\u201d \u201chorse,\u201d and \u201cscold.\u201d The only feature differentiating these words are the subtle variations in their tonal inflections, which give them their distinct definitions in Mandarin.\nA research team from the University of California, San Francisco (UCSF) capitalized on the tonal nature of Mandarin to investigate how adult brains respond to foreign languages. The team\u2014led by assistant professor of neurological surgery Matthew Leonard and postdoctoral scholar Han Yi\u2014conducted a study in which they asked ten native English speakers to learn to distinguish between different tones. The researchers played recordings of male and female Mandarin speakers saying characters such as \u201cma\u201d with varying inflections approximately two hundred times. They then recorded the patients\u2019 responses and their brain activity, studying how their neurons fired in response to the sounds.\nWhile previous studies typically used non-invasive techniques such as functional magnetic resonance imaging (fMRI) to scan the patients\u2019 brains, Yi and Leonard opted for a different approach. fMRI often results in muddled data, as researchers must isolate the participant\u2019s distinct neuroactivity from other noise captured by the machine. However, Yi and Leonard avoided this complication by using 256-channel electrodes implanted directly into the patients\u2019 brains, allowing them to witness neurons firing live. The unprecedented clarity of their data was due to the subset of volunteers that they worked with: patients with epilepsy who already had electrodes installed in their brains to track their seizures. Using these high-density electrodes, Yi and Leonard examined the patients\u2019 distinct neural responses.\nThe results were unexpected. The team originally hypothesized that activity in one region of the brain called the superior temporal gyrus would increase as individuals became more accustomed to distinguishing the tones. However, disparate clusters of neurons were activated by each tone, and over time, their activity fluctuated, increasing for a while before fading. Leonard described this strange, intricate process of language learning as analogous to \u201cfine-tuning neural knobs.\u201d\n\u201cSome cells changed in specific ways, and this suggests that the process of learning is not simply a matter of turning up the \u2018new language knowledge,\u2019 but rather fine-tuning a bunch of smaller knobs that are designed to encode this type of information,\u201d Leonard said.\nThese shifting \u201cneural knobs\u201d represent the opposing forces of stability and neuroplasticity\u2014the brain\u2019s ability to adapt to new stimuli\u2014attempting to strike a precarious balance. The war between retaining one\u2019s foundational, native tongue and absorbing new knowledge explains why adults find it so difficult to learn a new language. Children, on the other hand, learn new concepts seemingly effortlessly because their minds are highly plastic, without the same engrained stability as adults\u2019 minds.\nAlthough Yi and Leonard have now established a fundamental understanding of these neural processes, they recognize that there are still many more complexities to unravel.\n\u201cIn this study, we looked at the very beginning stages of learning,\u201d Leonard said. \u201cThis is what\u2019s changing during the first thirty minutes of a native English speaker learning the sounds of Mandarin.\u201d In the future, the team hopes to investigate how participants will react when given the specific meanings associated with each tone, further illuminating the inexplicable process of language learning.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/the-tug-of-war-between-plasticity-and-stability-the-science-of-learning-languages/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How Worms Remember Their Enemies: Transgenerational inheritance of avoidance behavior in C. elegans",
            "author": "Kayla Yup",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-8-500x141.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Rebecca Moore.\nImagine if your great-great-grandmother passed down a story that warned your family to avoid an enemy. Now, let\u2019s propose that you never heard this message explicitly, and instead, it manifested in the form of a gut feeling, a biologically wired warning felt upon nearing that threat. C. elegans, a species of worm commonly studied in biology, uses a powerful intuition like this to avoid pathogens based on the lethal danger the pathogens posed to the worms\u2019 ancestors.\nResearchers Rebecca Moore, Rachel Kaletsky, and Coleen Murphy at Princeton University discovered that this \u201cgut feeling\u201d C. elegans inherit is pathogen avoidance behavior. The pathogen in this case is Pseudomonas aeruginosa (PA14), which kills C. elegans within two to three days upon exposure.\u00a0\nIn a paper published in Cell, the researchers were able to show that C. elegans used horizontal memory transmission\u2014transfer of memory between members of an ecosystem\u2014by observing that worms not yet exposed to the pathogen could learn this avoidance behavior through exposure to lysate from pathogen-trained grandmothers.\u00a0\nBy comparing worms exposed to PA14 with controls, the researchers discovered that worms learn to avoid PA14 after direct exposure to the pathogen for twenty-four hours. This avoidance behavior relies on P11, a small PA14 RNA that, when \u201cread,\u201d sends a signal from the worm\u2019s germline to neurons, resulting in pathogen avoidance. With P11 still present in the worm\u2019s reproductive cells, inheritance of this avoidance behavior is possible without direct exposure to the pathogen.\nThe researchers also discovered the molecular mechanism by which this horizontal transmission of memory occurs: transposons, segments of DNA that can jump to different locations in the genome. Usually, transposons are considered dangerous because their presence in genomes can lead to disease and the degradation of host fitness. However, the researchers found that the Cer1 retrotransposon expresses virus-like particles that can transfer memory of learned pathogen avoidance to other worms.\u00a0\nMurphy believes that the most interesting discovery the team made was that when one set of animals is trained, they secrete these molecules into the media. \u201cIf you put that media onto untrained animals, they learn the information. So they\u2019re literally transferring memories,\u201d Murphy said.\u00a0\nThis mechanism of memory storage had been previously considered impossible due to the theorized Weismann barrier, a barrier between germline and somatic cells that preserves germ cells. Under this theory, hereditary information could move from germline to body cells, but never the reverse. The behavior of C. elegans, however, defied this hypothesis. \u201cThis is the way for an animal who doesn\u2019t necessarily teach its young to transmit this information to its progeny. So, I think we have to come back and maybe re-evaluate the idea of the Weismann barrier,\u201d Murphy said.\nInterestingly, this memory transference ends after four generations. There is likely a biological reason for this limit. \u201c[C. elegans] don\u2019t always avoid [the pathogen] because sometimes Pseudomonas can be a nutritious food source depending on the temperature or other conditions,\u201d Moore said.\nWorms serve as a model system for mammalian species. The researchers\u2019 discovery may therefore set the stage for discoveries about humans in the future. \u201cAvoiding pathogens is something that we do,\u201d Kaletsky said. \u201cAnd in terms of the smaller RNA biology, I mean, our gut is loaded with bacteria. So it really opens up the possibility that we communicate with our gut microbiome through similar mechanisms.\u201d\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/how-worms-remember-their-enemies-transgenerational-inheritance-of-avoidance-behavior-in-c-elegans/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Eyes are the Windows to the Robot\u2019s Soul: How mutual gaze with a robot impacts human social decision-making",
            "author": "Gonna Nwakudu",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/IIT-Social-Cognition-in-Human-Robot-Interaction-unit-standing-with-the-robot-used-in-the-experiments-Figure-2-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of IIT.\nMovies like Her, The Iron Giant, and Chappie reveal a trend in the media of pondering the social relationship between robots and humans. Researchers affiliated with the Instituto Italiano di Technologia (IIT) sought to understand this phenomenon in a study focused on how social interactions with a robot affects how humans make decisions in a social context.\n\u201cWhat we try to do is to actually understand those parameters [of social interaction]. What is it that makes an interaction smooth and natural and pleasant?\u201d said Agnieszka Wykowska, a professor of engineering psychology who leads IIT\u2019s Social Cognition in Human-Robot Interaction unit.\u00a0\nThe team\u2014consisting of Wykowska, Marwen Belkaid, Kyveli Kompatsiari, Davide De Tommaso, and Ingrid Zablith\u2014invited participants to play a game where both they and a humanoid robot controlled cars that were heading towards each other. After looking into the eyes of the robot, the participant decided whether to divert from the path or keep moving forward at the risk of colliding with the other car. In each trial, players were scored depending on the outcome; one car moving straight while the other diverted resulted in the highest possible payoff for the former, and both cars moving straight and colliding with each other resulted in the highest possible loss for both players. One group of participants received reciprocated eye contact from the robot in most of the trials, while the other group received it on fewer occasions.\nAfter making eye contact with the robot, participants were slower in choosing to divert the car or keep it moving straight compared to the situations in which there was no eye contact. Further analyses of participants\u2019 brain activity revealed higher neural synchronization during trials in which the robot reciprocated eye contact. \u201cThis high neural synchronization is related to higher cognitive effort to separate irrelevant signals. Here, [that signal] was eye contact with the robot,\u201d Kompatsiari said. Mutual gaze also impacted how the participants played the game, with the group that received less eye contact from the robot playing a more self-oriented strategy.\u00a0\nKompatsiari and Wykowska hope studies like this can improve on the field of social robotics. \u201cThere\u2019s this trend in social robotics that we should make the robots be as social as possible,\u201d Wykowska said. \u201c[But] I think it\u2019s quite striking to see that the social is not necessarily always beneficial. So it can be that you have tasks where you need to focus on something, and then having a social robot right next to you might not necessarily help.\u201d\u00a0\nOn the other hand, their work provides insight on how robots can be used as proxies to human-human interactions. \u201cIf humanoid robots will be around, they might automatically trigger mechanisms in our brain to treat them as social agents, and we might start having social attitudes towards those robots,\u201d Wykowska said.\u00a0\nWhile there is still a long way to go before robots become completely integrated into human life, they have already impacted fields such as clinical psychology. Kompatsiari noted, for example, the ways that some robots can interact with patients with autism. \u201c[These interactions] can induce the robot to assist the therapist to train specific mechanisms of social cognition,\u201d Kompatsiari said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/eyes-are-the-windows-to-the-robots-soul-how-mutual-gaze-with-a-robot-impacts-human-social-decision-making/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Move Away from Water!",
            "author": "Zeki Tan",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Image-1-2-500x335.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Arlynn Aquino.\u00a0\nOf the natural disasters that disrupt families and livelihoods, none makes a larger impact than the mighty flood. Globally, damages due to flooding cost 651 billion dollars from 2000 to 2019, not to mention the tens of thousands of lives lost. Vulnerability to the effects of flooding, however, also encompasses psychological trauma, disease, and forced migration. A new study suggests that while humanity is unlikely to witness a catastrophic worldwide deluge for the foreseeable future, growing numbers of people are becoming vulnerable to the effects of flooding due to climate change and rapid changes in population, infrastructure, and land use.\u00a0\nResearchers from the Dartmouth Flood Observatory (DFO), Google, and Cloud to Street, a firm that maps flood-exposed communities worldwide, used satellite imagery collected by the MODIS imaging sensor aboard NASA\u2019s Terra and Aqua satellites to measure rapid changes in landscapes after floods. While these satellites can only capture images at a 250-meter resolution, they cover all of Earth\u2019s surface daily. Using this data from 913 flood events that occurred from 2000 to 2018, the team identified coastal regions inundated by major floods. They then developed a Global Flood Database to aggregate these findings.\nResearchers estimated that 2.23 million square kilometers were inundated over the past two decades, and between 255 and 290 million people were directly affected by flooding. This effect was unevenly distributed worldwide; many people exposed to flooding live in South and Southeast Asia, with ninety percent of all exposures to flooding concentrated in the two regions. Most worryingly, flood-prone areas have experienced rapid population growth in recent years, to the order of fifty-eight to eighty-six million. The proportion of people exposed to flooding worldwide increased by twenty to twenty-four percent from 2000 to 2015, compared to a previous estimate of 2.6 percent from 1970 to 2010.\u00a0\nThe study is distinctive for its emphasis on observational data as opposed to hypothetical climate modeling. \u201cPrevious estimates [of flood exposure] have used flood models, which disagree with each other a lot, and they don\u2019t take into account [factors like] human infrastructure,\u201d said Colin Doyle, co-author of the study and director of technology at Cloud to Street. Flood models employ algorithms to predict the depth and extent of floods in communities during hypothetical storms.\u00a0\n\u201c[Our calculations were] significantly higher than any previous estimates,\u201d Doyle said.\u00a0\nThere are, of course, limitations to the data. For instance, the DFO only includes floods that were well-documented in news media, meaning that floods from areas with less coverage like Africa and South America were excluded. These biases underestimate the numbers exposed. Thus, the substantially higher estimates suggested by the study remain conservative.\nWhat does this mean for people who reside in these areas and the governments that manage them? Only about thirteen percent of disaster funds are allocated toward preparedness, mitigation, and adaptation. \u201cPutting money in beforehand towards preparation [\u2026] is about four times more effective in terms of reducing loss versus responding afterwards,\u201d Doyle noted. He added that investments should be made in \u201cgreen infrastructure and insurance so that the most vulnerable people in low- and middle-income countries have a safety net when they need it.\u201d With these steps, perhaps, floods will wash away fewer people\u2019s homes and livelihoods.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/move-away-from-water/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Undergraduate Profile: Anna B Albright (YC \u201923)",
            "author": "Sophia Burick",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Chong_1-2-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "For Anna Albright (YC \u201923), caring about our climate is a way of life. It all began in her high school environmental science class. As she learned about worrying phenomena like the greenhouse gas effect and its feedback loops that melt our ice caps, she couldn\u2019t help but feel deeply frightened. \u201cThe only way I could fight this feeling, fight the fear, was to think, I have to be a part of the solution,\u201d Albright said.\nSo, she got to work. Even before she arrived at Yale, she threw herself into climate activism. She testified at the Massachusetts State Senate, spoke at an MIT climate summit, and helped draft the City of Cambridge\u2019s climate goals. At Yale, she has made it a mission to continue this work, exploring her activism in a new dimension: capital allocation.\u00a0\nEarly on, Anna discovered a great interest in a rapidly growing area of finance called environmental, social, and governance (ESG)-based investing. ESG-based investing is centered around the idea that an investor should weigh a company\u2019s achievement of environmentally stable, socially responsible, and internally ethical practices before deciding to invest. Albright believes widespread implementation of ESG holds great potential to galvanize fast and effective positive change for our climate. \u201c\u200b\u200bTrillions of dollars\u2014tens of trillions of dollars\u2014move through the financial system each year,\u201d Albright said. \u201cEven if you can get a portion of that to go to better places, or you change the incentives around where it goes, or you even change the standard morals or ethics about what you can invest in\u2014that really has an impact.\u201d\nShe began her work promoting ESG at Yale with the Yale Student Investment Group (YSIG). She was one of only three girls in her YSIG class and, to her knowledge, the only Environmental Studies major in the group. \u201cMy goal is definitely two things,\u201d she said. \u201cNumber one is to make sustainability central to investment strategy and financial strategy. And number two is to make these spaces more accepting spaces for people who face a stigma about entering the industry.\u201d She became a YSIG board member her sophomore year, and has been remarkably successful over the last few years in actualizing both of her missions. With the help of another board member, she made ESG a required component of every soft pitch given in the group, and she\u2019s proud to report the group\u2019s newest applicant class is fifty percent women. Next summer, Albright will work as an ESG analyst for J.P. Morgan, bringing her passion for sustainability in finance to the corporate world.\nLast fall, at the height of the pandemic, Albright was inspired by an Intro to Marketing course at the School of Management to apply for a job unlike anything she\u2019d done before: a social media manager position for the Yale School of Public Health Instagram page. \u201cWhen I saw this job come up, I was really excited, because I felt like there was a lot of latent opportunity there that Yale had not harnessed,\u201d she said. Before her arrival, the page featured mostly student profiles and campus photos and had less than two-thousand followers.\u00a0\nAlbright knew the account could be so much more\u2014a place for the public to gain knowledge in an accessible and fun way. \u201cOne, they were hungry for information about Covid,\u201d she said. \u201cAnd two, they were hungry for fun, digestible internet content. That\u2019s all they wanted.\u201d With the help of her boss, Kayla Steinberg, Albright began to radically change the account. They creatively communicated essential information about public health during the pandemic using trending memes and art that captured the attention of thousands of Instagram users.\u00a0\nIn the last year, the account\u2019s reach has skyrocketed to over fifteen-thousand followers, and they\u2019ve received attention from some uber-famous public figures. \u201cAriana Grande reposted one of the posts, which was huge,\u201d she said. In another instance, her work (partially) inspired a student\u2019s future. \u201cA student tweeted, \u2018I just decided I\u2019m going to Yale School of Public Health. Not going to lie, their memes had something to do with it,\u2019\u201d she said.\nIf there\u2019s one running theme in Albright\u2019s work at Yale and beyond, it\u2019s her passion for cutting through the apathy that so often plagues society, from climate change to a global pandemic. \u201cThe hardest step is getting past the apathy,\u201d she said. \u201cAnd when you can do that, you can change people\u2019s minds.\u201d\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/undergraduate-profile-anna-b-albright-yc-23/",
            "captions": [
                "Photo courtesy of Lauren Chong"
            ]
        },
        {
            "title": "The Silent Mental Health Threats of COVID-19: Your feelings of paranoia are not all that uncommon",
            "author": "Shudipto Wahed",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/The-Silent-Mental-Health-Threats-of-COVID-Kat-Moon-500x348.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "During the Great Depression in 1929, immigrant workers became scapegoats for economic hardship, accused of taking jobs away from native-born Americans. After the tragedy of 9/11, many people grew fearful that their lifelong Muslim neighbors could somehow be implicated in the terrorist attacks. Such crises have historically caused individuals to see others as a threat. Drastic changes tend to make people more paranoid.\nThis trend continues with the COVID-19 pandemic. Toilet paper stock quickly ran out as shoppers rushed to acquire household supplies as if in a post-apocalyptic frenzy. Asian Americans experienced an exponential increase in hate crimes due to fringe conspiracy theories regarding the origin of the SARS-CoV-2 virus. Differing opinions on mask-wearing have turned into heated, politicized debates. Everyone seemed to share a heightened sense of apprehension about the future.\nYale Cognitive Research Scientist Praveen Suthaharan, Associate Professor of Psychiatry Philip Corlett, and their team recently published a study in Nature Human Behavior about the effects of the COVID-19 pandemic on individuals\u2019 paranoia. To these researchers, the widespread uncertainty caused by the pandemic provided an unprecedented opportunity to track the impact of an unfolding crisis on human beliefs.\nA Pandemic of Paranoia\nConstantly wearing a mask to protect each other from a virus we cannot even see with our own eyes, against a disease that is in many cases asymptomatic, can be overwhelming\u2014enough to put anyone on edge. Previously mundane activities, like going to the grocery store or visiting grandparents, now draw concerns: just by doing them, one could contract or transmit a potentially fatal disease.\nThe study\u2019s authors saw that paranoia significantly increased throughout the duration of the COVID-19 pandemic, with self-reported paranoia levels peaking as states drew closer to reopening. Overall effects on other mental illnesses were also negative. \u201cWe have all experienced challenges since the onset of the pandemic, and we also noticed this in our data: that over time, depression and anxiety increased during the lockdown,\u201d Corlett said.\nEnsuring that the general public remains calm and willing to work together is essential to overcoming a crisis such as the COVID-19 pandemic, especially in efforts like vaccination and social distancing. While many have argued for and against the merits of mandatory lockdowns, this study\u2019s data demonstrate that divergence in state-level response correlated with differential increases in paranoia\u2014both self-reported and measured via laboratory tasks. Vigorous, proactive lockdown policies were associated with less paranoia when compared to lax lockdown policies. One may similarly expect to see different outcomes based on states\u2019 varying mask mandates, Corlett posited.\nTo Mask or Unmask\nOver a year into the pandemic, wearing a mask while around others should seem like a no-brainer. Masks are cheap, effective, and easy to wear. Suthaharan\u2019s team was interested in understanding why so many people were and are still opposed to wearing a mask, despite the seemingly clear cost-benefit analysis for doing so. \u201cIt\u2019s similar to when you see a patient smoking a cigarette outside of the hospital,\u201d Corlett said. \u201cWe wanted to understand why people engage in behaviors risky for their health.\u201d\nIn their study, the researchers found that paranoia was highest during reopening in states that required mask-wearing. This supports the notion that, in social settings, humans are \u201cconditional cooperators\u201d\u2014we tend to follow rules as long as we perceive others doing the same. As soon as this is no longer true, we tend to stop following these rules. As the data suggested, when there was a mask mandate but people saw others without a mask, that raised confusion and paranoia. In fact, individuals with paranoia were far more reluctant to wear masks and reported wearing them significantly less.\nSuthaharan wanted to know whether mask mandates themselves could have contributed to the increased mental health issues experienced during the pandemic. To that end, his team performed a type of analysis called \u201cdifference-in-differences,\u201d which allowed them to infer causal relationships by comparing changes in paranoia levels in states that implemented a mask mandate to states that did not, or only recommended it. The analysis revealed that mandated mask-wearing was associated with a forty percent increase in paranoia levels.\nThese results could be connected to a lack of clarity in public health messaging, Corlett conjectured. Early in the pandemic, health organizations such as the CDC and WHO did not fully support masking, even claiming inefficacy at times. Later, emerging evidence supported a reversal in opinion, which in turn led to mask shortages and induced worries among people who were now unsure about whether they would be able to get masks.\nThe uncertainty and paranoia caused by mask mandates possibly led to distrust of public health organizations as mask-wearing became a politicized topic. \u201cIn no other time in history have we experienced a pandemic this problematic, and instead of dealing with it as a community of like-minded people, what we\u2019ve done is double down on our differences,\u201d Corlett said.\nAll in this Together\nIf there is any comfort to be taken by those who have experienced mental health difficulties since the start of the pandemic, it is that nobody is alone in their struggle. With this collective aspect in mind, Suthaharan and his team were keen to study group-level cognition to see if characteristics and experiences shared by a population affected mask-wearing or paranoia.\nUsing an index of cultural tightness and looseness, developed by psychologists at the University of Maryland, to measure a state\u2019s cultural tolerance for rule-breaking, the researchers found that stricter states that mandated mask-wearing experienced the lowest rates of mask-wearing. Individuals in culturally tight states may have grown paranoid seeing others without masks, leading to overall lower levels of mask-wearing in these states. Fear of social reprisal due to anti-mask sentiments may have further driven their paranoia.\nMany of those who were hesitant to wear a mask were also hesitant to receive a COVID-19 vaccine, with unproven conspiracy theories circulating about its development and its usage in government surveillance. The research team found that paranoia was significantly correlated with belief in these specific conspiracy theories, as well as belief in other theories, such as that prominent Hollywood entertainers are involved in child trafficking.\nThese results demonstrate that our surrounding culture and environment can substantially affect mental health. \u201cIt was very interesting and informative to show that group-level characteristics such as rule-following and cultural tightness impacted peoples\u2019 behaviors and beliefs,\u201d Corlett said.\nCognitive Origins\nThe Corlett lab has been interested in studying the origin and neural mechanisms of paranoia for several years\u2014even before the pandemic. Notably, within the field of psychiatry, there are mixed opinions regarding the origins of paranoia in the mind and brain. Some believe that the brain has a distinct module for dealing with social relationships and that problems with this part of the brain cause paranoia. Corlett, on the other hand, contends that the same reward mechanisms in our brains that tell us whether we like things, such as different types of food or even money, are implicated in paranoia. To him, we do not differently process positive or negative feelings towards something in social versus nonsocial settings.\nIn this study, the authors conducted two types of experiments to assess paranoia: social and nonsocial. In the nonsocial task, participants were instructed to choose between three cards that each had a different probability of being \u201ccorrect.\u201d They were also told that the underlying probabilities would change, but not how often or when. A paranoid individual would likely switch their choices more frequently, even after positive feedback (\u201cwin-switching\u201d), incorrectly attributing probabilistic errors to a shift in underlying probabilities. In the social task, instead of using cards, individuals were told they could collaborate with one of three individuals who would either help or hurt them.\nThe researchers found that the win-switching frequency in the nonsocial task was indeed significantly correlated with paranoia, validating that performance on the task was an accurate measure of one\u2019s paranoia levels. More importantly, they also found that there was no difference in behavior between the social and nonsocial tasks, suggesting that Corlett\u2019s theory may offer a more valid and accurate understanding of paranoia\u2019s origin.\nInterestingly, participants in this study performed the same tasks before and during the pandemic, yet yielded starkly different outcomes in each condition. This may shed light on the replication problem in psychological research, where many published findings cannot be reproduced by other researchers. It is possible that some of these findings could be merely artifacts of changing real-world conditions between replication attempts. But even so, this study suggests that real-world changes can have profound impacts on individual behavior in laboratory tasks.\u00a0\nAn Informed Future\nThis study could have many implications for the field of psychiatry, and the authors hope that its insights into human psychology will help those struggling with mental illness. They also hope that their research will affect positive change for the ongoing COVID-19 pandemic. Given how paranoia affects individual responses to worldwide crises, the study\u2019s results could help guide future decision-making and inform effective communication between the public, governments, and other organizations.\u00a0\n\u201cConducting online research during a pandemic was a challenge, but also inspiring,\u201d Corlett said. \u201cIt is unusual to be so connected to real-world events and to study them as they unfold, and for our data to have implications for how the situation could be handled differently now, and in the future.\u201d\nAbout the Author\nShudipto Wahed is a sophomore in Benjamin Franklin from Pittsburgh, Pennsylvania interested in studying Molecular Biophysics & Biochemistry. Shudipto conducts research on protein engineering in the Ring Lab at the Yale School of Medicine. Outside of YSM, Shudipto is a senator for the Yale College Council and an analyst in the Yale Student Investment Group.\nAcknowledgments\nThe author would like to thank Professor Philip Corlett for his time and enthusiasm.\nExtra Reading\nReed, E. J., Uddenberg, S., Suthaharan, P., Mathys, C. D., Taylor, J. R., Groman, S. M., & Corlett, P. R. (2020). Paranoia as a deficit in non-social belief updating. ELife, 9.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/the-silent-mental-health-threats-of-covid-19-your-feelings-of-paranoia-are-not-all-that-uncommon/",
            "captions": [
                "Art Courtesy of Kat Moon."
            ]
        },
        {
            "title": "A Shift in the Psychedelic Paradigm: Could shrooms shake up the future of psychiatry?",
            "author": "Rayyan Darji",
            "authorLogo": "",
            "date": "November 18, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Using-Psychedelics-to-Curb-Depression-Elaine-Cheng-500x398.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "On a cold November day in 1957, Laika made history as she rode into orbit on a Soviet spaceship, withstanding tremendous acceleration to become the first living being to circle the Earth. Laika wasn\u2019t a trained astronaut\u2014she was a dog, a former stray from the streets of Moscow chosen for this historic, but ultimately fatal, mission.\nIn the name of science, humans have since launched hundreds of different animals into space. Now, however, scientists are sending mice on a very different kind of trip\u2014one that doesn\u2019t require them to leave the laboratory, much less the Earth.\u00a0\nRather, they\u2019re on a mushroom trip.\u00a0\nResearch into the neurological effects of psilocybin, the hallucinogenic compound found in so-called \u201cmagic mushrooms,\u201d has experienced a powerful revival in recent years. Psilocybin is a serotonergic psychedelic, meaning that it has a high affinity for serotonin receptors and produces altered states of consciousness, including positive mood. Clinicians and academics have long been interested in the potential of these substances as therapies for neuropsychiatric disorders, including depression and addiction, but their clinical implementation has faced considerable challenges.\nThe frontal cortex\u2019s neuroplasticity, or its ability to adapt over time, has proven fundamental to the efficacy of antidepressant therapies. Results of previous studies suggested a potential relationship between psychedelics and neuroplasticity, but the particulars remained unknown. To address some of these uncertainties, researchers from Yale School of Medicine\u2019s Department of Psychiatry examined psilocybin\u2019s effect on the brain and demonstrated psilocybin-induced structural neuroplasticity at cellular resolution for both short and long timescales.\nStructural and Behavioral Effects of Psilocybin\nPsilocybin has a centuries-long tradition of medicinal and spiritual use, particularly among Indigenous peoples. Despite this, however, psilocybin has not been extensively studied in the context of Western medicine, leaving many questions about its neurological functions unanswered. \u201cPsychedelic compounds like psilocybin produce temporary psychedelic experiences that last for four to six hours, but it\u2019s a mystery as to how those short-term actions translate to longer-lasting therapeutic effects on mental illnesses,\u201d said Alex Kwan, associate professor of Psychiatry and Neuroscience at Yale and senior author of the paper. By studying how psilocybin affects neuron structure, researchers could bridge this gap and offer a structural explanation behind its well-observed lasting therapeutic effects, which include a substantial reduction in depression and anxiety symptoms according to early but promising clinical trials.\nIn this study, the researchers administered various doses of psilocybin to mice and evaluated the neurological effects through a series of tests. \u201cOne of our focuses is on neuronal structure. We used two-photon imaging, a fluorescence imaging technique used for live tissues, and confocal imaging, an optical laser imaging technique with high resolution, to see the structural changes caused by single-dose psilocybin,\u201d said Ling-Xiao Shao, first author of the paper and a postdoctoral associate researcher in Kwan\u2019s lab. The researchers used the two-photon imaging technique to longitudinally track the dendritic spines\u2014protrusions from the membranes of dendrites, the branch-like appendages of neurons that receive communications from other cells\u2014in neurons within the mice\u2019s medial frontal cortex. These spines play a vital role in receiving and processing electrical impulses.\u00a0\nThe study\u2019s results suggest that a single dose of psilocybin was sufficient to enhance the formation of dendritic spines in the medial frontal cortex of the mouse, increase spine head width, and boost spine protrusion length. A month after administration of psilocybin, approximately a third of psilocybin-induced new dendritic spines remained. These results are especially promising for potential therapeutic use, as conditions like depression are associated with a loss of synapses in the frontal cortex region. Psilocybin\u2019s stimulation of lasting dendritic growth may offer a solution.\u00a0\nWhile imaging neural modifications clarifies the physical effects of psilocybin, it does not fully account for the functional outcomes of the compound. To understand the impact of these structural changes on behavior, the researchers applied footshocks to the mice and assessed if single-dose psilocybin improved their ability to escape stressful conditions. The results demonstrated that mice exposed to psilocybin exhibited healthier stress-response behavior.\nWhile this study provides compelling evidence in support of the enduring actions of psilocybin in the brain, it is still unclear whether the compound\u2019s therapeutic potential can be isolated from its hallucinogenic effects. Kwan and Shao\u2019s study found that suppressing psilocybin\u2019s hallucinogenic effects by knocking out a key serotonin receptor, 5-HT2A, did not interfere with the therapeutically promising changes in neuron structure. However, further research is needed to determine if this separation of function is possible in humans.\u00a0\nThe Rise (and Fall) of Psychedelic Psychiatry\nKwan and Shao\u2019s recent foray into the world of hallucinogens is representative of a larger, ongoing renaissance in psychedelic research after decades of fluctuating acclaim and condemnation. When Swiss researcher Albert Hofmann first discovered LSD\u2019s potent hallucinogenic effects in the early 1940s, he was not alone in his excitement about the drug\u2019s psychiatric potential. Hundreds of academic articles expounding psychedelics\u2019 effects appeared in medical journals throughout the 1950s. So began a brief and initially promising affair between psychedelics and clinical psychiatry in the United States. Various clinics and institutions, including Harvard, devoted significant resources to researching the therapeutic potential of psilocybin and LSD. Psychedelic researchers, such as Timothy Leary and Richard Alpert, became household names.\nHowever, growing backlash against the free-loving, acid-tripping counterculture of the 1960s\u2014facilitated by psychedelics\u2019 association with anti-war dissidence\u2014began to turn the political tide. In 1965, the passage of the Drug Abuse Control Amendments Bill banned the unlicensed individual manufacturing and sale of hallucinogenic drugs, signaling a strengthened political and legal resistance to hallucinogens and ringing a death knell for psilocybin. In 1970, the Controlled Substances Act explicitly designated psilocybin a Schedule I drug, the most restrictive classification, indicating a high potential for abuse and no accepted medical use. In so doing, the Act not only subjected psilocybin to extremely prohibitive regulations, but also heavily stigmatized its use, taking the wind out of the sails of psilocybin research for years.\nBy Kwan\u2019s own recollection, the landscape of psychedelic research was nearly barren even just a decade ago. \u201cReading from other labs who were studying this fifteen years ago, the culture was very different, very restrictive,\u201d Kwan said. \u201cThere were no suppliers of these compounds\u2026 there were only a few labs who would [synthesize psychedelic compounds] in the United States.\u201d\nThe Psychedelic Revival\nIn recent years, however, the research landscape has shifted. With greater knowledge of how drugs function on a molecular level, further research into the science of addiction, and growing recognition of the failures of the War on Drugs, popular conceptions of drug use are shifting. While much of the mainstream drug debate focuses on recreational use, these changing perspectives have opened up the academic and clinical fields as well.\u00a0\nKwan and Shao\u2019s study adds to a growing body of research into the therapeutic potential of psilocybin and other psychedelics to treat mental disorders. As a compound used in conjunction with psychotherapy, psilocybin has a number of uniquely appealing characteristics\u2014it\u2019s non-addictive, has low risk of overdose, and may require less frequent dosing than selective serotonin reuptake inhibitors, the most common class of antidepressants.\u00a0\nFinancial support for research from activist organizations, academic institutions, and commercial entities has accompanied this growing recognition of psilocybin\u2019s potential. Echoing the academic enthusiasm of the 1950s, centers dedicated to the study of psychedelic drugs have opened at a number of research institutions in recent years, among them Johns Hopkins, Massachusetts General Hospital, and New York University. Promising clinical psilocybin trials in the U.S. led the FDA to designate psilocybin a \u201cbreakthrough therapy\u201d in 2018, indicating significant institutional optimism about the drug\u2019s therapeutic potential. Kwan and Shao\u2019s own study reflects the growing acceptance of psychedelic research, given its publication in Neuron, a prestigious peer-reviewed research journal.\nEven in today\u2019s more liberal environment, however, obstacles remain for those interested in conducting research with psychedelics. \u201cEven though the public perception is changing quickly, the funding is still slow,\u201d Kwan explained. \u201cWe had a pilot grant from Yale, but [this research] is not funded right now at the federal level, so it\u2019s tricky.\u201d The National Institutes of Health has abstained from funding psychedelic research, even as commercial interest in psychedelic psychiatry grows.\u00a0\nMoreover, while Kwan and Shao are optimistic about the therapeutic potential of psilocybin, they caution against framing psychedelics as a panacea for mental illness. Noting \u201cthe possibility of adverse effects,\u201d Kwan described particular risks for people with a history of psychosis or cardiovascular issues. \u201cThere\u2019s a lot of hype in terms of what these compounds can do, but they\u2019re definitely not going to be a solve-all,\u201d Kwan cautioned.\nIn the meantime, though, Kwan and Shao intend to remain an integral part of this research. The results of their study offer fertile ground for further exploration of psilocybin. After observing the neurological changes induced by psilocybin, Kwan and Shao are eager to address new questions regarding the particular molecular signals, brain receptors, and neural cell types involved.\nFive decades on from the initial criminalization of psilocybin, the psychedelic research landscape again appears bright. While we may not be \u201cturning on, tuning in, and dropping out\u201d any time soon, researchers like Kwan and Shao remind us that the future of psychiatry may well be psychedelic after all.\nAbout the Authors\nAnna Calame is a junior in Davenport College studying the history of science, medicine, and public health. Outside of her work with the YSM, Anna is involved with Yale UAID, YaleBleeds, and the club tennis team.\nRayyan Darji is a sophomore in Grace Hopper interested in studying neuroscience on the pre-med track. In addition to writing for YSM, Rayyan is involved with Yale Muslim Students Association, Alzheimer\u2019s Buddies, and YNEURO.\nAcknowledgments\nThe authors would like to thank Alex Kwan and Ling-Xiao Shao for discussing their research process and findings with them, and the research team would like to acknowledge the non-profit Usona Institute for providing psilocybin for research.\nExtra ReadingShao, L.X., Liao, C., Gregg, I., Davoudian, P.A., Savalia, N.K., Delagarza, K., & Kwan, A.C. (2021). Psilocybin induces rapid and persistent growth of dendritic spines in frontal cortex in vivo. Neuron, 109(16). \u200b\u200b\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/a-shift-in-the-psychedelic-paradigm-could-shrooms-shake-up-the-future-of-psychiatry/",
            "captions": [
                "Art Courtesy of Elaine Cheng."
            ]
        },
        {
            "title": "The Lives of Black Holes and Galaxies: New Models for All Scales of Motion",
            "author": "Daniel Ma",
            "authorLogo": "",
            "date": "November 8, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Ma_Figure1-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "How do supermassive black holes swallow up matter and help drive the galaxies of our universe? This fundamental question in astrophysics has yet to be fully answered, but it strikes at the heart of our creation and existence. Supermassive black holes, present in most galaxies, play a key role in galaxy evolution through their gravity, but nobody knows exactly how. In particular, the way these supermassive black holes accrete matter has been uncertain. For example, quasars\u2014active galactic nuclei powered by supermassive black holes\u2014are so powerful that they can outshine their entire host galaxies and be seen billions of light-years away. But how can so much gas accrete so rapidly as to sufficiently power these quasars?\nEarlier this year, Daniel Angl\u00e9s-Alc\u00e1zar\u2019s research group at the University of Connecticut made groundbreaking success in modeling black hole-galaxy interactions, finding a viable mechanism for black hole gas accretion and quasar luminosity. This model is unique in its use of novel mathematical techniques, dubbed \u201cLagrangian Hyper-refinement,\u201d to accurately represent the flow of gas into a black hole on both small and large scales at once.\u00a0\nSpatial and Temporal Scales of Black Hole Simulations from simonsfoundation.org on Vimeo.\nAnimation illustrating the large range of spatial and temporal scales captured by the new simulations, with more than a thousand times better resolution than previously possible. Zooming in from the intergalactic medium on scales beyond one million light-years down to the inner ten light-year region of a massive galaxy, the predicted influx of gas into the accretion disk surrounding the supermassive black hole is high enough to power a luminous quasar at the epoch of peak activity. Credit: Angl\u00e9s-Alc\u00e1zar et al. Astrophysical Journal 2021.\nAnimation illustrating the large range of spatial and temporal scales captured by the new simulations, with more than a thousand times better resolution than previously possible. Zooming in from the intergalactic medium on scales beyond one million light-years down to the inner ten light-year region of a massive galaxy, the predicted influx of gas into the accretion disk surrounding the supermassive black hole is high enough to power a luminous quasar at the epoch of peak activity. Credit: Angl\u00e9s-Alc\u00e1zar et al. Astrophysical Journal 2021.\nPreviously, researchers had to make simplified guesses as to how black hole accretion would influence their galactic models, as the galactic models didn\u2019t have the necessary resolution to incorporate existing black hole accretion models. This was a major limitation, considering how much the black holes\u2019 mass could influence surrounding structures. But Angl\u00e9s-Alc\u00e1zar\u2019s new model is able to do the equivalent of \u201cadding more pixels to an image in the region where you want to zoom in,\u201d he said, dynamically generating more gas circulation elements wherever the black hole is at any given moment to increase the resolution. Hence, even though the model begins on a multi-galactic scale, one can zoom in a million times at its center and see activity on the scale of only a few light-years.\u00a0\nThe model\u2019s results have been very promising. The presence of large asymmetries in galaxy shapes was found to be crucial to the accretion process. As a galaxy rotates, its asymmetrical parts, such as spiral arms, exert a constant gravitational pull on rotating gas. This makes the gas slow down, fall into smaller orbits, and eventually fall into the black hole. The model produced fractal-like generations of such spiral arms from the galaxy scale down to the accretion disk scale, supporting this theory\u2019s application on all scales.\u00a0\nMost impressively, under some conditions, the inflow of gas into the black hole was found to be large enough to explain luminous quasars. In other words, gas was entering the black hole fast enough to account for the quasar\u2019s energy output. \u201cThis was the first time that a single simulation covering the whole range of scales had been able to show that effect,\u201d Angl\u00e9s-Alc\u00e1zar said.\u00a0\nWhen the researchers studied the few quasars near enough to the Earth to observe in detail, they obtained results that resembled the model\u2019s. Additionally, the model shows that, surprisingly, even supermassive black holes can move substantially over time, and galaxies change their shapes by the interactions between their arms and migrating central black holes.\nBut an even bigger surprise was that the model, with certain starting conditions, also showed that galaxies often go into and out of active phases over time. Dormant supermassive black holes\u2014such as our own galaxy\u2019s Sagittarius A*, which doesn\u2019t accrete much matter at the moment\u2014can become active again after several million years by similar steps as described previously. The process, however, occurs at a much lower level, with galactic features slowing gas down and making it fall inward. These results greatly enhanced the team\u2019s confidence in the model, as they not only matched known statistics on the frequency of dormant versus active black holes, but also showed that the model could cover two different situations despite being made for only one.\u00a0\nAngl\u00e9s-Alc\u00e1zar is very optimistic about his model\u2019s future. \u201cWe can do these kinds of experiments on dwarf galaxies or on galaxies more like our own Milky Way, or the same galaxy but at an earlier phase, or even the very early universe, back when the first galaxies were forming,\u201d he said. Angl\u00e9s-Alc\u00e1zar also wishes to make the model even more accurate by including the effects of black holes\u2019 strong winds and relativistic jets.\u00a0\nThe door is wide open to new discoveries. And each discovery is another crucial step towards understanding our world. \u201cIn order to understand galaxies, we have to first understand black holes,\u201d Angl\u00e9s-Alc\u00e1zar said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/the-lives-of-black-holes-and-galaxies-new-models-for-all-scales-of-motion/",
            "captions": [
                "A galaxy swirls around a dormant black hole. There is very little gas immediately next to the black hole (hence the dark disk), but occasionally, filaments of gas will be drawn in from further out and temporarily reactivate the black hole. Images courtesy of Dr. Angl\u00e9s-Alc\u00e1zar (https://iopscience.iop.org/article/10.3847/1538-4357/ac09e8)."
            ]
        },
        {
            "title": "A Tech Clairvoyant for Paralyzed Voices: A New Prosthesis that Translates Brain Activity to Speech",
            "author": "Alex Dong",
            "authorLogo": "",
            "date": "November 8, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/artificial-intelligence-3685928_1280-500x333.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "He had not been able to speak for sixteen years. At the age of twenty, the patient, known as BRAVO-1, experienced a severe stroke resulting in paralysis and anarthria, the loss of the ability to articulate speech. But now, after the implantation of a novel neuroprosthesis, BRAVO-1 can communicate efficiently with the world\u2014using only his brainwaves. Edward Chang, neurosurgeon and Chair of Neurological Surgery at the University of California San Francisco (UCSF), spearheaded this decades-long effort to successfully decode words and sentences from neural activity.\nChang\u2019s journey with the brain started during his time in medical school at UCSF, where with brain mapping techniques he observed surgeries where the patients were actually awake. \u201cIt dawned on me that there was a huge, huge need to better understand how the human brain works to treat neurological conditions that we don\u2019t necessarily have cures for yet,\u201d Chang said. \u201cI decided to go into neurosurgery because it not only allowed me to work directly with the brain, but also take care of patients in a way that\u2019s hard to do in other fields.\u201d\u00a0\nIn addition to practicing, Chang conducts research as co-director of the Center for Neural Engineering and Prostheses, which is a collaborative organization between UCSF and UC Berkeley that focuses on developing biomedical technology to help people with neurological disabilities like paralysis and speech disorders.\u00a0\nOver the last decade, Chang\u2019s lab intently studied the region of the brain that controls the vocal tract. \u201cWhat we found was a map of the different parts of the vocal tract and kinematic properties that give rise to speech,\u201d Chang said. This neural code for every consonant and vowel is composed of elemental movements, such as the tongue moving forward, that are very precise and highly coordinated. With this newfound knowledge, they sought to create a device that could translate brain activity into words. Thus, over the past decade, Chang and his research group have been working on a \u201cneuroprosthesis\u201d\u2014a device that can record and decode the participant\u2019s brain activity, then display their \u201cspeech\u201d on screen.\u00a0\nHelping to lead these efforts is post-doctoral researcher David Moses, whose interest in programming, bioengineering, and their intersection with medicine and neuroprosthetics led him to the Chang lab. Thus began the BRAVO (BCI\u2014brain computer interface\u2014Restoration of Arm and Voice) clinical trial, in which Chang and his team enrolled their first participant, BRAVO-1, to begin testing the potential speech neuroprosthesis.\u00a0\nThe neural implant, composed of 128 electrodes that record neural activity from the surface of the brain, was implanted in BRAVO-1 over the brain region that controls the vocal tract. Unlike the telepathic transmission commonly depicted in sci-fi movies, this technology relies on the patient trying to engage in speech: the implant detects these signals, which are then analyzed. \u201cThis isn\u2019t like mind reading or any internal monologue\u2026 it has to be controlled by volitional attempts to speak,\u201d Moses said. Alongside the development of the hardware, Chang\u2019s research group primarily focused on creating and programming the software behind this new device.\nIn February of 2019, they implanted the device in the patient\u2019s sensorimotor complex, which controls speech. Two months later, BRAVO-1 began to attend fifty data-recording sessions over a span of eighty-one weeks. \u201c[BRAVO-1] is an incredible person and truly a pioneer. Even though we had a lot of proof of principle, there\u2019s a lot of reasons it might not have worked,\u201d Chang said.\u00a0\nOne such concern was that after the patient had not spoken for over fifteen years, there was no telling how much information about his speech attempts would be represented in the expected part of his brain. During each session, the participant performed many trials of two different tasks: an isolated-word task and a sentence task. Twenty-two hours of data were collected from over 9,800 trials of the former task, which involved the participant\u2019s attempts to say one word from a predefined set of fifty common English vocabulary words. In addition, 250 trials of the sentence task, in which the participant attempted to produce word sequences from the same set, were also performed. Both tasks helped the researchers train, fine-tune, improve, and evaluate their computational models.\u00a0\nFinally, the conversational variant of the sentence task was implemented, in hopes of demonstrating a real-time sentence-decoding process. The participant was first visually prompted with a question or statement onscreen. Then, he tried to speak in response to the prompt from a predefined set of fifty common English vocabulary words. The electrode arrays in the implant detected and collected the brain signals, which were then sent and processed in real-time to the computational processing system.\u00a0\nIn the system, first, a speech detection model identifies when the participant has been attempting to speak. This algorithm specifically detects the onsets and offsets of the participant\u2019s word production attempts directly from brain activity, limiting the temporal window of relevant signals analyzed in the later steps. Next, a word classification algorithm predicts the probability that each of the fifty words has been attempted. However, this is not as simple as identifying one signal associated with one word. \u201cThere isn\u2019t one particular part of my brain that only lights up when I\u2019m saying just that word,\u201d Moses said. Instead, when we pronounce certain words, our brain relays signals to our vocal tract, which then performs certain articulatory gestures such as opening our mouths. Thus, the brain activity processed by the neural implant is not necessarily limited to certain words or phrases, but rather depends on the pattern of articulations associated with each word.\u00a0\nA third algorithm yields the probabilities for the next word in a sentence given the previous ones. This language model is based on English linguistic structure; for instance, \u201cI am very good\u201d is more likely to be said than \u201cI am very going.\u201d Finally, the predicted word or sentence is displayed onscreen as feedback, demonstrating the newfound possibility of \u201cspeech\u201d for the paralyzed patient.\nChang\u2019s system better resembles real-time speech in terms of accuracy of communication and rapid pace, achieving a median rate of 15.2 words per minute decoded and a median word error rate of 25.6 percent. The research team\u2019s next steps include replicating these results in more than one participant: as long as the patient is cognitively intact and can attempt to produce speech, this neuroprosthesis could potentially be useful for people with a variety of injuries or disabilities, interpreting their brain waves and allowing them to communicate once more.\u00a0\nHowever, while this device is certainly ground-breaking, there are still some limitations with the current system. \u201cIt seems very unlikely that we could just expand this current form to a thousand words,\u201d Moses said. The team intends to keep working on modifications or alternative approaches to their initial proof-of-concept to expand the neuroprothesis\u2019 potential. The ultimate vision is some kind of brain-computer interface that is convenient, portable, and minimally intrusive, with the ability to decode words and sentences quickly, facilitating accurate communication with the outside world.\n\u201cNow that we even have this initial proof of concept, and this first shred of evidence that this is feasible, it\u2019s really quite motivating to see how far we can go with it,\u201d Moses said. The researchers describe this project as a unique opportunity to tangibly help paralyzed people reconnect and communicate with the outside world, which the team finds incredibly rewarding and is committed towards pursuing. Ultimately, Chang and his research team hope to restore the individual\u2019s voice\u2014thereby reaffirming both the patients\u2019 autonomy and fundamental connection to humanity.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/a-tech-clairvoyant-for-paralyzed-voices-a-new-prosthesis-that-translates-brain-activity-to-speech/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Mathematically Perfect Egg",
            "author": "Eunsoo Hyun",
            "authorLogo": "",
            "date": "November 8, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/TheMathematicallyPerfectEgg-Saachi-Grewal-500x357.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Over millennia, the egg has evolved to become one of the most adaptable shapes in nature: strong, small enough for safe delivery, and capable of surviving in extreme conditions. This distinctive shape has long been a subject of fascination among researchers. \u201c[We are investigating] whether some mathematical laws were designed first and nature was created in accordance to them, or vice versa,\u201d said Valeriy Narushin, a researcher at Vita-Market Ltd and the Research Institute for Environment Treatment in Ukraine. Narushin\u2019s recent work on developing a universal mathematical formula for egg shape demonstrates a collaboration between biologists, engineers, and scientists, united by a common desire to crack the mystery of this unique natural phenomenon.\nThere are four main categories of egg shapes: circular, elliptical, oval, and pyriform. The most commonly recognized egg shape, which we encounter in chicken eggs, is the oval. \u201c\u200b\u200bAs for me personally, I like pyriform, or speaking in mathematical language, conical eggs. These are laid by some species of waders and guillemots,\u201d Narushin said. Pyriform, in contrast to the oval, is a more unconventional \u201cpear-like\u201d or pointed shape. There are many hypotheses as to why certain types of eggs evolved this way, ranging from their structural integrity to their ability to fit into nests efficiently, but there is no clear explanation yet as to why some eggs converged to a pyriform shape over time.\u00a0\nAt first glance, it may seem quite straightforward to map the shape of an egg using mathematical equations. However, while these equations are very good at creating idealized egg shapes that can be used in art and architecture, they fall short when it comes to tracing a real egg. Thus, the challenge was to deduce a universal mathematical formula that corresponds to all types of egg shapes and is easily transferable between geometrical figures.\u00a0\nThe researchers successfully developed a more complex, universal formula based on measurements of the egg length, maximum breadth, vertical axis shift, and diameter at one quarter of the egg length. This formula allows them to theoretically describe any avian egg, keeping in mind that small discrepancies are to be expected due to the diversity of eggs as a natural object. Importantly, the formula can describe the shape of any of the four egg types\u2014a feat that has never before been achieved to this level of accuracy.\nIn the process of collecting data for this study, the researchers also furthered a more comprehensive project aimed towards sustainable and nondestructive methods of egg evaluation. \u201cElaboration of non-destructive methods for testing eggs is the basic goal of our research group, which we call the \u2018Eggy-team,\u2019\u201d Narushin said. The researchers used images instead of actual eggs whenever possible and did not handle any endangered or wild bird eggs. This is part of a long-term goal: the development of non-invasive research methods can improve poultry management and environmental conservation efforts.\u00a0\u00a0\nBut why the obsession with eggs? \u201cAccording to Professor Tim Birkhead, [eggs] are the most perfect things on the Earth. And we fully agree with him. From ancient times, eggs were used as cult objects in art, architecture\u2026 etc. And of course, an egg is an excellent food used in more than ten-thousand recipes,\u201d Narushin said.\u00a0\nThe study of eggs has far-reaching impacts. In the food industry, egg density and the ratio of egg weight to surface area are crucial in considering egg freshness, shell thickness, storage conditions, and incubation success. \u201cIf you know a geometrical formula of a given egg, it\u2019s rather simple to recalculate all these parameters (curvature, a longitudinal length and others) with equations of the integral geometry,\u201d Narushin said.\u00a0\nThe egg also provides a source of architectural inspiration.\u00a0 \u201cThe egg profile has several advantages for architects due to its harmonic shape, relative strength, and minimal consumptions of building materials,\u201d Narushin said. \u201cFamous egg constructions include The National Centre for the Performing Arts in Beijing and the Gherkin in London.\u201d From food science to art, the egg has an influence far beyond what its humble appearance may suggest.\nNow that this universal formula has been found, what lies in the future of oomorphology? \u201cThe first [investigation] is based on deducing universal formulae for calculating volumes and surface areas of different egg types, and their ingression into the principles of mathematical evolution,\u201d Narushin said. \u201cThe second one is related to the study of shell mathematical secrets. Why is the shell relatively thick in some species and thin in others? Hope we can propose some results very soon.\u201d\nSo the study of eggs continues, one formula at a time.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/the-mathematically-perfect-egg/",
            "captions": [
                "Graphic by Saachi Grewal"
            ]
        },
        {
            "title": "The Future of Carbon Capture: Unlocking Cheap Conversion of Carbon Dioxide to Methane",
            "author": "Sarah Cook",
            "authorLogo": "",
            "date": "November 8, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/30953392578_1449f7758f_o-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "These days, it\u2019s hard to escape the reality of climate change in daily life. Carbon dioxide is one of the main greenhouse gas drivers of climate change: according to the EPA, 6,558 tons of the gas were emitted in the United States in 2019 alone. But what if there was a way to \u2018harness\u2019 this carbon dioxide and instead transform it into usable energy? Enter: carbon capture.\u00a0\nResearchers from the U.S. Department of Energy\u2019s Pacific Northwest National Laboratory (PNNL) recently discovered a new method of integrated carbon capture that converts carbon dioxide into methane, a main component of natural gas. The reactants of this method include waste carbon dioxide, a 2-EEMPA solvent, and renewably sourced hydrogen. While traditional carbon capture methods usually boil the carbon dioxide out (the capture step) before shipping it elsewhere to be converted into methane (the conversion step), this new process simply passes the carbon dioxide over a catalyst and mixes it with hydrogen, all in one chamber, completing the conversion at one site. \u201cRather than just doing the wasteful regeneration [of carbon dioxide], we\u2019re just doing the conversion at the same time,\u201d Heldebrant said.\u00a0\nAnd best of all? This method presents the lowest price of carbon capture so far.\u00a0\nThe 2-EEMPA solvent used in the method has been in development for fourteen years with corporations such as Florida Corporation, GE Global Research, and University Partners, with twenty-million dollars of Fluor Corporation funding. Unlike traditional solvents, 2-EEMPA has a low water content and thus can more easily dissolve carbon dioxide more easily, while requiring less overall energy to complete the conversion process. Hence, while pPrevious methods required high temperatures to push the equilibrium in favor of the conversion, but 2-EEMPA simply allows the chemicals involved to facilitate the conversion to methane, necessitating only about half of the typically required temperature and pressure.\u00a0\nBecause of this ability to reduce the amount of energy used in the conversion of carbon dioxide to methane, using 2-EEMPA in power plants could decrease the price of carbon capture by nineteen percent. \u201cRight now, everybody talks about wanting to do carbon capture, but there is a high cost,\u201d Heldebrant said. Current commercial technology can capture carbon dioxide at $58.30 per metric ton, but this new method costs only $47.10 per metric ton. This method therefore reduces total capital investment by thirty-two percent and the minimum selling price for natural gas by twelve percent.\u00a0\nIt\u2019s important to note that while this new process produces methane, which is itself a harmful greenhouse gas, synthetic methane\u2019s carbon neutrality and household and industrial uses still make it an improvement over other forms of methane. Furthermore, Heldebrant\u2019s project was funded in California, where the new low-carbon fuel standard prohibits the use of methane derived from fossil fuels in a few years. This makes Heldebrant\u2019s research even more vital for companies currently relying on producing natural gas. \u201cUltimately in the long term, we would love to see everything go to renewables, but at least right now, we would much rather see something that\u2019s carbon-neutral as opposed to carbon-positive just pulling the methane out of the ground,\u201d Heldebrant said.\u00a0\nCompared to previous methods, this method\u2019s low price creates financial incentives for carbon capture, but it also creates a potential problem of oversaturation of the methane marketplace once the method becomes large-scale. \u201cIf we\u2019re only going to be making methane, you\u2019re going to disrupt the entire methane marketplace, and then that basically means there\u2019s no longer an economic driver to do it,\u201d Heldebrant said.\u00a0\nIn the future, PNNL hopes they can find new substances to which they can convert waste carbon dioxide, such as dimethyl ether (a type of diesel additive), cyclic carbonate (a type of electrolyte solvent in batteries), and polymer carbon dioxide. The work to pioneer carbon capture technology at such low costs has been decades in the making, but this new research has finally shown that cheap carbon capture technology is not only feasible, but also has the potential to become a beneficial driver of the economy and environment.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/11/the-future-of-carbon-capture-unlocking-cheap-conversion-of-carbon-dioxide-to-methane/",
            "captions": [
                "PNNL researchers developed a cheaper way to convert carbon dioxide to methane. Image courtesy of the Pacific Northwest National Laboratory."
            ]
        },
        {
            "title": "Building a Battery Future: Exploring the Viability of Sodium Batteries in a Lithium Dominated World",
            "author": "Jordan Sahly",
            "authorLogo": "",
            "date": "October 10, 2021",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Sahly_Figure2-500x453.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Google images, creative commons.\nEvery day around the world, modern luxuries are plugged in, charged, drained, and the cycle begins anew. Critical to this energy dependence is the lithium-ion battery\u2014the electrochemical backbone behind cell phones, laptops, electric cars, and most other battery-powered devices. In the US alone, electronics consume some two thousand metric tons of lithium annually, of which over fifty percent arrives as imports from other countries such as China, Chile, and Australia.\u00a0\nYiren Zhong, a postdoctoral associate in Yale\u2019s Department of Chemistry, understands the need to find a substitute for lithium-ion batteries. \u201cWe all know that the lithium is a very very limited resource, not only in the Earth\u2019s crust but also in the oceans, in the lakes,\u201d Zhong said. Resource scarcity and related environmental concerns have inspired chemists\u2014including Zhong\u2014to look for candidates no further than a row down in the periodic table. One promising candidate is sodium, an alkali metal like lithium. Sodium and lithium have many similar qualities due to periodic trends, with the notable difference that sodium is larger in atomic size and has less electric potential overall. However, sodium is also far more abundant naturally on Earth. Would this periodic similarity make sodium a prime candidate for battery production? This is what Zhong set out to study with his research, published in August of 2021 in the Journal of the American Chemical Society.\nDespite it\u2019s natural abundance, sodium has a long way to go before replacing lithium as a primary battery component. There are pros and cons for sodium metal as an electrode; for one, sodium has good reversibility compared to lithium, however, it cannot be charged or discharged very quickly. Reversibility for a battery is the ability to return the electrochemical reaction back to its original reactants, meaning batteries with good reversibility can be recharged and reused. Sodium\u2019s reversibility in batteries is promising, however intrinsic elemental properties stand in the way of sodium\u2019s potential. Zhong\u2019s research group investigated these properties through rigorous experiments testing sodium batteries at varying power levels, then examining the electrode\u2019s physical and chemical structure after both charging and discharging. The research team performed the experiments with currents at high levels closer to those of lithium batteries and far lower currents for comparison. When the sodium electrode was discharged at the higher currents it performed with only zero to sixty percent Coulombic efficiency\u2014the efficiency with which a battery outputs usable electrons (electricity) that it produces\u2014 and an interesting physical reaction indicated a key elemental difference between lithium and sodium. When built through charging, sodium metal electrodes naturally form in dendritic structures, which are long, thin columns of metal that form porous, microscopic forests on the surface of the electrode. However, when charged at high current densities these dendritic structures are formed with non-metallic impurities that reduce the reversibility of the battery overall. When discharged at high current densities, these impure porous surfaces allowed fast- moving current to react unevenly\u2014especially at the base of the electrode\u2014causing electrode erosion and eventual electrical disconnection. These results indicate that the low performance of sodium batteries stems from theirits elemental characteristics, namely their its larger atomic size. Electrodes made from sodium metal have more spread- out dendritic structures due to larger atomic size, which creates the porous surface that allows for erosion of the electrode foundation layer at high currents, like waves washing away the base of a sand castle. However, Zhong\u2019s findings also suggest a favorable future for sodium. At low power levels, the sodium battery did not decay and performed favorably with Coulombic efficiencies as high as 99.5 percent. At these low current densities, sodium batteries may demonstrate commercial usefulness in technologies like short- range transportation tools.\nHaving observed sodium\u2019s intrinsic characteristic limiting its potential in batteries, Zhong\u2019s group laid the foundation for future sodium battery technology. One of his newest ideas involves the electrode shape itself. \u201cMy current thinking is trying to use a three- dimensional electrode,\u201d Zhong said. He theorizes that a three- dimensional electrode may reduce local current density across a larger surface area, which subsequently improves electrochemical reaction in the battery. As our society\u2019s energy dependence grows each year, more environmentally friendly batteries become a necessity rather than a goal. \u201cThe number one reason for that is because we need to develop a battery future. . . by the year 2050, I would envision that sodium would be one of the major components in the battery market,\u201d Zhong said. Sodium metal has the potential to help build a sustainable battery future, and thanks to the continued work of ingenuitive innovative chemists, that future is in reach.\nCitations:\nJaskula, B. W. (2021, January). Lithium. US Geological Service. Retrieved September 2021.\u00a0\nZhong, Y. (2021, September 16). Personal interview [Zoom interview].\nZhong, Y., Shi, Q., Zhu, C., Zhang, Y., Li, M., Francisco, J. S., & Wang, H. (2021). Mechanistic\u00a0\ninsights into fast charging and discharging of the sodium metal battery anode: A comparison with lithium. Journal of the American Chemical Society, 143(34), 13929\u201313936. https://doi.org/10.1021/jacs.1c06794\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2021/10/building-a-battery-future-exploring-the-viability-of-sodium-batteries-in-a-lithium-dominated-world/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Alumni Profile: Paul Hanle (PhD \u201975)\ufffc",
            "author": "Sophia Burick",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/DONG1-1-400x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "From curating exhibits at the Smithsonian to teaching judges about the facts of climate change, Paul Hanle (PhD \u201975) has spent decades helping the public appreciate the importance of science.\u00a0\nHanle came to Yale in 1969 with the intention of earning his PhD in physics but changed directions soon after. \u201cI was interested in both physics and how physicists think, where their ideas come from, and how the circumstances in which they work enable science to develop,\u201d Hanle said. He focused his studies on the History of Science & Medicine and was awarded his PhD in 1975.\nAfter his fourth year of studies, Hanle won a fellowship at the Smithsonian Institution. He was appointed as a curator at the soon-to-open National Air and Space Museum in 1974. One of his proudest accomplishments was overseeing the creation of the Air and Space Smithsonian magazine. \u201cIt was extremely exciting and gratifying to create something brand new,\u201d Hanle said.\u00a0\u00a0\nHanle had been bitten by the museum bug. He went on to lead two museums\u2014the Maryland Science Center and the Academy of Natural Sciences of Philadelphia. As CEO of the Maryland Science Center, Hanle pursued new, creative routes of communicating scientific knowledge. For example, he helped lead the Museum Film Network, which produced the IMAX film To the Limit\u2014a film exploring human physiology through athletics. \u201cIt was a very powerful strategy for conveying scientific information,\u201d Hanle said. \u201cThe audience didn\u2019t necessarily know they were learning science.\u201d As president of the Academy, Hanle opened an exhibit on dinosaurs that brought museum visitation to record highs. Hanle\u2019s ingenuity in his leadership at these museums created meaningful opportunities for the general public to engage with scientific thought.\nHanle went on to become the first president of the Biotechnology Institute, an organization centered around getting kids excited about modern bioscience. Each year, the organization grants BioGENEius awards to students who completed outstanding science projects, honoring them at an annual convention attended by thousands of representatives from biotechnology companies.\nWhile working at the Biotechnology Institute, Hanle advised President Barack Obama\u2019s 2009 Educate to Innovate initiative, a bipartisan effort to advance the level of STEM education available to kids across the country. \u201cIt was successful in helping to raise the profile of the issue and getting companies to realize that they had a stake in STEM education,\u201d Hanle said.\u00a0\nIn 2011, Hanle shifted his work towards educating the public about climate change. \u201cIn my view, it\u2019s the greatest challenge to humanity and the planet,\u201d Hanle said. \u201cIt is truly existential.\u201d\u00a0\nHe became CEO of Climate Central, an organization focused on communicating the scientific facts of climate change to the public. One of their major projects involved getting local meteorologists to incorporate information about the impact of climate change on weather into their daily newscasts. \u201cThere\u2019s a maxim in communication about climate change\u2014to convey simple messages, repeated often, by trusted messengers,\u201d Hanle said. \u201cThose three elements are a very important way to reach people who might otherwise not be reached.\u201d\u00a0\nClimate Central\u2019s impact is widespread; figures generated by the organization illustrating what rising sea levels would look like at iconic places like the Gate of India and the White House were used at the United Nations\u2019 Climate Change Conference in 2015 to emphasize to delegates the dangers of rising temperatures.\nIn 2018, Hanle embarked on his latest effort: founding the Climate Judiciary Project at the Environmental Law Institute. The project\u2019s mission is to educate judges about climate science and its connection to environmental law. \u201cI realized that a lot of interesting things were happening in legal cases around trying to hold emitters or producers accountable for the effects of climate change,\u201d Hanle said. \u201cIt seemed to me that one of the crucial things we could do is to educate these decision makers, the judges, about the objective, scientifically valid facts of climate change.\u201d The program has received strong interest from judges, and project leaders are currently planning to expand it internationally.\u00a0\nHanle\u2019s advice for getting people to care about climate change is simple: stick to the science. \u201cIf you can convey the scientific facts objectively, you might reach a broader audience,\u201d Hanle said. \u201cThat audience may include people who are not necessarily sympathetic to social movements for climate action or are even skeptics, but who might be convinced that there\u2019s a really serious problem about climate change that needs to be addressed now.\u201d Hanle\u2019s work exemplifies how scientific communication and education can be used to create positive change.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/alumni-profile-paul-hanle-phd-75%ef%bf%bc/",
            "captions": [
                "Headshot of Paul Hanle."
            ]
        },
        {
            "title": "Science in the Spotlight: Our Biggest Experiment by Alice Bell",
            "author": "Tori Sodeinde",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Sodeinde-figure-2-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "What do whales, fizzy water, and a 364-foot Ferris wheel have to do with the climate crisis? In her new book, Our Biggest Experiment: The Epic History of the Climate Crisis, author and climate activist Alice Bell answers this question and many more as she explores the climate crisis from a unique perspective, focusing not only on the future of the planet but also on the history of how we reached this critical point.\u00a0\nDevoting each chapter to a different aspect of environmental history, Bell explains the first weather maps, the advent of electricity, and even the origins of the term \u201ctree hugger\u201d\u2014trust me, it\u2019s not what you\u2019re expecting. Starting with scientist and activist Eunice Foote\u2019s 1856 experiment positing the effect of increased carbon dioxide on atmospheric temperatures, Bell weaves together the story of how humans began shaping the earth. The book highlights several little-known but influential climate scientists, including Foote and Guy Calendar, the English scientist who linked Earth\u2019s rising temperatures to rising carbon dioxide concentrations in the 1930s.\nWhen trying to find ways to combat climate change, certain ideas crop up time and time again, like the idea of a technofix, a new technological approach to the problem of climate change that tends to oversimplify the problem and distract from the root problems. \u201cIt\u2019s almost a magician\u2019s trick. It\u2019s a way of looking at shiny new tech\u2026 and not old tech that\u2019s destroying the world,\u201d Bell told Yale Scientific. Despite the excitement surrounding alluring new ideas like cloud seeding and artificial volcanoes, we must exercise caution. \u201cAll technology\u2019s kind of a double-edged sword. We have to think of how we apply it, who\u2019s in charge, and what other technologies we need alongside it,\u201d Bell said.\u00a0\nOne single solution will not solve the crisis, and focusing on futuristic quick fixes can distract from the basic problems that need to be addressed, like our dependence on and overuse of unrenewable energy sources. Bell remains hopeful but pragmatic: today, our future will depend more on minimizing, rather than totally reversing, climate change. Keeping the world half a degree colder might sound inconsequential, but in reality, it equates to countless lives, homes, and livelihoods saved.\u00a0\nBell stresses the importance of developing a personal connection to the environment and climate. It\u2019s easy to become cynical and apathetic when thinking of the climate crisis as an ambiguous, ominous tide of change, but forging personal connections to the environment\u2014whether through planting trees, joining environmental action groups, or investing in renewable energy\u2014can remind us of the close relationship between our lives and the environment. If you\u2019re unsure where to begin, reading Bell\u2019s book could be a good start. \u201cIt\u2019s hard to feel like you understand [the climate crisis], but I understood it more because of the history, and so I wanted to share that with other people,\u201d Bell said. With a more complete understanding of the past, we can hopefully begin building a more sustainable future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/science-in-the-spotlight-our-biggest-experiment-by-alice-bell/",
            "captions": [
                "Arctic ice sheets melting. Image courtesy of Pressenza."
            ]
        },
        {
            "title": "Counterpoint: Do Hospitals Really Do No Harm?\ufffc",
            "author": "Hannah Shi",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Sherman-headshot-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "\u201cFirst, do no harm.\u201d All doctors swear by the ancient Hippocratic oath. But we must ask ourselves, do hospitals really do no harm? The production, distribution, and eventual disposal of medical drugs and equipment are major contributors to climate change. In fact, if global healthcare was its own country, it would be the fifth largest emitter on the planet. The severity of healthcare\u2019s carbon footprint contradicts the values of a system centered around protecting human health. Physicians are contributing, whether they realize it or not, to one of the largest public health crises in human history.\u00a0\nYale Professor Jodi Sherman provides a solution as to how healthcare can strive to \u201cdo no harm\u201d on a global scale. Her research focuses on creating sustainability metrics that help inform administrative and physician decision-making towards more environmentally sustainable operations. Sherman\u2019s recent paper published in British Medical Journal introduces the idea of \u201cplanetary healthcare,\u201d which expands the principle of \u201cfirst, do no harm\u201d beyond the patient to the environment. In an interview with Yale Scientific, Sherman isolated three ways in which physicians can adopt this planetary healthcare lens: first, reduce emissions from healthcare services; second, match the supply and demand of healthcare services; and third, reduce the demand for healthcare services.\u00a0\nOn the first point, healthcare emissions are often embedded in the products and spaces physicians use when providing care. By using sustainability metrics, physicians can select drugs, equipment, and procedures that are less polluting yet still produce the same clinical outcome. For example, Sherman\u2019s work on tracking the life cycle of anesthesia drugs reveals that certain gases, such as desflurane and nitrous oxide, are significantly higher contributors to emissions compared to other clinically similar options. In addition to guiding clinical practices, empowering physicians with the environmental information associated with certain medicines and products used in treatments helps them leverage organizational purchasing power to influence a more eco-friendly industry.\nSecondly, healthcare resources are often inappropriately utilized, which creates unsustainable practices that fail to match supply and demand. \u201cIn the U.S. over fifty percent of healthcare is devoted to five percent of the population with advanced chronic disease\u2026 there are also alarming statistics on how much we spend on end of life [care] and it\u2019s not frequently the care patients would choose if they were better informed,\u201d Sherman said. It is necessary to both mitigate excessive resource consumption while also maximizing high value, clinically effective treatment, which ultimately leads to more positive environmental outcomes.\nFinally, it is imperative that we reduce our demand for healthcare resources. This involves directing care resources upstream and incorporating non-pharmacological and lifestyle methods to preventing disease. Medical services contribute to only twenty percent of health and wellbeing, while the rest is attributed to social and environmental factors. Integrative healthcare aims to address this other eighty percent of human wellbeing by informing patients of healthier life choices (such as reducing alcohol consumption) and alternative pain management strategies (such as acupuncture and meditation). Moreover, consistent primary care enables early prevention, detection, and treatment, leading to better health outcomes. As such, it is important to invest in primary care and public health so that preventative measures can reduce the demand for acute treatment of advanced disease down the line.\nSeveral sectors must come together if we wish to achieve net-zero emissions in healthcare. With the COVID-19 pandemic, the world witnessed global mobilization and cooperation in healthcare unlike anything ever seen before. \u201cWhile we had an increased need for emergency care and critical care, and obviously increased consumption of personal protective equipment and other healthcare resources, the global medical community came together quickly, sharing information, redesigning models of care, increasing access to telehealth, and moving towards a circular economy\u2014meaning, keeping materials in use for longer,\u201d Sherman said. \u201cThis begs the question, why are we not doing this routinely?\u201d\u00a0\nThe pressures of the pandemic forced physicians to challenge the culture of disposability and excess consumption of resources within medicine. Medical practitioners safely succeeded at efforts to adapt practices, increase communication, and become better stewards of healthcare resources, proving that rapid change in response to a crisis is possible. Indeed, the world is now faced with a global crisis more urgent than anything we have dealt with before. The lives of all people and the planet are at stake. Doctors swore to \u201cdo no harm.\u201d It is now time to \u201cdo no harm\u201d to our environment.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/counterpoint-do-hospitals-really-do-no-harm%ef%bf%bc/",
            "captions": [
                "Yale Professor Jodi Sherman encourages the medical field to \u201cdo no harm\u201d\u2014not just to patients, but to the environment, too."
            ]
        },
        {
            "title": "Q&A: How Can Physics Teach Us About Climate Change?",
            "author": "Kat Moon",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/moon-figure-1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "This year, the Nobel Prize in Physics was awarded to three scientists, Syukuro Manabe, Klaus Hasselmann, and Giorgio Parisi, for their contributions to the understanding of complex systems. They each pioneered research on modeling Earth\u2019s climate and the nature of disorder in physical systems. By awarding the prize to climate scientists for the first time, the committee conveyed a clear message: climate change study is a rigorous form of scientific research.\u00a0\nSo, how have scientists used physics to analyze climate change?\u00a0\nIn the 1960s, Manabe, now a climatologist at Princeton University, created mathematical models of the Earth\u2019s climate to demonstrate how increased levels of carbon dioxide in the atmosphere raise the surface temperature. German meteorologist Hasselmann furthered the study by linking climate to the weather as a chaotic system, ultimately supporting that human activity, such as the generation of carbon dioxide emissions, is responsible for the change in climate. Both models are now foundational to the current understanding and research of climate change.\u00a0\nMeanwhile, Parisi, an Italian physicist at the Sapienza University of Rome, focused on quantum field theory, a framework to construct models of subatomic particles. He used this to discover patterns from underlying disorder and fluctuations in complex systems. The idea of analyzing irregularities in a complex system is analogous to evaluating numerous variables in the Earth\u2019s climate.\u00a0\nPhysics teaches us about climate change through mathematical models and complex systems. These physicists\u2019 recognition by the Nobel Committee emphasizes the rigorous scientific foundation underlying the study of climate change, ultimately prompting us to take action.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/qa-how-can-physics-teach-us-about-climate-change/",
            "captions": [
                "Syukuro Manabe and Klaus Hasselmann\u2019s work is central to showing the correlation between global warming, carbon dioxide level, and human activity."
            ]
        },
        {
            "title": "Into the Newsroom: The Yale Program on Climate Change Communication",
            "author": "Hannah Han",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Leiserowitz-384x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "For some Americans, the phrase \u201cclimate change\u201d conjures images of barren lands crippled by drought and forests decimated by wildfires. For others, climate change is a distant thought, a phenomenon entirely unrelated to human activity.\nFor over a decade, the Yale Program on Climate Change Communication (YPCCC) has studied Americans\u2019 changing perceptions of climate change and provided critical public opinion surveys for news outlets such as CBS, NBC, CNN, and The New York Times. YPCCC was founded in 2007 and is directed by Anthony Leiserowitz, a senior research scientist at the Yale School of the Environment.\nLeiserowitz\u2019s journey into the realm of climate change communication was unanticipated\u2014a confluence of his seemingly disparate interests and serendipity. As an undergraduate, Leiserowitz majored in International Relations, studying Cold War politics. But in 1990, he was offered a position at the Aspen Global Change Institution, a research center in Colorado, surrounded by snow-capped mountains and dense conifer forests. For four years, Leiserowitz immersed himself in climate studies among the world\u2019s leading environmental scientists, learning about carbon pollution and climate models.\nHowever, Leiserowitz eventually grew frustrated with the narrow focus on natural science. \u201cThe only reason we have [global warming] is because of people [and their decisions],\u201d Leiserowitz said. \u201cThis isn\u2019t a natural science problem. This is a human science problem.\u201d\nThis realization would guide the rest of his career. Leiserowitz devoted himself to studying human responses to the climate crisis, earning a master\u2019s and doctorate in Environmental Science, Studies, and Policy at the University of Oregon. He then spent four years at Decision Research, a research institute in Oregon, where he studied public risk perceptions and decision making, seeking the answers to pivotal questions concerning the climate crisis: How do people perceive the natural and social worlds? What are the psychological and political factors that shape human decision-making? How do we better communicate climate change and engage people in climate science?\u00a0\nLeiserowitz founded YPCCC in 2007, when he was hired by the Yale School of Forestry and Environmental Studies\u2014recently renamed as the Yale School of the Environment. The Yale Program includes psychologists, geographers, political scientists, sociologists, and others who conduct studies on public opinion and engagement. YPCCC has spearheaded research on public attitudes regarding climate change in more than 120 countries, including the United States, China, India, and Brazil. The program has also partnered with governments, media organizations, and companies, including Facebook and Google, supporting their climate change communication goals.\nLeiserowitz reiterated that all of our lives are entangled with the burning of fossil fuels: they are woven into the clothes we wear, the electronics we purchase, and the appliances we use. Every time we buy a product, we contribute to climate change. Every time we vote, we choose leaders who will either support or oppose climate policies. Multiply this by seven-and-a-half billion people, and the need for large-scale messaging becomes clear.\n\u201cOne of the major shifts that we\u2019ve seen change over the past ten years is recognizing how important communication is as a way to engage the broader society itself,\u201d Leiserowitz said. YPCCC\u2019s research has found that many people perceive global warming as a remote issue. \u201cMany Americans continue to think of climate change as a distant problem\u2014that this is about polar bears, or maybe developing countries, but not the United States, not my state, not my community, not my friends, not my family, not me,\u201d Leiserowitz said. As a result, the issue is often psychologically distant, blending into the noisy background of people\u2019s lives, where it doesn\u2019t seem salient.\nTo engage a national audience in climate change, Leiserowitz also founded Yale Climate Connections (YCC). A climate change news service and national radio program, YCC broadcasts a new one-and-half-minute story about climate change every day on more than 680 frequencies nationwide. YCC\u2019s listeners are not just located in liberal regions of the U.S.; in fact, two-thirds of its stations are located in congressional districts that voted for former president Donald Trump. YCC\u2019s stories feature the voices of Americans from all backgrounds\u2014racial justice activists, religious leaders, business owners, doctors, farmers\u2014communicating that climate change is harming Americans right here and now.\nCurrently, Leiserowitz is working to build a Global Center for Climate Change Communication at Yale to foster international research and public engagement, at a scale equal to the size of climate change itself.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/into-the-newsroom-the-yale-program-on-climate-change-communication/",
            "captions": [
                "YPCCC\u2019s founder and director, Anthony Leiserowitz."
            ]
        },
        {
            "title": "Cook Stoves and Pollution Mortality",
            "author": "Risha Chakraborty",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Poorer-Households-in-India-Final-Breanna-Brownson-500x290.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Breanna Brownson.\nNowhere is the diversity in the impacts of climate change more obvious than in India. There, great disparities in people\u2019s access to pollution-causing technologies ultimately culminate in stark differences in health and lifespan. Pollution is the single greatest environmental cause of premature mortality worldwide, but the proportion of Indian babies and moms dying from it vastly exceeds the global average.\u00a0\nWhile researchers have long studied the tie between emission origin and pollution spread, as well as the impacts of this pollution on human health, these disciplines had historically remained unconnected. The question of why families located in specific areas of India disproportionately felt the impacts of atmospheric pollution lingered.\u00a0\nTo correlate the hotspots of pollution-based premature mortality with proximity to emission-causing technologies in India, Narasimha Rao, an associate professor at the Yale School of the Environment, assembled a team of researchers from Yale and the International Institute for Applied Systems Analysis with different areas of expertise. Serving as climate justice advocates, they sought to understand the income-specific impacts of pollution and to propose policies to address these interconnected disparities in India.\nThe Integration of Models\nClimate change models have existed as long as climate data has been collected\u2014for nearly two centuries. The need for research correlating specific emissions to public health issues might seem obvious\u2014after all, while the causes of pollution inequity have gone uninvestigated, pollution\u2019s inequitable health impacts have been theorized for as long as we have known pollution to be detrimental to health. However, as Rao acknowledged, there has been a historical lack of research in this field. \u201cIn science, you can only ask the questions you can answer, and this fell through the cracks of intersection boundaries,\u201d Rao said.\nPrior to this study, Rao, as a footprinting climatologist, lacked the tools to link emissions to health markers, such as respiratory illnesses and premature mortality. Similarly, those working on the health impacts of emissions did not have the tools to understand the spatial distribution of atmospheric pollution according to location and consumption of fuels and technologies. While many climate researchers have thought about linking these two areas, the fact that separate tools are involved in creating each model meant there was previously no way to pursue the connection. Rao\u2019s novel insight was to devise an analytical framework where the results from the emissions contribution model would provide data to fuel the health and socioeconomic impacts model, and vice versa.\u00a0\nThe linked contribution and impact model Rao\u2019s team created was a culmination of many smaller models with different purposes, each exchanging information with the others. Rao worked on the aspect of the model that linked spatial distributions of \u201cpoint sources\u201d\u2014people and industries\u2014across a region to the emissions from that region. His team had a good understanding of point sources\u2019 emission generation patterns, including the usage of fuels involved in transportation, heating, or making food in cook stoves, and those that were indirectly wasteful, such as generating food waste and running electricity.\u00a0\nOnce his team localized emissions to these point sources, an atmospheric model was implemented to reflect realistic weather patterns, including air flows and temperature changes, and deduce the ultimate stabilized concentrations of pollutants. Finally, an impact model linked the pollutant concentrations to individual exposure and mortality, demarcated by age, sex, socioeconomic status, and proximity to urban centers.\u00a0\nThe impact model also mapped the socioeconomic characteristics of people and inferred their future energy demands; for example, rising disposable income could mean that individuals would buy more polluting technologies, such as new fridges or cars, or less polluting technologies, such as gas stoves instead of biomass stoves. These results would in turn provide feedback to the emissions model. Thus, the cyclical nature of the model pipeline ensured that both the emissions and health impacts could be modulated over time.\nNot only was the model predictive over time, but it was also highly generalizable across global regions. \u201cYou can change out the data, and you\u2019d represent a different part of the world,\u201d Rao said. Since the underlying algorithm remained the same, it was simply a matter of \u201cplugging in\u201d different data points\u2014adding or removing emission-causing technology contributions, changing the population distribution, changing the atmospheric characteristics\u2014and \u201cchugging\u201d to customize the model for any region.\u00a0\nThe team chose to look at India as the first application of the model because India has a mix of income levels and polluting technologies that makes the source and extent of pollution unclear. The model provided clear evidence for what might have been superficially obvious: poorer households in India disproportionately face the impacts of pollution. The pollution inequity is jarring\u2014in fact, the poorest decile of the population in the country faces a mortality risk that is nine times greater than that of the richest decile in the country.\u00a0\nMore importantly, the model highlighted the exact sources of pollution that were causing families of lower socioeconomic status to suffer premature mortality. The most lethal sources of pollutant emissions in India are biomass-burning cook stoves, which cause indoor air pollution and are primarily used by poorer, rural Indian families who cannot afford liquid petroleum gas stoves\u2014the typical choice for richer, urban-based families. According to Rao, pollution from cook stoves leads to nearly one million deaths of Indian babies and mothers every year.\u00a0\nMoreover, the ambient air pollution that is produced by public services such as transportation and electricity generation far exceeds any benefits these families receive from these services. While they do not consume electricity or use transportation to the same magnitude as richer families, poorer families face asymmetrically exaggerated mortality risks.\u00a0\u00a0\nThe Role of Government\nClimate researchers and public health officials alike have recognized that this grim narrative of inequity in pollution-attributed mortality cannot continue. What policies can be passed to address this disparity?\u00a0\nIn Rao\u2019s ideal world, addressing pollution in its totality and switching from pollution-causing fossil fuels to clean energy within the next ten years is imperative. \u201cBiomass cook stoves need to go away, since the health impacts of indoor air pollution completely dwarf the ambient air pollution,\u201d Rao said. However, poorer Indian households wouldn\u2019t be able to afford and reliably use clean fuels unless the government provided it to them.\nThe government has taken a necessary first step. \u201cIn the past decade, aggressive policies have provided a free stove and a free gas cylinder to fifty million households in India,\u201d Rao said. \u201cThe problem is, the fuel has continued to be expensive, so they haven\u2019t used those new stoves as much. It\u2019s just a governance failure: we need to make sure that the fuel is cheap.\u201d He acknowledged that some policies could cause market failures or require public investments. But since poorer people suffer most from the exorbitant price of clean fuels, the onus to provide cheap, clean fuel is on the government.\u00a0\nAccording to Rao, one of the more feasible solutions is to use targeted emissions policies, where the costs of emission are apportioned to the consumers of fuels. This would incentivize lower fuel usage and in turn decrease ambient air pollution.\u00a0\nThe proposals don\u2019t stop there. \u201cWe need to address food waste and garbage disposal in cities and areas that are affluent, where most of the consumption waste is coming from. We need to create the policy instruments for the costs to flow to the right people,\u201d Rao said. Such policies, along with governments ensuring that clean fuels are accessible to poorer households, could reduce exposure to air pollutants.\u00a0\nBy providing free stoves to a significant proportion of India\u2019s population, the Indian government has shown that it has the capacity to provide clean energy to poorer households. It also seems like it has the capacity to implement targeted emissions policies.\u00a0\nBut capability doesn\u2019t always translate to action. \u201cUnfortunately, the cliche is that there needs to be strong political support for it. There is a cost that has to be paid,\u201d Rao said. And according to him, that is not something that scientific research alone can repair. \u201cUnderstanding people\u2019s dependence on the fuels, the nature of the lack of reliability of the fuel supply, and the political economy of the fuel price setting and subsidies are essential,\u201d he said.\u00a0\nBecause of the results of the model, scientists now know the contributors and victims of pollution, both geographically and in terms of socioeconomic characteristics. For meaningful change to occur, governments and the public must also internalize these findings. Rao\u2019s current personal goal is to improve global understanding of how to diffuse clean fuels and sustainable energy technologies fast and wide. Accordingly, he joins the gamut of an increasing force of researchers, who by writing policy reports, publishing academic papers, and making data available to non-governmental organizations, are increasingly influencing governmental decisions.\u00a0\n\u201cI like to think of myself as an academic activist, as having the privilege of generating [scientific] insights,\u201d he said. \u201cI see it as an obligation on my part to make those insights available as broadly as possible.\u201d\u00a0\nClearly, \u201csolving climate change\u201d or \u201cfixing pollution\u201d is much easier said than done. Even though the technology to reduce emissions exists, its equitable implementation remains a challenge. Nevertheless, Rao and his team shed some much-needed light on the social ramifications of pollution inequity and mortality. Their work points to targeted emissions policies and biomass cook stove replacement policies as necessary, even inevitable, solutions.\u00a0\nAs scientists and climatologists continue to embrace their roles as policy influencers and activists, governmental inaction will no longer remain an option. In this way, Rao\u2019s ideal world\u2014one in which pollution inequity is vanquished\u2014just might become a reality.\nFurther Reading:\nRao, N. D., Kiesewetter, G., Min, J., Pachauri, S., Wagner, F. (2021). Household contributions to and impacts from air pollution in India. Nature Sustainability, 4(10), 859\u2013867.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/cook-stoves-and-pollution-mortality/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Temperature Toll",
            "author": "Anna Calame",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Extreme-Temperatures-Could-Affect-Mental-Health-Noora-Said-427x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Noora Said.\nToday, climate change is not only at our doorstep\u2014it\u2019s in our living rooms, on our kitchen tables, and even in our pockets, through near-constant coverage on television news, newspapers, and social media. Climate stories are often accompanied by aggressive images: wind- and rain-battered palms, neighborhoods swallowed up by churning floodwaters, forests consumed by flames, disturbingly vibrant thermal maps.\u00a0\nWhile these photographs impactfully illustrate the physical devastation wrought by extreme weather, recent research suggests they may fail to capture a less visible but key consequence of climate change: its impact on mental health. Studies conducted by Eun-hye Yoo, associate professor of geography at SUNY Buffalo, and Kai Chen, assistant professor of epidemiology at the Yale School of Public Health, identified a possible link between extreme temperatures and increased mental health-related emergency room (ER) visits. Such an association, though still subject to further research, may have meaningful implications for how we think about climate change.\u00a0\nA Gap in the Literature\nWhile climate research has increased significantly over the past two decades, not all ramifications of the impending crisis have been investigated equally. Yoo and Chen are seeking to address a consequential gap in the literature: the effect of extreme temperature, both hot and cold, on mental disorders. To that end, they co-authored two studies with other collaborators on potential associations between extreme temperature events and ER visits for mental health reasons in New York State. While the first study examined a wider array of mental disorders, the second study investigated specific conditions, such as anxiety disorders, mood disorders, substance abuse, and dementia, as reasons for ER visits.\u00a0\nThough prior studies suggesting probable links between heat and negative mental health outcomes have been conducted, the field remains relatively sparse in comparison to the larger body of climate research. To account for this, Yoo points to the fact that psychologists are primarily interested in analyzing individual behaviors, while epidemiologists engage almost exclusively with population-level data. As a result, overlap between research in environmental epidemiology and mental disorders is relatively rare.\u00a0\nFor their part, these two researchers come to the field from different backgrounds\u2014Chen, an environmental health epidemiologist, has long harbored an interest in the health implications of climate change, while Yoo\u2019s area of expertise is geographic information science and spatial statistics. Nevertheless, they share a deep concern for this under-investigated correlation, and the two enjoy an amiable relationship, each quick to credit the other for their unique contributions to the study.\u00a0\nExploring the Effects of Extreme Temperature\nTo investigate the relationship between exposure to extreme temperature and risk of increased ER visits, the researchers employed a time-series analysis. Time-series models, a common type of statistical analysis, use a series of data points collected at fixed time intervals to make a prediction or estimate an association. In Yoo and Chen\u2019s studies, the model consisted of two time series\u2014temperature and ER visits\u2014which both varied daily. \u201cWhat we do in this model is try to find an association between these two time-series,\u201d Chen said. \u201cBut in the meantime, there are a lot of other things going on that may influence this relationship, so we need to use our model to control them.\u201d\nData on daily ER visits for mental health disorders were collected from the New York State Department of Health and compared to climate and air pollution data obtained from the National Center for Environmental Information Climate Data Online System. The ER records, dating from January 2009 to December 2016, included demographic information like race, age, and sex, as well as the primary diagnosis code, which the researchers used to identify mental disorders in ER patients. Daily precipitation and minimum, average, and maximum temperatures were examined as part of the temperature time-series. Separate time-series analyses were conducted in ten labor market regions in New York State, and a meta-analysis was performed to pool the result for the whole state.\u00a0\nNotably, the model was designed to consider any delayed effects on mental health caused by temperature exposure. While a lag period of seven days was used to identify short-term exposure effects on increased ER visits, their analysis also evaluated this exposure-response relationship for a longer period of twenty-one days.\u00a0\nClimate Consequences for Mental Health\nThe first study, which focused solely on Erie and Niagara counties, indicated a strong positive association between maximum temperature and increased ER visits for mental illness. Significant risk was observed at temperatures above twenty-nine degrees Celsius and below eight degrees Celsius. Across all lag periods, heat effect was found to elevate one\u2019s risk of visiting an ER for mental illness. For maximum daily temperatures under eight degrees Celsius, the researchers observed a delay of zero to fourteen days between exposure to extreme cold temperatures and increased ER visit risk. In other words, the cold effect on ER visits was not always evident until up to fourteen days after exposure to temperatures below eight degrees Celsius. However, neither precipitation nor air pollution were found by this study to alter the observed temperature-mental illness relationship.\nThough the first study suggested that extreme temperatures may induce adverse mental health effects for people of all ages and races, it also indicated a disproportionate effect for certain subpopulations. Youth and elderly populations, defined as ages zero to nineteen and over sixty-four, respectively, seemed more susceptible to heat effects. Additionally, the model suggested greater risk of ER visits for African Americans ages fifty to sixty-four exposed to intense heat as compared to other racial groups in the same age category. Some posit that the observed vulnerability of African Americans, the elderly, and young people to extreme temperatures may reflect disparities in access to healthcare, housing, and technology on a larger, societal scale.\u00a0\nTo examine how differences in geography, climate, and population impacted exposure-response relationships, the researchers expanded the study to include ten different labor regions in New York State. Unlike in the first study, they did not find short-term exposure to extreme cold to be associated with increased ER visits for any mental disorder. However, the findings did suggest a positive association between maximum daily temperatures above 27.07 degrees Celsius and elevated risk for ER visits. Diverging from the findings of the first study, no racial group or age cohort was observed to be more vulnerable to the effects of heat than any other group.\u00a0\nThe varying results between northwestern New York counties and New York State as a whole suggest that the results of any particular analysis are subject to geographic and climatic limitations and that further expansion of the study is required to make more generalizable conclusions. Foremost, both studies support the researchers\u2019 hypothesis that extreme temperatures increase one\u2019s risk for visiting the ER for mental health reasons.\u00a0\nNew Possibilities for Public Health\nMeasures currently in place to protect the public from the effects of severe weather include radio warnings of impending extreme temperatures, required heating systems in New York housing, and publicly available cooling and heating centers in urban areas. Unfortunately, such efforts often fail to meet the needs of the most vulnerable populations. Cooling and heating centers are rarely adequate in number or capacity in low-income, under-resourced neighborhoods, the very areas where they are needed most. Additionally, unlike heating systems, air conditioning in housing is not necessitated under New York law. This places an additional financial burden on tenants and, in many cases, effectively removes their access to such systems altogether.\nChen cautioned that while improving existing measures is necessary, as they provide immediate support to vulnerable groups, adaptive actions like air conditioning are ultimately \u201cdouble-edged swords.\u201d Air conditioning increases energy demand and emissions, thus exacerbating climate change. Chen and Yoo pointed instead to research suggesting that the cultivation of green spaces in so-called \u201cheat islands,\u201d urban areas that retain high levels of heat, can reduce temperatures naturally. By adding green spaces, communities can promote better mental and physical health without compromising the environment.\u00a0\nUltimately, however, most climate research indicates that effective prevention of climate change will require efforts on a much larger, societal scale, including the commitment of governments and corporations to achieve net zero emissions.\u00a0\nAn Expansive Research Landscape\nYoo and Chen know that their work is far from done. For all the questions this study answers, it raises just as many new ones. Both highlighted the need for future research to intimately involve psychologists. \u201cWhile we were working on this study, I had a lot of conversations with psychologists,\u201d Yoo said. \u201cWe have a lot of interesting hypotheses that need to be verified, but in some cases, this is hard to do with population data\u2026 We need to combine population-level studies with cohort studies.\u201d\u00a0\nYoo emphasized that future studies should investigate new or more diverse populations in different climatic regions to better understand the variation observed between the county- and state-level studies as well as discrepancies in outcomes between subgroups.\nChen expressed particular interest in further exploring how and why short-term exposure to extreme temperatures can exacerbate more long-lasting, chronic conditions. \u201cThat\u2019s something we don\u2019t know much about,\u201d Chen said. \u201cThere must be something, through biological or societal mechanisms, that can explain how temperature [has this effect]. This is paving the way for more research on this topic.\u201d\nAs climate change accelerates, it seems that the urgency of Yoo and Chen\u2019s research will only become more apparent. Without a proper understanding of how extreme temperature events might increase potential for severe mental health episodes, we cannot be adequately prepared for the full range of climate consequences. After all, as the oft-repeated climate activism saying goes, the climate is changing\u2014why aren\u2019t we?\nFurther Reading\nYoo, E. H., Eum, Y., Gao, Q., &; Chen, K. (2021). Effect of extreme temperatures on daily emergency room visits for mental disorders. Environmental Science and Pollution Research, 1-14.\u00a0\nYoo, E. H., Eum, Y., Roberts, J. E., Gao, Q., &; Chen, K. (2021). Association between extreme temperatures and emergency room visits related to mental disorders: A multi-region time-series study in New York, USA. Science of The Total Environment, 148246.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/the-temperature-toll/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The New Rumplestiltskin: Spinning Wood into Plastic",
            "author": "Lucas Loman",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Using_wood_type2-Kat-Moon-500x348.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Kat Moon.\nAvocado seeds, lobster shells, fish scales, red algae, cactus leaves\u2026 and now, wood. What do these items have in common? As it turns out, researchers around the world have turned to all these unexpected materials to develop biodegradable alternatives to plastic.\nPetrochemical plastics are plastics derived from crude oil and natural gas. Such nonrenewable resource-based plastics have pervaded modern life\u2014they can be found everywhere, from fertilizers to packaging to clothing, and are cemented as an integral part of society. According to the International Energy Agency, petrochemical feedstock now accounts for twelve percent of oil demand around the world. But it is not the quantity alone that renders plastic a global issue\u2014instead, it is the lack of biodegradability.\u00a0\nA potential solution may lie in bioplastics, alternative materials that use different biomass feedstock to create bio-based plastics that are biodegradable. A breakthrough study on the creation of bioplastic from natural wood was recently published in Nature Sustainability, co-authored by Yuan Yao, assistant professor of industrial ecology and sustainable systems at the Yale School of the Environment (YSE), and Liangbing Hu, a professor at the Center for Materials Innovation at the University of Maryland.\nThe quest for a biodegradable plastic to combat the billions of metric tons of plastics accumulating in the environment has led to the creation of these bioplastics. Currently, petrochemical plastics last for hundreds to thousands of years due to the stable long polymer chains they contain, such as those found in polyethylene, polystyrene, and polyvinyl chloride-based plastics. Because previous efforts to produce bioplastics have been associated with the use of toxic chemicals, weak mechanical strength, and poor water stability, researchers started to wonder: how could a balance between degradability and durability be achieved?\nIn this study, the research team reports a method of fabricating lignocellulosic bioplastic that not only demonstrated recyclability and biodegradability, but also dramatically improved durability. \u201cThere are many people who have tried to develop these kinds of polymers in plastic, but the mechanical strands are not good enough to replace the plastics we currently use, which are made mostly from fossil fuels,\u201d Yao said in a Yale School of the Environment News article. Overall, their bioplastic showcases high mechanical strength as well as improved water and thermal stability.\nBuilding Better Bioplastic\nTo create bioplastics, researchers typically extract lignin and cellulose, two organic polymers responsible for plant structure, from wood. The team performed a process called in situ lignin regeneration, whereby instead of isolating lignin and cellulose, they homogenized wood powder, or made it uniform, to form a high-density, viscous slurry.\u00a0\nNext, deep eutectic solvent (DES)\u2014a group of biodegradable and recyclable substances\u2014was used to dissolve lignin and break apart the hydrogen bonds between cellulose fibers. Water was then added to the slurry for lignin regeneration from the DES. Finally, the DES was removed from the mixture through a filtration and washing process, leaving behind a stable cellulose-lignin material. Through a simple casting process, the team fabricated bioplastic films.\u00a0\nIn sharp contrast to cellulose film, lignocellulosic bioplastic was found to be considerably more resistant to water damage. The researchers demonstrated that it absorbed water at a much slower rate than standard cellulose film. As a result, lignocellulosic bioplastic samples maintained their shape well past thirty days of being submerged in water, far beyond the point at which cellulose film degraded.\nWhile the durability of lignocellulosic bioplastic is critical for its large-scale use, the most important characteristic of this new bioplastic was its ability to break down under the right conditions. When the researchers subjected it to an outdoor environment, they found that exposure to sun, wind, and rain was enough to completely break it down within five months. For comparison, PVC\u2014a commonly-used synthetic plastic\u2014subjected to identical conditions remained unchanged. \u201cThat [characteristic] is what really makes this plastic good: it can all be recycled or biodegraded,\u201d Yao told the Yale School of the Environment News. \u201cWe\u2019ve minimized all of the materials and the waste going into nature.\u201d\nThe more sustainable production process of lignocellulosic bioplastic, in addition to the material\u2019s impressive physical properties, makes it a promising replacement for less environmentally friendly petrochemical plastics. This bioplastic follows a closed-loop cycle in which microorganisms in soil can naturally degrade the material. Typical plastics take hundreds of years to decompose in nature, filling up landfills and potentially leaching toxic chemicals into groundwater; in contrast, this type of bioplastic breaks down far more quickly and poses less risk to communities and nature in the process. The lignocellulosic bioplastic can also be recycled.\nBarbara Reck, a senior research scientist at the Yale School of the Environment, characterized the project\u2019s findings as an impressive innovation. \u201cA bioplastic is fully degradable under regular outdoor conditions, offering an opportunity to reduce putting a much-needed end to the accumulation of at least some plastics in the natural environment,\u201d she said.\nThe Future of Bioplastics\nThe environmentally friendly, closed-loop cycle used to create this bioplastic signals hope for a future where strong, biodegradable bioplastics can be produced from resource-abundant, sustainable, and renewable biomass.\u00a0\u00a0\nHu told the Yale School of the Environment News that the malleability of this bioplastic will allow for several applications. From being molded into a film for use in plastic bags to being shaped for use in automobile manufacturing, this bioplastic may help solve our society\u2019s current dependence on plastic.\u00a0\nBecause this lignocellulosic bioplastic is made of biomass feedstock, its production would entail the use of local materials rather than nonrenewable fossil fuels, which would further mitigate environmental damage. \u201cIt is very promising to see the flexibility in the biomass feedstocks used for this process,\u201d Reck said. \u201cOne can imagine a decentralized production network that uses predominantly local materials, which in turn would keep the overall environmental impacts [of the lignocellulosic bioplastics] rather low.\u201d\nYao\u2019s team\u2019s work on using wood as a substitute for plastic presents significant substitution potential for petroleum derived plastics. Mark Ashton, Morris K. Jesup Professor of Silviculture and Forest Ecology and the Director of the Yale Forests, further emphasized the benefits of using bioplastic over petrochemical plastics. \u201c[Bioplastic usage can] mov[e] a product that has a large environmental impact because of its persistence to one that might potentially be relatively benign,\u201d Ashton said.\nIn determining a sustainable production network, the team has continued to research how scaling up manufacturing for this bioplastic could impact forests. The issue with using wood byproducts is that large-scale production may require massive amounts of wood, which could negatively impact forests and local ecosystems.\nAccording to Yao, the research team is responding to this potential issue by working with a forest ecologist to build forest simulation models, which could elucidate the connection between the growth cycle of forests to the manufacturing process of this bioplastic. Such advances in the processability and functionality of wood could motivate better forest management practices in addition to realizing the lower environmental impact of using wood as a sustainable material.\nConsidering our far-reaching reliance on plastic in society, the discovery of a biodegradable, durable bio-based plastic is worth its weight in gold. In this way, the researchers are like Rumpelstiltskin\u2014spinning something valuable out of a natural material in ways we never thought possible.\nFurther reading:\nAnusewicz, J. (25 March 2021). Turning Wood Into Plastic. Yale School of the Environment News. https://environment.yale.edu/news/article/turning-wood-into-plastic\u00a0\nXia, Q., Chen, C., Yao, Y., Li, J., He, S., Zhou, Y., \u2026 & Hu, L. (2021). A strong, biodegradable and recyclable lignocellulosic bioplastic. Nature Sustainability, 1-9.\nXiao, S., Chen, C., Xia, Q., Liu, Y., Yao, Y., Chen, Q., Hartsfield, M., Brozena, A., Tu, K., Eichhorn, S. J., Yao, Y., Li, J., Gan, W., Shi, S. Q., Yang, V. W., Lo Ricco, M., Zhu, J. Y., Burgert, I., Luo, A., \u2026 Hu, L. (2021). Lightweight, strong, moldable wood via cell wall engineering as a sustainable structural material. Science, 374(6566), 465\u2013471.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/the-new-rumplestiltskin-spinning-wood-into-plastic/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Greta Thunberg Effect",
            "author": "Hannah Huang",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/The_Greta_Thunberg_Effect-Ann-Marie-Abunyewa-500x349.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Ann-Marie Abunyewa.\nZooming with me from across the pond in London, Anandita Sabherwal, a PhD student at the London School of Economics, explained how she arrived at the topic of her latest publication in the Journal of Applied Social Psychology.\u00a0\n\u201cI was very interested in the idea of social identity and social reference, and who acts as a social reference when it comes to climate activism,\u201d she said.\u00a0\nSabherwal had been sitting in her adviser\u2019s office, bouncing research ideas around with him. Together, they came to the realization that they should study the effect that Greta Thunberg has had on climate activism. That idea, coupled with a collaboration with the Yale Program on Climate Change Communication (YPCCC), led to their recent paper, \u201cThe Greta Thunberg Effect: Familiarity with Greta Thunberg predicts intentions to engage in climate activism in the United States.\u201d\u00a0\nThunberg, a teenage activist from Sweden, has inspired countless people of all ages from across the globe to both care about and act against climate change. Sabherwal and her colleagues wanted to know what makes a young, seemingly ordinary teenager so influential in convincing people to partake in collective actions like contacting government representatives, donating time and money, and attending strikes and protests\u2014actions that help a larger group and not just themselves.\u00a0\nLiving, Learning, and Collaborating Across Continents\nSabherwal\u2019s interest in studying how people react to communication about climate change is driven by the many places she\u2019s lived in. Born and raised in India, she saw how the water shortage crisis forced women to walk ever-farther distances to get water, even driving some farmers to suicide. While studying at Yale-NUS College in Singapore, she participated in a study abroad program at Pomona College, where she was surprised by how highly politicized climate change is in the US\u2014a characteristic that she thinks is more exaggerated here than anywhere else she\u2019s lived. \u201cDifferent political groups don\u2019t even agree on whether climate change is worth discussing as a problem or looking for solutions for, and that blew my mind,\u201d she said.\u00a0\nNow a new PhD student at the London School of Economics, she has observed that although people in the UK want to act, there is an intention-action gap. \u201cPeople want to do something, but they also don\u2019t want to sacrifice a lot of their privileges and ways of life to get to that point,\u201d she said.\nFrom India to Singapore to the US to the UK, she has seen and studied first-hand how countries differ in how they are affected by and deal with climate change. \u201cI realized that this would be an amazing thing to study because socially and psychologically, there is a lot to unpack here,\u201d she said. \u201cWhy do different groups react so differently to the same information? How do they adapt differently based on their social status and class? What impacts do they face?\u201d\nSabherwal and her colleagues sought to establish whether increased exposure to Thunberg was predictive of increased motivation to participate in collective action against climate change. They also wondered if collective efficacy\u2014the idea that working as a group can bring about the accomplishment of specific goals\u2014was behind this effect.\u00a0\nThe UK researchers first attempted to study the Greta Thunberg Effect in a sample of adults drawn heavily from the East and West Coasts of the US; however, their efforts were foiled by how well people already knew Thunberg. \u201cPeople were already so exposed to her that when we did an experiment exposing people to Greta, it had no effect,\u201d Sabherwal said. \u201cEveryone in our control group knew Greta just as equally. People were much more aware of Greta and much less polarized on her than was nationally representative.\u201d Then, an encounter with a former labmate from Sabherwal\u2019s time at Pomona led to the opportunity to collaborate with the YPCCC.\u00a0\nYPCCC conducts annual surveys on the US population and, fortunately, had data that were more representative of people\u2019s opinions on climate change and Thunberg. YPCCC\u2019s data solved the problem that UK researchers had run into earlier. Moreover, because of how politicized climate change is in the US, there was a wide range of opinions on climate change, which made the US data an interesting sample on which to test the researchers\u2019 hypotheses.\u00a0\nWhat is So Special About Thunberg?\nIn the study, after participants were asked how familiar they were with Thunberg, they were also asked questions measuring their belief in collective efficacy (how likely was it that a group of ordinary citizens, working together, could affect the actions of government or businesses) and questions measuring their intent to engage in collective actions (how likely the individual was to vote for a candidate, attend a rally, listen to a speech, etc.).\u00a0\nAs expected, they found that familiarity with Thunberg induces people\u2019s sense of efficacy: they feel like if they work along with others, they can make an impact. This is because Thunberg has modeled both collective action\u2014leading and supporting climate strikes, for example\u2014and worldwide impact, such as speaking at high-profile events like United Nations conferences.\u00a0\nSurprisingly, there was no difference in the Greta Thunberg Effect across age groups. The researchers had hypothesized that her impact would be more apparent in younger people, but they were glad to see that she impacted all age groups similarly.\u00a0\nWhat also stood out about Thunberg was her appeal across the political spectrum in the US. \u201cGenerally, if a leader appeals to one political segment, they backfire with the other political segment. It\u2019s not that the effect is just lowered. It backfires,\u201d Sabherwal said. \u201cBut we found that Greta was also appealing to conservatives, even if to a lesser extent compared to liberals.\u201d In light of these findings, she posits that Thunberg\u2019s emphasis on intergenerational justice and her lack of clear alignment to a specific political party underlie her success.\u00a0\nFinally, to Sabherwal, Thunberg\u2019s humility and relatability allow her to connect with the general public. Leaders are typically elite in some way, whether it be in educational background, power, or wealth. Academic experts, government leaders, and wealthy people are examples of the types of elite leaders that abound in the arena of climate change activism. Elite leaders, however, can alienate people in the general population for the exact reasons they are conspicuous in the first place. \u201cSure, Jeff Bezos can donate twenty million dollars to climate change research. I can\u2019t do that,\u201d Sabherwal said. \u201cBut by always conveying that she\u2019s just like us, Greta has been able to be a leader that we can look up to and say, \u2018If Greta can do it, we can do it too.\u2019\u201d\nFighting Anxiety with Action\nAs a researcher whose entire day is spent focusing on climate change and seeing how reluctant people are to change their behavior, thinking about the future can be anxiety-inducing, Sabherwal admitted. But when a person like Thunberg says there is still time to change, it gives her great solace. \u201cGreta inspired me to take care of my anxiety by taking action, by doing something about it, which I think is a message she consistently gives,\u201d Sabherwal said. \u201cBecause unless you act, it\u2019s very easy to get overwhelmed by the state of climate change right now.\u201d\u00a0\nSabherwal believes in Thunberg\u2019s unique power. \u201cMost of us will change because we know that the social norm has changed. But there are a few individuals that will change the social norm, and that\u2019s how societies change,\u201d Sabherwal said. As her recent study reveals, the Greta Thunberg Effect is real and impactful. Hopefully, it will continue to change people\u2019s minds, their actions, and our society for the better because\u2014to use one of Thunberg\u2019s trademark phrases\u2014our house is on fire, and we\u2019re running out of time to save it.\nExtra Reading:\nSabherwal, A., Ballew, M. T., Linden, S., Gustafson, A., Goldberg, M. H., Maibach, E. W., Kotcher, J. E., Swim, J. K., Rosenthal, S. A., & Leiserowitz, A. (2021). The Greta Thunberg effect: Familiarity with Greta Thunberg predicts intentions to engage in climate activism in the United States. Journal of Applied Social Psychology, 51(4), 321\u2013333.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/the-greta-thunberg-effect/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Making Buildings More Energy-Efficient Could Save Lives\ufffc",
            "author": "Bella Xiong",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Energy-Efficient-Building-Cathleen-Liang-500x357.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Cathleen Liang.\nEven before the pandemic, people spent about ninety percent of their time indoors. Given how many hours we spend in these spaces, it is important to think about how changes in building design or operation impact indoor air quality.\nThe burning of fossil fuels contributes to global warming by accumulating large quantities of carbon dioxide and particulate matter smaller than 2.5 microns in the atmosphere. The latter is a pollutant with one of the largest health effects\u2014despite its minuscule size, it can both cause and exacerbate cardiovascular diseases, respiratory diseases, and cancer.\u00a0\nWhile many factors contribute to emissions of carbon dioxide and particulate matter\u2014wildfires and cars, for example\u2014a major source of air pollution originates from buildings and building-related operations. According to the US Energy Information Administration, residential and commercial buildings consume forty percent of all energy in the US. This issue makes buildings an important target for measures that increase energy efficiency and reduce carbon dioxide and pollution emissions.\u00a0\nDrew Gentner, Yale professor of Chemical & Environmental Engineering, and Kenneth Gillingham, professor of Economics, along with their colleagues from Yale\u2019s Solutions for Energy, Air, Climate & Health Center, embarked on a necessary interdisciplinary investigation. In their new study, published in Science Advances in August, the researchers used the Yale-NEMS (National Energy Modeling System) model, which models the effects of various building energy efficiency scenarios they designed based on literature. Leveraging their perspectives on the dynamics of air pollution in indoor and outdoor spaces, they investigated scenarios that could impact carbon dioxide emissions associated with energy use and energy-related emissions of outdoor pollutants.\u00a0\nThe project was motivated by the desire to both improve human health and help us tackle climate change. \u201cIt is not a new issue, and we have known for a long time how important it is, but quantifying the effects of strategies to address climate change is more relevant now than ever,\u201d Gillingham said.\nEnergy Efficiency Scenarios\nGentner and Gillingham\u2019s study evaluated how energy efficiency measures could improve building tightness, a measure of outward and inward air leakage in buildings. These energy efficiency measures included changes to infiltration, natural ventilation, and heat, ventilation, and air conditioning (HVAC) recirculation adoption. The researchers\u2019 goal was to explore ways to reduce energy losses associated with air leakage from indoors to outdoors, and vice versa.\u00a0\nTo do so, they created two scenarios: \u201cIntermediate EE\u201d and \u201cOptimistic EE.\u201d The \u201cIntermediate EE\u201d scenario provides close to twenty percent increased efficiency on all building appliances and equipment. In this scenario, the annual efficiency improvement from better building shells\u2014which separate the building\u2019s interior spaces from its exterior spaces\u2014can achieve cumulative improvements of more than fifty percent. The \u201cOptimistic EE\u201d scenario is a more idealistic model, allowing for fifty percent increased efficiency in appliances and equipment, along with more than sixty percent of cumulative annual efficiency improvement from increasing the quality of building shells.\nThese two scenarios are based on possible future energy efficiency improvements for building services and shell structure materials. Shell structure materials are used to secure the building composition by transmitting applied forces on the surface. The energy efficiency improvements address space heating and cooling, water heating, lighting, refrigeration, and culinary services for residential and commercial facilities. They also address building shell efficiency improvements in the residential, commercial, and industrial sectors for both existing and new structures.\u00a0\nAnother focus was improving recirculation with filtration, which can help mitigate indoor concentrations of particulate matter. Considering how energy efficiency is greatly related to the emission of energy production-related pollutants, these two scenarios also provide estimates for how many premature deaths in the United States would be avoided in each case.\nUsing the outputs of the Yale-NEMS model, along with the building energy efficiency scenarios, the researchers evaluated how concentrations of particulate matter could change indoors as a function of building tightness. The study examined how the two building energy efficiency scenarios would impact air quality across the entire US housing stock.\nThe researchers explored the interconnectivity of outdoor and indoor air quality by looking at the changes in infiltration while also considering the variations in indoor emissions across houses in the US. These emissions are closely related to cooking activities, and the resulting concentrations are impacted by the presence of particle filtration\u2014which, in turn, is related to building HVAC systems.\u00a0\nCompared to the reference case of the energy efficiency scenarios, the Yale-NEMS model predicted that decreasing energy-consuming activities could improve general outdoor air quality. On a larger scale, it also shows that indoor air quality related to building energy efficiency improvements depend largely on indoor emissions and home design characteristics. According to the research team\u2019s findings and interpretation, by 2050, both efficiency scenarios could yield a six to eleven percent reduction in energy-related carbon dioxide emissions and an eighteen to twenty-five percent reduction in the main particulate matter emissions. Ultimately, following the energy-saving scenarios could reduce outdoor emissions, potentially saving 3,700 to 7,800 lives per year in the United States by 2050.\u00a0\nA Call to Action\nUnfortunately, the study\u2019s findings also show that energy efficiency improvements could negatively impact indoor air quality in some homes. Due to lower air exchange rates, infiltration caused by tightening the building shell for energy efficiency gains might result in greater exposure to indoor contaminants in some buildings. The observed changes in indoor air quality show that it is essential to increase awareness of indoor particulate matter emissions. Because of this, indoor air filtration improvements should also accompany energy efficiency improvements. This might be especially significant for low-income housing, which tends to have inadequate indoor air filtration due to the usage of more health-damaging materials.\u00a0\nStill, even after accounting for changes in indoor air quality, the thousands of premature deaths that could be avoided by improving the energy efficiency of buildings should not be neglected.\nOverall, estimates of public health improvements reveal the urgency of reducing the outdoor air or outdoor pollutant emissions associated with energy use. \u201cAttention to ventilation strategies, indoor emissions, and investments in interior air recirculation systems with filtration, such as better-performing filters in HVAC systems, require careful consideration from a policy standpoint and can help to minimize potential negative effects on indoor air quality,\u201d said Gentner. This could help to improve indoor air quality even further, preventing even more premature deaths.\u00a0\nMaking buildings more energy-efficient can help us move toward a more environmentally safe future. Going forward, individuals also have an opportunity to consider how personal housing choices can affect air pollution. By choosing a more environmentally sustainable option of housing, for example, thousands of premature deaths may be avoided each year. \u201cThis study provides guidance to policymakers who are trying to understand what it would mean to have intensive energy efficiency improvements. It tells us what the benefits could be, but also what additional efforts are needed to achieve the benefits,\u201d said Gillingham.\u00a0\nTo address climate change, we must pay close attention to the impacts of air pollution. This requires considering emissions from a variety of sources. Whether it is through improving building efficiency, reducing air pollution emissions, or changing personal choices, each of us has a role to play. A tremendous amount of work remains to be done, but scientists like Gentner and Gillingham are using what they know to combat climate change by initiating conversations that could lead to policy changes.\nWorks Cited\nK. T. Gillington., P. Huang., C. Buehler., J. Peccia., , D. R. Gentner. (2021, August 20). The climate and health benefits from Intensive Building Energy Efficiency Improvements. Science Advances. Retrieved November 6, 2021, from https://www.science.org/doi/10.1126/sciadv.abg0947.\nXing, Y.-F., Xu, Y.-H., Shi, M.-H., & Lian, Y.-X. (2016, January). The impact of PM2.5 on the human respiratory system. Journal of thoracic disease. Retrieved November 6, 2021, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4740125/.\n\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/making-buildings-more-energy-efficient-could-save-lives%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: EVST 219: Philosophical Environmental Ethics",
            "author": "Lucy Gilchrist",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/gilchrist-hands-1-500x235.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Stephen Latham, JD, PhD, stumbled upon bioethics by happenstance in his first job after law school. Now the director of Yale\u2019s Interdisciplinary Center for Bioethics, Latham is perhaps best known for his popular spring-term course, Bioethics and Law. His new course this fall, Philosophical Environmental Ethics, focuses on the philosophical questions relevant to the climate crisis.\nFirst, Latham wants his students to understand the broad contours of the field since the 1970s. \u201cAt that point, environmentalism was a fight against dumping stuff into the water, or releasing stuff into the air,\u201d Latham said. Early environmental activists weren\u2019t yet aware of\u00a0greenhouse gases as a harbinger of climate change. They decentralized human affairs in their discourse, focusing their concerns on animals and ecosystems. Latham explained that the increasing visibility of the climate crisis in the public and scientific imagination has shifted discussion back toward humans. \u201cToday, under pressure from the urgency of the need to do things about the climate, people are thinking about how we can save the climate for ourselves,\u201d Latham said.\nCurrently, most environmental discussions center on the extractive value of the environment. \u201cPhilosophical environmental ethics raises slightly more technical questions about how to value nature in itself,\u201d Latham said. For example, the \u201cnonidentity problem\u201d considers the responsibilities we have to future generations who will only exist because of present-day choices about climate change. \u201cIf we don\u2019t do anything about climate change, people fifty years from now would be looking back on us and saying, \u2018You left us this horrible planet,\u2019\u2026 but you could point out to them that they only exist because we didn\u2019t do anything about climate change,\u201d Latham said. Our current actions\u2014or inactions\u2014will decide who will be left to reckon with the climate crisis in future years.\nTopics in his course seem to beg for political action, and Latham hopes his students will respond to the impulse. \u201cI want people out there protesting against more extraction of fossil fuels and in favor of renewable energy and carbon capture and so on,\u201d Latham said. However, he also realizes that the ability to protest against climate change often comes from a place of privilege. \u201cIt\u2019s hard to say to someone who\u2019s just getting by, \u2018You have a moral obligation to be thinking about climate change,\u2019\u201d Latham said.\u00a0\nBut the target of Latham\u2019s instruction are Yale students\u2014privileged by their education\u2014who he hopes will leave his course equipped with the tools to address climate change in their activism, careers, and personal lives. \u201cI\u2019m arming them with arguments that they might be able to use in the future, whether it\u2019s to a city council or to their intransigent uncle over Thanksgiving dinner,\u201d Latham said.\u00a0\nTrained as a lawyer and a scholar, Latham recognizes that the philosophical perspective he can provide on environmental issues is only one piece of the puzzle. Nevertheless, the ability to reason and write about our ethical responsibility to mend the environment can help his students contribute to political and scientific action.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/science-in-the-spotlight-evst-219-philosophical-environmental-ethics/",
            "captions": [
                "Philosophical environmental ethics considers our generation's responsibilities to the future inheritors of the planet. Our current actions\u2014or inactions\u2014will decide who will be left to reckon with the climate crisis in future years. Image courtesy of Pixabay."
            ]
        },
        {
            "title": "Mirror Mirror On the Wall\u2026 Is One Mirror Image Better Than Us All?",
            "author": "Sherry Wang",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/chemists-500x416.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "The chemistry of molecule-making is quite particular: sometimes, a reaction produces two mirrored versions of a molecule, but only one remains sufficient for a given application.\u00a0 In processes such as drug development, using the wrong mirror image can have devastating biological effects. Some catalysts can speed up a chemical reaction while producing one mirror version preferentially over the other. Historically, these catalysts have been made with toxic metals. But the 2021 Nobel Prize in Chemistry was awarded to two scientists\u2014Benjamin List of the Max-Planck Institute for Coal Research and David MacMillan of Princeton University\u2014 who developed organic catalysts that are mirror image-selective, helping to make reactions more environmentally friendly.\nList discovered that the amino acid proline could replace the function of metal catalysts while producing the more favored mirrored version of a molecule. At the same time, MacMillan designed small organic molecules that, like proline, had catalytic functions and could generate one mirrored version of a molecular product over the other. MacMillan officially coined the term for this process: \u201casymmetric organocatalysis.\u201d\nThis method of catalysis is eco-friendly: it decreases the need to use toxic metals as catalysts and also decreases the time of reaction. Approximately thirty-five percent of the world\u2019s gross domestic product depends on catalysis, so the creation of a more efficient and environmentally sustainable tool has major benefits. Production of the preferred mirrored version through organocatalysis has revolutionized the field of chemistry, one reaction at a time.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/mirror-mirror-on-the-wall-is-one-mirror-image-better-than-us-all/",
            "captions": [
                "Benjamin List and David MacMillan, winners of the 2021 Nobel Prize in Chemistry for the discovery of asymmetric organocatalysis. Image Courtesy of News Europa."
            ]
        },
        {
            "title": "Undergraduate Profile Elea Hewitt (\u201922): Insights from a Year of Farming",
            "author": "Sophia David",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/FIgure-5-1-375x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Senior Elea Hewitt described herself during her gap year as the happiest she had been in years. Returning to Yale from a year spent on her family\u2019s Oregon ranch, she has fascinating perspectives on the intersection between farming and agriculture, social justice, and sustainable environmental practices.\u00a0\nHewitt grew up in rural Oregon in the Willamette Valley on her family\u2019s farm. Homeschooled until high school, Hewitt looks back fondly on her primary education. She was taught by her mother and given freedom to let her interests guide her learning, which often took place outside. Now an Environmental Studies major at Yale, Hewitt has observed the continued relevance of things she learned early on. For example, she was already familiar with some of the concepts in her Economics of Natural Resources class because of experiences in her early childhood.\u00a0\nA gap year gave Hewitt the opportunity to connect with her family farm in a way that she never did while busy in high school. She enjoyed spending days outside, being active, and caring for the animals. Beef and lamb are the farm\u2019s main products, but they also have chickens, turkeys, and a few ducks. Hewitt highlighted that one of the joys of the ranch is stewarding Navajo-Churro sheep and maintaining relationships with other breeders to preserve both the breed and a familial cultural practice.\nCurrently, Hewitt\u2019s family is working to convert pastureland into multi-tiered agroforestry silvopasture, which combines tiers of trees and other plants with livestock. They plant chestnut trees at the top, then hazelnut trees, then berries and vines. At the bottom, they plant ground cover, such as mushrooms and sorel. Animals graze between rows of plants, eating their fallen food, pruning them, and providing manure to help them grow. This method of planting maximizes production value, allowing for the cultivation of more calories per square acre. Most importantly, because each plant requires and replenishes different resources, it helps restore the soil\u2019s nutritional balance.\u00a0\nImbalances in soil nutrition have become a problem on many large-scale farms. Although it may seem that industrialized agriculture is more efficient than smaller scale farms, this is only the case for the first ten to fifteen years. Over longer timelines, it becomes extremely wasteful, costly, and inefficient due to problems with soil quality, water contamination, and transport cost.\u00a0\nHewitt\u2019s farming background has also made her aware of the injustices that common industrial farming practices cause, to both the planet and humans.\u00a0\n\u201cHumans have lived on the planet for so long, but we\u2019ve only lived [in an industrialized way] way for two -hundred years. It has resulted in so much poverty and inequality. Industrial agriculture is agribusiness, and there\u2019s something unethical about centering a business model around something that is a basic need,\u201d Hewitt said. \u201cHowever, due to the way the agribusiness system developed in America, there is little room for a just transition at this point. An overhaul centering Indigenous and local agriculture production pathways is necessary.\u201d\nHewitt would like to see a return to community-based food production, with more people involved in farming, more farmer\u2019s markets, and less reliance on food sourced from afar. \u201cI think society would be a better place if more people had experience with agriculture. I think there is a disconnect from reality that exists today, a result of peoples\u2019 lived experiences which often center around academic or non-physical work,\u201d Hewitt said. \u201cAt the end of the day, we have to remember that we\u2019re human; we\u2019re animals. We have a body that was designed for work, and it\u2019s important to be well-rounded.\u201d\u00a0\nHewitt identified some changes she would like to see here at Yale. First and foremost, she encourages the university to hire more Indigenous faculty. On the individual level, she wishes that each Yale student could visit both the Yale Farm and a landfill. Encouraging them to face a reality they might not encounter on a daily basis, she believes such experiences could leave a lasting impression, impacting students\u2019 future decisions. Hewitt also raised the idea of creating a \u201cclimate credit,\u201d which would require students to gain environmental awareness, just as they are required to learn about math or science. Elea expressed how this awareness is crucial; ignoring it is no longer an option.\u00a0\nAfter college, Elea hopes to work on different types of farms, work for a non-profit, and travel. She hopes to learn through these diverse experiences before she eventually takes over her family\u2019s farm, where she will continue to implement Indigenous and environmentally sustainable practices, working towards a more socially just future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/undergraduate-profile-elea-hewitt-22-insights-from-a-year-of-farming/",
            "captions": [
                "Image courtesy of Elea Hewitt."
            ]
        },
        {
            "title": "Cleave the Chlorine!: A catalyst to help remove chlorine from pollute water",
            "author": "Sydney Hirsch",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure1_Hirsch-500x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Anthropogenic pollutants\u2014that is, those released by human activities\u2014are toxic and can pose serious risks to human and ecological health. Chlorinated phenolic compounds (CPs), often used in pesticides, herbicides, and various other chemical products, are one such type of pollutant. These compounds need to be removed from water systems by a process known as hydrodechlorination. Conventional treatment methods such as filtration, however, are not effective. As a result, scientists have begun to explore electrocatalysis as an alternative technique to cleave the chlorine from phenol, ridding systems of CPs.\u00a0\nPalladium-based catalysts offer a promising solution to catalyze or promote this reaction. However, palladium (Pd) is a costly material, and past experimentation with Pd nanoparticles (Pdnano) has demonstrated various limitations in dechlorination efficiency. A team of researchers at Yale, including post-doctoral fellow Dahong Huang and senior professor Jaehong Kim, devised an electrocatalytic technique utilizing single-atom palladium (Pd1) that circumvents both the cost and mechanistic issues posed by Pdnano. Their efforts, in collaboration with Brookhaven National Laboratory, yielded a system fourteen times more efficient than Pdnano at the atomic scale.\nThe researchers\u2019 experiment consisted of mounting the Pd single-atom catalyst (SAC) onto a reduced graphene oxide (rGO) support, which allows for rapid electron transfer and sufficient distribution of the SAC. Unlike Pdnano loaded onto an analogous support, in which many Pd atoms sit under the surface, all of the palladium atoms on the Pd1/rGO are available for reaction. Thus, the atomic efficiency of Pd1 can reach one hundred percent.\u00a0\nIn addition, Pd1 uses less palladium than Pdnano, making it cost-efficient as well. In fact, it costs only seventeen cents to cover a square meter of rGO with the palladium SAC, whereas Pd nanoparticles run around thirty-seven dollars per square meter. This dramatic reduction in cost is vital in the context of water treatment, as the broader objective of this research seeks to find efficient and cost-effective ways to treat large volumes of water.\nIn previous research involving palladium-induced catalysis, scientists also noticed that the catalyst could be deactivated by the products of hydrodechlorination. This result was seen in experimentation with Pdnano, wherein the chloride released by the reduction reaction clung to the palladium surface and prevented further catalytic activity. Kim and his team recognized, however, that single-atom palladium circumvents this \u201cpoisoning effect\u201d since the unsaturated nature of the SAC allows any adsorbed chloride to be released quickly and the reaction to progress unhindered. The researchers demonstrated this phenomenon experimentally. Throughout the electrocatalytic reaction, in which chlorines were removed from the phenolic compounds, the chloride ion concentration in solution remained close to one hundred percent, indicating that the Pd1/rGO surface had not adsorbed chloride after dechlorination of the phenols.\u00a0\nAdditionally, phenol was the only product in solution, highlighting the selectivity of this mechanism. \u201cImagine you have a pollutant like chlorophenol in water and you\u2019re trying to treat it. But water also has a lot of other stuff in it. You don\u2019t want your reduction power to reduce the rest of the organics in water. We want a treatment scheme that selectively destroys the pollutant, and this palladium single atom-based material can selectively target reducing chloro-compounds, which is the ultimate goal,\u201d Kim said.\u00a0\nThe presence of electron metal support interactions (EMSI) between the Pd1 atoms the rGO support promotes the catalytic reaction. Electrons flow through the palladium-oxygen bonds and transfer directly to what is adsorbed on the Pd1, whether it be a chlorophenol (direct reduction) or a proton. In the latter, atomic hydrogen is formed to reduce the chlorophenol, a process termed indirect hydrogenation. With previous methods using Pdnano, two atoms of hydrogen formed H2 and thus failed to contribute to the electrocatalytic hydrodechlorination. Pd1 avoids this issue due to its limited adsorption sites and spatial separation.\u00a0\nKim\u2019s research demonstrates the potential of palladium SACs in becoming a prominent part of water treatment solutions. Before considering the broader applications, however, there are many smaller-scale steps to be taken in this line of work. \u201cWe need to continue to test this material for a wide range of scenarios. At the same time, we are not claiming that [palladium] is the best material,\u201d Kim said. \u201cThere are many other options for the metal as well as the substrate, and we do not know what the best is.\u201d\nFuture studies may continue to test the long-term stability of SACs and optimize its properties for a given reaction, ultimately working to detoxify environmental systems. \u201cYou have just seen the tip of the iceberg,\u201d Kim said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/cleave-the-chlorine-a-catalyst-to-help-remove-chlorine-from-pollute-water/",
            "captions": [
                "SONY DSC"
            ]
        },
        {
            "title": "Atmospheric Rivers: How global warming influences the stability of water vapor streams",
            "author": "Crystal Liu",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-9-500x326.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of the U.S. Coast Guard.\nNot all rivers run on land. Atmospheric rivers (ARs) are pathways of intense water vapor transport in the extratropics, the mid-latitude areas beyond the tropics. Seung Hun Baek and Juan Lora at Yale\u2019s Department of Earth and Planetary Sciences examined new models to evaluate the past and future influences of human activity on AR fluctuations.\u00a0\nAn AR can be advantageous or detrimental depending on its strength. The Scripps Institution of Oceanography at the University of California San Diego categorizes ARs based on a five-level scale, ranging from \u201cweak\u201d to \u201cexceptional\u201d in strength and \u201cbeneficial\u201d to \u201chazardous\u201d in impact. An AR of level two (Moderate) can help replenish low reservoirs after a drought, but ARs of four and five (Extreme and Exceptional) often lead to heavy precipitation and floods.\u00a0\nHigher temperatures can strengthen ARs by increasing the amount of water vapor in the air. Two important factors that affect temperature are the warming effects of greenhouse gases (GHGs) and the cooling effects of industrial aerosols, such as smoke and particulate air pollutants. Baek and Lora showed that there was little human-induced change in AR characteristics from 1920-2005, as the effects of GHGs canceled out those of aerosols. Compared to natural variability, human activity only caused statistically significant changes in the North Atlantic and the Southern Pacific, and these changes were small in scale.\u00a0\nHowever, when the scientists applied the same framework to project future changes, they saw a drastically different picture. Relative to the historical evaluation, they predicted far more vigorous ARs from 2005-2080, simulating a roughly twenty-millimeter per month rainfall increase in many regions and over one hundred percent more frequent extreme precipitation over much of Europe. These natural disasters can lead to flooding, property losses, and casualties.\u00a0\nBaek and Lora used the Representative Concentration Pathway of 8.5 watts per square meter (RCP8.5) in their prediction model. The RCPs were proposed by the United Nations Intergovernmental Panel on Climate Change (IPCC) in its Fifth Assessment Report. They represent a series of GHG concentration scenarios, and RCP8.5 corresponds to \u201cvery high GHG emissions.\u201d In 2014, the IPCC stated that without additional efforts to constrain emissions, the baseline condition would fall between RCP6.0 and 8.5. \u201c[RCP8.5] is certainly pessimistic, but it is possible and very worth thinking about, as we\u2019ve been following that trajectory relatively closely,\u201d Lora said. Plus, the models stay conceptually valid regardless of the numbers. \u201cIf greenhouse gases went up less, the intensification of atmospheric rivers would be less. But qualitatively it will still go up,\u201d Baek said.\u00a0\nThe researchers also evaluated the altitude of changes in AR characteristics. Changes at a higher altitude, although smaller in magnitude, closely mirror those at a lower altitude. \u201cMid-latitude weather systems have a vertical structure that goes from the surface up into the troposphere, so we want to understand how these [AR] changes occur in the vertical direction as well,\u201d Lora said.\u00a0\nWith such large experiments came numerous challenges. Collecting and analyzing the data was an especially arduous task. \u201cAtmospheric rivers use daily data, so it\u2019s pretty high resolution temporally. I think we analyzed or generated something like twenty terabytes of data.\u201d Baek said.\u00a0\nLora, on the other hand, expressed words of gratitude. \u201cYale maintains very good computing capabilities. [During the pandemic,] we are lucky as computational scientists in that we run simulations and analyses on computers that we can access remotely,\u201d he said.\u00a0\nIt is astonishing that industrial aerosols, an important air pollutant, can cool the atmosphere. Can humans make use of this property? Indeed, solar geoengineers have been considering injecting aerosols into the stratosphere. This field has received much attention recently, but its implementation is currently far from reality due to many unknown consequences. \u201cThink about the mass extinction event that killed the dinosaurs. A large proportion of that was probably due to aerosols blocking the Sun. So maybe it\u2019s not [a path] we want to go down,\u201d Lora said.\u00a0\nIn future studies, the scientists hope to examine the influence of global patterns, such as the El Ni\u00f1o\u2013Southern Oscillation, on atmospheric rivers. Several regional studies have observed these phenomena, but simulations like the one in this paper can help paint a global picture. The scientists also aim to elucidate the impact of individual forcings, or perturbations to the Earth system, on atmospheric rivers\u2014not only to gain an insight on this elaborate system, but also to shed light on the possible effects of solar geoengineering and other human modifications to the atmosphere.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/atmospheric-rivers-how-global-warming-influences-the-stability-of-water-vapor-streams/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Climate Change and Evolution: What wood frogs tell us about adaptation to climate change",
            "author": "Isabel Trindade",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/fig1_trindade-500x336.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nLoss of biodiversity is just one of many grave consequences due to climate change. Recent research sheds light on a species\u2019 capacity to escape extinction by evolving rapidly at microgeographic scales. A study from the Skelly Lab of the Yale School of the Environment replicated research from 2001 that investigated how various populations of wood frogs, Rana sylvatica, exhibited differing embryonic development characteristics in response to factors associated with climate change.\nThe study sought to understand how certain species could adapt to climate change.\u00a0\u201cWood frogs are a great study system because they form natural metapopulations and are highly adapted to cold and therefore sensitive to warming,\u201d said A. Andis, a PhD candidate in the Skelly lab. Results showed that embryos in 2018 developed at rates fourteen to nineteen percent faster than those in 2001 on average. Further, there was variation among embryonic development rates across frog populations separated only by small geographic differences, a pattern found in both the 2001 and 2018 studies. Several environmental factors attributed to climate change, including canopy cover and pond temperature, influenced development rates.\n\u201cWhen it comes to predicting conservation outcomes into the future, [scientists] tend to [ignore] the capacity for organisms to adapt and variation within species and populations,\u201d Andis said. This study provides some hope that organisms can mediate the effects of human environmental impacts. However, this capacity is limited\u2014  \u201ctoo much change, too quickly\u201d still has disastrous effects. Some species, unfortunately, may already be approaching this rate limit or have passed it already, a phenomenon known as \u201cextinction debt.\u201d\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/climate-change-and-evolution-what-wood-frogs-tell-us-about-adaptation-to-climate-change/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Search for a Household Contaminant\u2019s Health Impacts",
            "author": "James Licato",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Factory_Water-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Factories use dioxane, a potential carcinogen, to manufacture a variety of industrial compounds. Image courtesy of Flickr.\nFor decades, a simple organic compound, 1,4-dioxane, has contaminated the household products of many Americans. This chemical, commonly known as dioxane, is used to synthesize and stabilize many industrial compounds. Consequently, it is a known contaminant in many laundry detergents, soaps, and other consumer products. Although exposure to dioxane has been demonstrated to cause cancer in animals, carcinogenic effects in humans have yet to be proven. Due to this knowledge gap, there is no federal standard for levels of dioxane in drinking water or wastewater streams. Further research is needed to support more stringent regulations by the EPA.\u00a0\nResearchers at the Yale School of Medicine hoped to contribute to this question by investigating how dioxane causes cancer in living organisms. The research team, led by Ying Chen and Vasilis Vasiliou, utilized a special type of mouse model to determine the mechanisms by which dioxane could damage cells. The researchers administered high doses of dioxane to two groups of mice: a group of normal mice and a group of mice with a specific genetic modification. This modification removed the gene responsible for the coding of an important liver enzyme that produces a chemical called glutathione.\u00a0\nIn a previous study, the researchers found that dioxane damages the liver through oxidative stress, a state in which an imbalance of toxic free radicals causes cellular damage. Glutathione is an antioxidant produced by plants and animals to balance oxidative stress. By removing the gene that produces glutathione in the liver, researchers hoped that the DNA and cellular damage caused by dioxane would be more apparent\u2014and along with it, dioxane\u2019s mechanism of action.\u00a0\nFor three months, both groups of mice were exposed to high levels of dioxane, either orally or through drinking water. The researchers used a high concentration of dioxane to more easily pin down the acute effects and potential action mechanisms of dioxane. At the end of the period, the mice were euthanized, with blood and liver samples collected.\u00a0\nResearchers found that dioxane negatively affected many functions of the liver in mice. Additionally, the mice lacking the gene responsible for the enzyme were affected more severely than the normal mice, confirming the research team\u2019s hypothesis. Their results indicate that dioxane alters redox balance, or the balance of toxic free radicals and antioxidants like glutathione.\u00a0\nAlthough the current study did not pinpoint the exact mechanism for cancers caused by dioxane, the team\u2019s findings reveal that oxidative stress may serve as a candidate mechanism of dioxane liver carcinogenicity. \u201cRedox balance will play a significant role in dioxane metabolism in humans,\u201d\u00a0said Yewei Wang, a postdoctoral researcher on the team.\u00a0\nThe team plans to continue their research. Although pinpointing how dioxane causes cancer will usher in more regulation and consumer protections, there are still many roadblocks in determining the toxicity of dioxane. \u201cDownstream metabolites of dioxane are still unknown,\u201d Wang said. This poses a challenge for researchers looking to investigate the effects of dioxane contamination and toxicity, as the true scope of contamination cannot be determined.\u00a0\nSome states, however, are not waiting for further confirmation of dioxane\u2019s carcinogenicity in humans. Two states, New York and California, have passed legislation setting maximum levels for the contaminant in drinking water and other consumer products like detergents and cosmetics.\u00a0\nThe researchers used lab mouse models to investigate dioxane\u2019s potential cancer-causing effects. Image courtesy of Wikimedia Commons.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/the-search-for-a-household-contaminants-health-impacts/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Tiny Molecule\u2019s Big Role in Brain Development: How retinoic acid regulates the connectivity of the prefrontal cortex",
            "author": "Neil Kadian",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Kadian_Figure2-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nThere are more synapses in the human brain than there are stars in the Milky Way. The developing brain manages to wrangle and organize over one hundred trillion neural connections\u2014many orders of magnitude greater than the number of base pairs in our genome. Deciphering how the body constructs such mind-bogglingly complex cellular structures might demystify psychiatric diseases and the evolution of the brain. In a recent study published in Nature, researchers from the Yale School of Medicine identified a small signaling molecule, retinoic acid, that plays a key role in the development of the prefrontal cortex.\nLocated in the front of the human brain, the prefrontal cortex regulates complex behavior, personality expression, and decision making. Compared to other animals, anthropoid primates possess enlarged prefrontal cortices. To identify genes that are uniquely upregulated in the prefrontal cortex, the researchers analyzed transcriptome data\u2014information regarding gene expression across different brain regions\u2014from databases including BrainSpan and PsychENCODE. They identified 125 protein-coding genes that are upregulated in the human frontal lobe, which includes the prefrontal cortex and motor cortex, during mid-fetal development, when gene differentiation becomes highly enriched. Of the 125 genes identified, many were associated with the small signaling molecule retinoic acid.\n\u201cSince retinoic acid-regulated genes are enriched in the prefrontal cortex, we decided to analyze these genes more closely,\u201d said Mikihito Shibata, a co-first author of the study and associate research scientist in neuroscience at the Yale School of Medicine. Retinoic acid is a signaling molecule involved in the development of a plethora of anatomical structures, including the spinal cord, heart, liver, eye, and limbs. By micro-dissecting brain tissue, the researchers found a clear gradient of retinoic acid in the brains of mid-fetal humans and macaques: high levels saturated the prefrontal cortex in the front of the brain, then sharply dropped after the prefrontal cortex and continued decreasing towards the back.\u00a0\nThe researchers identified similar gradients of retinoic acid synthesizing enzymes and receptors and an enrichment of retinoic acid degrading enzymes in the regions surrounding the prefrontal cortex. These findings indicate that expression of retinoic acid receptors and synthesizing and degrading enzymes localize the molecule\u2019s activity to the prefrontal cortex.\nBut what happens when this network is disrupted? In mutant mice that did not express retinoic acid receptors, retinoic acid signaling in the prefrontal cortex decreased. When compared to normal mice, these mutant mice expressed 4,768 genes differently in the mouse equivalent of the prefrontal cortex. Intriguingly, many of these genes are known to be responsible for synapse and axon development, suggesting that retinoic acid regulates synapse and axon development in mice. Levels of critical synapse proteins such as DLG4 and synaptophysin were reduced, as well as the number of mushroom dendritic spines, structures that receive inputs from other neurons.\nNext, the researchers used diffusion tensor imaging (DTI), an advanced MRI-based imaging technique, to observe the effect of retinoic acid on long-range brain connections. In mutant mice that did not express retinoic acid receptors, DTI identified a reduction in connections between the mouse prefrontal cortex and another brain region known as the thalamus.\u00a0\nThe connection between the prefrontal cortex and thalamus is critical for cognitive function, and abnormalities in the connection have been implicated in psychiatric diseases such as schizophrenia. \u201cBeyond having an importance in understanding the evolution and development of the prefrontal cortex, this paper has critical implications in the way we conceptualize and possibly treat schizophrenia,\u201d said Kartik Pattabiraman, co-first author and a Child and Adult Psychiatry Fellow in the Child Study Center at the Yale School of Medicine. \u201cIt\u2019s thought that schizophrenia is caused by disruption of the adolescent brain, but we provide evidence that schizophrenia could instead be a developmental disorder. To truly prevent it, we might have to intervene much earlier.\u201d\nOn the other hand, in mice that did not express CYP26B1, an enzyme that degrades retinoic acid, retinoic acid signaling expanded beyond the prefrontal cortex. Connections between the thalamus and the prefrontal cortex expanded to regions adjacent to the prefrontal cortex, and the mouse prefrontal cortex developed characteristics unique to the primate prefrontal cortex. Does this mean that increasing neural retinoic acid activity could generate super intelligent mice? \u201cIt\u2019s\u00a0probably more complex than that. But testing the behavior of CYP26B1-deficient mice is a next step\u201d Pattabiraman said.\u00a0\nIn the future, Shibata and Pattabiraman are interested in further exploring the role of retinoic acid, uncovering the secrets of brain development and evolution, and identifying new paradigms for clinical treatment.\n\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/a-tiny-molecules-big-role-in-brain-development-how-retinoic-acid-regulates-the-connectivity-of-the-prefrontal-cortex/",
            "captions": [
                "B0004165 Neurons in the brain - illustration\nCredit: Benedict Campbell. Wellcome Images\nimages@wellcome.ac.uk\nhttp://images.wellcome.ac.uk\nIllustration of a network of nerve cells in the\nbrain. They are covered with grid lines suggesting\nfuturistic analysis and measurement.\nPublished:  - \n\nCopyrighted work available under Creative Commons by-nc-nd 2.0 UK, see http://images.wellcome.ac.uk/indexplus/page/Prices.html"
            ]
        },
        {
            "title": "Breaking Bonds with Computer Models: A new approach for understanding proton-coupled electron transfer",
            "author": "Madison Houck",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Houck_Figure2-500x332.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Unsplash.\nWhat do fuel cells, water splitting, and artificial photosynthesis have in common? They\u2019re all vital technologies in the fight to transition away from fossil fuels towards a brighter, cleaner energy future. They also all require a specific type of chemical reaction to work. This reaction, called a proton-coupled electron transfer (PCET) reaction, is widespread across energy studies, as well as in biological systems. In this reaction, protons and electrons are transferred either simultaneously or one at a time. Understanding PCET reactions is fundamental to a better understanding of how to improve cutting-edge sustainable technologies.\u00a0\nRobert E. Warburton, an Arnold O. Beckman Postdoctoral Fellow at Yale University working in the Hammes-Schiffer group, has approached this important problem using computational modelling. While previously his collaborators in the Mayer lab had collected experimental data on the PCET reactions, computational modeling can give deeper insight into these systems. \u201cIf we want to understand how to control the chemistry, we need to know what happens in between that initial and final stage that you see in an experiment. And a lot of times that happens on very short timescales,\u201d Warburton said.\u00a0\nHis main research goal was to examine how different materials require different amounts of energy to undergo a PCET reaction. Each material has a unique property called band gap. Band gap is associated with the difference in energy between the highest and lowest electron levels within the material. Warburton initially hypothesized that a larger band gap would make a PCET reaction have a larger bond dissociation free energy (BDFE), which measures how hard it is to break a bond.\u00a0\nSpecifically, Warburton\u2019s study focused on how defects in materials could affect the reaction.\u00a0 Defects could cause the material to react all at one site: PCET can occur at either low electron levels or, in the case of a defect, high electron levels that carry a positive charge. Typically, only one value is reported for the BDFE, so it\u2019s important to consider how the defects in the material could impact its actual performance.\nSome of the titanium oxide (TiO2) metal oxides transferred the electron from the valence band, a lower electron energy level where the outermost electrons of the material lay, and some transferred the electron from the conduction band, a higher electron energy level to which some of these electrons jump. TiO2 is an ideal material to study this because its conduction band has a different orbital shape than the valence band. The conduction band, more closely associated with titanium, has an electron cloud, or orbital, that is shaped like a flower. The valence band, more closely associated with oxygen, has an orbital that is shaped like a peanut. Warburton\u2019s model showed a significant difference between the BDFE of the valence and conduction bands.\nAlthough these results confirmed Warburton\u2019s hypothesis, he and his collaborators concluded that the model was too simple. While there certainly was a relationship between the band gap and the energy of the bond, that wasn\u2019t the whole picture. \u201cWe saw the big result that is interesting and compelling, but we don\u2019t necessarily have a straightforward answer as to why. So really the hard part about this was doing the analysis and sensitivity,\u201d Warburton said.\nIn order to have a more complete model, Warburton and his colleagues incorporated another theoretical framework, called Marcus theory. Marcus theory deals with the rearrangement of atoms in the material during electron transfer. More specifically, an electron transfer can only occur if there is enough energy to rearrange chemical bonds in the surrounding environment to accommodate the transfer. Including these effects in the model made it more complicated but better able to explain experimentally observed behavior.\nWarburton says his work is far from over. \u201cAll we\u2019ve been looking at so far is reaction energies and thermodynamics\u2014basically how favorable the processes are. Now we want to start looking at the kinetics of these reactions, so how fast they go,\u201d he said. Further down the line, his results could one day help us understand why there may be gaps between the theoretical and actual performance of materials. Armed with this understanding, engineers and scientists can choose the optimal material for green technologies. Although this research seems incredibly specific, the applications are far-reaching and could impact the way we design green technologies in coming years.\nWarburton\u2019s postdoctoral research is supported by the Arnold and Mabel Beckman Foundation through an Arnold O. Beckman Postdoctoral Fellowship. This research study was also supported as part of the Center for Molecular Electrocatalysis, an Energy Frontier Research Center funded by the U.S. Department of Energy, Office of Science, Basic Energy Sciences.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/breaking-bonds-with-computer-models-a-new-approach-for-understanding-proton-coupled-electron-transfer/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Food Addiction Across Demographics: How environmental context might increase distress",
            "author": "Lauren Chong",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-1-1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nWhat does it mean to be addicted to food\u2014and is food addiction the same for everyone? According to a new study by the Yale School of Medicine and University of Minnesota Medical School, rates of food addiction\u2014the compulsive consumption of foods high in sugar and fat, leading to symptoms of distress\u2014differ across demographic and weight groups.\nIn the study, participants reported their views on healthcare and food consumption as well as their clinical, demographic, and body-mass index (BMI) information. Those who had food addiction symptoms such as distress or impairment as a result of their eating habits were placed into the food addicted category.\nStatistical analyses revealed that females and people with obesity were more likely to report distress related to the food addiction symptoms after controlling for symptom frequency. \u201cWomen might experience more pressure related to food and weight, and therefore [are] more likely to experience symptoms of distress from eating,\u201d lead researcher and Yale postdoctoral fellow Meagan Carr said. \u201cPeople who are overweight and obese experience stigma and prejudice, so it\u2019s also possible that they might have more reactions to food addiction.\u201d\u00a0\nCarr emphasized the need for a better understanding of food addiction. \u201cThe data show that it may be better to move beyond focusing on people\u2019s individual choices around food, and instead think about environmental context and other contributors,\u201d Carr said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/food-addiction-across-demographics-how-environmental-context-might-increase-distress/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Can You Learn More Than a Fifth Grader?: Attitudes toward learning in children and adults",
            "author": "Odessa Goldberg",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure2_Goldberg-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Emki Production.\nHow much do you think you can learn in a year\u2019s time? At the Cognition and Development Lab at Yale, researchers compared children\u2019s and adults\u2019 attitudes toward how much knowledge they believed one could acquire in one year. The research was driven by previous findings showing that children are more optimistic than adults when it comes to knowledge acquisition attitudes. Research scientist Kristi Lockhart sought to see if shortened time frames, methods of learning, or types of knowledge affected this attitude. Who was more optimistic?\nApparently, children. \u201cEven though they made a distinction of what they could learn [with different methods of learning] if you look at some of their scores, they are still above average [compared to] the adults,\u201d Lockhart said.\u00a0\nBut this optimism is not without its limits. Children ages five to seven still believe two-year-olds are unable to learn anything, making a bigger distinction between themselves and the two-year-olds than themselves and adults. Additionally, they distinguish themselves specifically, displaying a self-enhancement effect; in other words, each child believes they will be able to learn more than their peers.But the question remains: why are the children so optimistic? Lockhart has a few theories. First, this optimism may be necessary to keep children motivated in schools. It may not be unfounded, as adults routinely underestimate how much children can learn. Conversely, children may maintain this level of optimism because they don\u2019t yet have the metacognitive skills to consider the effort required by knowledge acquisition. In early life, children seem to learn without consciously exerting effort, potentially causing them to view knowledge acquisition as easy.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/can-you-learn-more-than-a-fifth-grader-attitudes-toward-learning-in-children-and-adults/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Predicting Crop Contaminants with Machine Learning",
            "author": "Annabel Wallace",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Env_contamination1.if_-500x333.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Crops can become contaminated in a variety of ways based on the environments in which they grow. Some examples include deposition from organic chemicals in the air, direct application of pesticides, and ground-water contamination. Image Courtesy of Flickr.\nOur food can become contaminated even before it\u2019s pulled out of the ground. As a result of naturally occurring deposition, chemicals applied in agricultural practices can enter crops through the soil and water that plants uptake. Researchers have previously struggled to accurately predict how crops are contaminated due to the complex interactions between crops and their environment. Feng Gao, a postdoctoral associate in the Department of Genetics at the Yale School of Medicine, along with a team of scientists from around the globe, recently used machine learning (ML) to address this problem and shared their findings in the Journal of Hazardous Materials.\u00a0\nGao tested four existing ML algorithms, programs that formulate predictions for a system based on a sample data set. These four models\u2014Fully Connected Neural Network (FCNN), Gradient Boosting Regression Tree, Random Forest, and Supporting Vector Regression\u2014were utilized to predict root concentration factors (RCFs), the amount of contamination in the root compared to that in the soil around it. Two hundred forty-six data points collected from other studies on crop contamination for eleven crops and fifty-seven chemicals were inputted into the machine algorithms. Gao identified the FCNN as the greatest predictor of RCFs, as indicated by this model\u2019s higher R-squared value and lowest mean absolute error.\u00a0\nThis study demonstrates how machine learning, specifically the FCNN, provides a more accurate model for identifying which food is contaminated than did previous approaches. Equipped with this tool, scientists hope to mass-measure and avoid contamination in crop growth, ensuring that our food is safe to eat.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/predicting-crop-contaminants-with-machine-learning/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Mitigating Climate Change with Green Roofs",
            "author": "Abigail Jolteus",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Image-1-2-500x281.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Green roofs, roofs covered in plants, could help cool cities.\nAs the world population increases, the need for urban infrastructure also increases. Human activities, coupled with rising global temperatures, result in a phenomenon known as an urban heat island: a city that is significantly warmer than surrounding rural or suburban areas. Urban heat islands can have detrimental effects on the environment and humans. Many cities have implemented green infrastructure such as green roofs\u2014roofs covered with plants\u2014to address the rising temperatures. It is easy to assume that all green roofs are equally beneficial, but there are many different types of green roofs with varying degrees of effectiveness. Yale researcher Kathryn McConnell investigated a low-cost method of evaluating them.\nMcConnell measured the effectiveness of three green roofs in Chicago: a Walmart Supercenter rooftop, City Hall\u2019s rooftop, and Millennium Park, a large public park on top of various parking garages and a railyard. The green roofs varied in their plant species composition, and thus also the amount of soil and irrigation required. Data from the satellite Landsat 5, which is public information, was used to evaluate the changes before and after green roof installation by recording the Land Surface Temperature (LST) and normalized difference vegetation index (NDVI). This was done at each green roof and at a nearby rooftop to ensure that no other variables were affecting the LST.\u00a0\n\u201cPeople tend to think that all green roofs have cooling effects,\u201d McConnell said. But her findings indicated that not all green roofs have a cooling effect on the environment and that the effect varies by type. Green roofs with a greater diversity of species, with deeper soil and irrigation requirements, tended to be more cooling.\u00a0\nPolicymakers and planners now have a low-cost method of evaluating the effectiveness of green roofs in their city, which they could use to adjust city plans and create a better environment for their residents.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/mitigating-climate-change-with-green-roofs/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Painting the Ocean: More Deadly than Fun",
            "author": "Connie Tian",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Picture1-4-500x331.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Marine plastics. Image courtesy of the Science Photo Library.\nPlastic waste has been a visible and growing problem around the world for decades. Various campaigns have been launched by corporations, grassroots organizations, and governments promoting recycling, aimed at reducing our use of single-use plastics and raising awareness on the impact of plastic on the oceans. Single-use plastics are a major source of plastic in the ocean, littering the shorelines of beaches and stretching out across the sea in the Great Pacific Garbage Patch. However, recent research has shown that there is a much more prevalent and invisible threat to the ocean: microplastics.\nMicroplastics are fragments of plastic smaller than five millimeters long, often created by the weathering of larger pieces of plastic debris. Prior studies have demonstrated that the amount of microplastics in the ocean is much greater than the plastic floating on the ocean\u2019s surface. Recently, professor Andrew Turner at the University of Plymouth has expanded upon these studies and found that paint flakes could be one of the most abundant microplastic particles in the ocean yet.\u00a0\nTurner and his team studied the abundance of microparticles captured by plankton trawls in the North Atlantic Ocean. His team discovered that each cubic meter of seawater could contain approximately 0.01 percent paint flakes. After fibrous microplastics, these paint flakes may be the most abundant source of microplastics in the ocean.\nTurner noted that these paint flakes come from boats. Boats are painted with anti-corrosive and antifouling paint that discourages aquatic organisms from attaching to the underwater portion of the boat\u2019s hull. The paint is not only detrimental to marine life, but also more brittle than fibrous plastics. \u201cPaint breaks down more readily than other plastics, and its toxic additives [such as copper and iron] come out more easily. Paints have an additional implication that they are more toxic than an equivalent size of plastic,\u201d Turner said. Thus, it is the abundance, toxicity, and mobility of these paint flakes that warrants closer attention, Turner reasoned.\nWhile there are regulations on the type of paint allowed on boats, many boats still grandfather older, more toxic paints. Furthermore, boats must be painted to prevent damage from marine wildlife. Future steps will likely rely on manufacturers developing less toxic, more degradable paints. Hopefully, with Turner\u2019s new data, more manufacturers and policymakers will be galvanized to come up with better alternatives.\u00a0\nThis, of course, does not mean that only boat owners and manufacturers can make a difference. Microplastics that contaminate the ocean come from various sources, ranging from the single-use plastics we consume every day to the fibers from fast fashion clothing. Furthermore, these microplastics are not just confined to the ocean. Microplastics are found in the air we breathe and even the human gut. So, until more degradable types of materials are developed, consumers, manufacturers, and policymakers must all work to reduce plastic consumption as much as possible.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/painting-the-ocean-more-deadly-than-fun/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Fault in Our Stars",
            "author": "Ethan Olim",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Olim-Uppal-Figure2-500x270.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of the European Organization for Astronomical Research in the Southern Hemisphere.\nFar above the rush of everyday life, past our fragile atmosphere, and across millions of miles of space, billions of stars glow. While bright city skylines already make it difficult for people in urban areas to enjoy this beautiful night sky, a new source of light pollution is on the rise: satellite megaconstellations, also known as satcons. Satcons are collections of thousands of artificial satellites launched by commercial companies, and they are lighting up the night sky. Researchers from the University of Regina, University of British Columbia, and University of Toronto at Scarborough recently collaborated on a predictive model for the damage satcons will ultimately cause to their research and to the night sky.\nIn the last few years, researchers have seen the impacts of satcons grow both in their research and in their everyday lives. Astronomer Samantha Lawler moved to Saskatchewan in 2019 for a faculty position at the University of Regina and was able to see the Milky Way from her home for the first time. But she saw something else as well: a growing number of satellites whizzing by due to Starlink, a satellite constellation operated by SpaceX with the stated goal of providing worldwide internet service. \u201cI knew from my calculations that this [was] going to be a big problem for a lot of areas of research in astronomy,\u201d Lawler said.\nAstronomers often collect data by using telescopes to take pictures of the sky in different wavelengths of light, such as visible, infrared, and radio. However, the recent increase in satcons has resulted in an increasing number of images being contaminated by satellite streaks. While this can currently be corrected for by taking several images of the same patch of sky, this restorative measure will become increasingly unreliable as more satcons are launched and more images are contaminated. Even telescopes in space aren\u2019t immune to satellite contamination\u2014the historic Hubble Space Telescope has to contend with it as well. The future James Webb Space Telescope will be one of only a few telescopes free from their influence, due to its more distant orbits.\nThe brunt of the impact of satcons will likely be felt by astronomers who study the skies in visual wavelengths. As images become more and more filled with satellite streaks, they will contain fewer and fewer pixels of data that are actually useful to researchers. For example, the Vera Rubin observatory, a nearly $500 million facility in Chile, has predicted that thirty percent of its images will be severely impacted by satellite trails. \u201cThe same science goals [in visual astronomy] can happen, but they\u2019re going to take longer,\u201d Lawler said.\nOther types of astronomical research will feel the impact of satcons as well. Near Earth object observations, which involve monitoring for asteroids potentially dangerous to our planet, will become much more difficult as satellites are mistaken for asteroids. Radio astronomy will also be hit hard as commercial satellites begin making noise at frequencies currently reserved for research.\u00a0\nIn most fields of astronomy, it will simply take more data over more time to reach the same findings. But getting access to telescopes and observatories to take data is already incredibly competitive for researchers. \u201cIt just means that fewer people are going to be able to get science results. We don\u2019t actually know what we\u2019re going to miss, and that\u2019s pretty sad,\u201d Lawler said.\nTo get an idea of the damage satcons will cause, Lawler and two other researchers created a model based on reflectivity estimates and launch filings to the Federal Communications Commission (FCC). Their model allows anyone curious to enter a latitude, time of day and year, and several other factors, and view an estimate of what satcons will affect their night sky. It is freely available at http://megaconstellations.hanno-rein.de/.\nIn creating this model, researchers faced the major challenge of modeling the reflectivity of satellites without specification information from the companies. As such, they used a classic physicist trick: modeling every object as a sphere. This allowed for surprisingly successful predictions, creating data that matched with observations better than more complicated attempts. They also had to balance countless other complex factors, including distribution models for orbits. But their work will pay off: such an accurate model will be extremely useful to other researchers going forward.\nIt\u2019s worth questioning how this problem could be fixed instead of simply modeled better. At first glance, there seems to be an easy solution: regulate the corporations launching the satcons. But unfortunately, no regulations currently exist for low Earth orbit. At the moment, industry is voluntarily having some discussions about the issue: this July, the National Science Foundation hosted SATCON 2, a conference to facilitate conversations between astronomers and satellite operators. But \u201cit just became incredibly clear during the meeting: you [corporations] don\u2019t have to be here. You don\u2019t have to talk to us,\u201d Lawler said.\nCompanies are ultimately under no obligation to respect the night skies, and never will be without a major change in international regulation, which would take years to implement. Meanwhile, SpaceX continues to rapidly launch satellites into space. \u201cMy hopes are not enormously high that [regulation] will happen fast enough,\u201d said Hanno Rein, an astrophysicist at University of Toronto at Scarborough.\nSatcons are also causing enormous environmental problems. Their launches release an incredible amount of carbon into the atmosphere.\u00a0\nAnd that\u2019s not the end of the damage they can cause. SpaceX alone plans to have 42,000 satellites that will be replaced every five years, meaning that they will have to deorbit more than twenty satellites per day. These satellites will burn up in Earth\u2019s atmosphere, depositing six tons of aluminum and other materials into our upper atmosphere daily and wreaking untold environmental havoc.\u00a0\nOne measure could help prevent this fate: the global recognition of low Earth orbit as an environment. This would force environmental impact assessments to be conducted for these satellites, giving governments a better idea of their potential damage to the atmosphere.\nWhile researchers would much rather return to their preferred areas of study, satcons are not going away\u2014so unfortunately, neither is research into their effects, including their climate and environmental impacts. For example, teams have begun to look into what huge quantities of deorbiting satellites might imply for Earth\u2019s atmospheric chemistry. Research may also need to examine the biological implications for animals that rely on the night sky for navigation.\u00a0\nAstronomers will continue working to mitigate the effects of satcons on their research, including attempting to lower the numbers of satellites launched. Additionally, they will advocate for satellites to be launched into orbits minimally destructive to research. Finally, they will aim to make satellite-impacted research as useful as possible\u2014for example, work is being done to perfect algorithms to remove satellite damage from images. \u201cSomeone could describe it as chemotherapy for your images. It\u2019s not great, not ideal, but it\u2019s better than nothing,\u201d Lawler said, attributing the phrase to astrodynamicist Moriba Jah at the University of Texas Austin.\u00a0\nUnfortunately, while these strategies help mitigate the damage wrought by satcons, they can never fully undo it.\u00a0\nThe benefits brought by Starlink and other satcon services are certainly worthy of acknowledgment. But only a tiny fraction of the world\u2019s population will be able to afford these services\u2014Starlink internet service currently costs $99 a month, plus a $499 upfront cost. This creates a familiar system where wealthy countries reap the rewards of technological advancement while the entire world feels its negative consequences. A tiny portion of the Earth will gain faster internet service, and an even tinier portion will line their pockets. But untold volumes of astronomical research\u2014and perhaps more tragically, the sheer beauty of the clear night sky\u2014will be lost to all.\n\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/the-fault-in-our-stars/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Wildfires and Ocean Blooms",
            "author": "Krishna Dasari",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Dasari-Wu_Figure2-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nFrom September 2019 to March 2020, Australia experienced one of the worst recorded wildfire seasons in its history. Spanning 18.6 million hectares, the wildfires were responsible for massive ecological and socioeconomic damage. Around three billion animals were estimated to have been displaced or killed, causing a severe loss of biodiversity that will prove difficult to recuperate from. Furthermore, 715 million tons of carbon dioxide and various aerosols were released into the atmosphere over the course of the bushfires, the effect of which was felt around the world.\nDespite the undeniably catastrophic effects of these fires, their unprecedented nature provided researchers with a unique opportunity to study the global impacts of wildfires\u2014including their previously under-studied consequences for marine ecosystems. The researchers hope that further research on this topic can help us better predict and respond to wildfires and their effects in the future.\nScientists Weiyi Tang and Joan Llort, helming an international team of researchers under biogeochemist Nicholas Cassar and climatologist Richard Matear, were intrigued by the relationship between two known phenomena: wildfires drag nutrients like iron into the atmosphere, and iron deposition can trigger phytoplankton blooms in water given the right conditions. Further motivated by the limited research on the marine effects of wildfires, the scientists used data from the bushfires to determine their effects on phytoplankton blooms in the South Pacific Ocean.\u00a0\n\u201c[The bushfires] provided us with a unique opportunity to see how and if such wildfires could have an impact on ocean ecosystems downwind. Very often in science it\u2019s very difficult to detect the signal from the noise, but here we had an unprecedented wildfire event, and so this was a unique opportunity,\u201d Cassar said.\nTo measure aerosols produced by wildfires, the team used black carbon aerosol optical depth (AOD) data provided by the Copernicus Atmospheric Monitoring Service (CAMS). Black carbon AOD cannot actually be measured directly, but is rather estimated from overall AOD, which is in turn measured spectroscopically by satellites in the atmosphere. This data reflects the concentration of all aerosols in a given air column\u2014not just black carbon aerosols produced by fires. The CAMS aerosol model uses meteorological data to separate total AOD into many subcategories, including black carbon, dust, sulfate, and salt.\u00a0\nAOD values for these wildfires were abnormal, reportedly over three-hundred percent higher than average values since 2004. They indicated eastward drift of black carbon into the South Pacific Ocean, which was then confirmed through modeling of air trajectories from meteorological data.\nTo quantify phytoplankton growth in the South Pacific, the team took advantage of the fact that phytoplankton, as photosynthetic organisms, produce the green pigment chlorophyll a (Chla). Chla concentrations could then be estimated from publicly available satellite observations as a proxy for phytoplankton biomass. This satellite data was subsequently confirmed by marine floats deployed by Argo, an international program that collects ocean data with an array of below-the-surface floats that occasionally surface to transmit their data to satellites.\u00a0\nJust six months after the wildfires started, Chla concentrations increased by more than 150 percent compared to historical concentrations in oceanic regions along the path of aerosol transport. Furthermore, these increases in concentration occurred just days to weeks following spikes in black carbon AOD, suggesting a connection between wildfires and phytoplankton blooms, and further revealing just how swiftly events of this scale can impact the globe.\nThe international team also found that aerosols collected at a station downwind of bushfires had iron concentrations over five times the median value of concentrations observed at the same station from 2016 to 2019, when smaller wildfire events occurred. The formation of blooms requires a variety of nutrients and environmental conditions\u2014iron alone is not always sufficient. In this case, the South Pacific Ocean likely had all the sufficient conditions for phytoplankton growth except for iron during the wildfire season, meaning the iron deposits from migrating aerosols were likely sufficient to support the Chla concentration increase observed in oceans. Thus, the aerosols produced from the Australian bushfires may provide an explanation for the observed phytoplankton blooms in the South Pacific.\nBlooms can have varying ecological effects depending on the type of phytoplankton and the characteristics of the body of water and environment. In some scenarios, the blooms may, in fact, benefit the climate. Through photosynthesis, phytoplankton sequester carbon dioxide from the atmosphere. However, the authors have not yet been able to determine if the carbon dioxide sequestration is short-term, with carbon dioxide quickly recycled back into the atmosphere, or long-term, with carbon dioxide exported to the deep ocean as plankton biomass. In future wildfire seasons, they hope to determine what fraction of the carbon is sequestered long-term by using sediment traps to capture plankton biomass exported into the ocean from blooms.\u00a0\nFurther investigating long-term sequestration effects will provide important data that can be used to create better climate models. Current climate models do not sufficiently account for the various and widespread effects of wildfires. \u201cYou\u2019re expecting that the frequency, the intensity, the duration of some of these wildfires is going to increase,\u201d Cassar said. \u201cAnd so, if we\u2019re going to project our climate in the future, we need to understand how these wildfires also impact ocean ecosystems because of their role in the carbon cycle.\u201d With further testing at other wildfire sites and more detailed biogeochemical analysis, the team hopes they can develop a better understanding of the climate-related impacts of wildfires that would facilitate future climate predictions.\nUltimately, this project would have been impossible without international cooperation. The majority of the data, including black carbon AOD data and Chla concentration data, was sourced from organizations and projects producing publicly available atmosphere and ocean data. This collaborative data-sharing and type of cooperation is typical in the field of oceanography. \u201cBecause the oceans are global, and because no one owns them, there\u2019s a real strong international collaboration culture in this space,\u201d Matear said. Such a spirit of collaboration provides a model for future climate research\u2014international cooperation is necessary to address this global issue.\u00a0\nWith this project, the research team revealed the dynamic, interconnected nature of our climate and ecology. In fact, Matear and other climatologists are changing the language they use to reflect this connectivity. \u201cI\u2019m going to use the word \u2018earth system\u2019 rather than \u2018climate,\u2019\u201d Matear said. \u201cThat\u2019s probably a big change that\u2019s happening in the climate modeling space, just acknowledging that climate and carbon cycle processes are intimately linked and you probably don\u2019t want to separate them.\u201d\u00a0\nClimatological trends that may seem small on paper, such as a global increase in temperature by just two degrees Celsius, can have far-reaching and catastrophic effects. As weather patterns and natural phenomena become more severe due to climate change, so too do the impacts they have on regions around the world, on species nearing extinction, and on delicate climate systems.\u00a0\nToday, humans have become deeply entangled in this environmental web. \u201cWe\u2019re such a successful species that we\u2019re impacting our climate\u2026 We\u2019re impacting the temperature of the atmosphere and the likelihood of droughts in some regions, so I think there\u2019s a local and global impact of our species that we have to take into account,\u201d Cassar said.\u00a0\nIt is vital to understand how local perturbations by humans can cause drastic changes on a global scale. This study reveals just how much we have yet to uncover about the connectivity of Earth\u2019s natural and artificial systems. Cassar, Matear, and their team, for example, observed links between wildfires and phytoplankton populations thousands of miles away. Future research into this issue will require searching for more unexpected connections between climate-related phenomena.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/wildfires-and-ocean-blooms/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Rationing Breaths",
            "author": "Sophia Li",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Li-Zheng_Figure1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nIt\u2019s in the very air we breathe. Invisible gases, small but pervasive, travel and lodge themselves in our airways as we go through our daily motions. The truth is, the air we breathe is not equitable in its distribution. Harmful pollutants such as nitrogen dioxide (NO2) aggregate in particular communities, leading to severe health disparities and stark gradients in air pollution maps. It has long been known that low-income, urban neighborhoods and communities of color experience significantly worse air pollution than higher-income, majority-white neighborhoods. Sally Pusede\u2019s group from the University of Virginia took this research a step further, conducting a broad survey of the air pollution of the United States and comparing it with various external factors such as days of the week and vehicle pollution in order to locate specific drivers of the disparities.\nThis project combined environmental research with environmental justice policy in hopes of elucidating inter-community disparities. It focused on nitrogen dioxide, NO2, an air pollutant commonly released from road vehicles and fossil fuel combustion reactions. NO2 is also a key factor in atmospheric oxidation and secondary pollution, as it reacts with other chemicals in the air to form pollutants that are not otherwise directly emitted into the atmosphere, such as ozone and acid rain. NO2 has been previously shown to increase levels of respiratory irritation and can lead to hospitalization due to impaired lung function and shortened life expectancy.\nThe researchers used data from the TROPospheric Ozone Monitoring Instrument (TROPOMI), a satellite launched in 2017 that maps nitrogen dioxide levels almost daily, providing a high degree of clarity for air pollutant emissions at the city-level. \u201cPrior to TROPOMI, the satellite observations [regarding NO2 emissions] were too coarse to look within a city, so you couldn\u2019t go into a city and look at how NO2 is distributed. With these finer scale observations, we can now look at the steep gradients within a city to the point where you can look at a map of NO2 and make out the individual roads,\u201d said Mary Angelique G. Demetillo, a graduate student in Pusede\u2019s group.\nWith the TROPOMI data, they were able to calculate mean NO2 tropospheric vertical column densities for each 1 x 1 km2 area. Pusede\u2019s group analyzed NO2 data from 2018 to 2020 from fifty-two of the largest cities, stopping right before the start of the pandemic to eliminate any changes in pollution caused by reduced social activity. The cities sampled were \u201curbanized areas,\u201d so the data reflected intra-urban, rather than suburban-urban, differences. The data was classified by race, ethnicity, and income to compare the air pollution in low-income communities of color to that of high-income, majority-white neighborhoods and to quantify inequalities in terms of NO2 pollution. \u201cAll of the data that we used was publicly available, so anyone can use it, and it\u2019s just a question of what\u2019s the best method and how can we integrate all of these types of datasets together. For me, that challenge is pretty exciting,\u201d Demetillo said.\nPrevious research in this field had already established these existing disparities, but Pusede\u2019s group wanted to look into the drivers of these disparities. In this paper, they compared the data between weekends and weekdays, and cross-referenced this with patterns in diesel truck traffic, allowing them to see what proportion of the atmospheric disparities were due to diesel truck emissions. While diesel trucks make up between three and five percent of vehicles at any given time, they contribute thirty to fifty percent of air pollution from NO2 and many other harmful chemicals and particles.\u00a0\n\u201cPeople who live in impacted communities have long known that diesel trucks are a major contributor to disparities, but what we contribute here is really sort of the quantification of those [disparities] and the ability to see those [disparities] across cities and in so many cities at the same time,\u201d Pusede said. Data regarding diesel truck emissions was taken from the Fuel-Based Inventory from Vehicle Emissions, which provides information on emission rates and fuel use.\nThe results of this study indicate that in general, the air pollution in lower-income communities of color is twenty-eight percent higher than that of high-income majority-white neighborhoods. Some of the cities with the highest inequalities were Phoenix, Arizona (where NO2 pollution was forty-six percent higher for lower income communities of color) and Los Angeles, California (where pollution was forty-three percent higher). Regarding diesel truck emissions specifically, air pollution decreases by sixty-two percent on weekends\u2014in part because more vehicles are parked on the weekends.\u00a0 Despite this, disparities still remain, as NO2 pollution in lower-income communities of color only falls by thirty-seven percent.\u00a0\nThis study only used data from 2018. \u201c[Over time] broadly speaking, there have been really large gains in air quality across the country, but disparities have persisted throughout this time,\u201d Pusede said.\nJust having this data in front of us is not enough. Pusede\u2019s group hopes to influence policymakers with these findings to induce changes that confront and dismantle this inequality. And this work doesn\u2019t just relate to scientists. \u201cFor sure it would take interdisciplinary collaboration with people who work with human activity data, urban planning, maybe even historians to assess how the placement of communities and roads has contributed to the current-day air pollution distribution,\u201d Demetillo said. These policies could take the form of identifying specific areas in urban regions that should be more highly regulated for diesel truck traffic.\u00a0\nBut even if diesel truck emissions were effectively brought down to zero, there would still be disparities in air pollution from other sources. Thus, moving forward, researchers must investigate other major contributors to air pollution and its unequal distribution, as well as patterns affecting human exposure to it and the causes of these disparities. Human activity data shows us that patterns in activity affect an individual\u2019s exposure to pollution. Meteorology affects the distribution of NO2 within the atmosphere, which also affects our exposure to pollution. Urban planning is a major factor in air quality disparities, as the placement and structuring of communities and roads affects how pollution is distributed.\nClosely analyzing satellite data is also key to reducing inequality and lowering air pollution. In this study, since the data was so finely resolved spatially, some temporal data was sacrificed: the researchers used seasonal or annually averaged data. However, they are now looking into daily satellite observations, which could provide more temporal data regarding these disparities that their current analysis could have missed.\u00a0\nAdditionally, as NO2 is not distributed homogeneously in the horizontal direction, there will be different levels of exposure to NO2 as you travel across Earth\u2019s surface. However, the satellite data currently used takes an atmospheric cross section that doesn\u2019t account for these horizontal gradients. Looking into them with new satellite data will be yet another important step forward in the future of this research.\n\u201cI think an important part of this work is incorporating local communities and local governments into this work. Now that we have a stronger technical grasp on this data, we can better work with those communities to address issues that we might not even know they are experiencing. I think their voices and their perspectives would greatly contribute to this work,\u201d Demetillo said. With more research into atmospheric inequality with collaboration from affected communities, policymakers, and others in the field, we can look forward to concrete changes to alleviate disparities\u2014as well as tackle pollution as a whole.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/rationing-breaths/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Cow Total 101",
            "author": "Jack Litke",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Litke_Figure1-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Dr. Caroline Bagshaw\nLike those in all animals, the internal biological processes of cattle create byproducts that must be peed, pooped, or (rather notoriously) farted out. Collected waste from the world\u2019s 1.5 billion cows creates a mess for farmers and scientists alike. In addition to the potent greenhouse gases released from their farts, the solid and liquid waste generated by these famously flatulent ruminants can pollute water systems, reduce air quality, and contribute to global warming. Urine contains nitrogen, which is naturally converted into nitrous oxide, a greenhouse gas three-hundred times more powerful than carbon dioxide. Globally, cattle urine accounts for nearly 1.6 percent of greenhouse gas emissions. Scientists from New Zealand and Germany think they may have discovered a solution: toilet-training cows.\u00a0\nLindsay Matthews, a researcher at the University of Auckland and the science leader, has considered the possibility for a long time. In a 2007 radio interview on the harmful environmental effects of cow waste, the interviewer humorously suggested that Matthews train cows to use the loo. The interviewer, thinking his wacky suggestion would whiz by without much more than a laugh, was shocked to hear that Matthews thought it possible.\u00a0\nInfluenced by American behavioral psychologist B.F. Skinner, Matthews and his team developed a backward-chaining\u2014that is, working backwards from the goal\u2014three-step process for training cows.\u00a0\nFirst, they established a specially constructed latrine as the correct place to \u201cvoid.\u201d Individual calves were given a diuretic and led into the latrine. Every time a calf urinated, they were rewarded with either a molasses drink or crushed barley\u2014\u201cBen and Jerry\u2019s [for] cattle,\u201d described Matthews. Training sessions, which lasted for no more than forty-five minutes, were continued until the calves turned to receive the reward after urination eighty percent of the time, or until eight or ten sessions had been completed. At this stage in the training, Matthews and his team were unsure whether they had only conditioned the calves to expect reward upon urination, or whether they had also established the latrine as the correct location for urination.\nNext, the calves were allowed to roam freely in a segment outside the latrine. Calves that moved into the latrine to micturate\u2014that\u2019s jargon for urinate\u2014were rewarded, while \u201caccidents\u201d outside the latrine were punished with a three-second water spray. Calves were considered sufficiently trained after three consecutive correct urinations occurred during a session. By the end of the study, eleven of sixteen calves were declared successfully trained.\nFinally, a second section was opened leading to the latrine, requiring the calves to control their reflexes over an extended time period and distance. Remarkably, successfully trained calves urinated in the latrine approximately seventy-two percent of the time without any corrective intervention from the experimenters.\nMatthews and his team hope that their research findings will be implemented by large and small-scale operations around the world. Matthews acknowledges that there will be some challenges in scaling-up the training, but he is confident that modern technology exists to enable training on a large scale. He suggests that young calves\u2014which are handled frequently and can be kept individually\u2014be monitored and rewarded using machine vision. Maintaining the correct behavior will require careful design and strategic positioning of the latrines, but Matthews is optimistic that \u201c[they] can crack it.\u201d\nMatthews suggests that punishment for urination outside may not be required for training. During the training process, some of the calves were successfully trained without the three-second water spray. Of the calves that were punished, most immediately stopped urinating, entered the latrine, and finished their business. \u201cThe latent behavior was already there,\u201d Matthews said, \u201cThe calves just needed a reminder for it to be correctly expressed.\u201d\u00a0\nThe calves are like \u201ckids who know the toilet, [and] know the routine. They just get so distracted,\u201d Matthews said.\u00a0\nHe also thinks that training processes that reward for correct behavior inherently punish incorrect behavior: the absence of a reward following incorrect behavior is itself corrective. Matthews and his team will further explore this possibility in the future, as eliminating the punisher will facilitate training on a large scale.\nMatthews\u2019 research has demonstrated that these \u201cdopey\u201d ruminants are actually quite intelligent. Through training, they can gain an interoceptive awareness of their urinary systems and learn to control their reflexes\u2014often faster than an infant. And we have a lot to gain when we don\u2019t underestimate cows\u2019 brainpower: capturing eighty percent of cow urine will reduce ammonia emissions by fifty-six percent and significantly reduce the release of nitrous oxide.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/cow-total-101/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Bacterial Birth of \u2018Living Medicine\u2019",
            "author": "Simona Hausleitner",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Hausleitner_fig1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Every year, millions of patients recover from life-threatening surgeries and other medical procedures, only to get a secondary infection caused by the presence of bacterial, fungal, or viral particles on medical implants. In fact, the Centers for Disease Control (CDC) estimates that healthcare-associated infections account for an estimated 1.7 million infections and 99,000 associated deaths each year in the United States alone. Medical implants such as catheters, pacemakers, and prosthetic joints act as ideal habitats for biofilms\u2014bacterial colonies that aggregate on smooth surfaces and remain highly resistant to treatment with antibiotics.\u00a0\nIn the past, the only methods for treatment involved surgical removal of the implant or degradation of the biofilm using enzymes, which often had toxic effects on the human body. Researchers at Pulmobiotics, a spinoff company from the Center of Genomic Regulation in Spain, have recently developed a state-of-the-art technique to solve this problem: \u201cliving medicine,\u201d or the introduction of genetically engineered bacteria to fight the dangerous pathogens within the body.\u00a0\nIn this technique, researchers decide on a \u201cgood bacterium\u201d to use, then remove specific genes to eliminate the infectious or disease-causing capability of the bacterium. They then equip the bacteria with an engineered genetic platform designed to secrete antibiofilm and bactericidal enzymes\u2014giving the bacteria the ability to disintegrate or \u201cfight\u201d infectious biofilms.\u00a0\nMaria Lluch Senar, a biotechnologist who formerly worked at the Center for Genomic Regulation before founding Pulmobiotics with her research partner Luis Serrano, has been working with the bacterium Mycoplasma pneumoniae for over ten years in an attempt to characterize its genome. Ultimately, the researchers sought to create a bacterial chassis, a genetic framework that could house and support exogenous DNA without interfering with the bacterium\u2019s functional purpose: targeting ventilator-associated pneumonia.\u00a0\nWith a mortality rate of ten to fourteen percent, ventilator-associated infection is caused by pathogenic bacteria like Staphylococcus aureus, which \u201cgrow in thick layers that are very difficult to target by using conventional antibiotics because [the antibiotics] cannot cross [the bacterial] barrier,\u201d Senar said.\u00a0\nThus, the lab aimed to engineer a bacterium that could fight against biofilm infections: removing the pathogenic factors of M. pneumoniae DNA while concurrently adding synthetic promoters and sequences designed to destruct S. aureus biofilms in the lungs.\u00a0\nThe researchers chose to use M. pneumoniae for their microbial chassis due to several favorable biological characteristics. The bacterium, for example, had known activity in lungs. \u201cWhen you want to engineer a live biotherapeutic, it is important to look for bacteria that is naturally present, or already colonizing, the target organ,\u201d Senar said. M. pneumoniae also had a genetic advantage: \u201cThe strain has a unique genetic code that prevents gene transfer,\u201d Senar said. Moreover, M. pneumoniae\u2019s slow division allowed for an expanded production time scale in the lab and provided additional control over the bacteria\u2019s replication rate in vivo. Thus, if there was a major problem with the delivery system of the chassis, it was easier to contain the spread of bacterial growth and remove the bacteria from the patient\u2019s lungs.\u00a0\nHowever, the biggest advantage of M. pneumoniae was its lack of a cell wall. The immune system\u2019s pathogen recognition mechanisms often target bacterial cell walls; thus, this feature of M. pneumoniae would allow it to escape immune recognition, preventing host elimination of the microbial chassis. This also allows for a combined treatment approach: after the bacterial chassis secretes biofilm-dispersing agents, antibiotics and bacteriolytic enzymes can be co-administered to attack the cell wall of S. aureus without damaging M. pneumoniae.\nThe researchers delivered the biofilm-fighting genes to M. pneumoniae with plasmids, circular pieces of DNA that can be transferred from cell to cell. They assembled the plasmids from DNA fragments of genes of interest using the Gibson method, a molecular cloning technique. Of interest, the researchers delivered genes that drove continuous, localized production of dispersin B, a hydrolytic enzyme that breaks down S. aureus bacterial cells, to provide long-term disruption of the biofilms. After genetically engineering their M. pneumoniae, the researchers tested their chassis in mice models to verify its safety and efficacy.\u00a0\nThe research team is also looking beyond S. aureus biofilms. Due to the natural ability of M. pneumoniae to colonize the respiratory tract, bacterial therapies hold important future potential in many medical therapies. \u201cThe 21st century is becoming the century of synthetic biology,\u201d said Senar, highlighting genetic engineering\u2019s increasing potential to create novel treatments for a wide range of diseases, from cancer to \u200b\u200bchronic obstructive pulmonary disease.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/the-bacterial-birth-of-living-medicine/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Unpacking the Cell\u2019s UPS: The role of vesicle tethers in cell membrane fusion",
            "author": "Alexandra Paulus",
            "authorLogo": "",
            "date": "February 28, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/paulus-fig-1-new-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of iStock.\nVesicular transport is a vital process that allows proteins to travel from one location to another in package-like vesicles. When a vesicle reaches its target membrane, it has two fates. It can undergo full fusion, in which the vesicle completely fuses with the membrane to deliver its cargo. Alternatively, it can undergo kiss-and-run, in which the vesicle connects with the membrane before rapidly reclosing. Seong An, a research associate at the Yale School of Medicine, discovered that bridge-like vesicle tethers, such as exocyst complexes, play an unexpected role in fusion mode selectivity.\u00a0\nTo investigate the exocyst\u2019s role in the tethering process, An first mutated Exo70, an exocyst subunit, so that it could no longer directly bind to the membrane. Unexpectedly, this did not prevent tethering\u2014instead, it promoted kiss-and-run over full fusion. When membrane binding by the mutated Exo70 was \u201crescued\u201d using optogenetics, a technique that uses light to control protein function, full fusion occurred. Finally, An found that in the absence of the exocyst, vesicles that were optogenetically tethered to the membrane merely underwent kiss-and-stay, a version of kiss-and-run in which the vesicle remains at the membrane after fusing. \u201cThe evidence suggests that membrane binding by Exo70 is not necessary for tethering but vital for the mode of vesicle fusion,\u201d An said.\nFurther research may shed light on cellular processes such as cell migration, as full fusion events play a role in membrane expansion. \u201cNow that we\u2019re able to observe vesicle tethering in real time, we can study what kind of impact membrane fusion has physiologically,\u201d An said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/unpacking-the-cells-ups-the-role-of-vesicle-tethers-in-cell-membrane-fusion/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Reintroducing Forest Fires",
            "author": "David Zhang",
            "authorLogo": "",
            "date": "February 21, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Prescribed-Burn-500x223.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "A prescribed burn. Image courtesy of National Park Services\nFor the past hundred years, human interventions\u2014including fire-suppression policies\u2014essentially removed fire as an ecological factor from New England forests. The lack of fires has drastically altered the landscape of these forests. Past studies have shown the short-term implications of the removal of regular disturbances such as low-intensity fires, but a recent publication by researchers at the Yale School of the Environment characterized the long-term effects of reintroducing prescribed burns on southern New England oak-hickory forests. \u201cBy reintroducing fire, we were trying to return the forest to its natural state,\u201d said Caroline Borden, first author of the study.\u00a0\nImplementing a cutting and burning treatment, the researchers conducted a before-after-control impact study to collect data on control plots that were never burned and treatment plots that were burned on several occasions over a twenty-three-year period. After removing the midstory (middle layer trees) and some of the overstory (upper layer trees) by cutting, they collected data on the remaining overstory and understory (ground level plants) before and after the burn treatments. They also collected soil samples after multiple burn treatments.\u00a0\nComparing the control and treatment plots, the researchers showed that prescribed burning, which mimics the low-intensity fires that were likely observed over large areas of southern New England during pre-European settlement, resulted in greater understory plant density and diversity, driving compositional shifts towards more shade-intolerant plants. Furthermore, there was a higher level of variance in soil nutrients like nitrogen and potassium on burned plots, which may be a potential driver of increased understory diversity. Together, these results show the potential of a cut and burn treatment. \u201cThe combination cutting and burning treatment appears to be successful at driving compositional shifts and maintaining high understory diversity,\u201d Borden said.\u00a0\u00a0\nThe suppression of fires over the last 100 years has played a role in recent catastrophic wildfires on the West Coast. \u201cWith the suppression of fire, the forests have become way overstocked in carrying capacity, and with the onset of recent droughts\u2014more severe because of shifts in climate\u2014trees have become\u00a0stressed, predisposed to insects and disease, and subsequently many of the stems are now standing dead,\u201d said Mark Ashton, principal investigator of the study. \u201cOne dry lightning strike or human match and the whole lot goes off.\u201d\u00a0\nBorden hopes this research will help guide future implementation of prescribed burns. \u201cMy biggest goal for this publication is that it falls into the hands of other researchers and foresters working in similar oak-hickory systems so that it can inform their\u00a0use of prescribed burns in the future.\u201d Borden said. \u201cThis was one reason that we chose to publish it in\u00a0Fire Ecology, an open-access journal.\u201d\u00a0\nStudying this site has been extremely rewarding for Borden. \u201cAs a student researcher,\u00a0one of the most exciting aspects of this project was being able to situate our observations in the broader historical context of this ecosystem,\u201d Borden said. Members of the Ashton Lab just implemented another prescribed burn in the spring of 2020, and Borden hopes that future researchers will continue to study this site.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/reintroducing-forest-fires/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Altering MicroRNA Function",
            "author": "Hannah Barsouk",
            "authorLogo": "",
            "date": "February 21, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2-2-500x281.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Qiagen.\nHave you ever wanted to do something, just because you were told you can\u2019t do it? Worry not\u2014people aren\u2019t the only ones susceptible to reverse psychology. Even at the level of our own cells, forcing little rebellious RNAs to \u201cclean their [molecular] bedroom\u201d isn\u2019t always straightforward. But a pair of trained eyes can dream up the right techniques.\nAlex Svoronos and Donald Engelman weren\u2019t always the microRNA experts they are today. While working on a separate project for his PhD in Biomedical Engineering in Engelman\u2019s lab at Yale, Svoronos noticed something strange about these small non-coding sequences. MicroRNAs control gene expression by silencing the signals carried by messenger RNAs (mRNA) before they can be translated into protein. But while examining literature about the genes they affect, Svoronos found some contradictions. \u201c[One paper] would say a specific microRNA\u2019s function was one thing, while another paper would claim it to have a completely opposite function,\u201d Svoronos said.\u00a0\nWith their interests piqued, the researchers randomly selected microRNAs referenced at least fifty times across various publications. \u201cWe observed conflicting reports for eighty-five percent of the microRNAs we looked up,\u201d Svoronos said. Wanting to further explore these inconsistencies, the Yale researchers selected miR-125b\u2014a known regulator of genes associated with cell proliferation, apoptosis, and metastasis\u2014as their microRNA guinea pig.\u00a0\nComputational and mathematical modeling combined with cell experiments revealed something incredible: the initial relative amount of miR-125b\u2019s target genes in the cell determines which gene the RNA silences. For example, if a greater concentration of genes that inhibit apoptosis are originally present in the cell, miR-125b will silence these genes and therefore promote apoptosis. On the other hand, if a greater proportion of genes expressed are pro-apoptotic, the molecule will inhibit these genes and prevent apoptosis. Seemingly changing its mind depending on what\u2019s most popular, our rule-breaking miR-125b simply can\u2019t stick to the status quo.\u00a0\nLooking forward, Svoronos and Engelman are exploring applications of their new understanding. But knowing we can one-eighty the role of microRNA in a cell by expressing more of one target gene or another fundamentally changes how we view these molecules. MicroRNAs\u2019 ability to selectively silence cancer genes could be exploited in the development of new anticancer drugs, vaccines, and other therapies. And as Alex Svoronos parts with the Engelman lab to complete his medical residency in ophthalmology, his PhD work will hopefully follow him, as the next decade brings about microRNA therapeutics to treat disorders of the eye.\u00a0\nOur understanding of microRNAs still needs to grow up quite a bit. But as researchers explore potential avenues, they can take a lesson from microRNA\u2019s book and know it\u2019s always alright to change their minds one, two, four, or sixteen times.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/altering-microrna-function/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Fine Dust: Improving Prediction Models",
            "author": "Breanna Brownson",
            "authorLogo": "",
            "date": "February 21, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fine-Dust-500x351.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nFor those living in China, the simple act of stepping outside poses a major health risk. With each breath, people\u2019s lungs are filled with loads of tiny dust particles known as fine particulate matter (PM2.5). After breathing this air day after day, people are likely to experience throat and lung irritation. Medical conditions such as asthma and heart disease are often worsened by long-term exposure to air pollution.\u00a0\u00a0\nResearchers at the Nanjing University of Information Science and Technology have discovered that there are more of these particles in the air than previously predicted. The existing Weather Research and Forecasting model underestimated sulfate concentrations by eighty-one percent while overestimating nitrate by 184 percent and ammonium by fifty-seven percent.\u00a0\nBy taking the amount of water in clouds into account, researcher Tong Sha developed a model that more accurately portrayed the sulfate, nitrate, and ammonium concentrations in the air. Because much of the sulfate in the air ends up in clouds, cloud water content had to be analyzed. Supplementing the model with satellite observations of factors such as cloud cover, therefore, created more precise predictions to reflect atmospheric observations.\nThis new model will aid in creating better strategies to improve air quality. \u201cWhen the fog appears, we should adhere to the emission control strategies and reduce the sharp increase of PM2.5 concentration after the fog dissipation,\u201d Tong Sha said. Factory emissions should be reduced for a significant period of time following foggy days, since the high water content in clouds can retain more particulate matter.\nThis study will serve to reduce the impact of normalized mean bias, a type of bias in which people minimize environmental threats. By creating a more accurate model for studying fine particulate matter, this research will help combat air pollution.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/fine-dust-improving-prediction-models/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Circumtriple Star System with a Possible Planet",
            "author": "Sarah Feng",
            "authorLogo": "",
            "date": "February 12, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Feng-Figure-1-500x275.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of the European Southern Observatory.\nWhat if you lived on a planet where the sun never set\u2014in fact, where there were three suns? A new study by Jeremy Smallwood and his team at the University of Las Vegas, Nevada, along with collaborators from other universities, suggests that scientists may have found the first planet to orbit three stars at once. In a paper published in the Monthly Notices of the Royal Astronomical Society, researchers discovered that GW Ori\u2014a star system 1,300 light years from Earth in the Orion constellation\u2014is a circumtriple star system with three stars orbiting around each other within a loose, massive dust ring surrounding all three stars.\nUsing observations from the Atacama Large Millimeter/submillimeter Array Radio Telescope, scientists discovered a break in the disc of gas surrounding the system at 100 au (astronomical units, or the average distance from the Earth to the sun), as well as misalignments between each of the rings. Smallwood noted that there were two possibilities to explain this break in the gas disc: the triple star system\u2019s torque, or a planet orbiting the stars that is large enough to create this gap. Through the experiment, Smallwood\u2019s team theorized that it is likely the latter: a Jupiter-like, unhabitable planet.\u00a0\nIn May 2020, a team from the University of Victoria in Canada first initiated an investigation into GW Ori. Using ALMA telescope observations, they identified the three dust rings at 46, 188, and 338 au and first discovered the eccentricity of the innermost ring. Another team at the University of Exeter followed up on the study later in the year, arguing that the triple star system\u2019s torque was responsible for the gaps. Smallwood\u2019s simulation proved otherwise, as the team saw that the torque was insufficient to tear the disc like they saw in the data.\n\u201cIt was startling because we haven\u2019t seen a planet orbiting a circumtriple disc,\u201d Smallwood said. Planets easily form around binary star systems, but this is the first to be found orbiting around three stars. It\u2019s more unique to only orbit one star, like in our solar system.\u00a0\nIn protoplanetary disks of gas and dust, giant clouds of gas contract due to gravity, forming stars. As stars are born close together, their gravitational pull binds them together until they fall into relatively stable orbits. Occasionally, tighter binaries can sieve and accrete materials from others, but in this system, the stars are loose and orbiting around one another with gaps. The GW Ori system is young enough\u2014Smallwood estimates around one to ten million years in age\u2014that any planets would still be in their gas giant phases. But with more time, more planets might form.\u00a0\nThe discovery of this three-star system raises the potential of planets with three stars that are habitable. \u201cCurrently, [GW Ori] is not habitable. It\u2019s a Jupiter-like planet and it\u2019s mostly gas. But, in ten to a hundred million years, with rocky planets forming around?\u201d Smallwood said. Such a planet might be possible, if given the right conditions and enough time.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/a-circumtriple-star-system-with-a-possible-planet/",
            "captions": [
                "A visual computer model of the epicenter of GW Ori, based on data from the European Southern Observatory\u2019s Very Large Telescope."
            ]
        },
        {
            "title": "The All-In-One Battery",
            "author": "Alex Dong",
            "authorLogo": "",
            "date": "February 12, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-5-500x373.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Vijay Ramani.\nImagine an all-in-one battery that can both generate and store its own energy. Unitized regenerative fuel cells (URFCs) are devices that can, with the flick of a switch, convert hydrogen and oxygen into electricity and water, and vice versa. Bifunctional catalysts, which serve to speed up both reactions, are required in order for URFCs to be effective. One such bifunctional catalyst, Pt-pyrochlore, was discovered by a team led by Vijay Ramani, Roma B. and Raymond H. Wittcoff Distinguished University Professor at Washington University in St. Louis. Ramani has researched these hydrogen-oxygen fuel cells since his first year as a PhD student in Chemical Engineering at the University of Connecticut\u2014and has been enthralled ever since.\nThe two reactions performed by URFCs are the fuel cell reaction and the electrolyzer reaction\u2014exact opposites of each other. The former involves combining hydrogen and oxygen to generate water and electricity, while the latter is the reverse process, whereby water is split back into hydrogen and oxygen by adding electricity. \u201cIf you operate in one polarity, you combine hydrogen and oxygen to make water with electron flow, and if you switch the polarity, you can input electricity and split the water to give hydrogen and oxygen,\u201d Ramani said. Thus, this singular device can easily switch between generating fuel from water and electricity and converting the fuel into electricity and water.\u00a0\nRamani explained that the reversible conversion of hydrogen into protons and electrons is not a particularly difficult process. The main challenge involves transforming the oxygen into water and vice versa, since both reactions are sluggish. Thus, effective URFCs require a bifunctional catalyst that can make both of these reactions progress at a significantly higher speed to enable practical use. Scientists already knew the effectiveness of platinum as a catalyst for oxygen reduction and lead ruthenate pyrochlore as a catalyst for oxygen evolution, the opposite reaction. Ramani and his team effectively combined these two catalysts to yield Pt-pyrochlore, testing different combinations of metal compositions and optimizing bifunctional activity, surface area, and electron conductivity.\nThe implications of this successful bifunctional catalyst in URFCs are far-reaching. \u201cIt\u2019s a wonderful device for energy generation and storage,\u201d Ramani said.\u00a0\nFor instance, when energy sources are intermittent\u2014such as when electricity is generated from solar or wind energy\u2014URFCs can help buffer this inconsistent output. \u201cWhen the wind is blowing, you can essentially make and store hydrogen and oxygen through water electrolysis, and when the wind doesn\u2019t blow, you can use that hydrogen and oxygen to generate electricity to ensure a more constant output,\u201d Ramani said. This particular advantage is especially applicable to the space sector, where energy can be stored for lengthy periods of time, while electricity is generated whenever solar energy is accessible. Ramani, however, recognizes that these devices are still too expensive to be integrated into mass consumer applications.\u00a0\nNow, Ramani and his team are striving to work with industry partners to test and further de-risk the technology. \u201cIt\u2019s one thing to demonstrate something in the lab; it\u2019s completely different to take it to practice and make a commercial unit out of it,\u201d Ramani said. Ultimately, Ramani\u2019s work in improving URFCs through the Pt-pyrochlore bifunctional catalyst will make energy generation and storage more feasible, efficient, and streamlined.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/02/the-all-in-one-battery/",
            "captions": [
                "Scanning Electron Microscope (SEM) image of lead ruthenate pyrochlore and Pt-pyrochlore, which is the bifunctional catalyst."
            ]
        },
        {
            "title": "Regrowing Cartilage May Take an Electric Kick",
            "author": "Chloe Nield",
            "authorLogo": "",
            "date": "June 21, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Nguyen-and-Liu.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Thanh Nguyen.\nWhen Professor Thanh Nguyen began his position at the University of Connecticut, he was gifted a book about electricity in the body. Nguyen, who already had experience working with electric materials, was amazed by the possibilities of using such materials in medicine. Aware of the lack of treatment options for arthritis, he wondered if an electric material could be of use.\u00a0\nAccording to the Centers for Disease Control and Prevention (CDC), nearly a quarter of all adults in the United States suffer from arthritis. Arthritis results from problems in the cartilage tissue, which is especially difficult to heal because it lacks access to blood vessels, breaking down and leading to bones rubbing together.\nAt present, the primary treatment for arthritis is a cartilage tissue graft placed at the site of injury. Tissue can be taken from the patient themselves or others. However, this can lead to other arthritic problems, and the patient\u2019s body can reject foreign tissue.\u00a0\u00a0\nAlong with researcher Yang Liu, who had previous experience with tissue engineering, Nguyen began research on \u200b\u200bbiodegradable piezoelectric poly-L-lactic acid (PLLA) nanofiber scaffolds as a treatment for arthritis.\u00a0\n\u201cIn the lab, we use a very traditional medical polymer often used for surgical suture, so it\u2019s very safe, and transform it into a very special form so that it can produce an electrical charge when you apply force to it,\u201d Nguyen said.\u00a0\nNguyen and Liu found that this material could act as an electrical stimulator for cartilage regrowth. Electrical charge creates a friendly environment for tissue growth because it attracts stem cells, which are critical in repair. When PLLA is under pressure, such as a joint force, atom rearrangement within the scaffold creates a dipole. A huge breakthrough in the research was discovering that the negative side of this dipole better promotes the migration of stem cells.\nInitial research performed by Nguyen and Liu involved placing the PLLA scaffold in the joints of rabbits. Over two months, they have witnessed promising progress towards cartilage tissue regrowth. The main question now is: will it work in humans?\u00a0\nNguyen and Liu said that before clinical trials can occur, they want to explore three main issues. First, they need to see if the scaffold can survive under a load as heavy as the human body. Nguyen and Liu also need to discover how long the PLLA scaffold must be active so that the human cartilage tissue can regrow. A biodegradable material was chosen in the hopes that once the material has done its job, it will degrade and not require removal. However, this also means it must not break down until its work is complete. Finally, Nguyen and Liu explained that they want to optimize the scaffold before clinical trials, making sure that the scaffold can withstand the pressure of the human body while also emitting the optimal amount of electrical charge.\u00a0\nNguyen and Liu are excited for what\u2019s to come. In the future, they aim to research how the scaffold can be modified to treat various types of arthritis. Nguyen and Liu are hopeful to someday see these treatments realized in therapy for arthritis.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/06/regrowing-cartilage-may-take-an-electric-kick/",
            "captions": [
                "Thanh Nguyen (left) and Yang Liu (right) holding the PLLA scaffold."
            ]
        },
        {
            "title": "A New Battery Alternative",
            "author": "Elizabeth Lin",
            "authorLogo": "",
            "date": "June 21, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/car-6943451-500x250.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nWhile the idea of electric vehicles might sound appealing, the idea of your electric vehicle\u2019s battery combusting probably does not. As society shifts towards greener technology, many scientists and companies have looked into the potential of electric vehicles to reduce air pollution. However, society has been unable to integrate electric vehicles into daily life for various reasons. One major obstacle that scientists have been working to overcome is the lack of electric vehicle batteries that are both stable and easily produced.\u00a0\nElectron flow in batteries is facilitated through two electrodes, metal electrical conductors connected by a wire to form a circuit. These electrodes react with a surrounding electrolyte solution. As electrons flow through the circuit, the electrolyte offers a medium for positive ions to flow through, thus balancing the movement of electrons that is simultaneously occurring. An electrolyte has a high ionic conductivity if it allows for a high electron flow. The most conventional lithium batteries rely on organic liquid electrolytes\u2014solutions made of organic elements. However, these easily catch on fire, making them unsuitable for extensive consumer use. The only current alternative, stabler solid-inorganic electrolytes, are also unsuitable candidates for consumer use due to their complicated manufacturing processes.\u00a0\nGeorgia Tech\u2019s Professor Seung Woo Lee and Michael Lee have been working to find a solution to this. Earlier this year, they published an article highlighting a new material as a candidate for batteries. \u201cRubber electrolytes are safer due to their flame retardancy, and the synthesis methods of rubber electrolytes is\u2026highly possible to be adapted to the current roll-to-roll manufacturing process of battery production,\u201d Michael Lee said.\u00a0\nSo, what exactly is a rubber electrolyte? Seung Woo Lee\u2019s rubber electrolyte uses lithium salt, a cross-linked elastomer (a polymer with elastic properties), and plastic crystals. No one thought rubber, a famous insulator, would make for a good battery electrolyte, not even Seung Woo Lee and Michael Lee. \u201cWe were actually not working on the lithium metal battery at first. It was a breakthrough that we tried to do the lithium metal batteries in the lab,\u201d Michael Lee said. For him, coming up with the experimental design was the difficult part, while the subsequent experiments were relatively easy to execute.\nThe researchers use their materials to create a 3D structure with \u201ca high ionic conductivity at room temperature (portion of plastic crystal) and great mechanical stability (portion of elastomer ),\u201d Michael Lee said. This special 3D structure, which they refer to as a 3D interconnected plastic crystal phase, addresses the previous issue for rubber electrolytes in batteries: weak ionic conductivity. Furthermore, rubber\u2019s elastic properties offer it increased adaptability compared to solid electrolytes.\u00a0\nAlthough the feasibility of large-scale rubber electrolyte production needs to be investigated further, Seung Woo Lee\u2019s rubber electrolyte is promising for commercialization due to its relatively stable nature and the cheap cost of materials. \u201cThe ongoing research is basically [going in] two directions: one is to understand the 3D structures\u2026 all of the properties actually depend on the 3D structure. Trying to understand the structure and manipulate the structure is the first direction. The second direction is to scale up,\u201d said Seung Woo Lee. If proven easy to manufacture, these batteries could revolutionize not only electric vehicles, but also countless other products.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/06/a-new-battery-alternative/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Halogens: A Gaseous Peek into the Earth\u2019s History",
            "author": "Sydney Hirsch",
            "authorLogo": "",
            "date": "June 21, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/OceanPic-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Understanding the historical prevalence of elements on Earth offers us insight into the processes that led to our planet\u2019s development. One such group of elements is called halogens\u2014nonmetallic elements occupying the seventeenth column of the periodic table. Over time, the amount of halogens present on the Earth\u2019s surface has important implications and has been estimated to sit at about eighty percent\u2014putting only twenty percent of these gasses currently within the mantle (below the surface).\u00a0\nHowever, a pair of Yale researchers\u2014graduate student Meng Guo and Professor Jun Korenga\u2014found that this figure is a drastic overestimation. Attempting to validate previous estimates, the researchers instead found that almost ninety percent of stable halogens reside inside the present-day mantle! The error lies in the underlying assumptions of the prior calculations. The traditional method presumed that the ratio of elements in the crust and mantle have remained constant over time. When the Yale scientists abandoned this assumption, they realized that there is a mere ten percent of halogens on the surface of the present-day Earth.\n\u00a0Guo and Korenga\u2019s findings bear significant implications, not only for the history of halogen expulsion from and absorption into the mantle, but also for understanding the origins of life on Earth. The new budget suggests that the early Earth had high amounts of halogens on the surface that were gradually reabsorbed into the mantle over time. The significant takeaway relates to ancient seawater chemistry: a greater-than-expected presence of halogens would have affected the pH and alkalinity of the planet\u2019s oceans. \u201cThere is debate about where life started. The ocean was proposed to fertilize the origin of life, but our results indicate that the ocean may have been too salty\u2014three times saltier than the present-day ocean\u2026 It was more likely within inland freshwaters,\u201d Guo said. To further this research, Guo intends to develop a simulated model allowing for further holistic analysis of the solid Earth.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/06/halogens-a-gaseous-peek-into-the-earths-history-2/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Modeling Mind: Theory of Mind in Linguistic Communication",
            "author": "Katrina Starbird",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/mind_image-500x382.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Noora Said.\nConsider a Thanksgiving dinner where your mother asks you to set the table. She tells you to put out the square plates, the nice water glasses, and the large napkins. But when you go into the kitchen, you find that there are multiple square plates, you have forgotten which glasses your mom likes, and the napkins are all the same size. You guess which ones she wants and bring them all out. Unfortunately, all your guesses were wrong. You\u2019ve let your mother down. And now Thanksgiving is off to a highly traditional start\u2014all because of an issue in communication.\nCommunication is fundamental to the functioning of our society, but too many of us often fail to use it effectively in our interpersonal interactions. Researchers in psychology like Yale University\u2019s Julian Jara-Ettinger and the University of Oslo\u2019s Paula Rubio-Fernandez are deep in the weeds trying to understand what underlies this miscommunication. Most recently, they have focused on studying how our minds use linguistic communication to reference objects. Through their research, they hope to learn how we come to know what is in another person\u2019s mind.\nThe Experiment\nIn a series of three experiments, Jara-Ettinger and Rubio-Fernandez presented participants with a virtual trackpad that has four quadrants, each containing an object. For the first two experiments, this object is a simple shape. Its size and color vary from quadrant to quadrant. Participants also see a line of text that refers to one of these objects\u2014for instance, \u201cthe rectangle\u201d\u2014and are expected to click on that object. The participants are informed that these directions are written by someone who cannot see the contents of one of the four quadrants (\u2018the director\u2019). The participants\u2019 mission is to deduce where the blindspot is. Variations in the words used to indicate the target object may give clues.\nConsider a situation in which there are two rectangles of different colors on the screen, but one of them lies within the director\u2019s blindspot. The director will indicate \u201cthe rectangle\u201d rather than \u201cthe blue rectangle\u201d because it does not know it needs to distinguish between colors, only between shapes. This principle of not giving more information than necessary is known as a Gricean maxim of communication.\nEach time after selecting the target object, participants also identify the quadrant they believe constitutes the blindspot. They indicate their confidence about both choices by clicking closer or further away from the center of the screen, which would indicate complete uncertainty.\nRubio-Fernandez explained that the research team wanted to create an experiment that would ask people to work through linguistic ambiguity in the same manner that they would encounter ambiguity in the world. \u201cThey use what the other person knows, which objects they know about, and take into account whether or not the other person uses adjectives contrastively or not,\u201d Rubio-Fernandez said. \u201cThese three factors should allow someone with good social cognition to figure it out.\u201d\nIn the first experiment, the directions describe the target objects with adjectives regarding their shape and color. These are considered absolute adjectives because they have a fixed meaning\u2014a \u201cred cup\u201d looks red regardless of what color the cups around them might be. The second experiment repeated the process of the first but used size adjectives with a relative meaning. For example, when told to retrieve a \u201csmall cup,\u201d one would return with different cups depending on how big the surrounding cups are.\nThe second trial had an additional layer of uncertainty. The directions in this trial had some unknown propensity to use adjectives even though they would not be helpful in distinguishing between possible targets. For example, the director may ask for \u201cthe small triangle\u201d even when there is a display of all different shapes. This conditions the participant to believe that the director uses adjectives like \u201csmall\u201d where it is not necessary. Therefore, if the display later shows a new arrangement of shapes and asks for \u201cthe small rectangle,\u201d the participant cannot know whether the word \u201csmall\u201d is being used to contrast one rectangle from a second, thus making it harder to pinpoint the blindspot.\nThe third experiment replicated this experimental paradigm with real world objects rather than simple colored shapes.\nModels of the Mind\nTo understand how participants used language to identify the blindspot, the experimenters created two probability-based computer models that would go through the same trials as the human participants. They based these models on two different theories of how a person might try to approach the task.\nThe first model was based on a concept in psychology known as the \u201cTheory of Mind\u201d. Jara-Ettinger explained the model in terms of our interview conversation. \u201cYou\u2019re representing what\u2019s happening in my mind,\u201d he said. \u201cWhen you\u2019re talking with me, you realize that I\u2019m not just some regular object like a glass of water on a table. You have a very strong sense that there\u2019s a mental life inside of me. It\u2019s not just a curiosity; it\u2019s what you use to make sense of my behavior.\u201d\n\u201cTheory of Mind\u201d is the process of internally modeling the mental life of another. \u201cIt\u2019s a huge space of possible things that range from you knowing nothing to you knowing everything to you knowing some parts of things,\u201d Jara-Ettinger said. \u201cThen I can figure out, \u2018okay, so under which states of knowledge would your words make sense?\u2019\u201d\nThe first model, then, included three parameters: the random chance that the target object would be in the chosen quadrant (a one in four probability), the increased random chance that it would be in one of the quadrants visible to the director (a one in three probability), and the probability that the director was using as few adjectives as possible. The model calculated the last parameter based on the director\u2019s word choice in each experiment. This last probability factor allows it to consider the likelihood that the director is using adjectives unnecessarily, thus presenting a model of the director\u2019s mind.\nThe second model, or the \u201cdeductive\u201d model, is much simpler. It used only basic logic like \u201cthe blindspot cannot be one of the indicated squares\u201d to identify the blindspot. Because this model lacks the final probability factor from the \u201cTheory of Mind\u201d model, it can only reverse engineer the director\u2019s intent. It does not imagine the set of possible beliefs that the director could have. Rather, it identifies which quadrants the director can see to guess which quadrant is out of their sight.\nOur Minds\nJara-Ettinger and Rubio-Fernandez found that the \u201cTheory of Mind\u201d model was a great fit for the data derived from human trials across all three experiments, while the \u201cdeductive\u201d model was not. Both the \u201cTheory of Mind\u201d model and human participants were relatively successful at locating the director\u2019s blindspot. The high correlation between \u201cTheory of Mind\u201d and data from human trials suggests that it is likely that people use \u201cTheory of Mind\u201d in their everyday lives.\nJara-Ettinger said the results give us reason to marvel at the power of our minds. \u201cIf we designed the model to make the best possible inferences it can and participants are giving you identical answers, it seems that on average, participants are also giving you the best possible inferences,\u201d he said.\nBut what does this mean for daily communication? If people are, in fact, relatively good at determining another\u2019s blindspots, why is it that we miscommunicate so many times each day?\n\u201cIt\u2019s very surprising because it seems that one of the most salient things for us is that in conversation, we get each other wrong,\u201d Jara-Ettinger admitted. But he then reoriented the question: \u201cYes, we do get things wrong, but we also just take for granted how often we get things right. We\u2019re just so used to getting inferences very quickly that we just kind of ignore those.\u201d\nFurther Reading\nKeysar, B., Lin, S., & Barr, D. J. (2003). Limits on theory of mind use in adults. Cognition, 89(1), 25-41.\nSources\nJara-Ettinger, J., & Rubio-Fernandez, P. (2021). Quantitative mental state attributions in language understanding. Science Advances, 7(47). https://doi.org/10.1126/sciadv.abj0970\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/modeling-mind-theory-of-mind-in-linguistic-communication/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Meta-Gut: Conservational Clues Provided by Hippo Poop\ufffc",
            "author": "Hannah Shi",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Meta_Gut_Hippos_detailed-Luna-Aguilar-500x269.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Luna Aguilar.\nConservation ecology is on everyone\u2019s mind today and with good reason. With global warming and imminent extinctions making daily news, the preservation of ecological biodiversity has never felt more urgent. To this end, conservation ecologists have made an effort to identify the key players in the most ecologically diverse ecosystems in the world, hoping to find clues about the relationships between organisms and nonliving factors that make such ecosystems high-functioning.\nKenya\u2019s Mara River Valley is a prime example. The fish, birds, and hippos in the Kenyan Masai Mara are interdependent for survival, but recent evidence suggests researchers have overlooked the key players: microbiota. The ecological stability of the Masai Mara is characterized by the relationship between these two biotic spheres, described by community coalescence theory. The basis of this relationship, as it turns out, can be found in hippo poop.\nThe Meta-Gut\nThousands of hippos in Kenya\u2019s Mara River Valley excrete an estimated 9.3 tons of feces each day. This waste contains gut microbiomes with trillions of bacteria and archaea, which may even function outside the animal itself. Christopher Dutton GRD \u201919, a postdoctoral associate in the Department of Ecology and Evolutionary Biology at Yale, and collaborators such as Amanda Subalusky GRD \u201916, who is also a postdoctoral associate in the same department, have found that the microbiome of hippos may play an unanticipated role in regulating biological and chemical processes within their larger ecosystem. \u201cIs it possible that these pools could actually, in a way, be functioning like an extension of the hippo gut?\u201d Dutton said. \u201cIt\u2019s kind of crazy to think that gut microbiota can be driving what\u2019s happening in this whole river.\u201d This continual exchange of organic matter between hippos and their environment has led to the proposition of a novel conceptual framework known as the \u201cmeta-gut.\u201d\nHippo Pools: What Makes Them Special?\nAll animals carry specialized microorganisms in their digestive tract which help facilitate biologically essential processes such as the metabolism of carbohydrates and the synthesis of amino acids, fatty acids, and vitamins. As hippos wallow in the Mara River, they unload their gut microbiota through the excretion of waste, introducing nutrients and microbes into the river. The meta-gut suggests that this continual loading of organic matter results in an environmental patch within an ecosystem that shares similar characteristics to the gut environment of the host animal. In other words, the river ecosystem inherits characteristics of the hippo gut.\nEven without expensive genomic technologies, Dutton and his colleagues had deduced that the constitution of the pools that had high hippo density \u2013 high-subsidy hippo pools \u2013 differed from pools further upstream. High-subsidy hippo pools were anoxic, or oxygen-depleted, with higher concentrations of methane, hydrogen sulfide, and minerals such as magnesium and calcium, as well as lower concentrations of oxygen and nitrates (compared to the oxic conditions of low-subsidy hippo pools and the Mara River itself). Genomic technology allowed the researchers to correlate these findings with the microbial communities found in both the hippo gut and high-subsidy hippo pools and identify the key microbes causing these biochemical differences in the pools.\nSpecifically, Dutton and his colleagues used 16S rRNA sequencing technology to compare RNA genomes across samples from areas in the Mara River with high and low hippo population density. 16S rRNA sequencing confers two benefits over other sequencing technologies. First, each organism has 16S rRNA specific to its species, making the 16S rRNA a highly-identifiable label. Second, since rRNA itself is a relatively short-lived biological molecule like RNA, researchers were able to characterize which members of the microbial communities in hippo feces actually play active roles in shaping the ecosystems the hippos inhabit.\nHippo Gut Influences on the Biogeochemical Cycles of the Mara\nThe idea of the meta-gut may revolutionize our understanding of the abiotic and biotic components in an ecosystem. Within high-subsidy hippo pools, certain biochemical differences were clear. For one, active microbial communities common to the hippo gut and hippo pools were strongly associated with higher concentrations of biochemical oxygen demand, methane, nitrous oxide, and hydrogen sulfite, suggesting that hippo gut microbes may be driving these chemical changes in the river. Secondly, as tons of hippo feces sink into the water, the river environment becomes anoxic. This chemical change may allow for the successful transfer of hippo microbiota into the river, and survival after, as microbes from within the gut are adapted to anaerobic environments present in the digestive tract of animals.\nAs this organic unloading occurs, the microbial communities from the hippo gut can colonize the digestive tracts of other animals, including fish and insects, in the Mara River Valley. Multiple species of fish in tropical rivers consume hippo feces and, in doing so, may participate in the larger meta-gut. \u201cIf some of the hippo microbiota is colonizing the guts of fish and insects, you have to start asking yourself questions like, \u2018Is it possible that the fish that are living with hippos and consuming their feces are somehow gaining some type of physiological advantage from the gut microbiota that they\u2019re taking?'\u201d Dutton asked. If such processes are possible, migrating gut microbiota from one species to another can confer important biological advantages for adaptation.\nHippo Pools Over Time and Space\nThese biological advantages and the meta-gut itself are not constant over time. Characterizing the hippo pool microbiome before and after flushing flows (large torrents of water that essentially recycle the water of the hippo pools) showed that the hippo pool\u2019s microbiome best matched the hippo gut\u2019s microbiome in the intervals between flushing. Evidently, it takes time for the meta-gut to be established. Moreover, the flushing flow experiment also provided clues to how the hippo pools impacted upstream parts of the river. Directly after flushing, the hippo pools most resembled the upstream river regions, indicating that there are some innate free-living microbial communities that are common in all parts of the river. However, the microbes that most contributed to the biochemical and ecological stability of the high-subsidy pools were directly derived from hippo feces and were largely contained to the hippo pools.\nThe Hippo Gut and Ecological Stability\nThus, there\u2019s more to the Masai Mara hippos than meets the eye. When hippos and their neighbors swim around in feces, not only are the animals propagating their own gut microbiota, but that of an entire ecosystem. Our current understanding of ecosystems, and the organisms that comprise the biodiversity of the ecosystem, are largely limited to what we can see and touch. However, the team\u2019s work with the hippos\u2019 gut microbiota, and consequently, the river ecosystem microbiota, point to the importance and ubiquity of microorganisms. Without them, the entire river ecosystem could collapse. \u201cWhen species cohabitate, I think it\u2019s really important that we acknowledge that every organism living in the Masai Mara is sharing their microbes,\u201d Dutton said. \u201cThe more diversity you have on the landscape, the more of a chance that you\u2019re going to get the correct colonization in your gut that helps you survive.\u201d\nBut even if the hippo meta-gut is crucial to the river ecosystem, why should this matter to us? If the ecosystem functions, as far as the planet-conscious person is concerned, there isn\u2019t much harm. And yet, the preservation of biodiversity, beyond just the preservation of ecosystems, is one of the central goals of ecology. Dutton explained the difference between a partially functioning ecosystem and an effectively functioning ecosystem. \u201cBiodiversity is so important, specifically [when we\u2019re] looking at the effective functioning of ecosystems,\u201d Dutton said. \u201cWhen we throw ecosystems out of whack, that\u2019s when we start to get these problems of excess carbon in the atmosphere from CO2, methane, and nitrous oxide.\u201d Thus, the preservation of the gut microbiome of the larger species, like hippos and beavers, in the Masai Mara is just as important to the functioning of geochemical systems as the preservation of the observable species themselves.\nFuture Steps\nNext, Dutton wants to specifically identify the taxa of the hippos\u2019 gut microbiota involved in nitrogen and carbon recycling that ultimately contribute to the growth and survival of plants, animals, and our planet. He will work with the hippos at an experimental stream facility at Disney and do detailed sampling of the biochemistry in microbial communities. Specifically, Dutton is excited about using metatranscriptomics, a technique that sequences the active genetic code in a cell to indicate what functions the cell is carrying out in real-time. Identifying the communities of microbiota that are functioning will enable the team to distinguish between the species that are present in the feces and those that play significant roles in the functioning of the meta-gut ecosystem.\nUltimately, the hippo meta-gut is a microcosm of all ecosystems, where the role of the microbiota has been largely underestimated. The respective focuses of ecologists and microbiologists studying this have been largely divergent until the concept of meta-guts was shown to be critical to the geochemical cycles that improve the welfare of the entire ecosystem and, ultimately, the entire planet. Thus, as we focus on the warming of the planet and the accumulation of carbon in the atmosphere, we must consider the preservation of biodiversity, from the smallest species to the largest. Though it might seem unexpected to think that part of the solution to climate change and ecological preservation is lodged in hippo poop, a better appreciation of the interspecies relations in an ecosystem and the roles they play will fill a critical gap in our understanding of life on our planet.\nFurther Reading\nCastledine, Meaghan, et al. \u201cCommunity Coalescence: An Eco-Evolutionary Perspective.\u201d Philosophical Transactions of the Royal Society B: Biological Sciences, vol. 375, no. 1798, 23 Mar. 2020, p. 20190252, 10.1098/rstb.2019.0252. Accessed 27 May 2021.\nSources\nDutton, Christopher L., et al. \u201cThe Meta-Gut: Community Coalescence of Animal Gut and Environmental Microbiomes.\u201d Scientific Reports, vol. 11, no. 1, 30 Nov. 2021, 10.1038/s41598-021-02349-1. Accessed 2 Jan. 2022.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/the-meta-gut-conservational-clues-provided-by-hippo-poop%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Visualizing the Heart of Photosynthesis",
            "author": "Shudipto Wahed",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/photosystemii-Ann-Marie-Abunyewa-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Ann-Marie Abunyewa.\nWater, sunlight, and a spoonful of sugar: a simple recipe that sustains much of life on Earth. Plants and other organisms famously use photosynthesis to convert light into the chemical energy that drives their lives. Central to this process is a protein complex called photosystem II (PSII), an enzyme that captures photons of light and breaks down water to release oxygen and protons.\nScientists have been interested in PSII since its discovery in the 1960s. Its relevance stems from the applicability of principles learned from biological solar fuel production to many fields, including synthetic photocatalysis, crop optimization, as well as evolutionary biology. Professor of Chemistry and Director of the Energy Sciences Institute Gary Brudvig has been studying photosynthesis for well over forty years. \u201cHis group has in many ways pioneered a lot of our most basic understanding of photosystem II,\u201d said Christopher Gisriel, a current postdoctoral associate at the Brudvig lab.\nBy the 1980s, researchers had identified a photosynthetic cyanobacterium that they could easily genetically modify. Studying this species, Synechocystis sp. PCC 6803 (Syn.6803), provided useful insights into PSII\u2019s photosynthetic mechanism, such as the specifics of water oxidation and electron transfer.\nWhat scientists could not do, however, was solve the molecular structure of this species\u2019 PSII protein. For biological proteins and enzymes, function is considerably affected by three-dimensional structure, like how a house-key works because of the proper arrangement of its grooves and how they fit within the lock. Because water oxidation is highly complicated, the lack of high-resolution structures to guide functional investigation has meant that many aspects of it remain unclear. \u201cSo basically, we\u2019ve been going in somewhat blind,\u201d Brudvig explained. \u201cIf you try to do structure-function studies with no structure, you\u2019re kind of on thin ice.\u201d\nIn an effort to fill in this gap, at the beginning of 2022, Gisriel and Brudvig\u2019s team published a Proceedings of the National Academy of Sciences (PNAS) study reporting the first cryo-EM structure of PSII from Syn. 6803. To the authors\u2019 surprise, there were a number of differences in the PSII structure compared to its previously presumed architecture, underscoring the need to re-examine previous data using this new structural blueprint. Not only do their findings challenge several time-honored notions about PSII\u2019s mechanism of action, but the reported structure also provides a basis for introducing tiny changes in the protein to unlock the mysteries of biological photocatalysis.\nThe Troubled Heart of Photosynthesis\nMuch of our knowledge of PSII can be attributed to site-directed mutagenesis experiments \u2013 in which targeted changes are made to DNA \u2013 conducted in the last fifty years. In these specific experiments, scientists introduced mutations in the PSII gene to assess the role of individual amino acids, which comprise proteins, in the enzyme\u2019s function. These studies have almost entirely been performed using Syn. 6803 cyanobacteria, which can survive with altered PSII if supplemented with glucose. This makes it an ideal model organism for mutagenesis because in many other species, mutations in PSII often led to cell death, leaving researchers unable to investigate function further.\nHowever, the molecular structure of PSII in Syn. 6803 had remained unsolved because the organism is sensitive to the harsh conditions required for techniques like X-ray crystallography, which is used to elucidate molecular structures. To this day, the only reported structures for PSII have come from thermophilic cyanobacteria, organisms that thrive in high temperatures. However, they are poor model organisms for mutagenesis experiments due to their intolerance of growing with altered PSII.\n\u201cAll this work has been going on in parallel\u2013 mutagenesis in organisms with no known structures, and structural determination in thermophiles that could not be mutated,\u201d Brudvig said. \u201cPeople just assumed that they were all the same and that they could use the thermophile as a basis for structure.\u201d Scientists have therefore been forced to proceed with this assumption to interpret their functional data.\nBut this approach may not be truly justified. Firstly, there are obvious differences in the DNA sequences of the PSII genes from mesophilic and thermophilic organisms, which implies diverging structure and function. Moreover, membrane proteins from mesophilic and thermophilic organisms are generally known to have different molecular characteristics. Thus, the study of PSII function is greatly limited by the lack of a high-resolution structure for the model organism from which most biophysical data comes: Syn. 6803.\nA Structural Blueprint\nLarge, often unstable, protein structures like PSII from Syn. 6803 are difficult, if not downright impossible, to crystallize for use in X-ray crystallography experiments. But there is now an alternative technique to visualize this three-dimensional structure: cryo-EM. Single-particle cryo-EM bombards a thin sheet of a protein solution with electrons, using a camera to detect how electron waves interact with the sample. A computer then reconstructs a 3D model of the protein from hundreds of thousands of 2D images in different orientations. \u201cI like to think of myself as a very, very high-resolution photographer,\u201d Gisriel said.\nThe Brudvig lab reported the structure of PSII from Syn. 6803 with single-particle cryo-EM at a resolution of 1.93 Angstroms (\u00c5). For reference, the average resolution for published cryo-EM membrane protein structures is ~5\u00c5. At this unprecedented resolution level, the Brudvig group could even see the presence of some individual protons within the complex.\nPSII is biologically found in a dimeric state, with two identical monomers, each containing twenty one subunits. The core consists of four subunits, with thirteen peripheral subunits embedded in the membrane and four \u201cextrinsic\u201d subunits found on the inner surface of the membrane. With their novel structure in hand, the Brudvig group could now identify any major differences between the thermophilic and Syn. 6803 PSII enzymes.\nCofactors are non-proteinous molecules within an enzyme that promote its catalytic activity. Most cofactors are indeed conserved between the two species, except for a pigment called BCR101, which helps absorb light energy. Previous studies had suggested that BCR101 was important to allow PSII to dimerize, where two identical PSII proteins chemically associate. However, even without BCR101, Syn. 6803 still retains a dimeric configuration, implying that BCR101 is not as crucial for this role. Interestingly, some peripheral and extrinsic subunits, namely PsbO, PsbU, and PsbV, are quite dissimilar between PSII from the different species. This was unexpected because these subunits surround the intricately controlled \u201cactive site\u201d of PSII, where the enzyme\u2019s catalytic activity occurs and performs key functions in water oxidation.\nThe last remaining extrinsic subunit, PsbQ, is found in both thermophilic and Syn. 6803 PSII. Notably, however, PsbQ had never before been observed bound in complex with the PSII protein. Its analysis revealed that its binding in Syn. 6803 is primarily driven by unique electrostatic interactions that are not present in the thermophilic cyanobacteria. PsbQ-binding does not induce any conformational changes in the PSII complex, so the authors believe that it mainly serves to provide additional protection for the active site.\nWater Channels\nThe authors were surprised to observe poor conservation of PsbO, PsbU, and PsbV between Syn. 6803 and thermophilic PSII structures. For decades, these extrinsic subunits have been thought to form channels into the active site to provide it with water to oxidize and routes for the protons and oxygen byproducts to exit. The striking differences observed in extrinsic subunit structures suggest that differences in these water channel functions are central to PSII\u2019s enzymatic activity.\nScientists had previously identified what they considered to be three main water channels: the large, broad, and narrow channels. Although the broad and narrow channel structures are relatively well conserved between Syn. 6803 and thermophilic PSII, the most notable differences were observed in the large channel. Analysis of thermophilic structures had suggested that the large channel may play an important role in transporting water and protons to and from the active site. However, the authors found that, in Syn. 6803, the large channel is completely blocked by extension of the PsbV subunit.\nBlockage of the large channel suggests that it may not actually be as crucial to PSII function as researchers had previously suggested. In fact, it is not much of a channel at all if one end appears to be closed off. These findings suggest that the narrow and broad channels may be the only ones that matter for water oxidation, which is supported by both their conservation in all known PSII structures and previous mutagenesis studies. Another plausible explanation is that PsbV may be involved in a sort of gating mechanism that selectively opens/closes the large channel.\nWhichever the case, this remarkable difference between the Syn. 6803 PSII and thermophilic PSII enzymes highlights the importance of the authors\u2019 reported structure. Without structural data from the model organism used for studying PSII, it is difficult to accurately interpret functional data, which could lead to assigning function in a manner inconsistent with true biophysical constraints.\nSignificance and Future Directions\nPhotosynthesis fuels the life of many organisms, from trees in the Arctic to hot springs cyanobacteria, to the grass outside Sterling Memorial Library. PSII is considered the only global solar fuel catalyst shared between all photosynthetic organisms and the central water oxidation enzyme. With this in mind, this research can help create a new generation of synthetic fuel catalysts, which could artificially reproduce this process of water-splitting to generate energy.\nThe structural differences in PSII from Syn. 6803 and thermophilic cyanobacteria have important implications in understanding the mechanism of water oxidation, suggesting that many of the field\u2019s prior findings may now require re-examination.\nWith cryo-EM, researchers can observe the structure of the mutated enzyme. This work holds vast promise in unlocking the mysteries that persist in understanding the biomolecular mechanisms of photosynthesis.\nFurther Reading\nHussein, R., Ibrahim, M., Bhowmick, A., Simon, P. S., Chatterjee, R., Lassalle, L., Doyle, M., Bogacz, I., Kim, I. S., Cheah, M. H., Gul, S., de Lichtenberg, C., Chernev, P., Pham, C. C., Young, I. D., Carbajo, S., Fuller, F. D., Alonso-Mori, R., Batyuk, A., . . . Yano, J. (2021). Structural dynamics in the water and proton channels of photosystem II during the S2 to S3 transition. Nature Communications, 12(1). https://doi.org/10.1038/s41467-021-26781-z\nSources\nGisriel, C. J., Wang, J., Liu, J., Flesher, D. A., Reiss, K. M., Huang, H. L., Yang, K. R., Armstrong, W. H., Gunner, M. R., Batista, V. S., Debus, R. J., & Brudvig, G. W. (2021). High-resolution cryo-electron microscopy structure of photosystem II from the mesophilic cyanobacterium, Synechocystis sp. PCC 6803. Proceedings of the National Academy of Sciences, 119(1), e2116765118. https://doi.org/10.1073/pnas.2116765118\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/visualizing-the-heart-of-photosynthesis/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Video Games for the Win",
            "author": "Crystal Liu",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Liu_Fig2-500x281.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Studio Bliquo.\nMarco, a fourth grader in an Italian public school, plays Skies of Manawak, a newly developed computer game, during class time supervised by his teacher. One zone in the game, \u201cThe Flight,\u201d looks like a typical action game: he collects objects, avoids obstacles, and battles enemies to fulfill a given quest.\u00a0\nOnce Marco finishes a level, he is directed to \u201cThe Village\u201d: this zone bears key characteristics of an incentive world, and he has to redeem points earned from \u201cThe Flight\u201d to decorate his village. The village comprises nine mini games, each designed to train a different cognitive skill. In one game that trains working memory, Marco is shown a series of graphics before being prompted to select the last three graphs he saw. In another game designed to cultivate split attention, he needs to control a person and a bird simultaneously, weaving around obstacles by jumping or sliding as the person and flying higher or lower as the bird. After he accomplishes a few tasks in The Village, Marco finally discovers the next quest that leads him back to \u201cThe Flight.\u201d Difficulties of the action segment and mini games are adapted based on Marco\u2019s performance on each task.\u00a0\nSkies of Manawak (SOM) is a child-friendly action video game developed by European researchers to train Italian reading skills in children and help develop the ability to pronounce words and texts fluently and accurately. They recruited 151 students aged eight to twelve without learning disorders in a public school for training. Students were randomly assigned either to the experimental group playing SOM or the active control group playing Scratch, a kids-tailored, interactive programming game.\u00a0\nResearchers integrated both Skies of Manawak and Scratch into the school curriculum. Students played the games during class time in a classroom for one hour twice a week over the span of six weeks. The training was simultaneously a social experience. \u201cFor example, the children that played Scratch not only learned the basics but also prepared a Christmas card altogether for their teachers and parents,\u201d illustrated Angela Pasqualotto, a post-doctorate researcher at the University of Trento and the University of Geneva who was the first author of the paper published in Nature Human Behavior.\u00a0\nParticipants were evaluated for their reading skills three times: before the training, right after the six-week period, and six months after the end of training. Besides word lists and meaningful texts, they are also asked to read out lists of pseudowords. Have you played the word-guessing game Wordle? How many times have you put in a word that reads perfectly fine, only to find out that it doesn\u2019t exist? Pseudowords are groups of letters that abide by the rules of pronunciation but aren\u2019t part of the vocabulary in a certain language.\u00a0\nAt the end of the six-week training period, students that played SOM demonstrated significant improvement in both reading speed and accuracy, while there was no difference pre- and post-test among students that played Scratch. This difference was maintained at a follow-up test six months after the training. This study pioneers in showing an improvement in reading accuracy in addition to reading speed, both of which are fundamental for literacy.\nBenefits of SOM were found to extend beyond improving literacy. The experimental group showed significant improvements in visuospatial attention and cognitive planning. The former was measured with a Bells Test adapted for children, where participants tried to find as many bells as possible amidst distractors in a graphic. The Tower of London test was administered to evaluate planning. This test is set up with two boards with pegs and several beads of different colors. Examinees try to move the beads on one board to match the pattern on the other in the least number of moves. Both advantages were maintained at the six-month follow-up. Further follow-ups twelve and eighteen months after training showed a small but significant improvement in Italian grades\u2014an advantage that grew over time.\u00a0\nBesides reading the text aloud, scientists also measured reading comprehension but found no significant improvement. \u201cComprehension is a more complex ability which requires many other subskills,\u201d explained Pasqualotto. However, she pointed out that comprehension was only measured right after the training, and long-term improvements in Italian grades may suggest slower and more modest progress in complicated skills like comprehension.\u00a0\nPrevious studies on non-conventional training tools have been largely centered around children with dyslexia, a learning disorder that involves difficulty in reading. Affected individuals have a hard time decoding letters and words into related speech sounds. This study extends positive findings in dyslexic children to a broader population.\u00a0\nIt took the experimenters over three years to complete the study\u2014two years on game design, followed by recruitment, training, and follow-up studies for up to eighteen months. Along the way, they encountered a variety of challenges. Game designers recruited over three hundred children aged eight to fourteen to help refine the SOM storyline and aesthetics. It was extremely tricky to get children at this age to follow instructions and to collect and analyze their opinions. When the game was finally ready for testing, researchers had to coordinate logistics with teachers and continuously edit their proposal to fit into the original curriculum.\u00a0\nUsually, in a randomized control trial, experimenters don\u2019t know whether a participant is assigned to the experiment group or the control group. This process of \u201cblinding\u201d reduces the researchers\u2019 biases when evaluating the participant. In this study, however, it was impractical to blind every experimenter, since at least one of them had to talk to school representatives and supervise the training. In the end, two experimenters were blinded, and the third, Pasqualotto, became the one who oversaw the entire program. Researchers compared the results scored by the blinded experimenters against combined results from all three of them and found no difference between the scores.\u00a0\nItalian is an extremely transparent language: from the rules of pronunciation, one can almost always pronounce the word correctly. In contrast, English is an opaque language, with numerous sounds corresponding to one letter and vice versa. In logographic languages like Chinese, there is no alphabet, and the reader needs to remember the sounds of each character. Pasqualotto and her team hope to assess the efficacy of SOM in other languages and compare it to that in Italian. \u201cMy expectation is that training attentional control and executive functions, particularly working memory and cognitive flexibility, could be beneficial for all languages,\u201d Pasqualotto said. But it will be interesting to investigate the potential differences in the extent of progress made across languages.\u00a0\nThe training was carried out before COVID-19 when social interactions were still largely unrestrained. However, with the global pandemic, it is harder not only for these interactions to happen in the classroom, but also for experimenters to meet with participants and administer the tests.\u00a0\nThe pandemic pushed Pasqualotto and her team to make it possible for children to play the game and carry out subsequent testing at home. While the game was originally developed on computers, the researchers are now coming up with a version on tablets, since touch-based technology is more accessible and popular in an average household. They are also renovating testing protocols, so that cognitive tests can be administered at home without the presence of experimenters. They hope to eventually develop a product complementary to school activities that is simultaneously useful for research purposes.\u00a0\nDespite the many challenges and obstacles, Pasqualotto has been pleased with what her team has achieved. \u201cResearch should have an impact on our life. This type of study is certainly demanding in terms of time and organization, but it also gives you a bigger reward and sense of satisfaction in the end,\u201d she said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/video-games-for-the-win-how-skies-of-manawak-is-improving-literacy-skills%ef%bf%bc/",
            "captions": [
                "Screenshot of Skies of Manawak Trailer."
            ]
        },
        {
            "title": "A Sticky Situation\u2026 Underwater",
            "author": "Eunsoo Hyun",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Hyun_Fig3-500x334.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nWhat do mussels have that we humans don\u2019t? Well, many things, but among them: the ability to stick to surfaces underwater.\u00a0\nStrong underwater adhesives have versatile and useful real-world applications ranging from underwater equipment repair to surgical glue. Researchers from the Washington University in St. Louis combined mussel foot proteins and spider silk to create a hydrogel that is able to adhere to surfaces underwater. \u201cNature already offers a wealth of materials, and some of them even outperform synthetic materials,\u201d said Professor Fuzhong Zhang, a lead researcher on the study. The mussel foot proteins naturally secreted by mussels allow them to adhere to a variety of surfaces, even in the harsh conditions of seawater. \u201cWe\u2019re inspired by natural materials that are very impressive in some aspects. The first step is trying to reproduce it. Once we are confident that we can synthesize the material with similar properties, then we can engineer it to make it perform better.\u201d Zhang said.\nAnd engineer it they did. The new adhesive hydrogel is able to stick to a wide range of surfaces \u2014 ranging from glass to mammalian tissues \u2014 underwater. The researchers began with the zipper-forming motif of an A\u03b2 amyloid protein, which conveniently tends to self-assemble into stable nanofibrils. Then, they added spider silk protein for much-needed material strength, and mussel foot protein for improved surface adhesion. The final hybrid protein was produced by engineered microbes. This process, which pushes the boundaries of traditional recombinant DNA technology, presented unique challenges to the researchers. \u201cThe mussel protein contains a special amino acid, DOPA, which basically offsets Tyrosine. It\u2019s not one of the 20 canonical amino acids. In our case, we have to engineer the bacteria so that it can incorporate DOPA into the protein with high efficiency.\u201d Zhang said. The incorporation of non-canonical amino acids is critical to the function of these tri-hybrid proteins.\u00a0\nThis microbial production of useful naturally-occurring materials has the advantage of allowing advanced, specific DNA control of functional groups. \u201cScientifically, the biggest challenge is to understand the sequence-property relationship of protein-based adhesives. With that knowledge, we will be able to create adhesives with desirable properties.\u201d Zhang said. The researchers were able to fine-tune the properties of the hydrogel \u2014 structure, strength, cohesion, adhesion \u2014 by adjusting the different domains and sequences of spider silk and mussel foot proteins.\u00a0\nOn a practical level, this novel hydrogel provides several advantages over pre-existing competitors in the field. Since the hydrogel is biocompatible and biodegradable, it is an attractive, unique candidate for tissue repair and surgical applications. Another feature is its mechanical similarity to collagen, a major structural element in the extracellular matrix. \u201cIt is critical for a surgical adhesive to have similar properties with the natural extracellular matrix because that can promote more rapid tissue repair and reduce the chance of failure.\u201d Zhang said. The hydrogel is also protein-based, as opposed to other previously developed polymer-based adhesives. One area in which a protein-based adhesive is necessary is coral restoration, where the adhesive must not only work well underwater, but also not release any potentially toxic materials.\u00a0\nThis project is an exciting example of the potential of synthetic biology. Zhang reminisced on the team\u2019s first, unexpected encounter with the possibilities of mussel foot protein. \u201cA few years ago, one of my graduate students, Eugene Kim (who is now an Assistant Professor at George Mason University), worked on this project. At that time, the adhesive protein he made looked the same as any other protein \u2014 it was just a powder that would dissolve in solution.\u201d Zhang said. Kim didn\u2019t test the proteins underwater \u2014 he simply added some protein solution between two aluminum bars. \u201cThe next day when he tried to pull, it was so strong he could not pull it apart. And he\u2019s a strong guy!\u201d Even before officially testing the material, the researchers found that it was strong enough to lift a full one-liter bottle of water despite only having a tiny area of adhesion.\u00a0\nSynthetic biology is a rapidly growing field, full of innovation and growth. \u201cI want people to learn more about the opportunity that synthetic biology provides to material science and material engineering. We would like to work with many researchers who believe in the power of synthetic biology. We welcome new students to join us and explore this exciting field together.\u201d Zhang said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/a-sticky-situation-underwater/",
            "captions": [
                ""
            ]
        },
        {
            "title": "On the Path to Bomb-Sniffing Insects\ufffc",
            "author": "Elisa Howard",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Howard_Fig1-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Baranidharan Raman. Have you ever considered hijacking an insect? While this may seem like an absurd idea, the notion of exploiting an organism for its biological attributes is not all that foreign. Take, for instance, the use of canaries in coal mines during the 1900s. The canary acquires oxygen both when it inhales and exhales, and this double dose of air results in the bird\u2019s increased vulnerability to carbon monoxide and other poisonous gases. Thus, the health of the canary provided a means for coal miners to understand the safety of their environment.\nProfessor of Biomedical Engineering Baranidharan Raman and colleagues at the Washington University in St. Louis aim to harness nature\u2019s incredible biology for a different purpose: hijacking the locust olfactory system to engineer bomb-sniffing insects. \u201cThrough evolutionary processes, biology has come up with these amazing small-molecule detectors that are present in your nose, my nose, as well as locusts,\u201d Raman said. In locusts, the approximately fifty thousand olfactory receptor neurons (ORNs) of each antenna convert odorants into neural signals that funnel into the antennal lobe. \u201cWhy not use the insect as a sensor, tap into the neural signals while the insect is interacting with the environment, and use those neural signals to understand whether chemical A or chemical B is present?\u201d Raman asked.\u00a0\nIn previous work, the researchers implanted electrodes to record neural signals in the antennal lobe, and they demonstrated that those neural responses provide a fingerprint to discern between explosive and non-explosive vapors in addition to different types of explosive vapors. In a recent study published in PNAS, Raman and his team investigated how locusts recognize a particular odorant regardless of stimulus history, dynamics, and context. \u201cYou can smell coffee in a coffee shop, grocery shop, or restaurant. It smells the same whether you are on the coast or in the driest of the Sahara Desert,\u201d Raman said. The same is true for locusts, but how?\nIn the presence of an odorant, neural signals from ORNs of the antenna drive the activity of cholinergic projection neurons (PNs) and GABAergic local neurons (LNs) of the antennal lobe. PNs and LNs reformat the signal, resulting in intricate spiking patterns among PN ensembles. Those PN patterns encode odor intensity and identity. To test the locust\u2019s invariant stimulus recognition ability, the researchers conditioned the insects through methods resembling that of Russian physiologist Ivan Pavlov. In the presence of a food reward, locusts automatically open their sensory maxillary palps. After the presentation of an odorant followed by a food reward in six training trials, the locusts learned to open their maxillary palps in response to the odorant alone.\u00a0\nRaman and colleagues examined changes in palp opening\u2014an indicator of odorant recognition\u2014in response to perturbations including varied stimulus dynamics, altered stimulus history, the existence of competing cues, and differences in ambient conditions. The results support the hypothesis that locusts detect an odor regardless of such perturbations. \u201cNow we know the behavior is stable. How stable are the neural responses?\u201d Raman questioned. The researchers recorded the activity of antennal lobe PNs and found much variability in odor-evoked firing for single-neurons and cell ensembles. \u201cThere was no single feature that was reliable and robust that allowed this percept of an odor to remain constant independent of all these perturbations,\u201d Raman said.\u00a0\nTo decode the neural responses, Raman and colleagues used a linear classifier. The classifier assigns a weight to each neuron and successfully predicts the presence of an odor if the sum of weighted neurons exceeds a threshold value. Investigating why the classifier works, they discovered two different ensembles of neurons in the locust olfactory system: ON neurons, active in the presence of the stimulus, and OFF neurons, active in the absence of the stimulus. The classifier assigns positive weights to the ON neurons and negative weights to the OFF neurons. \u201cWhen you combine the activity of all the ON neurons while subtracting the activity of the OFF neurons, if that sum is above a certain threshold value, the odor is present. Simple as that,\u201d Raman said. In fact, a classification scheme using only ternary weights\u2014positive one for ON neurons, zero for non-responders, and negative one for OFF neurons\u2014enables robust odor recognition.\u00a0\nUncovering more of locust olfaction through the study of ON and OFF neurons, Raman and his team are one step closer to exploiting biology\u2019s expertise to hijack the insect olfactory system. Next time you try to squash a bug, look closer. Bomb-sniffing insects are an innovation of the near future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/on-the-path-to-bomb-sniffing-insects%ef%bf%bc/",
            "captions": [
                "Researchers record the neural activity of locusts and decode those signals to determine the presence of odorants like explosive vapors."
            ]
        },
        {
            "title": "The Precise Choreography of Nature\u2019s Master Weavers",
            "author": "Hannah Han",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Han_Fig2-500x357.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr. \nIn one act of the famous ballet \u201cSwan Lake,\u201d fourteen dancers raise their arms and flutter their hands in synchrony, while the lead ballerina spins in a slow pirouette center-stage. As the ballet progresses, the dancers execute a series of choreographed motions\u2014jumps, twirls, and leaps\u2014that are distinctive for each of the four acts in the performance.\nThe sequence of a ballerina\u2019s movements can be applied to the equally elegant and complex process of spider web-building. Andrew Gordus, an assistant professor and behavioral biologist at John Hopkins University, has studied spider web construction for over five years. He explained that spiders, like ballerinas, build up a repertoire of techniques, such as leg sweeping, abdomen bending, and silk pulling, which they use during specific phases of web-building. When combined, these movements form the intricate architecture of their web.\nGordus\u2019s fascination with web-building began over five years ago, when he stumbled upon a stunning web while walking through Central Park. At the time, he wondered how such a small organism could accomplish such a complex feat.\n\u201cIt\u2019s amazing that an animal with a brain no bigger than a fly\u2019s built this web,\u201d Gordus said. \u201cAnd it\u2019s really impressive because if you went to a zoo, and you saw a chimpanzee build this web, you would think, \u2019Well, that\u2019s a really talented chimpanzee.\u2019 But this is being done by an animal with a really tiny brain.\u201d\nThis discovery prompted Gordus to read all of the existing scientific literature on web construction and to email researchers studying spider behavior. However, the field was not well-developed, and some of his questions remained unanswered.\nIn his last few months as a postdoc at Rockefeller University, Gordus\u2019s advisor allowed him to conduct experiments on spiders in a separate facility on their campus in New York City. When Gordus moved to Johns Hopkins University in 2016 to start his own lab, he continued studying web-building as a side project. Over time, more graduate students joined his lab, and the project gained traction, becoming the largest undertaking in his laboratory.\nThough Gordus is fascinated by the physical web itself, he is more interested in the behavioral processes that govern its construction. In his 2021 study published in Current Biology, Gordus studied the movements of hackled orb weavers, which are found in the western United States. Orb weavers typically build spiral-shaped webs using strands of silk that have the same dry, wooly texture as cotton candy. Gordus\u2019s love for these creatures is evident\u2014a red spider was sewn onto the black jacket he was wearing during our interview. (His hat was also emblazoned with a cartoon worm\u2014the other model organism he primarily works with in his lab is the roundworm, C. elegans.)\nIn his study, Gordus and his team were interested in inferring the spiders\u2019 internal states by examining the construction of their webs. He explained that every animal\u2019s behavior is dictated by a myriad of internal states, including hunger, sexual arousal, and emotion, that manifest in physical actions, such as grooming or mating rituals. \u201cThe question we wanted to know was: What are the behaviors that this web is a record of?\u201d Gordus said. \u201cWhat are the behaviors, the rules, [for each stage of] web-building?\u201d\nIn order to study these spiders\u2019 movements, Gordus and his team used infrared illumination and a high-speed camera, which captured the minute motions of each of the spider\u2019s eight legs. The entire process involved several attempts, unexpected failures, and an abundance of perseverance. Gordus said that they originally tried to study the spiders under red light, but the orb weavers refused to build their webs without complete darkness. The team then transitioned to infrared light, which is invisible to both humans and spiders.\nFurthermore, to track the orb weavers\u2019 movements, the scientists placed labels with infrared dyes on each of the spiders\u2019 legs, a technique commonly used to examine fly behavior. However, they were met with great resistance. \u201c[The spiders] hated having their limbs labeled, and they would just spend the whole time sitting there trying to take it off,\u201d Gordus said. \u201cAnd then, they would [sometimes stop building and would] stick to their own web, and we would come back, and they would just be dangling.\u201d\nInstead of the labels, the team decided to use a camera that detected the reflection of infrared light off of the spiders\u2019 bodies. They also adopted two recently published algorithms specifically designed for limb tracking, called LEAP and DeepLab Cut. The scientists first trained the algorithms on several thousand frames of spider movements, which they manually tracked. The algorithms were then able to track millions upon millions of frames, capturing the minute motions of the spiders\u2019 legs.\nAfter monitoring six different orb weavers, the team adopted a machine learning algorithm, called the hierarchical hidden Markov model (HHMM), to deduce patterns in web construction. The algorithm employed probability models to predict the spider\u2019s web-stage based on transitions in its behavior, without knowing where the spider was on the web. The researchers found that the predictions made by the HHMM mapped onto established phases of web-building based on the spider\u2019s position. This solidified the association between the orb weaver\u2019s distinct behaviors and specific phases of construction. Developing the model involved trial and error\u2014existing algorithms used to predict fly movements did not perform as well when applied to orb weavers, so they had to write their own code from scratch.\nAfter years of troubleshooting and diligent work, Gordus\u2019s lab finally developed a fully-fledged experimental system. Upon collecting their data and analyzing the results, the researchers came to a startling revelation. Contrary to their expectations, the orb weavers did not build their webs reflexively, moving from phase to phase without pausing. Instead, the spiders revised their work as they went, returning to past locations on their webs to rearrange misplaced strands of silk. Sometimes, the weavers even repeated entire phases of web construction before proceeding again, indicating that they might have internal models of their webs that they are attempting to replicate.\n\u201cWe were surprised [at] how frequently the spider could go back and try a prior phase over again,\u201d Gordus said. \u201c[The spiders are] constantly assessing what they\u2019re building with this internal goal, and [they have] a flexible way of trying to get to that goal.\u201d\nLooking ahead, Gordus\u2019s team hopes to study the effects of certain drugs on web construction in order to elucidate the neurological activity associated with each phase of building. The team is looking into the effects of two chemicals in particular: lysergic acid diethylamide (LSD), a potent psychedelic drug, and ecdysone, a steroidal hormone in arthropods that induces molting and influences decision making.\nAlready, the researchers have confirmed that ecdysone causes the orb weavers to stop building their webs at a certain stage. They also know that giving the spiders a microdose of LSD results in the construction of perfectly symmetrical, evenly-spaced webs. Gordus said he is interested in further studying the effects of LSD on neuromodulatory pathways, or chemical pathways in the brain that control internal states.\n\u201cIf the spiders build really good webs [after consuming LSD], then we want to know what changed in their behavior,\u201d Gordus said. \u201cAre they just executing the behaviors really well, like a professional web builder? Or do they have [obsessive compulsive disorder], and they\u2019re constantly doing a lot of error correction? We\u2019d like to know, what is the behavioral readout?\u201d\nBy deducing which motor neurons are activated in the spiders\u2019 brains after the administration of certain drugs, the researchers might be able to understand the effects of these chemicals on human behavior. For now, though, Gordus and his team are focused on studying orb weavers and the graceful, intricate choreography of their web-building.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/the-precise-choreography-of-natures-master-weavers/",
            "captions": [
                "A hackled orb weaver rests on its web. Gordus and his team used these animals as model organisms to study the construction of spider webs."
            ]
        },
        {
            "title": "Spanish Perro and Hungarian Kutya: Can Dogs Distinguish Human Languages?",
            "author": "Breanna Brownson",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Brownson_Fig1-1-386x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Dr. Laura Cuaya. \nJust about everyone with a pet has experienced the phenomenon of talking to an animal without any expectation of an intelligible response. Even though our pets don\u2019t understand exactly what we\u2019re saying, many pet owners claim that they have grown closer to their pets by talking to them. Have you ever wondered just how much your pet takes away from these interactions? Dr. Laura Cuaya and her fellow researchers at E\u00f6tv\u00f6s Lor\u00e1nd University\u2019s Department of Ethology have made great strides in understanding how dogs process what they hear.\nCuaya was motivated to study speech perception in dogs because of her personal experience moving from Mexico to Hungary with her dog, Kun-kun. \u201cBefore, I had only talked to him in Spanish. So I was wondering whether Kun-kun noticed that people in Budapest spoke a different language, Hungarian,\u201d Cuaya said.\u00a0\nCuaya noted that dogs are a particularly interesting species to study because their evolutionary history starts off completely separated from humans and later switches to taking place alongside humans with the advent of dog domestication. \u201cWith dogs, we have a wonderful opportunity to study the evolution of speech perception. Although humans and dogs are evolutionarily distant, due to the domestication process, both species have been sharing an environment for thousands of years. Dogs needed to adapt their social minds to a human environment. Understanding humans became important for them,\u201d Cuaya said. Although there are different biological mechanisms and neuronal pathways in dog and human brains, both species have developed unique manners of completing the same task\u2013\u2013recognizing human speech patterns\u2013\u2013over the course of their evolutionary history.\nCuaya conducted a study on eighteen family dogs (including her own dog, Kun-kun) to determine how the canine brain detects speech and represents language. Her research focused on determining how dogs react to four main types of sound: natural speech in a familiar language, natural speech in an unfamiliar language, scrambled speech in a familiar language, and scrambled speech in an unfamiliar language. To observe which parts of the dogs\u2019 brains were active in response to different types of speech, Cuaya used functional magnetic resonance imaging (fMRI), a scan that measures small changes in blood flow to map brain activity. Multivoxel pattern analysis (MVPA), a technique that correlates neural activity patterns to different areas of the brain where stimuli are processed, was used to analyze the fMRI results.\u00a0\nOne of the biggest challenges Cuaya faced was making sure the dogs stayed still in the fMRI machine. For fMRI scans to be usable, there can only be up to three millimeters of movement while the dogs are laying in the scanners. Dog trainers were brought in to teach the dogs to stay still for the duration of the scan, and dog owners stayed nearby throughout the entire scans to keep the dogs comfortable and relaxed. The dogs were free to leave at any time.\nCuaya found that the primary auditory cortex responsible for processing simple sounds in dog brains showed different responses to scrambled and normal speech. Furthermore, different neural activity patterns were seen in the secondary auditory cortex, the part of the brain that processes more complex noises, when dogs listened to the language they were most often exposed to compared to a language they hadn\u2019t heard before. Even though we don\u2019t teach our dogs the language we speak, they become familiar with it because of the evolutionary advantage associated with it. When we speak, our dogs are actually picking up on the rhythms in our voice and the sounds of our words. Dogs with the ability to recognize subtle cues in their owners\u2019 language were more easily domesticated, and with domestication came the benefit of food and shelter.\u00a0\nCuaya offered an analogy to help us better understand dog speech perception by comparing it to an experience many of us can relate to when traveling. \u201cMaybe you have experienced this feeling as a tourist in a new place. You think to yourself, I don\u2019t know what language that is, but I know it\u2019s not English,\u201d Cuaya explained. Dogs experience the same thing when hearing people speak in a language they aren\u2019t used to.\u00a0\nThe next time you go to vent about your day to your pets, maybe you\u2019ll think twice about just how much of your speech they\u2019re really picking up on. They might just be paying more attention than you think, and you have our mutualistic evolution with dogs to thank for that.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/spanish-perro-and-hungarian-kutya-can-dogs-distinguish-human-languages/",
            "captions": [
                "This picture is an artistic representation of how dogs interact with and process the world around them."
            ]
        },
        {
            "title": "Hazards of the Himalayas Clash with Today\u2019s Urbanization Patterns\ufffc",
            "author": "Daniel Ma",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Danielle-de-Haerne-Hindu--500x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Danielle de Haerne.\nThe Himalayan region\u2014Nepal, Bhutan, and the India Himalaya\u2014hosts not only intrepid mountaineers but also seventy-four million regular inhabitants. Thirty-six million of them live in areas susceptible to multiple natural hazards.\nYale researcher Jack Rusk, a graduate student at the Yale School of the Environment and the Yale School of Architecture who works at the Karen Seto lab, led a project whose machine learning model produced that last statistic. When considering wildfires, floods, and landslides as \u201chazards,\u201d forty-nine percent of people in the Himalayas live in areas susceptible to more than one of them\u2014despite those areas only encompassing thirty-one percent of the region\u2019s land. The model produced by Rusk and his colleagues provides data on the susceptibility of the Himalayas and allows geographers to consider hazard management in a novel way, treating different hazards not individually but all at once.\nAchievement of the models\nRusk\u2019s study is a part of the Urban Himalaya project, a NASA-sponsored collaboration between Yale, the University of British Columbia, Kumaun University in India, and the International Centre for Integrated Mountain Development (ICIMOD), an intergovernmental agency for the Himalayan region. The project seeks to understand two dimensions of the connections between Himalayan urbanization and natural hazards: how natural hazards affect urbanization and how urbanization processes can induce or prevent further hazards. Rusk\u2019s model attempted to answer the first half of that issue.\nIt took three years of adjustments to get the final model, which considers the risks of floods, wildfires, and landslides. Using historical records of the hazards and known environmental characteristics, the model would produce a map of hazard susceptibility for each variable, then combine those into a single map for overall multi-hazard risk.\nAn initial difficulty for Rusk was that the three hazards were tracked with different parameters. For example, he had to compare hazard intensity data in forms as different as flood depth at a particular location and the total volume of a landslide.\nThere was also the issue of non-reported data. If a hazard happens in a less populated area, it is less likely to be reported, skewing the distribution to favor more populated areas. Additionally, not all the factors had data for the same number of years. Furthermore, to have a single model incorporating different hazards, one would have to consider the same environmental factors.\nThe final paper used ten environmental variables, some of the more important ones being elevation, distance to permanent water, type of land cover, precipitation, slope, and soil type. Certain variables may be correlated for some hazards but not others, and not all of these would be relevant for every hazard. For example, slope has little to do with wildfires but is more associated with landslides.\nHence, a multiple-hazard informed model seemed implausible at first. Yet, these considerations are necessary to understand and improve life in the Himalayas, where multi-hazard risk is present over the long term and in the short term. Floods, wildfires, landslides, and earthquakes commonly cause each other, so hazard mitigation teams need to be prepared to handle these hazards simultaneously.\n\u201cYou need to develop a framework for hazard mitigation that describes the overlaps and interactions between hazards,\u201d Rusk said. \u201cPractices that are good for managing the risk of one hazard might exacerbate the risk of another.\u201d For example, clear-cutting land is a common hazard prevention method for wildfires\u2014creating a fire break. But since trees stabilize soil with their roots, denuding a piece of land also makes it more prone to landsliding, potentially leading to disastrous outcomes.\nUnderstanding the results\nRusk ultimately found that maximum entropy modeling would be the best for his data. Maximum entropy modeling works by finding the uniform hazard distribution for the entire region while accounting for the environmental variables. This methodology has several advantages. For one, it works without knowing where hazards did not happen, which negated the issue of inconsistent reporting. Additionally, it can handle both categorical and continuous environmental factors\u2014for example, specific types of soil and total precipitation are both variables in the final model. It also does not lose accuracy when fed irrelevant or correlated factors, allowing for a consistent set of factors to be used for all three hazards. Finally, it outputs a single probability for each hazard at each location. This simple output allowed Rusk\u2019s team to use a consistent methodology for defining \u201crisk\u201d for all three hazards, allowing them to combine the three hazard maps into one. When the model was constructed using a subset of the historical data, it was able to predict patterns in the rest, an early indication of success.\nRusk\u2019s results must be placed in the context of Himalayan urbanization patterns to make sense. Himalayan urbanization often occurs as micro-urbanization, a term coined by Seto to describe the growth of settlements that are small, scattered, and removed from existing cities. Tzu-Hsin Karen Chen, a postdoctoral fellow at the Seto lab who collaborated on Rusk\u2019s study, attributes micro-urbanization in the Himalayas to a feedback loop initiated by road construction. \u201cVillages [near a road] will have a lot of new products that are transported to the market in the urban area, and therefore they have more capital to expand,\u201d Chen said. Thus, people flock to settlements in thin, fertile valleys that are convenient places for expanding existing cities and optimal places to lay roads leading to them.\nHowever, these valleys are also the most hazardous parts of the Himalayas. Their moist, fertile soils take less water to saturate in a flood. Their steep hillsides and low elevation make them prone to landsliding, especially as settlement on the valley bottoms forces people to move up the hills and cut terraces for arable land. These valleys also have hotter temperatures than higher elevations do, making them more prone to wildfires during droughts.\nAnd yet, millions still inhabit these hazardous areas. \u201cThere are reasons to be near these urban agglomerations that aren\u2019t related directly to the presence of hazards\u2014access to education, access to healthcare, access to the money economy,\u201d Rusk said. People choose these opportunities for socioeconomic mobility, despite the hazards, in the hopes of connecting with a wider world.\nWhere to go from here?\nRusk is the first to admit that his work would have been impossible without his fellow researchers physically located in the Himalayas. \u201cI\u2019ve been humbled by the opportunity to work with such an amazing group of collaborators,\u201d Rusk said. Truly understanding the impacts of hazards requires talking to people where they happen; machine learning models can only go so far since they don\u2019t explain why hazards happen in certain patterns or how they affect people. \u201cIn all of this work, you just have to shuttle between large-scale patterns and everyday life on the ground,\u201d Rusk said.\nThe Yale team\u2019s next project will zero in on how urbanization changes the landscape locally and affects hazards\u2014the second part of the Urban Himalaya project\u2019s overall goal. \u201cWe have one map that assesses overall hazard patterns across the past three decades,\u201d Chen said, referring to the output of the current model. \u201cBut now we want to have a map for every year, from 1992 to the present.\u201d These maps will allow the researchers to see both hazards and urbanization change together.\nHumans are not only changing the environment on a local scale but also on a global scale. As climate change increases extreme precipitation and lengthens droughts, existing hazards will also grow in frequency and destructiveness.\nManaging multi-hazard risks requires the coordination of normally independent national governments, local agencies managing separate hazards, and individuals alike. Rusk\u2019s group has helped illustrate that progress can be made with an integrated, multi-talented team looking at the big picture. Now it is time to do the same back on the ground.\nFurther Reading\nRusk, J., Maharjan, A., Tiwari, P., Chen, T.-H. K., Shneiderman, S., Turin, M., & Seto, K. C. (2022). Multi-hazard susceptibility and exposure assessment of the Hindu Kush Himalaya. Science of The Total Environment, 804, 150039. https://doi.org/10.1016/j.scitotenv.2021.150039\nGrainger, C., Tiwari, P. C., Joshi, B., Reba, M., & Seto, K. C. (2021). Who is vulnerable and where do they live? Case study of three districts in the Uttarakhand region of India Himalaya. Mountain Research and Development, 41(2). https://doi.org/10.1659/mrd-journal-d-19-00041.1\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/hazards-of-the-himalayas-clash-with-todays-urbanization-patterns%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Holistic Model of Electric Vehicle Carbon Emissions",
            "author": "Tiffany Liao",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/liao_ev_image-500x282.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of AAA Living. \nElectric vehicle companies like Tesla and Rivian are making waves in the automotive industry, with Tesla expected to surpass General Motors\u2019 vehicle sales by 2023. However, as the electric vehicle (EV) industry has erupted into the spotlight, concerns regarding the indirect emissions from the EV life cycle emerged. While it is clear that tailpipe emissions from combustion engines are significantly reduced with EV adoption, the effects of indirect emissions from the full life cycle of an EV can be difficult to capture.\nHowever, researchers at the Yale School of Environment led by postdoctoral researcher Paul Wolfram have applied an integrative approach, combining supply-demand concepts of economics with ecology to accurately capture the effects of indirect emissions. Wolfram says, \u201cCombining engineering and economics methods allows us to capture more of the dynamics that life-cycle cost models themselves can\u2019t, such as market cycle and supply-demand mechanisms.\u201d\u00a0\nThe group found evidence contradicting concerns around the \u201cdirtiness\u201d of battery life cycles stemming from raw materials mining and a material-intensive manufacturing process. The effects of the latter can be mitigated by recycling. The electricity emissions of BEVs overall are still far lesser than the reduction of fossil fuel emissions. Furthermore, once the external effects of carbon on the public are priced into both fossil fuel and electric vehicles, EVs become the more cost-efficient option.\u00a0\nUltimately, Wolfram\u2019s work serves as a reminder that curbing climate change requires multiple moving parts. \u201cIt\u2019s a ripple effect \u2013 carbon emission reduction in every sector from manufacturing to car transport will lead to a much faster transition to electric vehicles,\u201d he said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/a-holistic-model-of-electric-vehicle-carbon-emissions/",
            "captions": [
                "Faster electric vehicle adoption can come from carbon emission reduction along all parts of the electric vehicle production process from material sourcing to car transport."
            ]
        },
        {
            "title": "Carbon Dioxide: Renewable Energy\u2019s Rising Star",
            "author": "Maya Khurana",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/khurana_capture_image-500x411.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Michael Grossman, Cleantech.\nCarbon dioxide has long been branded as an irredeemable chemical waste. But new research is showing that it can be extremely useful if harnessed correctly.\u00a0\nA study by graduate student Conor Rooney and his colleagues at the Wang Lab in Yale\u2019s Chemistry Department highlighted alternative uses for this chemical waste. In their experiments, carbon dioxide was converted using electricity and water such that it could undergo bond formation with a nitrogen-containing molecule. \u201cCarbon-nitrogen species are [very common] in a lot of the valuable chemicals that we rely on in our economy,\u201d Rooney said. \u201cIf we can take carbon from CO2 instead of from [a] fossil fuel byproduct, then we\u2019re able to make these carbon-nitrogen bonds in a sustainable fashion.\u201d\u00a0\nThe research team was able to synthesize a common class of chemicals known as N-methylamines with electrochemical reduction, a process that \u201chasn\u2019t really been done [before],\u201d Rooney said. But what is most exciting about the transformation of carbon dioxide into fuels is that it can create a green source of energy. Carbon dioxide would be converted using an energy source, which in the case of electrochemical reduction, is electricity. The reaction would, in turn, produce an energy-dense fuel that could then be used to further fuel the reaction. \u201cIt\u2019s an energy storage idea to have a circular carbon economy,\u201d Rooney said.\u00a0\nMoving forward,\u00a0 the Wang Lab will continue to investigate ways to create a circular carbon economy by researching sustainable methods to synthesize more carbon-nitrogen species. In the meantime, it is time to rebrand carbon dioxide as a promising resource that could play a prominent role in the future of sustainable energy.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/carbon-dioxide-renewable-energys-rising-star/",
            "captions": [
                "This image shows a green net capturing the CO2 smoke that is being emitted by a power plant."
            ]
        },
        {
            "title": "How to Stop a Sperm Cell (Or Make It Go Faster)",
            "author": "Christopher Esneault",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Development-Sperm-Art-Fertilization-Pregnancy-Live-956480-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of TBIT\nIt may seem like women will forever be plagued with the unfair burden of popping pills to decrease the odds of an unwanted pregnancy. However, researchers at the Yale School of Medicine are currently looking into the molecular processes that could either rev or halt the engines involved in sperm motility, and how those mechanisms could be altered to possibly create a method of birth control for men.\u00a0\nJae Yeon Hwang, associate research scientist from Dr. Jean-Ju Chung\u2019s lab at the Yale School of Medicine, is currently carrying out research regarding male germ cells. \u201cIn a birth process, the major two factors which can achieve new life are the sperm and egg,\u201d he said. \u201cAfter sperm cells are inseminated into the female reproductive tract, they simply migrate to meet the egg and penetrate it.\u201d\nHowever, there is more to the story. After insemination into the female reproductive tract, sperm cells begin their journey to the egg and are met with diverse female reproductive tract environmental factors. During this journey, sperm cells obtain fertilizing abilities \u2013 referred to as capacitation. This biological process triggers these cells to develop a unique motility pattern called hyperactivated motility, characterized by the beating of the flagellum, the tail on the end of the sperm, in high amplitudes. \u201cHyperactivated motility is triggered by an calcium influx,\u201d Hwang said.\u00a0\nWhile researchers knew that calcium was essential for the development of hyperactivated motility, they did not know how, specifically, the CatSper channel arranged itself on the sperm tail. It was the work of this lab that built upon knowledge of the previously discovered CatSper channel to understand how it is arranged on the sperm tail. When functional, CatSper allows for crucial calcium influx into sperm cells, which results in hyperactivated motility. However, if the CatSper channel is deficient, calcium cannot enter sperm cells, which means that hyperactivated motility cannot be triggered. This phenomenon results in male infertility.\u00a0\nHwang\u2019s work comes into play because the goal of his study was to understand how the CatSper channel is linearly arranged along the sperm tail. Without CatSper\u03c4, a protein found on the membrane of sperm cells, Hwang found that the linear arrangement of the CatSper channel fails to occur, thus impairing sperm hyperactivated motility and resulting in male infertility.\nWith the accomplishment of valuable research comes great moments of pride. Hwang mentioned that while learning from Cell Reports that they were going to publish his work was enough to make him incredibly proud, what made him even happier was reading the peer reviewers\u2019 comments on his paper describing how much they enjoyed reading his study. Realizing other experts in his field valued the work he was doing, Hwang felt a sense of pure fulfillment.\nAt the end of the day, this work has important implications. Hwang said that a new method of male contraception could theoretically be possible if they could block the CatSper channel and associated proteins. Conversely, he also added that if someone is having issues with fertility, the problem can be approached using knowledge of the CatSper\u03c4-CatSper relationship.\u00a0\nLooking into the future, with the help of the scientific progress made by Hwang and his colleagues, we are getting closer and closer to tremendous possibilities regarding the manipulation of male germ cells.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/how-to-stop-a-sperm-cell-or-make-it-go-faster/",
            "captions": [
                "Multiple sperm cells surrounding egg cell prior to fertilization."
            ]
        },
        {
            "title": "Q&A: Fishy Driving: Can Fish Navigate Outside Of Water?",
            "author": "Eva Syth",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Syth_Fig1-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nGoldfish are able to drive vehicles, suggests a new study from researchers at Ben-Gurion University of the Negev, Israel. Yes, you did read that correctly. The researchers studied the concept of domain transfer methodology, which refers to when a species applies an existing skill in an environment outside its own. In this study, the researchers investigated the ability of goldfish to transfer navigation skills from aquatic to terrestrial environments.\nTo carry out this study, the researchers constructed a Fish Operated Vehicle (FOV), consisting of a rectangular prism-shaped fish tank mounted on wheels. When the fish swam to an edge of the tank, the FOV would move in the direction of that edge. To test the terrestrial navigation capabilities of the goldfish in the study, the researchers mounted a colored panel on the wall of the examination room. The goldfish received a food pellet reward when they drove the FOV to the panel. The researchers found that even after changing the panel\u2019s location or adding decoy panels, the goldfish were able to reach the panel consistently.\nThe results of this successful goldfish navigation led to several key findings. For example, goldfish are cognitively able to learn tasks outside their natural environment. Additionally, while you likely won\u2019t catch a goldfish driver cruising down the highway alongside you anytime soon, the success of the goldfish navigation skills in both aquatic and terrestrial environments implies a potential universality in spatial representation, whether in water or on land.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/qa-fishy-driving-can-fish-navigate-outside-of-water/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Reviewing The Anthropocene Reviewed\ufffc",
            "author": "Lucy Zha",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Zha_Fig2.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of WNYC Studios.\nJohn Green, the author of several best-selling books such as Turtles All the Way Down, or better known to us college students as the host of the series CrashCourse which saved our world history grades, has also been producing a podcast titled The Anthropocene Reviewed. In his monthly episodes, he shares his epiphanies on the things that have kept humanity, humanity.\nIn truth, I see this podcast more like a John GreenTM personal journal. He does not contrive himself as an expert in anthropology; instead, he simply reflects on specific moments from his personal life. In the episode \u201cMortification and Civilization,\u201d John Green explores the evolution of the word \u201cmortification.\u201d To interpret it literally, Green defines \u201cmortification\u201d literally as \u201cto cause death.\u201d \u201c[Nowadays, the word means] extreme fear from public embarrassment\u2026 a low-level form of death,\u201d Green said. He then gives us an anecdote from when he was giving a talk in 2008, and one student at the end pointed out to him that his fly was open the entire time. Oops, what a great way to ruin the mood. By sharing his mundane experiences\u2014the Canadian geese in his backyard, the Dr. Pepper he drinks every morning, and a few lyrics from his favorite band, \u201cThe Mountain Goats\u201d\u2014Green gives the histories and scientific backgrounds of commonplace objects in his life.\nGreen extends the conversation from not only everyday occurrences but also problems that impact the world globally and that are deemed \u201cnews-worthy.\u201d Green admitted that he would give COVID-19 a one-star rating in the episode \u201cPlague.\u201d \u201cPlague is a one-star phenomenon, but our response needs not to be,\u201d Green said. He reassures us that the COVID-19 pandemic is by no means unprecedented. The Black Death in the 14th century decimated at least one-third of the European population. \u201cCorpses were laid on the streets of Florence\u2026 Father did not dare to visit their souls,\u201d Green said. However, in community, there also lies strength. When another round of the pandemic came around again in Eyam in 1665, the village came up with a plan together that held church services outdoors, maintained social distancing, and buried a family\u2019s own dead themselves. Humans had prevailed.\nFrom John Green\u2019s meticulous uncovering of his life\u2019s many intimate moments, he has proven to us that the Anthropocene is an era where happiness, loneliness, life, death, and many other contradicting emotions coexist because we, humans, are on this earth together. This podcast itself is also Green\u2019s way of connecting with his readers in a time where we are forced to be isolated. It is a miraculous feeling to see the famous and knowledgeable author, whom I look up to, talk to his listeners as a part of the ordinary ether. And in this age of quarantining, at least I, John Green, and other listeners of this podcast, are here together.\nIndeed, I would give The Anthropocene Reviewed a rating of five out of five stars.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/reviewing-the-anthropocene-reviewed%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Undergrad Profile: Kate Pundyk",
            "author": "Catherine Zheng",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/DONG1-500x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Alex Dong.\nAmidst a mess of flour and dough in a small San Francisco apartment, one can find 2022 Rhodes Scholar Kate Pundyk baking away, having set stacks of research journals and books on technology policy aside to try out a new recipe. While STEM and the humanities often find themselves on opposite ends of the spectrum, Pundyk found her calling in the intersection of technology and social policy through a long-winding path with many different research experiences and universities.\nPundyk first left her home in rural Crowsnest Pass in Canada at seventeen-years-old to live in Hong Kong. During her stay, she witnessed firsthand how the citizens stood up for their rights during the Umbrella Revolution. \u201c[I] realized how powerful activism can be, even in situations where it feels like the opponent is a very large and very powerful entity,\u201d Pundyk said. This experience abroad quickly became a turning point in her life, motivating her continued work in social justice and activism.\nPundyk started her college education as a political science student at Wellesley College following her two-year stay in Hong Kong. She found herself traveling to Cambridge each semester to take classes at MIT. With her time split between taking more humanities-oriented classes at Wellesley and technology-focused classes at MIT, the intersection between the two came about naturally. \u201cIt was impossible to go from any of the foreign policy, world politics courses that I kind of gravitated to, and then go to my cybersecurity class at MIT and not think about how those two overlapped,\u201d Pundyk said.\nPundyk became involved in the MIT Little Devices Lab during her time at Wellesley, which focuses on creating affordable medical technology for people in disaster or low-resource settings. As a technology policy researcher and political science student, she was primarily involved in researching how access to medical devices depended on financial stability. For example, she investigated how big pharma\u2019s corporate nature affects engineering and technology access, preventing low-income people from getting the medical care they need.\nAfter two years at Wellesley, Pundyk decided to return to Canada and work in the Office of the Premier in Alberta. With just two years of undergraduate education under her belt, Pundyk was adamant about pursuing her interests and creating change in fields that she believed mattered, taking part in progressive campaigns. Later in 2019, Pundyk transferred to Yale to pursue her interest in technology policy and its role in human rights abuses and equity.\nAt Yale, she found herself involved in a host of different activities and organizations. One of the most notable was reporting for the Sci-Tech desk at the Yale Daily News (YDN). Having worked in government, Pundyk knew that the ability to communicate technical subjects to lay audiences was lacking in many politics-oriented communities, and this was something she was hoping to work on at the YDN. With the COVID-19 pandemic, it was especially important for her to easily communicate the newly discovered science and engineered technology to a broader audience.\nWhile the pandemic didn\u2019t alter the course of her education too much, it became clear to Pundyk that she was following the right path. \u201cCOVID highlighted the cleavages in our society that urgently need to be focused [on]. [It] clarified that I\u2019m making the right choices and going for a career that centers human rights and tries to build up other voices that might be left out of the discussion,\u201d she said.\nIn addition to the YDN, Pundyk started working with the Yale Genocide Studies Program on a project known as Mass Atrocities in the Digital Era (MADE). As part of this project, she brought a technology-oriented angle to the research, focusing on how technology plays a role in bringing about human rights injustices, specifically looking into the accountability of human rights abusers, memorialization of victims, and prevention of future atrocities.\nFor the upcoming fall semester, Pundyk will continue studying the intersection of social policy and technology at Oxford during her Rhodes scholarship, pursuing a Master of Science degree in social data science and a Master of Philosophy degree in socio-legal research. She is looking forward to moving home to Canada after graduating from Oxford. \u201c[It] was less about any individual feat and more a confluence of a bunch of good things happening in a row and being surrounded by good people who built me up,\u201d Pundyk said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/undergrad-profile-kate-pundyk/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Why Don\u2019t Mice Get Covid?",
            "author": "Ryan Bose-Roy",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Why-dont-mice-get-COVID_-Sophia-Zhao-386x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Sophia Zhao.\nAmid the COVID-19 pandemic, a figure crawls from the darkness. Born from the collaborative efforts of investigators at the Yale School of Medicine, he represents a crucial scientific weapon for COVID-19 researchers \u2013\u2013 a bridge between understanding the disease and effectively treating it. He is a hero that wears no cape, and his name\u2026is Mr. G.\nOkay, his full name is MISTRG6.\nAnd he is a mouse.\nWho is Mr. G?\nMr. G is a genetically engineered mouse with a human-like immune response to COVID-19: through him (and mice like him), researchers may be able to better test both existing and new potential treatments against the virus. Mouse models like Mr. G can be crucial to answering key questions about how the virus works and how we can combat it.\nOver four hundred million cumulative cases of COVID-19 have been recorded in the past six months. Roughly eighty percent of them have been classified as \u201cmild\u201d. The remaining twenty percent of cases are \u201csevere,\u201d with symptoms including respiratory failure, blood clotting, and multi-organ dysfunction.\nWhy do some people experience only mild cases while others face life-threatening ones? Through Mr. G, Yale School of Medicine Sterling Professor of Immunobiology Richard Flavell and Esen Sefik, a post-doctoral fellow in his lab, aimed to find out.\n\u201cSome [COVID-19 treatments] worked in a subset of patients, but not all of them,\u201d Sefik said. \u201cThere were a lot of unknowns at the time, and we thought that if we had a model, we could help.\u201d\nThe challenges of an animal model\nScientists have traditionally relied on animal models to evaluate the safety and efficacy of vaccines and antiviral candidates. However, while a plethora of animals \u2013 ranging from rabbits to primates \u2013 have been studied for their immune response to SARS-CoV-2, no standard laboratory animals have developed severe respiratory failure, organ failure, or cytokine storms, which are intense inflammatory processes, seen in severe human cases. Some animals barely show any symptoms.\nBut the lack of symptom overlap with humans does not mean that these animal models lack usefulness as a starting point for study. Animals are affected by SARS-CoV-2; the difference merely lies in how they respond. With this in mind, if researchers could alter the response of a COVID-infectable species to match the human immune response, they could create a suitable animal model to study the disease.\nOf the animal species that do get infected, mice stand out as the most promising for this type of study. Mice have been used in biomedical research for nearly a century, and, as a result, scientists understand their physiology with near genomic-level precision. We also share about ninety-five percent of our DNA with mice, so our biological responses to disease are typically similar enough for findings to be translatable to humans. In addition, practically speaking, mice are small, easy to transport, and have a fast reproduction time with an accelerated lifespan, making them incredibly cost-effective and efficient for studying infectious disease processes.\nHowever, the differences in the immune response to COVID-19 between humans and mice still represent a major obstacle for researchers. In humans, inhaled SARS-CoV-2 travels to the alveoli in the lungs, where the exchange of carbon dioxide for fresh oxygen in the blood occurs. There, the virus hooks onto a protein called the angiotensin-converting enzyme type 2 receptor (ACE2), which provides an entry point into the alveolar cell lining. Once taken in, the virus breaks the cell apart, releasing millions of new viral particles and proinflammatory cytokines. These cytokines cause plasma and immune cells in the blood to leak into the alveoli, blocking gas exchange and causing fluid buildup in the lungs.\nHowever, unlike humans, standard laboratory mice that come into contact with SARS-CoV-2 do not show major signs of infection. This is partly because the ACE2 receptor in mice is structurally different from the ACE2 receptor in humans, enough so that SARS-CoV-2 generally cannot effectively bind to the mouse receptor, enter alveolar cells, and cause chronic infection. To address this difference, Flavell and Sefik turned to Akiko Iwasaki, the Waldemar Von Zedtwitz Professor in the Department of Immunology at Yale, who found a way to use gene therapy to induce mice to transiently express the human version of ACE2. By delivering the human-ACE2 gene through a mild adeno-associated virus (AAV) injected into the trachea, her team successfully transferred the gene into cells into the lung tissue of mice.\n\u201cHumanizing\u201d a mouse\nWhile mice with just the human-ACE2 gene get sick, they do not necessarily exhibit severe COVID-19 symptoms. The immune systems of mice and humans are just different enough that \u201chumanized mice,\u201d or mice adapted to have a human immune system, have become crucial tools in studying the clinical applications of anticancer and anti-HIV drugs. Thus, Flavell and Sefik teamed up with Iwasaki to develop a mouse with both the human receptor to SARS-CoV-2 and the human immune cells for disease response.\n\u201cHumanizing\u201d the mouse immune system occurs by taking progenitors of human immune cells and injecting them into a mouse. This technology is decades-old, and Flavell, along with Markus Manz and Regeneron Pharmaceuticals, have been pioneering work in this field for years. To create Mr. G,  Flavell\u2019s lab took a variety of human hematopoietic stem cells from fetal liver, cord blood, and adult blood and injected them into the liver of an immunocompromised baby mouse. Once the mouse was eight weeks old, the stem cells had differentiated to yield a system of human immune cells.\nOrdinarily, the mouse\u2019s immune system would recognize these human stem cells as \u2018foreign\u2019 and reject them. To preemptively address this issue, the researchers first genetically modified the mice when they were still clumps of embryonic stem cells: several mouse genes were replaced with human genes coding for proteins that would support humanization. The names of these \u2018humanization\u2019 proteins \u2014 M-CSF, IL3, SIRP\u0251, thrombopoietin, RAG2, and IL2RGamma \u2014 can be combined to form the acronym MISTRG, or, more concisely, the name of our hero, Mr. G.\nOnce the human immune cells were grafted, the human-ACE2 gene was injected into Mr. G\u2019s neck so that his lungs would respond appropriately to COVID-19. And after 14 additional days of waiting, Mr. G\u2019s \u201chumanization\u201d process was finally complete.\nMr. G on the battleground\nWhile the concentration of infectious SARS-CoV-2 in normal mice is quite low, the viral concentrations in Mr. G are comparable with the high levels found in severe human cases. \u201cIt\u2019s a good model to start with, and it is already telling us a lot about how we can go about treating the disease,\u201d Sefik said. Physiologically, Mr. G exhibits the same COVID-19 symptoms as severely ill humans: fibrosis, weight loss, and a heightened, persistent inflammatory immune response that damages tissues. These responses are virtually unobserved in normal mouse models.\n\u201cAs we learned more about [COVID-19] and the patient data kept coming, macrophages and monocytes seemed to be at the center of pathology,\u201d Sefik said. \u201cIf you look at other humanized animal models, unfortunately, most of them lack these cells.\u201d\nWhy does replacing mouse immune cells with human ones produce such adverse outcomes? Sefik hypothesized that human cells contribute in a unique way. \u201cThe way that human immune cells respond to the virus and produce antibodies results in delayed viral clearance, and so the virus also stays longer,\u201d she said. In standard laboratory mice, COVID-19 infection peaks in two days and goes away after four. In Mr. G, the infection lasts over a month, making it a chronic infection.\nTo test the effectiveness of different vaccines and antiviral therapeutic agents, Flavell and Sefik treated Mr. G with human monoclonal antibodies collected from patients by Michel Nussenzweig, an immunologist at Rockefeller University. They found that administering human antibodies to Mr. G eight hours before infection blocked his excessive weight loss and reduced the amount of infectious SARS-CoV-2 to undetectable levels. However, when these anti-COVID-19 antibodies were administered after infection as a therapeutic practice, the effect was much less pronounced, and the mice still exhibited some, albeit milder, symptoms.\nFinally, Flavell and Sefik tested the effect of dexamethasone, a potent immunosuppressive steroid currently used to treat patients with severe COVID-19 infection. They found that dexamethasone administration for mice like Mr. G, as in humans, worked best if delivered during a specific window of time when the immune system was activated for long enough to fight infection but not too long to cause infection.\nMr. G: more than a mouse\nFlavell and Sefik\u2019s research, done in collaboration with Iwasaki and several other researchers in and outside of Yale, is crucial in developing means to better understand and treat SARS-CoV-2 infection. Nevertheless, much work remains to be done. Mr. G\u2019s effectiveness as a model organism is still limited. \u201cWe have a good representation of monocytes and macrophages [immune cells], which is great, but we don\u2019t have all the cell types in place,\u201d Sefik said.  \u201cWe are not going to see all the pathologies that we need.\u201d  For instance, Mr. G does not exhibit blood clotting, a common symptom found in patients with severe COVID-19.\nRegardless, Mr. G does bear many of the same viral and therapeutic responses to different COVID-19 variants as humans. His creation represents a major milestone for researchers aiming to understand and treat the virus. Mr. G will scurry down the path of SARS-CoV-2 infection, sniffing out vaccines and antiviral drugs to save human lives.\nFurther Reading\nRongvaux, A., Willinger, T., Martinek, J., Strowig, T., Gearty, S. V., Teichmann, L. L., Saito, Y., Marches, F., Halene, S., Palucka, A. K., Manz, M. G., & Flavell, R. A. (2014). Development and function of human innate immune cells in a humanized mouse model. Nature biotechnology, 32(4), 364\u2013372. https://doi.org/10.1038/nbt.2858\nSources\nSefik, E., Israelow, B., Mirza, H., Zhao, J., Qu, R., Kaffe, E., Song, E., Halene, S., Meffre, E., Kluger, Y., Nussenzweig, M., Wilen, C. B., Iwasaki, A., & Flavell, R. A. (2021). A humanized mouse model of chronic covid-19. Nature Biotechnology. https://doi.org/10.1038/s41587-021-01155-4\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/why-dont-mice-get-covid/",
            "captions": [
                "Processed with VSCO with dog3 preset"
            ]
        },
        {
            "title": "Nanomagnets Offer Clues to Avalanches\ufffc",
            "author": "Gaukhar Alzhanova",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/avalanche-500x313.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Mt Kalmont.\nAvalanches do not solely take the form of snow falling down a mountain. Earthquakes, landslides, power grids, and even crashing stock markets are all avalanches in their own ways. Physicists have often used the 1D random-field Ising model (1D-RFIM) to approximate avalanche responses, but no experimental evidence has ever shown that the model verifies classical theoretical model predictions. A team of researchers from the Schiffer Lab at Yale and collaborators have provided the first-ever experimental realization of the 1D model.\nPreviously, the Schiffer Lab developed artificial spin ice (ASI), a collection of nanomagnets where each one behaves like a single magnetic spin, possessing one north pole and one south pole. These magnets can be arranged into any desired geometrical setup to give rise to various behaviors, including that of avalanches. But what exactly is avalanche behavior?\nConsider a row of nanomagnets with their north poles pointing down in a magnetic system. If a magnetic field is applied, then a single magnetic pole may flip, triggering neighboring magnetic poles to flip continuously down the chain due to the repulsive forces when like poles interact. This cascading event is also characteristic of avalanches.\nFor the experiment, the researchers used a square arrangement of the ASI\u2014four islands (a single nanomagnet) pointing towards a vertex. This is the simplest possible case, one with very well-defined initial conditions. Different magnitudes of the magnetic field were applied from this starting point, causing some islands to flip their poles. Using a magnetic force microscope, the researchers imaged the ASI sample and counted the number of islands that changed course.\n\u201cThis process takes a long time. On each [nanomagnetic lattice], we fabricated three different array sizes and numbers of islands, and four copies of each sample were made for every magnetic field to get better statistics. We\u2019re talking about hundreds of magnetic force microscope images, which took about six months. A single imaging takes 40 minutes, and not every image turned out usable,\u201d Nicholas Bingham, Associate Research Scientist of the Schiffer Lab, said.\nThe results indicated that avalanche size caused by the different island sizes and magnetic field strengths aligned well with the 1D model approximations. The beauty of this experimental realization is that the methods used in this study can be used to measure avalanche behavior in various other systems. For snowy avalanches, the framework could be instrumental for hazard prevention.\n\u201cNow that we showed the model works for the system, we can also work backward: design materials that behave in any way we want them to behave,\u201d Bingham said. Using the model, physicists know which parameters give rise to particular types of behavior, allowing for the specific design of materials with pre-determined behaviors. The Schiffer Lab now aims to understand avalanche behavior using more complicated materials.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/nanomagnets-offer-clues-to-avalanches%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "\u201cQuantum Physics Gets Even More Spooky\u201d\ufffc",
            "author": "Patryk Dabek",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Dabek_Figure1-500x400.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Physics World.\nFrom the collapse of supermassive black holes to phase shifts induced by electromagnetic fields, atom interferometers can measure how the fields surrounding us impact particles. But could it be possible to measure how potentials, the very basis from which fields are derived, actually impact particles? This possibility questions our classical understanding of electromagnetism, gravity, and how quantum mechanics plays into our understanding of the world.\nBut what even is quantum mechanics? In brief, quantum mechanics picks up where classical physics leaves off\u2014explaining the seemingly odd interactions of particles. One of the most principal concepts in quantum mechanics arose from the double-slit experiment, which showcased that light and matter can exist as a particle and as a wave that can be affected by electromagnetic and gravitational interactions. These interactions are still being explored by physicists today who explore how the potential of fields can impact particles, as well as the equivalence principle, which states that there is no difference between gravitational forces and accelerating reference frames.\nIn this study, Stanford physicists experimentally observed the Aharonov-Bohm effect\u2014a quantum mechanical effect where the wave of a particle is shifted by the potential of the field around it. While this effect has been measured as a result of electromagnetic interactions, which produced tiny wave shifts that could be measured by the arms of an interferometer, it had not been previously experimentally proven to be true for gravitational interactions. Utilizing an existing 10-meter interferometer, the group shot rubidium atoms through a dense tungsten ring. This source mass acted as a source of gravitational potential for one of the arms of the interferometer, ultimately inducing a phase shift due to gravitational interactions with the packet of atoms shot through the tungsten ring while leaving the packet of atoms traveling through the other arm unaffected. \u201cFor a long time, we have been asking what really is quantum, and can we characterize a methodology of using atom interferometry to characterize the gravitational interaction?\u201d said Mark Kasevich, principal investigator and former professor in the Yale Department of Physics. These results showcase how a particle\u2019s interaction with gravitational potential can create wave shifts in the same manner as an interaction with electromagnetic potential.\nThis experiment is leading both the effort to tie our classical understanding of physics to the quantum world and the search for real-world applications of quantum mechanics. For instance, the gravitational constant, which many of us know as roughly 6.674\u00d710 \u221211\nm3 \u22c5kg\u22121 \u22c5s\u22122, still holds many mysteries. \u201cThis experiment shows that quantum mechanical effects show up in gravity,\u201d Chris Overstreet, first author of the study, said. This experiment could establish the groundwork to measure gravity more precisely and potentially uncover hidden mysteries of physics in the process.\nKasevich also highlighted the humanitarian and economical applications of their research. Since atom interferometry is so adept at measuring small changes in gravitational gradients, it can be applied as a very powerful tool from space to precisely measure gravity and material density on Earth. \u201cWith climate change, that\u2019s a big deal. By using satellite gravity gradiometers, you see where water and other resources are located,\u201d Kasevich said, indicating that this technology can drive the discovery of valuable resources and better our understanding of the factors influencing global phenomena like climate change.\nUltimately, with an understanding of the quantum interactions in our world, we can create better predictions and new discoveries.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/quantum-physics-gets-even-more-spooky%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Halogens: A Gaseous Peek into the Earth\u2019s History",
            "author": "Sydney Hirsch",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/ocean-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nUnderstanding the historical prevalence of elements on Earth offers us insight into the processes that led to our planet\u2019s development. One such group of elements is called halogens\u2014nonmetallic elements occupying the seventeenth column of the periodic table. Over time, the amount of halogens present on the Earth\u2019s surface has important implications and has been estimated to sit at about eighty percent\u2014putting only twenty percent of these gasses currently within the mantle (below the surface).\nHowever, a pair of Yale researchers\u2014graduate student Meng Guo and Professor Jun Korenga\u2014found that this figure is a drastic overestimation. Attempting to validate previous estimates, the researchers instead found that almost ninety percent of stable halogens reside inside the present-day mantle! The error lies in the underlying assumptions of the prior calculations. The traditional method presumed that the ratio of elements in the crust and mantle have remained constant over time. When the Yale scientists abandoned this assumption, they realized that there is a mere ten percent of halogens on the surface of the present-day Earth.\nGuo and Korenga\u2019s findings bear significant implications, not only for the history of halogen expulsion from and absorption into the mantle, but also for understanding the origins of life on Earth. The new budget suggests that the early Earth had high amounts of halogens on the surface that were gradually reabsorbed into the mantle over time. The significant takeaway relates to ancient seawater chemistry: a greater-than-expected presence of halogens would have affected the pH and alkalinity of the planet\u2019s oceans. \u201cThere is debate about where life started. The ocean was proposed to fertilize the origin of life, but our results indicate that the ocean may have been too salty\u2014three times saltier than the present-day ocean\u2026 It was more likely within inland freshwaters,\u201d Guo said. To further this research, Guo intends to develop a simulated model allowing for further holistic analysis of the solid Earth.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/halogens-a-gaseous-peek-into-the-earths-history/",
            "captions": [
                ""
            ]
        },
        {
            "title": "We Need to Talk About Periods\u2026 Period\ufffc",
            "author": "Connie Tian",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/period1-500x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Patricia Moraleda.\n\u201cIf physicians don\u2019t even want to talk about periods, it furthers the stigma of literally being a woman and seeking care as a woman,\u201d said Dr. Linda Fan, Assistant Professor of Obstetrics, Gynecology, and Reproductive Sciences at Yale University.\nRegular menstruation is an important indicator of health in adolescents, and abnormalities in menstruation may indicate current or future health concerns. Because over half of the world population will menstruate at some point, education on and access to menstrual hygiene products is crucial. The American Academy of Pediatrics and the American College of Obstetricians and Gynecologists recommend clinicians provide anticipatory guidance on menstruation to patients at ages seven or eight. However, a recent study on local, low-income adolescents has found that this standard is not always met.\nThe study, led by Yale Medical School student Amelia Trant and Dr. Fan, focused primarily on Black and Latino adolescents. They found that only approximately fifteen percent of providers consistently ask their female patients about menstrual products, and forty-four percent of providers are concerned their patients cannot afford menstrual products. These results paint a less than optimistic picture of menstrual health in the United States.\n\u201cAdolescence is a crucial point of entry into healthcare,\u201d Fan said. Yet taboos surrounding menstruation add to the existing barriers that prevent access to menstrual health products and education. Furthermore, with the rising rates of childhood and adolescent obesity, the average age of menarche, the onset of menstruation, is decreasing. Thus, current educational approaches and standards must be re-evaluated to meet changing demographics.\nDespite these results, Fan is optimistic. Over the last decade, the increasing number of studies on menstrual healthcare has attracted more attention to the new standards that must be set. \u201cWe are only in the beginning stages of change. The real benefit will be seen in the next decades,\u201d Fan said,\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/we-need-to-talk-about-periods-period%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "E. coli\u2019s Streaming Bandwidth\ufffc",
            "author": "Abigail Jolteus",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/EColi-500x360.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nAfter a long week of classes, many students find solace in streaming a movie or show with friends \u2026 and they are not the only ones. Surprisingly, some microorganisms can also relate.\nYale researchers Henry Mattingly, Keita Kamino, Benjamin Matcha, and Thierry Emonet discovered that similar to your laptop streaming a video, E. coli bacteria use information from their environment to guide their actions. This occurs through a process called chemotaxis, where bacteria navigate chemical gradients towards areas with more favorable environmental conditions.\nYour internet connection limits how fast your laptop can stream, and the goal is to operate as close to those limits as possible. \u201cWe wanted to know [if] E. coli perform well by a similar metric\u2026climbing gradients near the theoretical maximum speeds given the quality with which they can measure their surroundings,\u201d Mattingly, a postdoctoral fellow in Emonet\u2019s lab, said.\nTo navigate chemical gradients, cells must answer a crucial question: \u201cIs the concentration of things I like increasing or decreasing?\u201d If the concentration is increasing, cells should continue swimming in the same direction. If not, they should randomly choose a new direction to swim in. The researchers showed that E. coli bacteria do not need to answer this question correctly every time\u2014only most of the time.\nThen, by quantifying the precision of the cell\u2019s measurement of its surroundings, they discovered that E. coli cells have a slow \u201cinternet connection:\u201d it is difficult for them to know whether things are getting better or not. But the cells use this information efficiently to swim up chemical gradients at speeds close to the theoretical limits.\nE. coli have a tiny bandwidth, but they\u2019ve evolved to push the theoretical limit of what they can get from it. This provides support for a broader hypothesis: biological systems have evolved to efficiently use limited information to perform their functions.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/e-colis-streaming-bandwidth%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Alumni Profile: James Diao (MY\u201818)\ufffc",
            "author": "Yusuf Rasheed",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Rasheed_Fig3.jpg.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Alex Dong.\nGrowing up next to the biggest medical center in the world, James Diao YC \u201818 was meant to be a doctor. A third-year medical school student at Harvard Medical School (HMS) and MIT, Diao was recently awarded the Churchill Scholarship to do a year of master\u2019s study in science policy at the University of Cambridge for the 2022-23 academic year. With this scholarship, he plans to take a deep dive into understanding the regulation of healthcare technology and the efficacy of clinical algorithms across diverse populations.\nDiao\u2019s initial interest in medicine and research stems back to his hometown of Sugar Land, Texas, where he shadowed Rachel Rau, a pediatric oncologist at the Texas Medical Center in high school. \u201cI learned a lot about science. I learned a lot about patient care. I thought her job was the coolest job in the world,\u201d Diao said. At Yale, he continued to shadow clinicians at Haven Free Clinic and became a Peer Counselor for Yale\u2019s anonymous and confidential hotline. Now, he\u2019s spending time with patients in his core rotations.\nIn addition to his clinical experience, Diao has also spent a lot of time on research. In April of 2020, he started studying the misuse of race in kidney function tests with Arjun Manrai at the HMS Department of Biomedical Informatics. Diao\u2019s idea to pursue this project was a bit spontaneous. \u201cMy mentor and I had previously worked on equity and representation for cardiovascular genetics, but kidney disease wasn\u2019t on our radar at all. It wasn\u2019t until I learned about the issue on Twitter that I began diving into the literature and thinking about ways to contribute,\u201d Diao said.\nThe \u201cissue\u201d Diao had stumbled upon was related to the glomerular filtration rate (GFR). GFR measures how well a person\u2019s kidneys can filter substances from their blood, which is essential in the early detection of potential kidney disease. The current test to measure someone\u2019s GFR is an equation that involves several variables, including age, sex, and race, with higher results indicating healthy kidney function. \u201cThe main issue is [with] the race and ethnicity component. If you\u2019re Black, your number will be assigned 16% higher,\u201d Diao said. As a result, Black patients with higher GFR numbers may have less access to specialist care, kidney transplants, and coverage by Medicare. Diao\u2019s research quantified the effect of including and removing race from the equation, and he found that up to one million Black Americans may receive unequal kidney care due to their race. When the race variable was eliminated, he found that access to diagnosis and specialist care increased for Black Americans. Race-free equations could also achieve the same performance metrics as the original ones. In October of 2021, the National Kidney Foundation and the American Society of Nephrology officially released national recommendations supporting a new race-free equation, citing Diao\u2019s research.\nDuring Diao\u2019s first year of medical school, he joined the machine learning team at tech startup PathAI, where he worked on deep learning models in pathology. He then joined Apple\u2019s Motion Health team, where he worked on studies to predict cardiovascular risk for the Apple Watch using accelerometer data from consumer wearables. Diao was named to the 2022 Forbes \u201c30 Under 30\u201d List for his work and received the prestigious Paul & Daisy Soros Fellowship in their 2021 cohort.\nWhen he\u2019s not conducting research, Diao is probably ballroom dancing. This hobby started in college when he searched for activities to get involved in. \u201cBallroom was one cool [club] where they don\u2019t care if you\u2019re new to it all,\u201d Diao said.You don\u2019t need to have any experience, you just show up, and their whole thing is \u2018We\u2019ll teach you!\u2019\u201d\nAs Diao finishes medical school and approaches the next step in his career, he hopes to continue tackling systemic problems in medicine. He wants to become a professor and investigator, studying the performance and equity of medical technology and translating this research to the realms of patient care, company advising, and clinical trials.\nDiao advises undergraduates to remember that they are only at the very start of their careers. \u201cThere will be so much time to double down on whatever ends up being your life\u2019s work,\u201d Diao said. \u201cI think there\u2019s a lot of value in exploring early and exploring all the different paths that are available to you and not committing so early.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/alumni-profile-james-diao-my18%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Shrewd Family Business that Sold Time\ufffc",
            "author": "Dhruv Patel",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Patel_Fig1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of the Science Museum Blog.\nIn the first four decades of the twentieth century, Ruth Belville\u2014alongside her modest pocket-watch\u2014sold time as part of her family\u2019s business. But to truly understand her story, we must understand why she sold time. Prior to the nineteenth century, people kept time by referencing the position of the sun: the sun\u2019s peak meant it was noon, and midnight was when the peak was furthest away. When mechanical clocks were invented, towns and cities began keeping a local time, meaning that noon would be exactly twenty-four hours after the previous noon. Time zones were also adopted in the mid-nineteenth century to standardize time across vast regions. Such standardization allowed for synchrony across cities and states in proximity to each other, a phenomenon that frequent travelers and railroad companies especially appreciated. Unsurprisingly, most people began using mechanical clocks. Though these clocks were more reliable than others, they were still not entirely accurate. For example, such clocks would slowly deviate from the local mean time (determined by the time zone). It is in this context that the story of the Belville family arises.\nIn London, the Royal Observatory in Greenwich was responsible for keeping the time. To signal the time to the public, the Observatory would raise a balloon above the building at precisely p.m. every day. Later, the Observatory installed a large clock on its gate so that anyone could see the accurate time at any moment rather than waiting for a signal. However, to view this clock, people had to physically make a trip from their homes and offices across London to the Observatory, which of course, was inconvenient. Moreover, calibrating watches and clocks in the nineteenth and early twentieth centuries was more complicated than it is today, requiring some level of expertise. Seeing this as an opportunity to profit, John Belville, an assistant at the Royal Observatory, began visiting a network of two hundred clients around London once a week, calibrating their watches and clocks with his own pocket watch, which he calibrated with the Greenwich mean time daily. This business passed to his wife when John died, and then to his daughter Ruth.\nAs with any business, the Belville family service faced competition, particularly when Ruth took over after her parents\u2019 deaths. Telegraphs were capable of signaling time, and different firms would compete to sell their telegraph time service. Nevertheless, Ruth had an advantage: electric telegraphs were not as accurate nor as reliable as her state-of-the-art pocket watch, which was accurate to the tenth of a second. Moreover, the firms selling telegraph time had trouble keeping their services in order and received many complaints. Ruth, however, was reliably consistent and professional. Indeed, the watch\u2019s accuracy and familiarity with the Belville family business made it an easy decision for clients to remain subscribed to this service.\nRuth Belville carried that pocket watch\u2014which she fondly called \u201cArnold\u201d\u2014around London every week for forty-eight years. Each day, she would visit up to ten customers across London, from the outskirt docklands to the central Mayfair. Over these forty-eight years, radio became a prominent method of communication (including communication about time), and the electric telegraph also became more accurate and reliable. However, there was still a market for Ruth\u2019s service\u2014the new technologies did not simply replace the older ones. Instead, they co-existed for quite some time.\nEventually, however, modern technologies outpaced Ruth\u2019s pocket watch. The invention of the telephone speaking clock, which gave the precise time on the third stroke, signaled to Ruth that her pocket watch could no longer compete with more efficient and accessible modes of communication provided by modern technologies. She finally retired at the age of eighty-six. In all, the Belville family business spanned 104 years, from 1836 to 1940. Before Ruth passed away in 1943, she donated Arnold to the Clockmakers\u2019 Company Museum.\nToday, we are all accustomed to seeing the time on our phones and digital watches. The Belville family business story is a tale of the industrializing world, a world filled with the clashing of the old and the new.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/the-shrewd-family-business-that-sold-time%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Palm Reading\u2019s Not a Myth? What Fingerprints Can Tell Us About Limb Development",
            "author": "Odessa Goldberg",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Golberg_Fig1-280x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nCome, come! Enter my ancient and mysterious tent where I can tell you your fears, dreams, and futures with only a glance at the palm of your hand. Well\u2026maybe not exactly, but I could tell you about the expression of your gene, EV11. A group of scientists from the International Human Phenome Project decided to compare people\u2019s fingerprints to their genomes. They found forty-three regions of interest but focused on the EV11 gene, which is involved in regulating how your limbs develop in the womb. So instead of your future, fingerprints may actually reveal the length of your fingers or your risk of leukemia. Fingerprint readings are a serious business. Certain patterns on your hands, such as skin patterning or palm creases, are associated with congenital genetic disorders like Down\u2019s syndrome. These interrelated traits suggest that genes associated with fingerprint development are pleiotropic, meaning that the same genes affect multiple traits with different phenotypes. These scientists plan to further investigate how exactly this pleiotropic mechanism works. Perhaps fingerprints could be used as a diagnostic tool in the future. So, I may not be able to read your future by studying your palms, but by studying your fingertips, I could tell you about your embryonic limb development. And that\u2019s pretty cool.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/qa-palm-readings-not-a-myth-what-fingerprints-can-tell-us-about-limb-development/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science Denial: Why it happens in Don\u2019t Look Up\ufffc",
            "author": "Sophia David",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/David_Fig1-500x256.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nThe phrase \u201cLive every day like it\u2019s your last\u201d is frequently thrown around. However, this advice is remarkably difficult to obey, in part because it is remarkably difficult to believe. In Adam McKay\u2019s movie Don\u2019t Look Up, people are informed by indisputable science that an impending comet will destroy the Earth in about six months; however, much of the world remains disturbingly in denial. People carry on with their lives, concerning themselves with trivial celebrity relationships and the presidential reelection.\nThis film overtly underscores the pervasive denial of scientific facts. In our society today, plagued by COVID-19 and threatened by climate change, the movie\u2019s message to trust science is all too relevant. Despite newspapers, scientific research, statistics, and distressing anecdotes, many refuse to get vaccinated, wear a mask, or make environmentally sustainable life choices. Of course, it is easier to ignore the fact that thousands of people die daily from COVID-19 or to deny that a comet is descending upon us. Without belief, there is no need for lifestyle changes, but there is also no hope for a solution.\nWhat, then, does it take to make people believe? In the film, as the end of the world looms closer and closer, hordes of Americans rally behind the \u201cDon\u2019t Look Up\u201d movement, blissfully ignorant of the enormous comet shining above them. It is not until one man looks up that the crowd follows, unveiling the truth. Seeing the comet for themselves makes them believe in its existence. While perceiving for oneself is likely more effective than statistics, it is unfortunately not always possible. In this case, by the time it became possible, their fate was imminent. Nothing could be done. Believing no longer mattered.\nThis raises the more nuanced question: what does it take to make people believe before it is too late? Perhaps we can take a lesson from this rallying scene. It was one man, importantly an insider of the \u201cDon\u2019t Look Up\u201d movement, who catalyzed a whole crowd\u2019s belief. We should not underestimate the power of convincing just one disbelieving person of a scientific truth. Not only does each vaccinated, masked, or recycling person make a difference, but each also has the power to communicate beliefs from within social networks. Just as one head turning up turns others, one conversation can lead to many more.\nThe movie divides people into two groups: believers and deniers. Yet, among the believers, some strive to solve the problem for the world and some strive to solve it for themselves. While many scientists work to destroy the comet to save Earth, others focus their attention on finding personal escapes from the disaster. Don\u2019t Look Up\u2019s message is more than just to trust science. Believing alone isn\u2019t enough to prevent the spread of COVID or global warming, and our conversations cannot stop there. These disasters affect us all, and just as we do not face them alone, we must use knowledge of them to protect, not just ourselves, but everyone.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/science-denial-why-it-happens-in-dont-look-up%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "It\u2019s All in Your Head: Zooming In on the Connections\ufffc",
            "author": "Cindy Mei",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Mei_Figure1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nFor decades, researchers have sought to map the \u201cconnectome,\u201d a structural wiring diagram of brain communication. Yale School of Medicine Professor of Radiology and Biomedical Imaging and of Neurosurgery and Director of Magnetic Resonance Imaging (MRI) Research Todd Constable and his lab are more interested in the functional connectome\u2014the organization of neurons working together during different tasks.\nBlood flow and neuronal activity are correlated, allowing active brain regions to be mapped via functional MRI, which assembles images made of 3D volume-pixels (\u201cvoxels\u201d) using blood-oxygen-level-dependent signals. Atlases (coordinate maps of brain structures describing outline or volume) are constructed by parcellating regions into fewer hubs called nodes based on functional synchronization, but there\u2019s no consensus on a singular atlas, making it difficult to compare and generalize findings that aren\u2019t dependent on the same atlas.\n\u201cWhen there\u2019s dysfunction in certain circuits, you want to be able to point and talk about them in a reasonable manner where people know what it is you\u2019re talking about. And right now, we don\u2019t really have that common language,\u201d Constable said.\nFinding an ideal, stable atlas was the challenge Wenjing (Wendy) Luo, a Ph.D. student in the Yale Department of Biomedical Engineering, and Constable originally sought to tackle. However, they discovered something many studies have long taken for granted.\nThe functional connectome is a matrix of nodes. Past research examined between-node changes and connectivity strength, but a study demonstrating changes in nodes across tasks inspired Luo and Constable\u2019s recent study published in NeuroImage examining within-node changes. \u201cWe were trying to find out what is actually driving node reconfiguration, and that led us to look at smaller-scale connectivity,\u201d Luo explained.\nUsing machine learning to analyze data from the Human Connectome Project S900, Luo\u2019s models displayed strikingly high accuracy in matching subjects\u2019 scans in one task (e.g., resting, gambling) to their corresponding scan in a different task, predicting the task performed in scans, and classifying subject gender. Additionally, by comparing singular voxels to others in the same node, she found that differences in inter-voxel connectivity affect node connectivity as a whole. The shift in voxel connectivity across tasks and conditions implies that neural activity within nodes is far from uniform and unchanging, as had been previously assumed.\nIgnoring within-node changes means loss of crucial information that could improve models\u2019 predictive power of a person\u2019s attention and memory and associations of behavior with brain activity. \u201cIf we take this information into account, lots of results of some previous studies should change,\u201d Luo reflects, referencing her paper which identified 50 studies that potentially misattributed results to between-region changes rather than changes within regions themselves. \u201cSo we have to be careful about many claims that have been made before.\u201d\nConstable has another important takeaway. \u201cThe brain is complicated. In the neuroimaging community, people keep wanting to boil things down to this region does this or this region does that. And I think that\u2019s the wrong approach. There are sophisticated systems that are flexible in how they team up to execute functions, and we need to embrace their complexity.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/its-all-in-your-head-zooming-in-on-the-connections%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Exciting Experiments in Exoplanets",
            "author": "Emily Shang",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/shang1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Courtesy of NASA Goddard Space Flight Center.\nAstronomers and laymen alike have wondered whether earth-like planets\u2013\u2013ones with the capacity to host life on their surfaces\u2013\u2013exist in the vast expanse of our galaxy.\nA collaboration led by scientists at Yale has made progress on this problem. Rachael Roettenbacher and Sam Cabot of Debra Fischer\u2019s lab use radial velocity observations, measures of a star\u2019s motion toward and away from Earth, to find shifts in the color of its light. These shifts indicate that the star\u2019s center of mass has moved from the gravitational tug of exoplanets, planets orbiting around the star. However, spots on a star, areas that appear cooler than others because the star\u2019s magnetic field has stifled heat energy transport, can distort light to mimic or degrade the signs of an exoplanet. Roettenbacher and Cabot focus on dark spots and how they affect radial velocity measurements.\n\u201cNow, these starspots are still very hot, but since they\u2019re contrasted with a hotter environment, they appear dark,\u201d Roettenbacher said. Roettenbacher has been studying spotted stars since she was an undergraduate. \u201c[I have] always been interested in [understanding] how we can detect the smaller spots in these sun-like stars,\u201d Roettenbacher said. Cabot has been studying exoplanets and radial velocity techniques since he was a first-year graduate student at Yale and has made these subjects a core part of his Ph.D. thesis.\nA regular challenge in identifying exoplanets has been that dark and bright spots on a star\u2019s surface warp measurements of radial velocity. However, Roettenbacher and Cabot can now use the advanced technology of Fischer\u2019s EXtreme PREcision Spectrograph (EXPRES) and other major astronomical facilities. These facilities include the Transiting Exoplanet Survey Satellite (TESS) and the Center for High Angular Resolution Astronomy (CHARA) Array, an interferometric array.\nThe researchers specifically studied the star Epsilon Eridani, a crowd favorite in astronomy communities since it is one of the brightest stars in the night sky. Epsilon Eridani is also especially active. \u201cSpots appear and disappear frequently on its surface, making it difficult to find new planets around it. But that also makes it an exciting star for testing new methods,\u201d Cabot said.\nUsing TESS, the team made reconstructions of the surface of Epsilon Eridani from which they modeled radial velocities, then compared their model to the data from the EXPRES. \u201c[We] plotted it and got [the] model, and it looked exactly like [the] data, which was really exciting. There is still room for improvement, but it means the model we have now is pretty accurate,\u201d Cabot said.\nThe team has its sights set on the next steps for this powerful technology. They continue to study Epsilon Eridani\u2014this time using the CHARA Array to obtain an image of the stellar surface to improve the model radial velocities and perfect their method for the search of exoplanets.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/exciting-experiments-in-exoplanets/",
            "captions": [
                ""
            ]
        },
        {
            "title": "\u201cHumanity: It\u2019s In Our Bones\u201d",
            "author": "Himani Pattisam",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Pattisam_Figure1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nWhat makes us human? Though the question is often posed in philosophy, art, and other humanities-centered disciplines, scientists in Dr. James Noonan\u2019s lab are investigating it from a biological perspective. Dr. Emily Dutrow, a then-graduate student in the Noonan lab, studied human genes through a different model: humanized mice.\n\u201cThis is the first instance of our lab generating a [humanized mouse model] project like this, and it opens up the types of studies that can be done in the future,\u201d Dutrow said. The humanized mouse model is a pioneering technology, and Yale leads in this emerging field.\n\u201cYale has a great deal of expertise in mouse embryology,\u201d said Noonan. For example, the Yale Genome Editing Center (YGEC) specializes in creating genetically engineered mouse models for investigators to use in their research. The center utilizes various techniques for these novel models, including CRISPR-Cas9 gene-editing technology, homologous recombination, and cryopreservation.\nThe Noonan Lab has a special interest in specific sections of the genome called human accelerated regions (HARs). Human accelerated regions are the human-specific areas of the genome that make us different from our primate counterparts. \u201cWhen I went into graduate school, I was initially interested in very big questions about evolutionary biology and what mechanisms differentiated species,\u201d said Dutrow, who has since moved on from the Noonan Lab to post-doctoral work at the National Institutes of Health. At Yale, Dutrow wanted to study how these HAR sequences made us who we are today.\nThe Noonan Lab utilized computational techniques to identify potential regulatory DNA sequences conserved between other species but different from humans. HAR2 was chosen because it had the largest acceleration signature or difference from a sister lineage in a primate closely related to humans, but the Noonan Lab plans to study the rest of the HAR sequences in the future.\nDutrow found that HAR2 increases the expression of the gene Gbx2, which regulates limb development. This HAR sequence was introduced into mouse embryos, and comparing their development with a group of mice with a primate-equivalent sequence revealed that HAR2 is involved in altering the rate of human limb development.\n\u201cThe goal [now] is to study how this change interacts with the other HARs,\u201d Noonan said. The lab\u2019s ultimate goal is to reconstruct a genetic pathway specific to human evolution.\nWith the success of the Noonan lab\u2019s first humanized mouse model, Noonan and Dutrow are both excited about the prospect of delving deeply into what makes us humans biologically different from chimpanzees or bonobos, our closest genetic relatives. It\u2019s hard not to be excited about this science: how incredible is it that mice are helping us discover the evolutionary and developmental basis of humanity?\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/humanity-its-in-our-bones/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How Pigs Could Help Us Pee: A New Era of Xenotransplantation\ufffc",
            "author": "Kayla Yup",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Yuo_Fig4-416x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Tyler Greer.\nFor Jayme Locke, the hardest part of being a transplant surgeon is knowing that a gold standard treatment exists, yet not being able to use it. In the face of end stage kidney disease, the biggest barrier to treatment is the ongoing organ shortage. With demand drastically exceeding supply, a radical solution is imperative. That solution oinks, rolls in mud, and can play videogames with their snouts. Enter the pig: an innovative solution to the organ supply crisis.\nAt the University of Alabama at Birmingham (UAB), Locke was the lead surgeon in a study that performed the world\u2019s first transplant of genetically modified kidneys from a pig into a human. According to Locke, there are eight-hundred thousand Americans with kidney failure, and within that group, six-hundred thousand are on dialysis. Only around ten percent of these Americans make it to the kidney transplant waiting list, and a measly three percent receive kidney transplants each year.\u00a0\n\u201cWe know kidney transplantation is the cure for kidney failure. We want to be able to offer the cure to everyone in need,\u201d Locke said.\nOnly about thirty-five percent of people survive past eight years on dialysis. Meanwhile, a kidney transplant offers a success rate of ninety-five percent (for deceased donor transplants) to ninety-eight percent (for living donor transplants). A kidney transplant also improves a person\u2019s quality of life. Kidney failure is an end stage disease\u2014if it is not fixed, the patient will die. Therefore, the prospect of having an organ on the shelf, waiting for anyone who needs it, is truly revolutionary.\u00a0\nIn their search for a donor source animal, pigs stood out. In order to meet the current and projected demand for kidney transplants, the research team needed an animal that could rapidly reproduce large litters. \u201cThe domestic pig was chosen because of its ability to \u2018scale-up.\u2019 They also have a lifespan close to thirty years, which is great when it comes to kidney longevity,\u201d Locke said.\u00a0\nHowever, since the pig is still relatively foreign to the human immune system, it was crucial to edit ten genes to make the pig kidney more \u201chuman.\u201d These edits, along with the standard immunosuppression involved in human-to-human transplantation, allowed the human body to tolerate the pig kidney, and for the pig kidney to sustain the person.\nThe specific genetic modifications included the targeted insertion of two human complement inhibitor genes, two human anticoagulant genes, and two immunomodulatory genes, in addition to the deletion of three pig carbohydrate antigens and the pig growth hormone receptor gene. The end result was a herd of genetically engineered pigs whose inability to express red blood cell antigens allows them to serve as universal donors.\nAccording to Locke, one of the greatest challenges in xenotransplantation is understanding tissue compatibility between the porcine donor and human recipient. If the tissues do not match between the donor and the recipient, the latter will reject the organ within minutes of establishing blood flow. To overcome this challenge, the team reached out to Vera Hauptfeld-Dolejsek and Julie Houp, co-directors of the UAB Histocompatibility Lab, who developed a novel assay specific to pig-to-human transplant.\u00a0\nFor the assay, the pig donor\u2019s red blood cells were combined with the human recipient\u2019s serum in a crossmatch. This assay tested whether a kidney from a pig could tolerate an adult human environment. The negative control was pooled human male AB serum, while the positive control serum contained IgG, an antibody known to react with porcine cells. In the study, the human recipient\u2019s blood was mixed with pig cells to demonstrate a negative crossmatch, allowing the transplantation to proceed. This ability to predict compatibility between the pig xenograft and the human recipient would prove to be very accurate.\nThe second hurdle of this study was testing for hyperacute rejection without harming a living person. Hyperacute rejection occurs a few minutes after the transplant as a result of the antigens being completely unmatched\u2014the body\u2019s immune system treats the transplanted organ as a foreign object and attacks it. The team\u2019s solution was to create the first human preclinical model.\nThe Parsons model was named in honor of Jim Parsons, a fifty-seven-year-old man from Huntsville, Alabama. Parsons had been a registered organ donor through Legacy of Hope, which is Alabama\u2019s organ procurement organization. In light of his sense of adventure and desire to make a difference, the Parsons family sought to pay tribute to his character. After Parsons was declared brain dead and his organs were deemed unsuitable for donation, the Parsons family ultimately consented to him serving as the first preclinical model for this groundbreaking study.\nWhile human brain death had already been used to harvest organs for human transplantation, it was novel to leverage brain death as a preclinical human model. One critical concern to be tested via the model was the vascular integrity of pig kidneys. Pigs do not have the same mean arterial pressure as an adult human being, so whether the transplanted kidney would be able to hold its integrity was unknown. Another goal of this preclinical model was to determine whether the genetic engineering, coupled with a negative prospective crossmatch, were sufficient to prevent hyperacute rejection.\u00a0\nDuring surgery, the two pig kidneys were positioned in the exact anatomic locations used for human donor kidney transplantation, and employed the same attachments to the renal artery, renal vein, and the ureter.\u00a0\n\u201cIn the present study, the crossmatch was performed prior to transplant\u2014just as happens in human-to-human transplantation\u2014and it was negative, predicting there would NOT be hyperacute rejection. The only way to validate this was to perform the actual transplant and demonstrate the kidney turned pink and made urine. We did this leveraging the Parsons Model, and in so doing, answered key safety questions without risking the life of a living person,\u201d Locke said.\nTo the team\u2019s delight, the pig kidneys reperfused promptly in the same manner as human transplants. The kidneys retained optimal color and turgor, the vascular connections between donor organ and recipient stayed intact, and there were no major bleeding episodes. Within around twenty minutes, the right kidney started making urine, later followed by the left. The ureter had successfully carried urine from the pig kidney into the human bladder. There was no sign of hyperacute rejection.\nThis success proved the accuracy of their crossmatch and firmly established brain death as a viable preclinical model for studying the human condition\u2014where a treatment\u2019s safety and feasibility may be tested without doing harm to someone. Such a model would extend far beyond xenotransplantation\u2014there are many diseases that have yet to be understood, along with new techniques and devices in need of testing before use on a living person.\u00a0\nIn a pathogen-free facility, a herd of pigs awaits. These pigs will be the proper size for adult human transplantation by June 2022. The team hopes that the FDA will approve their Investigational New Drug Application, and thereby allow the launch of a phase I clinical trial in living persons, a process Locke is hopeful to begin in 2022.\nParticularly in the era of COVID-19, regulatory agencies will rigorously assess the transmission of viral diseases from pigs to humans. In this study, the team tested the pig pre-procurement to ensure that the pig did not have any diseases. Further, the human recipient\u2019s blood was tested post-transplantation to prove the absence of pig-derived infections or diseases.\nLocke is hopeful that, as early as five to ten years from now, the pig xenograft kidney will be available for widespread use. She envisions xenotransplantation and allotransplantation as complementary; together, there is the real potential to completely eliminate the waiting list and wipe out the organ shortage.\u00a0\nFor now, our ability to pee may be secured, one pig at a time. Who knows what organ or animal will be next.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/how-pigs-could-help-us-pee-a-new-era-of-xenotransplantation%ef%bf%bc/",
            "captions": [
                "The surgical team prepares the abdomen of the recipient for xenotransplantation."
            ]
        },
        {
            "title": "Stressed Out? You Could Be Aging Faster",
            "author": "Kelly Chen",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/chen_stress_image-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nIn popular culture, we commonly believe that stress makes one age faster. A simple Google image search of \u201cstress and aging\u201d returns pictures of presidents from when they first started their term to a couple of years later, with the difference being a head full of gray hair.\u00a0\nPrevious research has proven this idea to be true in patients with high stress, including those with post-traumatic stress disorder, trauma histories, or other mental illnesses. Now, researchers from Yale\u2019s psychiatry department, including psychiatry resident Zachary Harvanek, have shown that stress makes even healthy populations age faster. Using GrimAge \u2013 an epigenetic clock or biochemical test that correlates with chronological age, disease, and mortality \u2013 the researchers found that stress might contribute to accelerated aging even before contributions from chronic illnesses start taking a toll. In this study, most participants were white and between 18-50 years old.\nHow can we slow down the effects of epigenetic aging when stress is a pervasive element in most of our lives? \u201cPeople who have stronger emotion regulation or stronger self-control seem to be more resilient not just to the psychological effects of stress but also to the physical effects as well,\u201d said Harvanek.\u00a0\nFuture research could involve investigating the impact of race and culture on epigenetic aging and testing whether methods that build emotion regulation actually lessen the psychological and physical effects of stress. And what can communities like New Haven and Yale do to help with these stress-causing factors? \u201cThe more important things are going to be providing those sorts of resources,\u201d said Harvanek.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/stressed-out-you-could-be-aging-faster/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Dopamine",
            "author": "Victoria Vera",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/vera_brain_image-500x354.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of iStock Photo.\nDopamine, a chemical that acts as a neurotransmitter, is responsible for sending thousands of tiny \u201cmessages\u201d that ultimately help generate several of our thoughts and actions. It has a myriad of functions within the body and brain, but it is best known for allowing us to feel pleasure, satisfaction, and motivation. With this in mind, it is no surprise that it is a major point of focus when discussing addiction and reward. Social factors are also known to heavily influence the human brain and psychiatric outcomes, although there is scarce research proving a biological connection. Because of that, leading researchers at Yale have set out to explore these connections.\nIn this project, led by Katina Calakos and Aleksandra Rusowicz, the team used Positron Emission Tomography (PET scans) to image dopamine receptor (D2/3 R) availability. This data was obtained from previous studies and then correlated to population and socio-economic measures obtained from the Social Explorer Analyses of the 2014-2018 Census.\u00a0\nThe results were surprising. For one, they found that higher D2/3R availability was significantly associated with a higher total population in residential ZIP codes. Similarly, in zip codes where a lower percentage of the population possessed a bachelor\u2019s degree or higher, there was a higher dopamine D2/3 R availability. Functionally, one could take this to mean that environment does have a significant impact on our brain chemistry.\nDopamine in and of itself is extremely useful and, as previously mentioned, necessary for normal bodily functions. However, issues can arise when there is too much or little of it. For example, excessive dopamine activity has been linked to anxiety, insomnia, and mania. On the other end of the spectrum, low dopamine activity can cause problems like muscular issues, cognitive impairment, and attention deficits. Considering this background and the findings from this research, one could assume that the environment does impact the way your brain works.\nAleksandra Rusowicz and David Matuskey, co-first author and corresponding author on this paper, respectively, discussed both the inspiration and the implications of this research, in addition to what it could mean going forward. This project was driven by prior animal studies focusing on how dopamine availability was affected by the animal\u2019s position within its \u201csociety\u201d and how that could later predispose them to develop drug dependency. Initially, this team asked questions focused on how greenspaces could affect brain chemistry, as environmental surroundings have been shown to affect brain activation. All those contexts came together to produce this more recent research.\u00a0\u00a0\nHowever, their findings represent one small step in filling this gap that is all too common for health research. Most of the evidence comes from epidemiological or longitudinal studies focusing on certain aspects of a population \u2013 living conditions, education, health, and correlations. However, the biological data to back-up these findings is simply scarce and a relatively new area of focus. This is why research like this could help inform future findings that focus even more closely on the type of social factors that impact social development. The investigators also expressed their hope that research like this could potentially have policy implications, providing a biological backbone to diversity and education initiatives in communities that are often neglected.\u00a0\nWhile Matuskey described the use of census data as \u201cadvantageous\u201d because they could focus on surroundings and environments, their research had some limitations. Despite how useful it was in gaining insight into these communities, it was fairly broad and could be considered outdated when we take into account the changes brought about by newer factors such as the COVID-19 pandemic. It is likely that if this team had had access to more specific data, we could have been able to discern even more detailed patterns about how location and social circumstances impact the brain developments in question.\nSocial factors have been correlated to health for years, but thus far, we have lacked the biological data to support this claim. Thanks to work like this, we now have biological data that can support the existing studies. As this type of science gains more traction, we will see more and more detailed results. Maybe one day, we can use those findings to push for policy change that ameliorates the roots of these problems.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/dopamine/",
            "captions": [
                "Human brain illustration with hormone biochemical (serotonin, dopamine, and norepinephrine) concept background"
            ]
        },
        {
            "title": "Hello Haloscopes",
            "author": "Isabel Trindade",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/qZ4rWjv95dJmQTVPYAmiqf-1200-80-1-500x350.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Livescience.\nDark matter is known to permeate our universe, but its exact nature has long remained a mystery. Now, new research from the Wright Laboratory at Yale sheds light on the presence of dark photons, a candidate for dark matter. The team, led by Sumita Ghosh, a graduate student in applied physics at the Wright Laboratory, developed new methods of analyzing existing data sets from devices known as haloscopes, which have previously been used to detect particles known as axions. This new method of detecting dark photons could help answer long-standing questions about dark matter.\nGhosh says that she had previously read about dark photons but had not studied them in her research before. Her greatest motivation, she says, coincided with the pandemic. \u201cI couldn\u2019t do my regularly scheduled work anymore,\u201d Ghosh said. Thus, she decided to focus on this project, whose work combines algebra, probability, and coding, all of which she could do at home. Ghosh was inspired by previous research on dark photons, including two studies in particular: one by Arias et al. on WISPy Dark Matter, and another by Caputo et al., \u201cDark photons: a cookbook.\u201d \u201c[The Caputo paper] is absolutely brilliant,\u201d said Ghosh, \u201cand inspired me to do a more rigorous job on one of the experiments [she analyzed], the CAPP haloscope.\u201d\nThis research is part of an ongoing scientific investigation into the nature of dark matter. Previous astrophysical observations indicate that around 85 percent of the matter in the universe is dark matter, the nature of which is still, for the most part, unknown. However, most of the previous research in dark matter has pointed to certain characteristics of dark matter: it is massive, stable, and manifests primarily through interactions with the observable universe, particularly gravitational interactions.\nOne candidate for the basic, or elementary, dark matter particle is the axion, which is detected using detectors known as haloscopes. A haloscope is a device made of a strong magnetic field in a microwave cavity, within which we search for signals matching the range of axion frequencies. Haloscopes can also detect the presence of dark photons, which are another dark matter candidate. Not much is yet known about dark photons, but according to Ghosh, they are a possible \u201cflavor\u201d of the photon and the mediator of a \u201cdark electromagnetic force.\u201d\n\u201cAll particles in particle physics have parameters, including mass, charge, and other properties with a numeric value,\u201d said Ghosh. Particles such as axions and dark photons, which we know less about, have is a range of possible values for each property. The combination of these ranges in vector form is known as the parameter space. This study describes a procedure to convert haloscope data from axion parameter space into dark photon parameter space, thus allowing for more potential detection of dark photons using haloscopes.\u00a0\nDark photon fields can be uniformly or non-uniformly polarized, both considered in this study. \u201cThe method outlined in this work for using a single cavity haloscope as a dark photon detector may be applicable to any haloscope that employs a similar analysis procedure,\u201d Ghosh said. Regarding the viability of the dark photon as a dark matter candidate, they have several mechanisms that allow them to naturally produce relic abundance \u2013 which refers to the amount of a particle that is still around after the Big Bang \u2013 of dark matter. However, Ghosh said, \u201cthe motivation for dark photons is not contingent on their comprising all of dark matter.\u201d\nThis research is significant because there are many materials that dark matter could consist of, each of which has a large parameter space. \u201cIt\u2019s important to try to narrow that down faster than we\u2019re currently able to,\u201d said Ghosh. \u201cEach experiment built is so expensive, and it would be amazing if we could make them all more productive by being able to interpret the same data in many different ways.\u201d Ghosh also noted that, since the publication of her research, other researchers have contacted her about ways to extend the results of their experiments, paving the way for further exploration of other particles beyond standard-model photons.\nFuture research in the direction of this study may include potential improvements in the signal strength detected by the haloscopes. In addition, the dark photon limits in the polarized case may be enhanced by tailoring the method of conversion to each haloscope experiment\u2019s analysis method. \u201cThis technique will be greatly enhanced by single photon detection, similarly to axion detection,\u201d Ghosh said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/hello-haloscopes/",
            "captions": [
                ""
            ]
        },
        {
            "title": "To Diagnose or Not to Diagnose",
            "author": "Gonna Nwakudu",
            "authorLogo": "",
            "date": "May 16, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/nwakudu_pills_image-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of iStock Photo.\nAfter the opioid epidemic peaked between 1990 and 2013, one challenge facing healthcare professionals is how to treat patients on long-term opioid therapy (LTOT) who are at risk of addiction.\u00a0\nTo better comprehend this challenge, Dr. William Becker and his team at the VA Connecticut Healthcare System and Yale School of Medicine invited medical specialists from the U.S. and Europe to discuss new diagnostic criteria for patients on LTOT for whom the benefit of the therapy is no longer outweighing the harm, but who may not meet criteria for opiate use disorder (OUD).\u00a0\nSpecialists who favored the creation of new diagnostic criteria, like Becker, want to shine light on the unique circumstances these patients face. \u201cWe did have a substantial minority of experts who said\u2026 there should not be a different entity,\u201d Becker said. \u201cWe\u2019ve heard from these experts that if we create a new diagnosis, it may\u2026 have the unintended consequence of stigmatizing people who have opioid addiction to non-medical sources of opioids.\u201d\nIn continuing this conversation, Becker strives to incorporate more specialists from diverse racial backgrounds as well as patient voices. \u201cThere has been a strong movement in bringing persons with lived experiences into clinical research,\u201d he said. \u201cIt hasn\u2019t happened much\u2026 in terms of thinking of creating diagnostic entities, but it probably should.\u201d\u00a0\nNevertheless, Becker is excited for this conversation to lead to new ways of tackling patient needs. \u201cWe have to be proactive earlier,\u201d Becker said. \u201cWe can identify this early, give it a name, and then develop protocols for getting appropriate treatment to patients sooner, rather than waiting until more adverse consequences develop.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/to-diagnose-or-not-to-diagnose/",
            "captions": [
                "Image depicts a person with a cast on one hand holding tablets in the other hand."
            ]
        },
        {
            "title": "Regrowing Cartilage May Take an Electric Kick\ufffc",
            "author": "Chloe Nield",
            "authorLogo": "",
            "date": "May 15, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Nguyen-and-Liu.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Thanh Nguyen.\nWhen Professor Thanh Nguyen began his position at the University of Connecticut, he was gifted a book about electricity in the body. Nguyen, who already had experience working with electric materials, was amazed by the possibilities of using such materials in medicine. Aware of the lack of treatment options for arthritis, he wondered if an electric material could be of use.\nAccording to the Centers for Disease Control and Prevention (CDC), nearly a quarter of all adults in the United States suffer from arthritis. Arthritis results from problems in the cartilage tissue, which is especially difficult to heal because it lacks access to blood vessels, breaking down and leading to bones rubbing together.\nAt present, the primary treatment for arthritis is a cartilage tissue graft placed at the site of injury. Tissue can be taken from the patient themselves or others. However, this can lead to other arthritic problems, and the patient\u2019s body can reject foreign tissue.\nAlong with researcher Yang Liu, who had previous experience with tissue engineering, Nguyen began research on \u200b\u200bbiodegradable piezoelectric poly-L-lactic acid (PLLA) nanofiber scaffolds as a treatment for arthritis.\n\u201cIn the lab, we use a very traditional medical polymer often used for surgical suture, so it\u2019s very safe, and transform it into a very special form so that it can produce an electrical charge when you apply force to it,\u201d Nguyen said.\nNguyen and Liu found that this material could act as an electrical stimulator for cartilage regrowth. Electrical charge creates a friendly environment for tissue growth because it attracts stem cells, which are critical in repair. When PLLA is under pressure, such as a joint force, atom rearrangement within the scaffold creates a dipole. A huge breakthrough in the research was discovering that the negative side of this dipole better promotes the migration of stem cells.\nInitial research performed by Nguyen and Liu involved placing the PLLA scaffold in the joints of rabbits. Over two months, they have witnessed promising progress towards cartilage tissue regrowth. The main question now is: will it work in humans?\nNguyen and Liu said that before clinical trials can occur, they want to explore three main issues. First, they need to see if the scaffold can survive under a load as heavy as the human body. Nguyen and Liu also need to discover how long the PLLA scaffold must be active so that the human cartilage tissue can regrow. A biodegradable material was chosen in the hopes that once the material has done its job, it will degrade and not require removal. However, this also means it must not break down until its work is complete. Finally, Nguyen and Liu explained that they want to optimize the scaffold before clinical trials, making sure that the scaffold can withstand the pressure of the human body while also emitting the optimal amount of electrical charge.\nNguyen and Liu are excited for what\u2019s to come. In the future, they aim to research how the scaffold can be modified to treat various types of arthritis. Nguyen and Liu are hopeful to someday see these treatments realized in therapy for arthritis.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/regrowing-cartilage-may-take-an-electric-kick%ef%bf%bc/",
            "captions": [
                "Thanh Nguyen (left) and Yang Liu (right) holding the PLLA scaffold."
            ]
        },
        {
            "title": "Mental Health Through the Ages\ufffc",
            "author": "Georgia Spurrier",
            "authorLogo": "",
            "date": "May 15, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/mental-health-g59cbe41ec_1920-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nChildhood mental health disorders can be pervasive, often remaining and recurring throughout life. A recent study published in the Journal of the American Academy of Child & Adolescent Psychiatry explored how access to mental health services during childhood may affect the incidence of adult psychopathology using a longitudinal design studying children in predominantly rural areas of North Carolina. The study assessed 1,420 children with a diagnosed psychiatric disorder and reassessed these children in adulthood. They discovered that participants who accessed mental health services in childhood did not show any reduced risk of adult psychiatric disorders compared to those who did not access childhood mental health services. \u201cThere\u2019s a gap between the tools we are creating and implementation in the real world,\u201d said Dr. William Copeland, a researcher at the University of Vermont Medical Center who led the study.\nMost psychiatric disorders develop during childhood or adolescence, highlighting the importance of focusing on early risk factors and establishing a strong childhood mental health system. As evidenced by this study, the current system is geared towards reducing impairment at the time of treatment. In contrast, mitigating risk for adult disorders may depend on many other factors. Notably, Copeland and his colleagues controlled for twelve different variables, such as family socioeconomic status and childhood trauma, between the groups of children who did receive services and those who did not. This helped isolate the use of services as the predicting variable of adult psychiatric risk. \u201cI think this is one of the strengths of our study\u2026we tried to mimic a randomized design within an observational framework,\u201d Copeland said. The findings in this study do not invalidate the importance of early life intervention and access to services but rather emphasize the pervasiveness of mental health conditions, underscoring the importance of intervention at several points across a lifespan.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/mental-health-through-the-ages%ef%bf%bc/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Counterpoint: Salamanders Should Not Be Alive",
            "author": "Nathan Wu",
            "authorLogo": "",
            "date": "May 15, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wu_Fig2-500x281.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nAccording to all known laws of evolution, there is no way that salamanders should be able to exist. At first glance, these creatures seem like marvels of evolution with regenerative abilities and other unique adaptations that protect them from predators. However, upon closer inspection, their very existence seems to break all rules. Their hearts are practically hollow, with muscle walls as thin as a single cell. Their cells are oversized, sometimes hundreds of times larger than those of humans. Trying to build such a small animal with such large cells is like trying to make a detailed sketch with a king-size Sharpie. Rather than being evolutionary marvels, salamanders seem to be on the verge of death at all times.\nPerhaps more surprising, though, is that many salamanders seem to be barely born. They normally start their lives as aquatic larvae and later metamorphose into terrestrial adults. However, several species have lost their ability to metamorphose, remaining confined to a half-larval state for the entirety of their lives, never losing their gills or developing strong limbs. Their bones never fully harden, remaining soft cartilage instead. Even their brains are embryonic, with less cell differentiation than their amphibious relatives.\nSo how are they still around?\nThe secret to this anatomical curiosity lies where most biological secrets lie\u2013within the genome. However, its peculiar phenotypes may not come from specific genes. Instead, they are a product of the quantity of DNA present.\nSalamanders contain some of the largest genomes of any animal, with some species carrying 38 times as much DNA as humans. Their slow development can be explained by the fact that all their \u201cextra\u201d DNA drastically increases the time it takes to transcribe DNA to RNA. The size of the salamanders\u2019 genome goes against the common notion that larger, more complex animals, like humans or primates, should carry larger genomes than simpler ones, like salamanders. So why are salamander genomes so large?\nScientists discovered that salamander genomes are riddled with sections of DNA called \u201cselfish genetic elements.\u201d These elements consist of short DNA segments, called transposons, which contain various genes that code for their own replication. Once copies of these transposons are produced, they insert themselves into different parts of the genome. Transposons can also affect the function of native genes, activating or deactivating them, potentially harming the host.\nTransposons are found in most living things, including humans, but their density in salamanders is extremely unusual. Usually, transposons are deleted over time through random mutations, but it is believed that salamanders parse their genomes at a rate much slower than humans or other organisms, resulting in the accumulation of genetic material.\nThese rogue, selfish genetic elements appear to be a wrinkle in the laws of evolution that we are familiar with. Scientists are beginning to look at the genome itself as an ecosystem, with transposons acting as species within it to better understand their role. Under such a model, transposons adapt and change to maximize their prevalence in the genome. If a transposon\u2019s location has a positive or neutral effect on the host, it will likely persist there, being passed down to future generations.\nUsually, if the accumulation of transposons begins to have detrimental effects on a species, natural selection will pare down the genome. The persistence of the salamander\u2019s large genome suggests that the downsides associated with it do not significantly affect them. As a result, this genetic process created a feedback loop where salamanders\u2019 slowly growing genomes pushed them into the evolutionary niche that they occupy today.\nOur knowledge of salamanders and transposons is altering our understanding of evolution. Not all changes to phenotypes are driven by evolutionary pressure or are beneficial to the organism. Rather than viewing DNA and organisms as inseparable, scientists are beginning to consider DNA as something that attempts to replicate itself through whatever means, without consideration for the overall well-being of its host.\nSalamanders\u2019 bloated genomes seem to have pushed it to the brink of extinction. Its mangled bones, flimsy heart, and underdeveloped body don\u2019t make any sense.\nThe salamander, of course, lives anyways. Because salamanders don\u2019t care what humans think is impossible.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/counterpoint-salamanders-should-not-be-alive/",
            "captions": [
                ""
            ]
        },
        {
            "title": "These Are Not the Genes You\u2019re Looking For",
            "author": "Sophia Burick",
            "authorLogo": "",
            "date": "May 13, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/24315920330_cf49ca5060_o-462x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Source: Image Courtesy of NIH Image Gallery. \nSince its inception in the 2010s, genome editing has been revolutionizing biotechnology, with methods like CRISPR/Cas9 empowering scientists with \u201cgenetic scissors\u201d that allow them to make remarkably precise edits to DNA\u2014the genetic instructions in cells that control cell function, development, and reproduction.\u00a0\nThis technology has widespread applications, from engineering solutions to genetic diseases to combating globally threatening plant pathogens. However, CRISPR/Cas9 is greatly limited by its inability to distinguish between genetic sequences that repeat several times throughout the genome, which occurs often. The Isaacs Lab at Yale University has discovered a powerful method to uniquely alter the genetic address of repeated genetic sequences. This method of \u201cfiltered editing\u201d allows CRISPR to identify and edit specific sites of repeated sections of DNA.\nFor Felix Radford, a graduate student at Yale and the first author of a recently published Nature Communications article on filtered editing, this discovery has been a long time coming. \u201cAs an undergrad taking molecular biology, I started to think more about biology as a technology,\u201d Radford said. \u201cPreviously, I was thinking about biology as various processes in life, in the human body, but these very complicated systems started to remind me more of how computers work.\u201d\u00a0\nRadford\u2019s view of biology as a tool to facilitate creative engineering was foundational to his interest in synthetic biology and ultimately led him to Yale professor of TKTK Farren Isaacs\u2019 lab as a graduate student. \u201cWhen I first joined the Isaacs Lab, my initial project was to engineer the ribosome, a molecular machine central to the function of all living organisms that are responsible for the synthesis of proteins or protein biomaterials,\u201d Radford said. But he quickly ran into an issue\u2014even in bacteria, which generally have much less repetitive genomes than humans, their genomes contained seven repeated copies of the ribosomal DNA. CRISPR/Cas9 was unable to distinguish the repeated sites of ribosomal DNA, preventing Radford from making the edits he wanted.\u00a0\n\u201cIt\u2019s like on the computer\u2014you find a string that you want to edit in a sequence. How do you search for that and find it?\u201d Radford said. \u201cIt\u2019s like Ctrl-F in the genome, but we have these repeated sequences that will lead you astray.\u201d\nRadford needed a solution. So he turned to self-splicing introns. These are RNA sequences that do not code for proteins and can excise themselves from exons (segments of RNA that do code for proteins). \u201cYou can put them into an RNA, and they will cut themselves out, leaving only the sequence that you want to edit remaining,\u201d Radford said.\u00a0\nDNA segments encoding self-splicing introns can be inserted into the genome to distinguish one repetitive site from another, providing a unique genetic address for CRISPR to recognize and target that site. When the DNA is transcribed into RNA, the self-splicing introns cut themselves out of the RNA strand and stitch together the gap. This solution was incredibly exciting to the Isaacs Lab since this tool would allow them to edit these repetitive sequences, which had previously been exceptionally difficult to target.\u00a0\nAfter the initial discovery, Issacs posed an interesting question to Radford: what if he expanded this method to modify many sites at once instead of just one site in the ribosome? \u201cTo do that, I needed to have different types of introns that could work in parallel,\u201d Radford said. \u201cWe ended up combining two different introns into one, and it worked in the same way as the original intron.\u201d This only widened the door to applications of this technology.\n\u201cOne application of this is that these repetitive genetic elements are found in many different organisms,\u201d Radford said. Repetitive genetic elements comprise over 50 percent of the human genome. The ability to specifically edit these repetitive sequences offers great potential for studying and combatting genetic diseases.\u00a0\nAnother application that the Isaacs Lab is readily exploring is the use of filtered editing to alter ribosomes and translation factors in the cell, repurposing cells to manufacture new sequence-defined polymers, proteins, and biomaterials. \u201cThis can be very important in utilizing biology as a means to evolve new materials and medicines,\u201d Radford said.\u00a0\nAs for Radford\u2019s future, he is interested in applying this technique to new problems. \u201cIn science, when you have new techniques, they open up a lot of possibilities that were not possible before,\u201d Radford said. \u201cI\u2019m curious to see where this goes, to see what new capabilities are available now that we can do this.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/05/these-are-not-the-genes-youre-looking-for/",
            "captions": [
                "Ribosomes (pictured above) control protein synthesis in the cell. By employing filtered editing, the Isaacs Lab is able to specifically edit repetitive genetic sequences in ribosomal DNA, creating genetically engineered ribosomes that can be used to manufacture sequence-defined polymers, biomaterials, and medicines."
            ]
        },
        {
            "title": "Undergraduate Profile: Jennifer Miao (YC \u201922)",
            "author": "Emily Shang",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Yale senior Jennifer Miao (YC \u201922) was recently awarded the Gates Cambridge Scholarship, a prestigious fellowship that fully supports Miao\u2019s pursuit of\u00a0a Ph.D. at the Laboratory of Molecular Biology at Cambridge (LMB). At Yale, Miao is a member of the Trumbull community, enjoys leading Yale\u2019s running club as the captain, and is currently working at the Mariappan Lab on Yale\u2019s West Campus.\nDespite Miao\u2019s incredible dedication to her scientific pursuits, she has not sacrificed her passion for the outdoors. Miao runs every morning despite long hours at the lab. When asked how she juggles her many commitments, she explained that she does not see her daily runs as a burden. \u201cIt really helps with balancing the stresses of lab, schoolwork, and just college life. It also helps to sort of get new ideas and just get away from work and come back to it with a sort of renewed vigor,\u201d Miao said.\nMiao\u2019s scientific journey started when she was a high school student working in a lab at UCLA under Associate ProfessorJose Rodriguez. She used X-ray crystallography to structurally elucidate the core of an infectious prion fibril which has been implicated in many neurodegenerative diseases. This work ultimately culminated in a paper detailing a new approach to resolving protein structures.\nMiao explained that a huge problem in structural biology today is the loss of critical information from the diffraction pattern returned by X-ray crystallography. This issue is, in part, avoided by using a related protein model in different stages to refine the existing model. However, Miao worked on adapting a new way to circumvent this issue by using fragments of a non-related protein model of the structure and obtaining an atomic structure through electron diffraction. Using this technique, Miao eventually published another paper displaying her findings on the core of prion fibrils and their relationship to a right or left orientation. Miao spoke at the prestigious 2019 CCP4 Study Weekend at Nottingham University, U.K. During her first trip to the U.K., she describes having enjoyable conversations with Phil Evans, a former group leader at the LMB, and Randy Read, a crystallographer at Cambridge University.\nWhen it comes to influential scientists and research mentors, Miao has no shortage of inspiration. Miao\u2019s first mentors in academia were Rodriguez and David Eisenberg of UCLA. Her unwavering focus as an undergraduate to obtain a Ph.D. comes from her love of the exploratory and collaborative manner with which Rodriguez encouraged his students to work. She fell in love with academia because her work with Rodriguez was curiosity-driven, as very few answers were known for the questions she was studying in his lab. \u201c[I] enjoyed thinking about and planning my experiments every day,\u201d Miao said.\nWhile Miao was pretty set on pursuing a Ph.D., she was unsure whether it would be in the U.S. or the U.K.. \u201cWhat really influenced me to look into the U.K. was Dr. Rebecca Voorhees at Caltech because she also did a Ph.D. at the LMB and was very enthusiastic about it,\u201d Miao said.\nMiao will be pursuing structural biology research elucidating the mechanism of mitochondrial protein recruitment from the cytosol, which would be influential in mitochondrial metabolism research. Miao is most excited about the community that facilitates diverse scientific discourse at LMB. \u201cThe culture is quite different from the US. There is coffee time and tea time every day, where most of the labs gather in the canteen on the top floor of the building to talk about science. At the canteen, there is an abundance of expertise across so many disciplines,\u201d Miao said.\nIn parting Yale, she advises any prospective STEM student interested in academia to fearlessly pursue their research passions and find great mentorship among the approachable research faculty. \u201cDon\u2019t [be] afraid to [\u2026]ask for help or get advice from professors. They\u2019re always willing to spend time to help undergraduates,\u201d Miao said. She cited her experience working with renowned RNA biologist Joan Steitz. \u201cPeople I thought would be completely unapproachable were actually very down-to-earth and easy to talk to,\u201d Miao said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/undergraduate-profile-jennifer-miao-yc-22-2/",
            "captions": []
        },
        {
            "title": "Science in The Spotlight: The Man Who Tasted Words",
            "author": "Elisa Howard",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Howard_1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Can we trust our own reality?\nAs neurologist Guy Leschziner describes in his recently released book, The Man Who Tasted Words, the senses of sight, sound, touch, taste, and smell enable humans to craft an understanding of the world outside of the physical body. \u201cThese senses are our windows on reality, the conduits between our internal and external lives. [\u2026] Without them, we are cut off, isolated, adrift,\u201d Leschziner writes. Moreover, as the phrase \u201cseeing is believing\u201d suggests, humans often rely on sensory information as infallible evidence obliterating all doubt about the existence of some entity or phenomenon in the world. However, are the senses accurate?\n\u00a0\u201cWhat we believe to be a precise representation of the world around us is nothing more than an illusion, layer upon layer of processing of sensory information, and the interpretation of that information according to our expectations,\u201d Leschziner says. He suggests that the sensory organs fail to function as accurate witnesses of reality. Therefore, we should question the reliability of conscious experience. In essence, the nervous system functions as a supercomputer manufacturing human perception through processes reconstructing sensory inputs largely without our awareness. That is, the physical interactions of the sense organs\u2014the eyes, skin, ears, nose, and mouth\u2014with the external world are merely basic inputs quite disparate from the nervous system\u2019s construction of perception.\u00a0\u00a0\nIf the nervous system shapes our reality, what happens when neural processes go awry? Throughout his book, Leschziner describes individuals with sensory abnormalities. For instance, one patient named James experiences synesthesia, in which stimulation of one sensory modality concurrently evokes sensation in another modality. For James, this involves the fusion of sound and taste, conferring the ability to essentially perceive the taste of words. The Lord\u2019s Prayer tastes like bacon, the name of his friend\u2019s wife tastes like chunky vomit, the word \u201ccourt\u201d tastes like a crispy fried egg, and his grandmother\u2019s name tastes like rich condensed milk. As James\u2019s story demonstrates, neurological conditions like synesthesia fundamentally alter one\u2019s experience and perception of reality.\u00a0\nHumans often rely on the senses for a faithful understanding of the external world. However, we must recognize the innate limitations of that approach. \u201cOur experiences and cold, hard reality can be almost entirely divorced, as with molecules of a particular structure and our experience of smell or flavour,\u201d Leschziner writes. The brain essentially manufactures a perception far removed from the physical world. Meanwhile, human perception remains reliant on the integrity of the nervous system that converts basic sensory inputs into conscious meaning. \u201cThe pathways, from physical environment to our experience of it, are convoluted and complex, vulnerable to the nature of the system, friable in the face of disease or dysfunction,\u201d Leschziner says. As it appears, the brain functions as the master controller employing unseen manipulations to manufacture a perception both distinct from physical reality and malleable in response to structural or functional changes in the nervous system.\u00a0\nPerhaps we cannot trust our own reality.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/science-in-the-spotlight-the-man-who-tasted-words-2/",
            "captions": [
                "Leschziner portrays the brain as a supercomputer constructing conscious experience. Image courtesy of Pixabay."
            ]
        },
        {
            "title": "Science in the Spotlight: Into the Metaverse",
            "author": "Kelly Chen",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Chen_1-500x282.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Your favorite artist takes the stage, and you cheer wildly along with the ten million other people standing next to you. No single physical stage could fit a crowd of that size, but there is a place that can.\nWelcome to the metaverse.\nThe future that we saw in sci-fi movies has hit the public as an emerging reality following Facebook\u2019s rebranding to Meta and the online gaming platform Roblox going public on the stock market.\nThe metaverse can be defined as many things: virtual reality, the evolution of the internet, a digital economy, a place where avatars of ourselves interact with others, and so on. So, to put it more clearly, Yonatan Raz-Fridman on the podcast \u201cInto the Metaverse\u201d reframes the question from what the metaverse is to what the metaverse isn\u2019t. \u201cThe metaverse is not a device. It\u2019s not something you\u2019re going to access from your mobile phone, VR goggles, or AR glasses\u2026The metaverse is the next iteration of the internet,\u201d Raz-Fridman said. A podcast co-hosted by Raz-Fridman and Matthew Kanterman, \u201cInto the Metaverse\u201d explores subjects from development and investment to experience within this new space.\u00a0\nOver the past two years, we have seen the effects of the pandemic on human lifestyle and our dependence on technology for connection and education. With isolation restrictions loosening in the U.S. and worldwide, most believe we will return to a state of pre-coronavirus normalcy. However, in actuality, especially in younger generations, constantly being online has been ingrained into daily rituals. For example, the average amount of time spent on Roblox has continued to increase even with more relaxed restrictions. \u201c[The metaverse is] going to reimagine our lives in virtual spaces,\u201d Raz-Fridman said. Starting from entertainment and gaming with companies like Roblox, Epic Games, and Unity, the metaverse will also extend into all industries, education, workplaces, and fundamentally, how we connect with others.\nThis novel technology is fascinating, even a bit scary, as there is so much to look out for. Who will govern the metaverse? Will the major companies developing the metaverse try to keep it as a closed ecosystem or a walled garden? Or, will control of the metaverse become more decentralized, something that could align with the growing popularity of blockchain technology, NFTs, and cryptocurrency?\nThere are so many other questions to consider. How do we increase internet access to more regions of the world that need it? Will the metaverse be a form of escapism from the real world? Or a place to exploit consumerism in the virtual world? How do we keep our human connections and identities? How will the metaverse affect climate change? How to define the metaverse and questions like these are constantly being discussed and reevaluated on the podcast \u2014take a listen! The hopeful stances of Raz-Fridman and Kanterman may alleviate some fears directed toward the metaverse or, at the very least, can give you some wonderful food for thought.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/science-in-the-spotlight-into-the-metaverse-2/",
            "captions": [
                "Person using a VR headset to access the metaverse. Image courtesy of Pixabay."
            ]
        },
        {
            "title": "Alumni Profile: Daniel SpielmanA Network Between Fields of Math",
            "author": "Risha Chakraborty",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Chakraborty_Fig1-348x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "With the advent of social media networks like Facebook and Snapchat, our world is increasingly connected and complicated. Understanding the nature of these networks now requires wading through enormous amounts of information and performing overwhelming computations. This problem will only multiply in the future, making arriving at any meaningful conclusions about data unimaginably difficult.\u00a0\nThis was the dilemma that Daniel Spielman (YC \u201992), Sterling Professor of Computer Science and Professor of Statistics and Data Science and Mathematics at Yale, sought to solve. He wanted to use a technique called sparsification, which takes large data sets and removes points that do not contribute important information about the data. He found inspiration in an almost unrelated field of mathematics. This venture helped him solve a decades-old problem in the field of operator theory, earning him the Ciprian Foias prize and the Polya Prize.\u00a0\nSpielman had initially thought that his problem was in the realm of linear algebra. \u201cIt\u2019s one of those courses every math major takes that talks about finite-dimensional spaces,\u201d Spielman said. However, upon discussion with visiting professors and his graduate students, Adam Marcus, a postdoc at Princeton University, and Nikhil Srivastava, a graduate student at UC Berkeley, he realized that his sparsification problem mirrored an existing problem in operator theory called the Kadison-Singer problem, developed in 1959. The Kadison-Singer problem, which examines how to divide a group into two groups that are as equal as possible, had previously been discussed in the fields of quantum physics and computer science but had not been explored in the field of data science.\u00a0\nThe Kadison-Singer problem, or the concept of partitioning groups in general, is relevant in everyday decision-making. Suppose a PE teacher needs to divide a class of students into two equally skilled teams to play kickball. To achieve this, he will need to rank the students by their kicking, throwing, and catching abilities and separate students so that the two teams are approximately equal in all three abilities. Spielman\u2019s initial paper proved that the Kadison-Singer problem was an equivalent restatement of the sparsification problem. In a monumental 2014 paper, Spielman and his colleagues proved the existence of a solution, countering Kadison and Singer\u2019s decades-long conjecture that not every mathematical group could be divided equally. Marcus, Srivastava, and Spielman\u2019s work earned them the Polya Prize in 2014. Proving the ability to partition groups provided the impetus to explore new ways to divide networks into relatively equal groups, which aided in network sparsification: if one group was simply omitted from the network, there wasn\u2019t any net loss of information. In subsequent years, Spielman and his team worked on developing mathematical tools to achieve such data sparsification, for which they received the Ciprian Foias prize in Operator Theory earlier this year.\u00a0\nSpielman\u2019s transformation of a linear algebra problem into an operator theory problem reflects his general approach to mathematics. He first became interested in solving challenging puzzles in the fourth grade, took college math and programming classes in high school, and pursued a bachelor\u2019s degree in mathematics and computer science at Yale. He has always been interested in using computational tools to solve problems. \u201cThere\u2019s a marriage between [math and computer science]. I was once trying a proof in my undergraduate lab, and a computer program found a counterexample in a couple of months that I wouldn\u2019t have found in a hundred years,\u201d Spielman said.\u00a0\nSpielman now employs computation in all of the problems he chooses to solve. \u201cI keep a list of problems that interest me, and when I am interested in working on a problem, I check if there\u2019s a similar problem on my list and if someone\u2019s already worked on similar problems,\u201d Spielman said. He claims he cannot predict what problem he wants to solve next. He may continue working on sparsification, networks, or topics in linear algebra but will inevitably draw inspiration from other mathematical concepts and fields. \u201cI completely change my research agenda every few years,\u201d Spielman said.\u00a0\nHe is currently working on establishing the Kline Tower Institute (KTI) for the Foundations of Data Science to sponsor talks between experts in different fields who want to employ data science techniques in their work. Ultimately, Spielman encourages every college\u00a0student to try some math classes. \u201cYou never know what\u2019s going to be useful, so you should take classes that interest you. Later in life, you may find that useful connection,\u201d Spielman said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/alumni-profile-daniel-spielmana-network-between-fields-of-math/",
            "captions": [
                "Daniel Spielman is the Sterling Professor of Computer Science and Professor of Statistics and Data Science and of Mathematics at Yale University. He strives to combine his intersectional interests in his current work with sparsification of data networks."
            ]
        },
        {
            "title": "Hidden Histories: Eunice Newton FooteThe Woman Who Discovered the Greenhouse Effect",
            "author": "Ann-Marie Abunyewa",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/EuiceFoote1-Catherine-Kwon-500x446.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Among the signatures at the 1848 Seneca Falls Convention for women\u2019s rights is the name Eunice Newton Foote. With her name inscribed next to those like Elizabeth Cady Stanton and Lucretia Mott\u2014both well known in U.S. history for their advocacy of abolition,women\u2019s rights, and suffrage\u2014she may seem like just another attendant at the convention, but her legacy was not fully recognized until just a few years ago. Today, we recognize her as the first person to recognize the impact of carbon dioxide on climate change, preceding John Tyndall, the scientist previously credited for this breakthrough.\nUsing a straightforward experimental setup, which included a cylinder, a likely glass, and thermometers placed inside, Foote concluded that carbon dioxide and moist air could absorb heat. Similar to how the glass in greenhouses can maintain heat inside its walls when it\u2019s cooler outside, certain gases can trap heat from the sun in the Earth\u2019s atmosphere. The significance of the greenhouse effect today is that rising carbon dioxide levels due to the burning of fossil fuels are contributing to climate change and global warming. Foote had made the connection that climate change is largely influenced by varying levels of gases like carbon dioxide and water vapor in the air; she subsequently published her results in the American Journal of Science and Arts in 1856. Her paper was also presented at a conference in the same year. However, Foote did not present her own article\u2014it was uncommon for women to have done so. Instead, a summary of her work was given by Joseph Henry, who would later become the first secretary of the Smithsonian Institution. His summary would be found in almost every publication that presented Foote\u2019s findings, while Foote\u2019s original publication remained unrecognized. Even though Henry recognized Foote as an equal in science, her legacy\u2019s absence suggests that others had minimized her contribution to the scientific community over time.\nIn 1859, about halfway across the world in Europe, Tyndall had also found that certain gases absorbed heat and immediately reported his findings to the Royal Institution. By 1861, he had carried out further experiments and published a paper. He had been one of several scientists who, like Foote, was concerned with the ability of certain gases to trap heat, and since then, he has received sole credit for the discovery of the greenhouse effect.\nThe mere five-year difference between Foote\u2019s discovery and the publication of Tyndall\u2019s paper raises questions about his omission of Foote\u2019s name in his acknowledgments. Given that some publications in the U.S. would not have been widely read in Europe and vice versa around this time, it is unlikely that Tyndall took from Foote\u2019s experiment and failed to give her credit.\u00a0\nHowever, this story still places Eunice Newton Foote\u2019s name on the long list of women, like Rosalind Franklin, Katherine Johnson, and Mary Jackson, whose efforts in STEM went unrecognized for years, and in some cases, for decades or centuries. Foote\u2019s story reminds us that women and nonbinary people continue to face discrimination, exploitation, and lack of due credit in STEM. Her presence at the 1848 Seneca Falls Convention was no accident\u2014Foote understood that the world she lived in would not recognize her contributions as a woman, and she wanted to see that change. Being friends with Elizabeth Cady Stanton, Foote helped Stanton organize the proceedings of the entire Seneca Falls Convention. Her signature is fifth on the Declaration of Sentiments, a seminal work from the conference that demanded equal rights for women, including the right to vote. While recognizing Foote\u2019s work is one more step in acknowledging the talents and contributions of underrepresented figures in STEM, it is a reminder that the field of science still has quite a long way to go.\n\n\n\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/hidden-histories-eunice-newton-footethe-woman-who-discovered-the-greenhouse-effect/",
            "captions": [
                "Eunice Foote, a pioneering scientist and women\u2019s rights activist. Art credited to Catherine Kwon."
            ]
        },
        {
            "title": "A Future for Fusion? Producing a self-heating plasma",
            "author": "Krishna Dasari",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Dong_Fusion-Alex-Dong-500x347.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Alex Dong. \nFusion \u2013 the ambitious goal of energy research and science fiction material from Iron Man to Star Wars. Though touted as the ultimate solution to our search for a clean and cheap energy source, practical fusion energy has eluded our grasp for decades since its theoretical conception in the late 1920s.\nDuring fusion, two isotopes of hydrogen\u2013deuterium and tritium\u2013are subjected to extreme heat and pressure until they form a plasma and subsequently coalesce into helium. During this process, a small fraction of the mass is converted into astronomical amounts of thermal energy. The process is far more sustainable, productive, and safe than any current energy source, but a series of physics and engineering challenges have long prevented retrieving a net gain in energy. However, recent developments at the National Ignition Facility (NIF), such as having the fusion fuel heat itself, are rapidly changing that narrative.\nJust east of San Francisco, the Lawrence Livermore National Laboratory, which hosts the NIF, has been tackling fusion since the 1960s. The multi-billion-dollar campus was created to engineer a particular path towards fusion: inertial confinement fusion (ICF). In this method, the inertia of the fuel keeps itself stationary for less than a billionth of a second, during which intense heat and pressure force its compression.\u00a0\u00a0\nInside the apparatus, deuterium-tritium fuel is contained within a diamond capsule, hovering at the center of a cylinder called a hohlraum. Lasers surround the hohlraum and inject light into openings on the hohlraum\u2019s ends at various angles. Some lasers\u2013outers\u2013strike the hohlraum at a greater angle and farther from the capsule than others called inners, and both cause X-ray emissions. These X-rays converge on the capsule like hammers on hot metal, carrying energy that ionizes the diamond surface, producing an explosion. This explosion generates pressure that initiates an implosion, compressing and heating the capsule and fuel to the point of fusion.\u00a0\nThese reactions operate on a small scale. Only two hundred micrograms of fuel are used, the energy entering the hohlraum\u20131.9 megajoules\u2013is only enough to run a computer for a few hours, and the fusion yield is currently less than that. However, the power involved is on a massive petawatt scale due to the speed at which the energy is consumed and produced. Burning more fuel requires extra control, a future goal for the team.\nFusion research proceeds through a stairway of milestones. \u201c[Each milestone] slowly tips the balance in the fusion plasma between [energy] losses and gains,\u201d said Omar Hurricane, the co-lead author of two breakthrough papers recently published in Nature. After the first milestone\u2014initial fusion with some self-heating\u2014comes fuel gain, where fusion yield surpasses the energy input. Next is the burning plasma state, where self-heating by helium nuclei produced during fusion eclipses external heating. Finally, ignition. Much like a rocket, ignition allows fusion reactions to take off. Ignition overcomes all cooling processes, and the fusion reactions become self-sustaining.\u00a0\nFollowing the launch of ICF experiments in 2009, the NIF achieved fuel gain in 2014. Subsequently, hundreds of scientists at the NIF set their eyes on the next milestone of the burning plasma state. However, they encountered one central problem: asymmetric implosions.\u00a0\n\u201cWe\u2019d like this nice spherical compression to maximize the transfer of kinetic energy. We put energy into the shell, it flies inwards, and it carries the fusion fuel on the inside, and at some point, it runs out of any place to go, converting that kinetic energy into internal energy. That\u2019s what heats the fusion fuel up,\u201d Hurricane said.\nIn an asymmetric implosion, the pressure is unevenly distributed around the capsule and fuel, inducing movement of the capsule\u2019s center of mass during the implosion. The kinetic energy of that movement is siphoned from the input energy, representing a major leakage in the conversion of the fuel\u2019s kinetic energy into internal energy. Asymmetry can be produced by imperfections in the capsule, in the lasers and their resultant X-rays, and in the inward movement of plasma generated when the lasers strike the hohlraum.\nThe scientists approached these problems through a combination of theoretical physics, experimentation, and iterative development of simulations. They soon discovered a problem: previous simulations weren\u2019t accurate in predicting the interference to the laser beams from laser-generated plasma. For example, a plasma cloud generated by the outers, which strike the hohlraum nearest to where the lasers enter, can expand rapidly and interfere with the inners, producing asymmetries.\n\u201cIt\u2019s been a very iterative set of steps where we go from doing experiments, seeing something wrong, figuring out what\u2019s wrong, how to fix it, implementing the fix, doing another experiment, and the whole cycle starts over and over again,\u201d Hurricane said. \u201cThat\u2019s what a lot of science is \u2026 but you do steadily make progress, and that\u2019s what we\u2019ve done over the last decade.\u201d\nOf the many proposed solutions, only two could be selected for testing due to limited resources. The first solution implements cross beam energy transfer (CBET), allowing one laser to transfer its energy to the other laser, given correct engineering of the laser wavelengths. CBET permits energy transfer to the inners, producing a more symmetric implosion. The second solution addresses the issue of the outer-laser-generated plasma interference. Creating pockets in the hohlraum at the site where outers hit increases the distance the plasma must travel toward the center. This gives inners more opportunity to travel without interference, decreasing laser asymmetry.\nNow that asymmetry is less of a limiting factor for energy transfer, the researchers have enlarged the fuel-capsule target, which increases the heating tendency of the fusion fuel relative to its cooling tendency. As further solutions to fuel-capsule asymmetry are developed, the fuel load can be increased, producing more efficient fusion reactions.\nThe NIF tested these three innovations in combination and found that they had achieved a burning plasma state, making substantial energy gains in the process. Their maximum fusion yield was 0.17 MJ, about ten times smaller than the input laser energy but ten times greater than the energy input into the fuel, far surpassing the fuel gain milestone.\u00a0\nWhile the significance of burning plasma for energy research is undeniable, the limited yield and scalability of the reaction hinder its applicability. A viable power source requires ignition, the efficient capture and conversion of released thermal energy into electric energy, and a yield surpassing the hundreds of megajoules required to operate the fusion reactor. Yet, the burning plasma milestone provides a strong foundation for the future of fusion. \u201cIt\u2019s an existence proof\u2026 that maybe this is possible, that we\u2019re not all crazy, and we\u2019re not wasting our time (entirely) working on this stuff. That being said, it\u2019s also showing it\u2019s actually much harder than people originally expected,\u201d Hurricane said.\nThe first of these requirements, and the last milestone from the physics end of fusion research, has already been achieved by the NIF \u2013 ignition! In unpublished results, the team achieved an energy yield of 1.35 MJ, approximately 70% of the input energy. Further research will focus on overcoming engineering hurdles to improve energy yield, increasing fuel volume while avoiding asymmetry, and better simulating compression dynamics.\nUnlike what science fiction often leads us to believe, these developments are not straightforward solutions designed by a few notable people but are decades-long projects requiring the input of generations of scientists and engineers repeatedly redesigning, testing, and troubleshooting. As the hundreds of scientists and staff at the NIF have demonstrated, the future of fusion is bright. Although we are still far from having miniature Suns powering our everyday devices, we now have experimental confirmation of a self-heating and even igniting plasma.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/a-future-for-fusion-producing-a-self-heating-plasma/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Brain\u2019s Brake on Overeating",
            "author": "Connie Tian",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Brains_Break_on_Overeating_SophiaZhao-386x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "We all have that friend. The one who can eat donuts and ice cream\u2013essentially whatever they want\u2013without gaining weight. On the other extreme, some people seem to gain weight no matter how little they eat or how much they exercise. So, what exactly is it that allows one person to remain thin without much effort but requires another to struggle to avoid gaining weight?\nOn the most basic level, your weight depends on the number of calories you consume, store, and burn up, but each of these factors is influenced by a combination of your genes and environment. They can affect your physiology and behavior, ranging from how fast you burn calories to what types of food you choose to eat. The human body maintains a delicate balance of \u201cadaptive feeding\u201d to ensure sufficient food intake and limit its consumption to maintain a stable body weight. In the face of environmental changes and food availability, this balance ensures body weight homeostasis. Today, this equilibrium is greatly skewed to favor a positive energy balance. As a result, the increasing prevalence of obesity highlights the need to better understand body weight control.\nA team of researchers, led by Dr. Albert Chen at the Scintillon Institute, Dr. Nicholas Betley, and Dr. Aloysius Low at the University of Pennsylvania, recently found that a distinct group of neurons in the cerebellum\u2014a region of the brain that had previously never been linked to hunger\u2014controls appetite. The project began with an unexpected finding by Chen\u2019s team, who noticed that they could make mice eat less by activating a small group of neurons known as anterior deep cerebellar nuclei (aDCN) within the cerebellum. Despite their specialty in spinal and cerebellar circuits involved in motor control, Chen and Betley contacted their colleagues\u2014Dr. Laura Holsen (Brigham and Women\u2019s Hospital), Dr. Roscoe Brady (Beth Israel Deaconess Medical Center), and Dr. Mark Halko (McLean Hospital)\u2014affiliated with Harvard Medical School to see whether this phenomenon could be observed in humans with eating disorders.\nThe Harvard scientists had previously collected a data set of functional magnetic resonance imaging (fMRI) of fourteen individuals with Prader-Willi syndrome (PWS), a rare genetic disorder characterized by insatiable hunger, developmental delay, and behavioral problems that can lead to life-threatening obesity. The researchers recorded the brain activity of these subjects while they viewed images of food either after eating a meal or after fasting for at least four hours. A new analysis of the data compared to the fMRI scans of unaffected individuals confirmed that the deep cerebellum was the only brain region that showed a significant difference in neural activity between PWS and control subjects. To precisely define the subgroup of neurons in the cerebellum responsible for this phenotype, Low, a Ph.D. graduate of Chen\u2019s lab, transferred to Betley\u2019s lab at the University of Pennsylvania, which specializes in studying homeostatic and hedonic feeding circuits.\u00a0\n\u201cIt had always been a graduate school dream of mine to do a project together with Nick,\u201d Chen said. \u201cIn fact, a lot of the collaborators on this project had worked together on the same floor in graduate school [at Columbia University], so we were determined to make this project work.\u201d\u00a0\n\u201cIt was through Low\u2019s dedication, however, that we were able to see this collaboration through,\u201d Betley said. \u201cEvery project for a graduate student runs into difficulty\u2014Low had discovered an incredible feeding phenotype but could not get the phenotype independent of a reduction in locomotion.\u201d While Low had observed that the specific activation of the aDCN in the cerebellum reduced food intake in mice, he also needed to prove that this phenotype was independent of locomotion, which was also known to be regulated in the cerebellum. Furthermore, since the cerebellum had never been linked to appetite regulation before, the proof had to be indisputable. For example, if the activation of the aDCN reduced the motor skills of the mice, which caused the subsequent decrease in food intake, they would not be able to definitively conclude that the aDCN was a direct feeding center.\u00a0\n\u201cWe were close to killing the project so many times,\u201d Chen said. \u201cBut, by continuing to pursue his theory and performing over a hundred new experiments, Low was able to define the precise subpopulation of neurons involved in regulating feeding\u2014and that was the entire difference,\u201d Betley said. Once Low had developed mice models where the feeding phenotype was completely isolated from locomotion, they could conclusively prove that the aDCN really was a feeding center rather than a center that affects feeding through a change in locomotion.\u00a0\nFurther experiments then elucidated the mechanism behind the feeding phenotype. The activation of aDCN activates ventral tegmental area dopamine neurons that release dopamine in the ventral striatum, a region of the brain involved in reward processing, motivation, and decision-making. The team had observed a strong correlation between levels of ventral striatal dopamine and reduction in food intake after aDCN activation. This seems paradoxical since higher dopamine levels should reinforce food intake while decreasing dopamine levels may result in anorexia. However, the long-lasting increase in baseline dopamine levels can reduce its responsiveness to food. Increasing baseline levels blunt how the brain\u2019s pleasure center responds to food, similar to how the effects of drug intake are blunted over time.\u00a0\nThe team also observed that the reduction in food intake did not cause any metabolic compensation or increased food intake to make up for the missed meal. Caloric deficits in animals usually cause their metabolism to slow down, but this was not observed in the mice models with activated aDCN. Thus, these findings have great potential to address obesity, as a reproducible caloric deficit will ultimately result in weight loss.\nToday, Chen and Betley continue their collaboration to test whether they can manipulate aDCN activity in patients with PWS using a noninvasive intervention known as transcranial magnetic stimulation (TMS). They are hopeful that TMS can be used to activate aDCN activity to reduce food intake in patients with PWS. These experiments could not only lead to a clinical trial to treat PWS but also open up new avenues for treating other types of eating disorders.\nChen and Betley hope that their research will change how scientists view neuroscience and how the general public views obesity more broadly. Their findings are only the latest in a series of discoveries revealing that different regions of the brain are not simply responsible for one specific subset of behaviors but rather overlap in their functions to regulate human behavior. Thus, Chen and Betley hope that large collaborations between experts in different brain regions will become more common.\u00a0\nMoreover, they hope that these findings will change how we view individuals with obesity. Unfortunately, it is common to blame people with obesity for their condition. However, rather than blaming a person for their lack of control or willpower, we might be more sympathetic to their condition, understanding that obesity is a disease. As we continue to learn more about how our brain, genetics, and environment impact our bodies, we will become more equipped to address eating disorders in a more compassionate and constructive manner.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/the-brains-brake-on-overeating/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Real-Life Infinity Stone: The Time Crystal",
            "author": "Anavi Uppal",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Uppal_2-500x333.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Robert Strasser, Kees Scherer, and Michael B\u00fcker on Flickr.\nIn grade school, many of us learned that there are three basic states of matter in the universe: solid, liquid, and gas. However, in recent years, scientists have created several more, including one state that seems to bend the laws of physics: a \u201ctime crystal.\u201d While it may sound more like an Avenger\u2019s oddity than a scientific reality, time crystals have unique properties that can be used for extremely precise timekeeping. Previously, they have been very difficult to create and maintain. Now, researchers from the United States and Poland have innovated a new way of creating time crystals that could allow them to leave the confines of sophisticated laboratories and be used for everyday applications.\nMost people are familiar with normal, garden-variety crystals: quartz, diamonds, snowflakes. These crystals consist of repeating patterns of atoms layered on top of each other to form a 3D structure. In 2012, theoretical physicist and Nobel laureate Frank Wilczek wondered if a similar phenomenon could exist where a crystal\u2019s pattern would repeat in time rather than in 3D space. The crystal\u2019s default state would be to switch back and forth between two different structures. What makes time crystals so strange and unique is that they spontaneously break time-translation symmetry, which says that a stable object will act the same throughout time.\u00a0\nWe have an intuitive sense of time-translation symmetry for objects in our daily lives. For example, imagine that you\u2019re holding a tray with a rubber ball on it. You tilt the tray from side to side, making the ball roll across the tray repeatedly. You expect the ball to make one trip across the tray each time it is tilted\u2014however, if the ball suddenly decided to rocket back and forth across the tray fifty times faster than the speed of your tilting, you would certainly be very surprised. This change breaks time-translation symmetry, just like time crystals do. Time crystals are naturally not in static equilibrium, making them a new state of matter.\nScientists first created a time crystal in 2016, and several groups have devised different versions of time crystals since then. However, they all have one unfortunate characteristic in common: they can\u2019t ever be taken out of the lab due to their complicated and precise configurations. In fact, after a certain amount of time, even the crystals in the lab will devolve and stop their periodic motion. These factors severely limit the lifetime of time crystals and prevent them from being used for everyday applications outside the lab. However, a few groups of scientists have proposed the creation of a time crystal out of light that wouldn\u2019t be bound by these limitations, and one recently succeeded in creating one of these time crystals.\nIn 2018, Hossein Taheri was a recently graduated electrical and computer engineering Ph.D. who had just started his lab at the University of California at Riverside. While visiting a friend for lunch at the California Institute of Technology and chatting about physics projects, his friend mentioned a curious concept he had never heard about before: time crystals. When he returned home that day, he found and read a review article that discussed time crystals, and it struck a chord with him. \u201cWithin a few days, I was just thinking that, well, we can create something with these properties!\u201d Taheri said.\nHe shared his thoughts with Andrey Matsko, a group lead and collaborator at the NASA Jet Propulsion Laboratory working with quantum and nonlinear optics. Matsko agreed that their work might relate to time crystals and greenlighted delving further into this line of research. In their first couple of papers, they wrote very cautiously about the concept. \u201cBut little by little, we realized that, well, we are on the right track. Why not shoot higher?\u201d Taheri said. Taheri then decided to contact and collaborate with Krzysztof Sacha, a physics professor at Jagiellonian University and one of the first researchers to study time crystals.\nTheir team\u2019s approach is simpler and less expensive than those previously used to create time crystals. They shine two lasers into a tiny crystal cavity roughly two millimeters across, and the beams bounce around the walls of the cavity. The beams are stabilized using a method called self-injection locking, which was developed by a team at OEwaves Inc. led by president and CEO Lute Maleki. If the beams are tuned to the correct power and frequency, the interacting light eventually spontaneously resonates at a frequency entirely different from the properties of either input laser beam, creating a time crystal in the cavity. Previous studies had only ever used solid-state physics to create time crystals\u2013theirs was the first to use light and optics.\nTheir light-based time crystal is revolutionary because it isn\u2019t subject to the limitations of solid-state physics. Previous solid-state time crystals required extremely cold cryogenic environments and complicated, expensive equipment. In contrast, optics work just fine at room temperature and can also create time crystals with a much longer lifetime. \u201cWhat we are offering with this work is that if you have a resonator and two lasers, and you spend probably a few thousand dollars on your setup, you in principle can generate a time crystal,\u201d Taheri said. This pioneering innovation makes the study of time crystals vastly more accessible and could pave the way for using time crystals in everyday applications.\nThe main application of light-based time crystals comes from their remarkably accurate timekeeping abilities. While they are some orders of magnitude less precise than state-of-the-art atomic clocks, they aren\u2019t picky about their environmental conditions and can thus provide highly accurate timing while being rugged enough to load onto a plane or car. This tradeoff in precision is necessary since the time crystal generated by the team cannot be more stable than the two lasers that created it. In order to have more stable lasers, the environment around the crystal would need to be tightly controlled, or the system setup would have to be more complicated.\nLight-based time crystals could also enable entirely new avenues of physics research through the creation of bigger time crystals. The \u201csize\u201d of a time crystal refers to the ratio between two different time periods: the time it takes for one complete back-and-forth structure change of the time crystal and the period of the laser\u2019s light waves. A \u201cbigger\u201d time crystal has a larger ratio. Most previous time crystals only had a size of two or three, while this research team\u2019s light-based system could create crystals with a size of twenty or even fifty. These bigger time crystals would essentially provide scientists with a larger \u201claboratory space,\u201d allowing them to do more complicated experiments. In particular, larger time crystals can be used to mimic condensed matter time crystal experiments that are otherwise difficult or even impossible to conduct in smaller time crystals. But beyond this known application, the study of the crystals themselves is still young and could result in fascinating new science that researchers can\u2019t yet imagine. \u201cThis, for me, is the most interesting application,\u201d Matsko said.\nIt\u2019s extraordinary that just ten years after Frank Wilczek\u2019s musings about the existence of time crystals, we are now close to seeing them outside the laboratory. But this transition from a dream to reality isn\u2019t a novel process\u2013even the first cell phone was inspired by Star Trek\u2019s sci-fi communicator devices. Scientists who dare to adventure have the incredible power to forge these far-fetched ideas into our world\u2019s reality.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/a-real-life-infinity-stone-the-time-crystal/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How to Trick a Tooth Fairy: Engineering Synthetic Tooth Enamel",
            "author": "Kayla Yup",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Synthetic_Tooth_Fairy_Kuo-Malia-Kuo-e1662269180764-491x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Kayla Yup.\nIf you find it difficult to brush and floss regularly, you might be in luck. Researchers from China and the US engineered an artificial alternative to enamel that was designed to be even stronger. But could this man-made enamel trick a tooth fairy?\nEnamel is the tooth\u2019s outer shell responsible for shielding teeth from damage. This tissue usually serves the body for over sixty years and cannot be regenerated. In addition to enamel\u2019s incredible durability, it possesses outstanding viscoelasticity\u2014the ability to endure vibration and deformational damage for long periods, such as when chewing. While viscoelasticity is key to enamel\u2019s longevity, its hardness allows teeth to bite through tough material. However, these mechanical properties are traditionally considered trade-offs and are difficult to reproduce in man-made materials.\u00a0\u00a0\nThe challenge was to figure out how to copy what nature had already designed. The key to enamel\u2019s seemingly paradoxical combination of properties turned out to be its hierarchical structure of elements, represented by the dense packing of nanowires interlaced with soft organic matter. The organic material is known as the amorphous intergranular phase (AIP), which effectively forms a connection between adjacent nanowires through strong chemical bonds. According to Lin Guo, corresponding author and Beihang University Professor of Chemistry, the abundance of unsaturated chemical bonds in amorphous materials allows for this tight binding.\u00a0\n\u201cThe notion of functional complexity, which requires some amount of order and some amount of disorder, is the great representation for this amorphous, disordered layer on the surface of the nanorods forming enamel,\u201d said Nicholas Kotov, corresponding author and University of Michigan Professor of Chemical Sciences and Engineering. \u201cThe inside of [the enamel\u2019s nanorod structure] is ordered for the stiffness, and the outside is disordered for the adaptability of the interfaces.\u201d\nThe interface is the area between the inorganic material\u2014the surface of the nanowires\u2014and the polymer around it. The AIP acts as a buffer layer that not only facilitates the transfer of force, but strengthens the interface. A strong interface is essential to protecting the nanowires from environmental attacks by acids, alkaline substances, and sharp temperature changes, while enhancing enamel\u2019s mechanical performance. This dynamic layer effectively restricts the propagation of cracks that tend to occur along the interfaces.\nIn order to successfully arrange the structural elements of their synthetic enamel, Kotov drew inspiration from previous studies of chemical engineering processes based on self-assembly. The self-organization of nanorods was achieved through a double freezing technology approach. By applying a freezing gradient, the nanorods were forced to align along one axis, resulting in their proper parallel alignment.\n\u201cEverything in living matter is based on self-organization,\u201d Kotov said. \u201cThis is ubiquitous. Manufacturing based on self-assembly is very attractive for its low-temperature requirements, high energy efficiency, and applicability to a multiplicity of structures\u2014from nanoparticles to nanorods to microscale particles to microscale and nanoscale dental works.\u201d\nTo test this structure\u2019s strength, the team applied an external load to a sample of their synthetic enamel. The nanowires initially slid in response, but the confinement of the organic matter in the gaps between nanowires restricted motion. This hierarchical structure ultimately improved crack deflection, allowing the synthetic enamel to withstand more force than natural enamel.\n\u201cDoes it mean that we have created material better than what has been created by living organisms after billions of years of evolution? The answer is yes, that\u2019s exactly the case,\u201d Kotov said.\nKotov proposed using this synthetic enamel to engineer \u2018smart teeth.\u2019 These sophisticated implants would detect disease inside of the mouth through sensors for anything from bacterial composition to inflammation. This enamel would afford these implants the same type of protection as normal teeth.\u00a0\nBeyond teeth, the simplification of enamel down to layers enables this structure to be built at multiple scales. The successful reproduction of tooth enamel opens the door to engineering other high mechanical performance materials.\n\u201cThe combination of high hardness and stiffness plus viscoelasticity, strangely enough, is very much needed for buildings because of earthquakes, especially for sensitive structures such as nuclear plants,\u201d Kotov said. \u201cSo, scaling up the preparation of materials like enamel and implementing enamel-like materials in other areas of technology are squarely in our plans.\u201d\nFor the inexperienced tooth fairy, this synthetic enamel could pose an evolutionary feat thanks to its strength. But to trick a seasoned tooth fairy, more research on mimicking the 3-D structure of teeth will be required.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/how-to-trick-a-tooth-fairy-engineering-synthetic-tooth-enamel/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Lego Robot\u2019s Organic Brain",
            "author": "Malia Kuo",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/LegoBrain_LanaZheng-500x347.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Lana Zheng. \nLego Hogwarts, Lego Krusty Krab, Lego Death Star. Sure. Fine. But what if there was an artificially intelligent, maze-solving Lego robot car? Well, that\u2019s exactly what Paschalis Gkoupidenis and his team at the Max Planck Institute for Polymer Research in Mainz, Germany, have created.\u00a0\nThe idea of artificial intelligence (AI) is the ability to harness the brain\u2019s efficiency at processing information on a technological level. Currently, a popular approach to achieving AI is the functional representation of biological information processing systems with artificial neural networks. These artificial networks are achieved by \u201cexecuting algorithms\u201d which loosely represent the function of the nervous system in traditional computer architecture. While this field has shown great promise for complex processing and efficient computing, the nature of AI\u2019s programming limits its interactions with our living world and its many triggers and signals. In this manner, it also lacks the efficiency and computing capacity to model biological systems.\nAlternatively, biological neural functions can be directly emulated with unconventional devices, circuits, and architectures. This hardware-based paradigm of brain-inspired processing is known as neuromorphic electronics, which can potentially be far more efficient at computing and processing. Still, in order to learn, intelligence requires \u201cembodiment\u201d through a physical or virtual body to receive environmental signals and act on the environment. \u201cRobotics, with its combination of a physical body and embedded neuromorphic electronics made of organic materials, can offer exceptional capabilities in distributed control, learning, and perception,\u201d Gkoupidenis said. By connecting the sensors with the actions of an intelligent machine, the associations between the electronics and the sensors (known as \u201csensorimotor integration\u201d) allow the machine to perceive the environment. When these associations change as a function of time, machines can learn and improve performance towards a target behavior.\n\u201cThis idea came after a morning coffee discussion with Professor A. Salleo in southern France. Back then, I was a postdoc researcher in France, and Salleo was on sabbatical from Stanford,\u201d Gkoupidenis said. \u201cThis was a really interdisciplinary project, so planning required knowledge in a wide range of disciplines and techniques such as electronics, microfabrication, 3D printing, and of course, robotics and biology.\u201d\u00a0\nWith this team, Gkoupidenis outfitted a Lego car with a neuromorphic circuit, which could be shrunk down to a few micrometers, similar to the size of biological neurons. This circuit created a connection between the sensors and the robot\u2019s motors, which are used to help the robot car perceive its surroundings and move around within it. \u201cThe key property of the circuit is that it\u2019s trainable, meaning that its electrical properties change gradually. This is achieved by gradually accumulating and storing ions inside the devices when the robot fails to achieve its task.\u201d The robot\u2019s mission was to make its way out of a maze of hexagonal unit cells in a honeycomb pattern. The researchers created a path towards the maze\u2019s exit by putting visual cues (circle arcs) at specific maze intersections that indicate a left turn, with right-turning as the baseline movement. Every time the robot failed to find the exit, it would hit the borders of the maze with its touch sensor. This interaction was then received by the neuromorphic circuit, allowing the robot to gradually learn the correct route out.\u00a0\nSpoiler alert: the Lego robot car found the exit!\nWhat is incredible about Gkoupidenis\u2019 research is their use of organic materials to make the circuit, which can conduct both electrons and ions. By using ions as the carriers of information instead of electrons, as in classic electronics, neuromorphic devices more realistically emulate biological processes. Furthermore, organic devices are soft, flexible, and even stretchable, potentially allowing these circuits to be distributed on a robot\u2014which is exactly what happens in living organisms where intelligence is literally distributed everywhere throughout their body. These concepts can be useful across a wide range of robotic systems, whether at home or in industry, agriculture, and the oceans. \u201cWe will see similar concepts in the future in smart bioimplants, for instance, artificial limbs or bioelectronic devices that learn gradually to live efficiently and together with their \u2018owners.\u2019 This will be a new type of hybrid, artificial-biological intelligence, in which both worlds operate synergistically,\u201d Gkoupidenis said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/a-lego-robots-organic-brain/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Sixth Sense from a Sixth Finger",
            "author": "Zeki Tan",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/A-Sixth-Sense-from-a-Sixth-Finger-fantom-fingah-Uriel-Teague-377x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Uriel Teague.\n\u201cPerception is real, and the truth is not.\u201d So said the wife of the late Philippine dictator in The Kingmaker, a 2019 documentary film. Although this quote embodies her distortion of the historical narrative surrounding her husband\u2019s rule, it also describes how people are sometimes fooled by their senses. We commonly assume that our perceptions provide infallible information about our bodies and the world around us. The brain\u2019s vast neural networks integrate senses\u2014including smell, temperature, and light\u2014to help us make sense of stimuli in our environment. For instance, we become aware of a burning fire through the smell of smoke, the heat it gives off, and the ringing of the fire alarm. Given that our bodies do not change drastically throughout our lives, our brains are accustomed to providing a unified experience of these stimuli.\u00a0\nHowever, recent research has suggested that we can alter how the brain represents the human body and trick it into perceiving the existence of imaginary body parts. Denise Cadete, a psychology Ph.D. candidate at Birkbeck, University of London, created a sensory illusion in which participants felt a sixth finger on their hand. To create this illusion, the participants placed their hands on both sides of a vertical mirror so that the reflection of the right hand would appear where the left was placed, with the left hand itself hidden from the participant. Experimenters then stroked each finger on both hands simultaneously, starting with the thumb and ending with the pinky finger. Finally, experimenters made twenty double strokes, one stroke on the table next to the right pinky and another along the outer side of the pinky.\nThough the left hand remained hidden from sight, participants could see the reflection of the right hand where the left should be so that it looked as though the experimenter was actually stroking the left hand and the empty space next to it. As a result, many participants reported feeling a phantom sixth finger on their left hand. Furthermore, experimenters were also able to vary the length of this sixth finger. By altering the length of the strokes they made on the table, researchers created the sensation of a sixth finger fifteen centimeters long, or twice the length of the pinky, and 3.8 centimeters long, or half its length.\nReactions to this perception differed from person to person, but the word participants used most often was \u201cstrange,\u201d even for those who did not report feeling a sixth finger. Matthew Longo, professor of cognitive neuroscience at Birkbeck and Cadete\u2019s research supervisor, explains that this illusion comes from the \u201ctemporal synchrony\u201d of the right pinky being stroked and the eye simultaneously seeing the same movement in empty space. \u201c[These coordinated events] are a very powerful cue to the brain that there\u2019s some causal link between these two things,\u201d Longo said. \u201cThe parts of the brain that are integrating visual and tactile information aren\u2019t interfacing directly with our high-level semantic knowledge. Instead, they are doing something more basic and automatic.\u201d In other words, the brain does not use logic, reason, or language to make sense of stimuli. It\u2019s as if the brain creates its own muscle memory to integrate sensory information quickly and automatically.\nGiven that our mental representations of the body are now known to be quite flexible, this study raises questions about the aim of creating prosthetic and robotic body parts. Should prosthetics be designed as replacement body parts trying to embody the appearance of the original counterparts? Or should they simply be tools, similar to Swiss army knives, each with unique functions? Cadete believes it is too early to tell, even though she and Longo were invited to tour Imperial College London to determine if this research can inform designs of robotic body parts.\nWhat\u2019s next? Cadete is now attempting to create the experience of a curved sixth finger. \u201cIn theory, it makes sense that we have some flexibility for [perceiving] length because our bodies become longer as we develop into adulthood,\u201d she said. \u201cHowever, the shape [of our bodies] is more or less the same throughout our lives.\u201d Nevertheless, their results look promising. Though the line between perception and reality can sometimes be warped, it is likely that for the foreseeable future, we will not grow phantom fingers on our hands. That is, until evolution or robotic hands prove otherwise.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/a-sixth-sense-from-a-sixth-finger/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Hidden Histories: Eunice Newton Foote, The Woman Who Discovered the Greenhouse Effect",
            "author": "Ann-Marie Abunyewa",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/EuiceFoote1-Catherine-Kwon-500x446.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Catherine Kwon.\nAmong the signatures at the 1848 Seneca Falls Convention for women\u2019s rights is the name Eunice Newton Foote. With her name inscribed next to those like Elizabeth Cady Stanton and Lucretia Mott\u2014both well known in U.S. history for their advocacy of abolition, women\u2019s rights, and suffrage\u2014she may seem like just another attendant at the convention, but her legacy was not fully recognized until just a few years ago. Today, we recognize her as the first person to recognize the impact of carbon dioxide on climate change, preceding John Tyndall, the scientist previously credited for this breakthrough.\nUsing a straightforward experimental setup, which included a cylinder, a likely glass, and thermometers placed inside, Foote concluded that carbon dioxide and moist air could absorb heat. Similar to how the glass in greenhouses can maintain heat inside its walls when it\u2019s cooler outside, certain gases can trap heat from the sun in the Earth\u2019s atmosphere. The significance of the greenhouse effect today is that rising carbon dioxide levels due to the burning of fossil fuels are contributing to climate change and global warming. Foote had made the connection that climate change is largely influenced by varying levels of gases like carbon dioxide and water vapor in the air; she subsequently published her results in the American Journal of Science and Arts in 1856. Her paper was also presented at a conference in the same year. However, Foote did not present her own article\u2014it was uncommon for women to have done so. Instead, a summary of her work was given by Joseph Henry, who would later become the first secretary of the Smithsonian Institution. His summary would be found in almost every publication that presented Foote\u2019s findings, while Foote\u2019s original publication remained unrecognized. Even though Henry recognized Foote as an equal in science, her legacy\u2019s absence suggests that others had minimized her contribution to the scientific community over time.\nIn 1859, about halfway across the world in Europe, Tyndall had also found that certain gases absorbed heat and immediately reported his findings to the Royal Institution. By 1861, he had carried out further experiments and published a paper. He had been one of several scientists who, like Foote, was concerned with the ability of certain gases to trap heat, and since then, he has received sole credit for the discovery of the greenhouse effect.\nThe mere five-year difference between Foote\u2019s discovery and the publication of Tyndall\u2019s paper raises questions about his omission of Foote\u2019s name in his acknowledgments. Given that some publications in the U.S. would not have been widely read in Europe and vice versa around this time, it is unlikely that Tyndall took from Foote\u2019s experiment and failed to give her credit.\u00a0\nHowever, this story still places Eunice Newton Foote\u2019s name on the long list of women, like Rosalind Franklin, Katherine Johnson, and Mary Jackson, whose efforts in STEM went unrecognized for years, and in some cases, for decades or centuries. Foote\u2019s story reminds us that women and nonbinary people continue to face discrimination, exploitation, and lack of due credit in STEM. Her presence at the 1848 Seneca Falls Convention was no accident\u2014Foote understood that the world she lived in would not recognize her contributions as a woman, and she wanted to see that change. Being friends with Elizabeth Cady Stanton, Foote helped Stanton organize the proceedings of the entire Seneca Falls Convention. Her signature is fifth on the Declaration of Sentiments, a seminal work from the conference that demanded equal rights for women, including the right to vote. While recognizing Foote\u2019s work is one more step in acknowledging the talents and contributions of underrepresented figures in STEM, it is a reminder that the field of science still has quite a long way to go.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/hidden-histories-eunice-newton-foote-the-woman-who-discovered-the-greenhouse-effect/",
            "captions": [
                "Eunice Foote, a pioneering scientist and women\u2019s rights activist. Art credited to Catherine Kwon."
            ]
        },
        {
            "title": "Counterpoint: The Future of Prosthetics Can Be Found On Venus\u2026 Flytraps",
            "author": "Hannah Shi",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Shi_2-333x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Images courtesy of Flickr.\nWhat if prosthetic limbs could act as true extensions of the human body? Not just metal machines, but rather, carbon-based devices that can interact with biological neural networks. With nearly thirty million people in need of prosthetics or orthotic devices, researchers are experimenting with new technologies that may allow for a new generation of prosthetic limbs that can drastically improve a person\u2019s mobility, quality of life, and independence.\u00a0\nTraditional prosthetics use silicon-based technology with limited bio-compatibility, circuit complexity, and energy efficiency. While these devices can restore some mobility and function to a lost limb, silicon-based solutions are fundamentally incompatible with the natural processes of ion signaling found within the body. As such, to allow for effective brain-machine interfaces, the future of prosthetics will require the development of artificial devices that can successfully integrate into biological systems.\u00a0\nSimone Fabiano and colleagues at the University of Norrk\u00f6ping, Sweden, are exploring this proof of concept. By developing neuromorphic systems, which are brain-inspired machines that mimic neural processes, it may be possible to integrate artificial technologies with biological tissues. The Venus flytrap, a carnivorous plant with two leaflets that can snap shut, was an ideal specimen to test this novel technology. Not only could the activity of the flytrap\u2019s ion channels be easily measured, but its closing motion also served as an obvious sign that the artificial signal went through. Using carbon-based artificial nerve cells, Fabiano and colleagues demonstrated that when a sufficiently high current was applied, Venus flytraps were able to respond to the electrical stimulus by snapping shut. These organic electrochemical transistors (OECTs) are modulated by gate-driven ionic doping and de-doping, closely resembling the ion-driven mechanics found in neural systems. In particular, Venus flytraps snap shut in response to the release of calcium ions in the cytosol. This enables the plant to react to the physical stimulation of its hairs by insects, allowing it to catch its food. By mimicking the neurochemical processes of the Venus flytraps, OECTs were able to provide electrical currents that could be received by organic electrical chemical neurons (OECNs) to trigger trap closure.\u00a0\nThese experiments are not the first time researchers have been able to control the response of a Venus flytrap. In 2007, Alexander Volkov of Oakwood University was able to use an artificial electrical current to cause the leaflets of a Venus flytrap to snap shut. While the work of Simone Fabiano shares similarities with Volkov\u2019s previous research, Fabiano\u2019s new experiments differ in a few key ways. Importantly, Fabiano was the first to use carbon-based devices that resembled the structure of the actual neuron. By including an artificial synapse, or a tiny gap which ions jump across, the controlled reactions of the Venus flytrap in Fabiano\u2019s research were more closely modeled off the true neurochemical mechanisms found in nature.\u00a0\nWhile closing a fly trap may still be a far cry from controlling a prosthetic limb with your thoughts, Fabiano and colleagues have demonstrated the possibility of interfacing OECNs with biological systems. Inducing the closure of a Venus flytrap may open the door to creating more complex brain-machine interfaces that can be applied to future prosthetic innovations.\u00a0\nEven now, prosthetics use has been associated with higher levels of employment, reduced phantom limb pain, and increased feelings of social acceptance. Still, it is common for patients with prosthetics to develop osteoarthritis or osteoporosis as a result of the inherent biomechanical disadvantage of current technologies. However, with the rising possibility of creating a seamless brain-machine interface that can mitigate the biomechanical drawbacks of traditional prosthetics, it is possible to invent a new generation of devices that can overcome the side effects of current prosthetics. Perhaps someday soon, the artificial nerves used to control a Venus flytrap will allow patients to have prosthetic limbs that are a true extension of themselves, controlled by their own neural networks.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/counterpoint-the-future-of-prosthetics-can-be-found-on-venus-flytraps/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Undergraduate Profile: Jennifer Miao (YC \u201922)",
            "author": "Emily Shang",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Yale senior Jennifer Miao (YC \u201922) was recently awarded the Gates Cambridge Scholarship, a prestigious fellowship that fully supports Miao\u2019s pursuit of\u00a0a Ph.D. at the Laboratory of Molecular Biology at Cambridge (LMB). At Yale, Miao is a member of the Trumbull community, enjoys leading Yale\u2019s running club as the captain, and is currently working at the Mariappan Lab on Yale\u2019s West Campus.\nDespite Miao\u2019s incredible dedication to her scientific pursuits, she has not sacrificed her passion for the outdoors. Miao runs every morning despite long hours at the lab. When asked how she juggles her many commitments, she explained that she does not see her daily runs as a burden. \u201cIt really helps with balancing the stresses of lab, schoolwork, and just college life. It also helps to sort of get new ideas and just get away from work and come back to it with a sort of renewed vigor,\u201d Miao said.\nMiao\u2019s scientific journey started when she was a high school student working in a lab at UCLA under Associate Professor Jose Rodriguez. She used X-ray crystallography to structurally elucidate the core of an infectious prion fibril which has been implicated in many neurodegenerative diseases. This work ultimately culminated in a paper detailing a new approach to resolving protein structures.\nMiao explained that a huge problem in structural biology today is the loss of critical information from the diffraction pattern returned by X-ray crystallography. This issue is, in part, avoided by using a related protein model in different stages to refine the existing model. However, Miao worked on adapting a new way to circumvent this issue by using fragments of a non-related protein model of the structure and obtaining an atomic structure through electron diffraction. Using this technique, Miao eventually published another paper displaying her findings on the core of prion fibrils and their relationship to a right or left orientation. Miao spoke at the prestigious 2019 CCP4 Study Weekend at Nottingham University, U.K. During her first trip to the U.K., she describes having enjoyable conversations with Phil Evans, a former group leader at the LMB, and Randy Read, a crystallographer at Cambridge University.\nWhen it comes to influential scientists and research mentors, Miao has no shortage of inspiration. Miao\u2019s first mentors in academia were Rodriguez and David Eisenberg of UCLA. Her unwavering focus as an undergraduate to obtain a Ph.D. comes from her love of the exploratory and collaborative manner with which Rodriguez encouraged his students to work. She fell in love with academia because her work with Rodriguez was curiosity-driven, as very few answers were known for the questions she was studying in his lab. \u201c[I] enjoyed thinking about and planning my experiments every day,\u201d Miao said.\nWhile Miao was pretty set on pursuing a Ph.D., she was unsure whether it would be in the U.S. or the U.K. \u201cWhat really influenced me to look into the U.K. was Dr. Rebecca Voorhees at Caltech because she also did a Ph.D. at the LMB and was very enthusiastic about it,\u201d Miao said.\nMiao will be pursuing structural biology research elucidating the mechanism of mitochondrial protein recruitment from the cytosol, which would be influential in mitochondrial metabolism research. Miao is most excited about the community that facilitates diverse scientific discourse at LMB. \u201cThe culture is quite different from the US. There is coffee time and tea time every day, where most of the labs gather in the canteen on the top floor of the building to talk about science. At the canteen, there is an abundance of expertise across so many disciplines,\u201d Miao said. In parting Yale, she advises any prospective STEM student interested in academia to fearlessly pursue their research passions and find great mentorship among the approachable research faculty. \u201cDon\u2019t [be] afraid to [\u2026]ask for help or get advice from professors. They\u2019re always willing to spend time to help undergraduates,\u201d Miao said. She cited her experience working with renowned RNA biologist Joan Steitz. \u201cPeople I thought would be completely unapproachable were actually very down-to-earth and easy to talk to,\u201d Miao said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/undergraduate-profile-jennifer-miao-yc-22/",
            "captions": []
        },
        {
            "title": "Alumni Profile: Daniel Spielman",
            "author": "Risha Chakraborty",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Chakraborty_Fig1-348x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "A Network Between Fields of Math\u00a0\nWith the advent of social media networks like Facebook and Snapchat, our world is increasingly connected and complicated. Understanding the nature of these networks now requires wading through enormous amounts of information and performing overwhelming computations. This problem will only multiply in the future, making arriving at any meaningful conclusions about data unimaginably difficult.\u00a0\nThis was the dilemma that Daniel Spielman (YC \u201992), Sterling Professor of Computer Science and Professor of Statistics and Data Science and Mathematics at Yale, sought to solve. He wanted to use a technique called sparsification, which takes large data sets and removes points that do not contribute important information about the data. He found inspiration in an almost unrelated field of mathematics. This venture helped him solve a decades-old problem in the field of operator theory, earning him the Ciprian Foias prize and the Polya Prize.\u00a0\nSpielman had initially thought that his problem was in the realm of linear algebra. \u201cIt\u2019s one of those courses every math major takes that talks about finite-dimensional spaces,\u201d Spielman said. However, upon discussion with visiting professors and his graduate students, Adam Marcus, a postdoc at Princeton University, and Nikhil Srivastava, a graduate student at UC Berkeley, he realized that his sparsification problem mirrored an existing problem in operator theory called the Kadison-Singer problem, developed in 1959. The Kadison-Singer problem, which examines how to divide a group into two groups that are as equal as possible, had previously been discussed in the fields of quantum physics and computer science but had not been explored in the field of data science.\u00a0\nThe Kadison-Singer problem, or the concept of partitioning groups in general, is relevant in everyday decision-making. Suppose a PE teacher needs to divide a class of students into two equally skilled teams to play kickball. To achieve this, he will need to rank the students by their kicking, throwing, and catching abilities and separate students so that the two teams are approximately equal in all three abilities. Spielman\u2019s initial paper proved that the Kadison-Singer problem was an equivalent restatement of the sparsification problem. In a monumental 2014 paper, Spielman and his colleagues proved the existence of a solution, countering Kadison and Singer\u2019s decades-long conjecture that not every mathematical group could be divided equally. Marcus, Srivastava, and Spielman\u2019s work earned them the Polya Prize in 2014. Proving the ability to partition groups provided the impetus to explore new ways to divide networks into relatively equal groups, which aided in network sparsification: if one group was simply omitted from the network, there wasn\u2019t any net loss of information. In subsequent years, Spielman and his team worked on developing mathematical tools to achieve such data sparsification, for which they received the Ciprian Foias prize in Operator Theory earlier this year.\u00a0\nSpielman\u2019s transformation of a linear algebra problem into an operator theory problem reflects his general approach to mathematics. He first became interested in solving challenging puzzles in the fourth grade, took college math and programming classes in high school, and pursued a bachelor\u2019s degree in mathematics and computer science at Yale. He has always been interested in using computational tools to solve problems. \u201cThere\u2019s a marriage between [math and computer science]. I was once trying a proof in my undergraduate lab, and a computer program found a counterexample in a couple of months that I wouldn\u2019t have found in a hundred years,\u201d Spielman said.\u00a0\nSpielman now employs computation in all of the problems he chooses to solve. \u201cI keep a list of problems that interest me, and when I am interested in working on a problem, I check if there\u2019s a similar problem on my list and if someone\u2019s already worked on similar problems,\u201d Spielman said. He claims he cannot predict what problem he wants to solve next. He may continue working on sparsification, networks, or topics in linear algebra but will inevitably draw inspiration from other mathematical concepts and fields. \u201cI completely change my research agenda every few years,\u201d Spielman said.\u00a0He is currently working on establishing the Kline Tower Institute (KTI) for the Foundations of Data Science to sponsor talks between experts in different fields who want to employ data science techniques in their work. Ultimately, Spielman encourages every college\u00a0student to try some math classes. \u201cYou never know what\u2019s going to be useful, so you should take classes that interest you. Later in life, you may find that useful connection,\u201d Spielman said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/alumni-profile-daniel-spielman/",
            "captions": [
                "Daniel Spielman is the Sterling Professor of Computer Science and Professor of Statistics and Data Science and of Mathematics at Yale University. He strives to combine his intersectional interests in his current work with sparsification of data networks."
            ]
        },
        {
            "title": "Science in the Spotlight: Into the Metaverse",
            "author": "Kelly Chen",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Chen_1-500x282.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nYour favorite artist takes the stage, and you cheer wildly along with the ten million other people standing next to you. No single physical stage could fit a crowd of that size, but there is a place that can.\nWelcome to the metaverse.\nThe future that we saw in sci-fi movies has hit the public as an emerging reality following Facebook\u2019s rebranding to Meta and the online gaming platform Roblox going public on the stock market.\nThe metaverse can be defined as many things: virtual reality, the evolution of the internet, a digital economy, a place where avatars of ourselves interact with others, and so on. So, to put it more clearly, Yonatan Raz-Fridman on the podcast \u201cInto the Metaverse\u201d reframes the question from what the metaverse is to what the metaverse isn\u2019t. \u201cThe metaverse is not a device. It\u2019s not something you\u2019re going to access from your mobile phone, VR goggles, or AR glasses\u2026The metaverse is the next iteration of the internet,\u201d Raz-Fridman said. A podcast co-hosted by Raz-Fridman and Matthew Kanterman, \u201cInto the Metaverse\u201d explores subjects from development and investment to experience within this new space.\u00a0\nOver the past two years, we have seen the effects of the pandemic on human lifestyle and our dependence on technology for connection and education. With isolation restrictions loosening in the U.S. and worldwide, most believe we will return to a state of pre-coronavirus normalcy. However, in actuality, especially in younger generations, constantly being online has been ingrained into daily rituals. For example, the average amount of time spent on Roblox has continued to increase even with more relaxed restrictions. \u201c[The metaverse is] going to reimagine our lives in virtual spaces,\u201d Raz-Fridman said. Starting from entertainment and gaming with companies like Roblox, Epic Games, and Unity, the metaverse will also extend into all industries, education, workplaces, and fundamentally, how we connect with others.\nThis novel technology is fascinating, even a bit scary, as there is so much to look out for. Who will govern the metaverse? Will the major companies developing the metaverse try to keep it as a closed ecosystem or a walled garden? Or, will control of the metaverse become more decentralized, something that could align with the growing popularity of blockchain technology, NFTs, and cryptocurrency?\nThere are so many other questions to consider. How do we increase internet access to more regions of the world that need it? Will the metaverse be a form of escapism from the real world? Or a place to exploit consumerism in the virtual world? How do we keep our human connections and identities? How will the metaverse affect climate change? How to define the metaverse and questions like these are constantly being discussed and reevaluated on the podcast \u2014take a listen! The hopeful stances of Raz-Fridman and Kanterman may alleviate some fears directed toward the metaverse or, at the very least, can give you some wonderful food for thought.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/science-in-the-spotlight-into-the-metaverse/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in The Spotlight: The Man Who Tasted Words",
            "author": "Elisa Howard",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Screen-Shot-2022-09-20-at-8.24.06-PM-500x278.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nCan we trust our own reality?\nAs neurologist Guy Leschziner describes in his recently released book, The Man Who Tasted Words, the senses of sight, sound, touch, taste, and smell enable humans to craft an understanding of the world outside of the physical body. \u201cThese senses are our windows on reality, the conduits between our internal and external lives. [\u2026] Without them, we are cut off, isolated, adrift,\u201d Leschziner writes. Moreover, as the phrase \u201cseeing is believing\u201d suggests, humans often rely on sensory information as infallible evidence obliterating all doubt about the existence of some entity or phenomenon in the world. However, are the senses accurate?\n\u00a0\u201cWhat we believe to be a precise representation of the world around us is nothing more than an illusion, layer upon layer of processing of sensory information, and the interpretation of that information according to our expectations,\u201d Leschziner says. He suggests that the sensory organs fail to function as accurate witnesses of reality. Therefore, we should question the reliability of conscious experience. In essence, the nervous system functions as a supercomputer manufacturing human perception through processes reconstructing sensory inputs largely without our awareness. That is, the physical interactions of the sense organs\u2014the eyes, skin, ears, nose, and mouth\u2014with the external world are merely basic inputs quite disparate from the nervous system\u2019s construction of perception.\u00a0\u00a0\nIf the nervous system shapes our reality, what happens when neural processes go awry? Throughout his book, Leschziner describes individuals with sensory abnormalities. For instance, one patient named James experiences synesthesia, in which stimulation of one sensory modality concurrently evokes sensation in another modality. For James, this involves the fusion of sound and taste, conferring the ability to essentially perceive the taste of words. The Lord\u2019s Prayer tastes like bacon, the name of his friend\u2019s wife tastes like chunky vomit, the word \u201ccourt\u201d tastes like a crispy fried egg, and his grandmother\u2019s name tastes like rich condensed milk. As James\u2019s story demonstrates, neurological conditions like synesthesia fundamentally alter one\u2019s experience and perception of reality.\u00a0\nHumans often rely on the senses for a faithful understanding of the external world. However, we must recognize the innate limitations of that approach. \u201cOur experiences and cold, hard reality can be almost entirely divorced, as with molecules of a particular structure and our experience of smell or flavour,\u201d Leschziner writes. The brain essentially manufactures a perception far removed from the physical world. Meanwhile, human perception remains reliant on the integrity of the nervous system that converts basic sensory inputs into conscious meaning. \u201cThe pathways, from physical environment to our experience of it, are convoluted and complex, vulnerable to the nature of the system, friable in the face of disease or dysfunction,\u201d Leschziner says. As it appears, the brain functions as the master controller employing unseen manipulations to manufacture a perception both distinct from physical reality and malleable in response to structural or functional changes in the nervous system.\u00a0\nPerhaps we cannot trust our own reality.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/science-in-the-spotlight-the-man-who-tasted-words/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Time to Meet Your Great^nth Grandparents",
            "author": "Eva Syth",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Syth_2-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nCan you create a family tree for all of humanity, dating as far back as 50,000 generations? A study from researchers at the University of Oxford says yes, at least in part. The researchers developed a new method using data from both contemporary and ancient DNA samples to construct whole-genome genealogies, providing insights into human history and evolution.\nThe researchers combined genetic data from several different datasets to carry out this study. Historically, this process has been challenging due to technical errors in the DNA sequencing process or the use of different DNA sequencing techniques altogether. The variation stemming from these issues makes it hard to accurately combine and compare this genetic data because researchers cannot tell if the differences in sequences are due to systematic inconsistencies in DNA processing or variation in the genetic sequences of the samples themselves. To address this issue, the researchers used \u201ctree sequences,\u201d graphs that represent the links between regions of DNA in contemporary samples and the ancestor where the region first appeared. Consider two samples of DNA: one contemporary and one old. If both samples shared a significantly similar sequence of nucleotides, they would be considered \u201cconnected\u201d in the graph.\nWith this challenge solved, the researchers combined eight datasets and used an algorithm to yield a network of twenty-seven million ancestors. The researchers found that the network reflected key moments in human history, such as the first human migrations. Who knows\u2014with this technology, you might be able to meet your great-great-great\u2026grandparents.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/qa-time-to-meet-your-greatnth-grandparents/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Decoding Machine Learning Mysteries Using Ants",
            "author": "Nathan Wu",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wu_1-500x348.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nWhat do ant colonies and the Internet have in common? Both are complex networks that manage large amounts of traffic. In ant colonies, this traffic comes from ants scurrying about, while on the Internet, it comes from packets of data sent between users. In these systems, computing is \u201cdistributed\u201d: system components only know what is happening locally. Rather than constantly monitoring everything and making micro-adjustments to keep the system stable, components respond to specific events, obeying general algorithms that collectively keep the whole system running.\u00a0\n\u00a0Scientists at Cold Spring Harbor Laboratory recently found that ant colonies use additive-increase/multiplicative-decrease algorithms to forage for food. These are the same algorithms used by the Internet to manage data traffic. With the Internet, the system responds by additively increasing the transmission rate if data is successfully sent and received. If sent data is not received, the transmission rate is decreased multiplicatively. Similarly, if an ant foraging for food successfully returns, the colony will additively increase the number of ants sent, while if ants fail to return, the number of ants sent out on the next trip is multiplicatively decreased.\u00a0\nAnt colonies are robust and avoid complete collapse despite their unpredictable outside environment. Many engineered systems, however, fail completely at the slightest tampering. Further study of distributed biological systems may reveal what makes them so hardy. Perhaps Internet engineers can learn something from ant colonies\u2014the two are more alike than they may initially seem.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/qa-decoding-machine-learning-mysteries-using-ants/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Brain Takes Out the Trash",
            "author": "Elizabeth Wu",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/wu_braincelegans-500x136.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Coleen Murphy. \nCleaning our homes is an important chore, as the buildup of trash interferes with our productivity and invites disease. It is just as important for cells to break down and dispose of old or damaged components through a process known as autophagy. Autophagy is especially vital in neurons\u2014our brain cells\u2014because they must last an entire lifetime. Furthermore, autophagy issues are associated with neurodegenerative diseases due to the buildup of dysfunctional proteins. Despite their importance, the mechanisms of local autophagy in neurons are not completely understood.\u00a0\nAt the Col\u00f3n-Ramos Lab at Yale, graduate student Sisi Yang used the microscopic roundworm C. elegans to study the fascinating cellular journey of ATG-9, a crucial protein for autophagy. Yang found that ATG-9 travels to the synapse, the junction at which two neurons communicate, in vesicles from the trans-Golgi network or membranous packages from the cell\u2019s \u2018shipping center.\u2019 Then, at synapses, vesicles containing ATG-9 undergo exo-endocytosis, the process by which cells release signals to communicate with each other.\nAbnormal accumulation of ATG-9 in neurons was observed in both mutant C. elegans with disrupted autophagy and mutants with disrupted endocytosis. By manipulating synaptic activity, Yang could control the ATG-9 trafficking into these abnormal accumulated structures, demonstrating links to defects in autophagy. Therefore, these findings led to the hypothesis that ATG-9 serves as a link between autophagy and neuronal activity.\u00a0\nInterestingly, C. elegans with mutations found in Parkinson\u2019s disease patients similarly exhibit abnormal ATG-9 accumulation and behavioral defects. According to Yang, the study\u2019s findings could offer insights into how early-onset Parkinsonism could be linked to ATG-9 mislocalization or dysfunctional autophagy. Information about the involvement of ATG-9 in both autophagy and exo-endocytosis may help explain molecular mechanisms behind the disease, providing targets for future treatments.\nAcknowledgment: The work was performed in collaboration with the laboratory of Yale University\u2019s Pietro de Camilli and with the laboratory of Jihong Bai from the Fred Hutchinson Cancer Center. \n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/the-brain-takes-out-the-trash/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Oldest Known Octopus Ancestor Named After President Biden",
            "author": "Daniel Havlat",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fossil-squid-thing-500x332.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Christopher Whalen.\nSome 330 million years ago, an unassuming soft-bodied cephalopod was buried and fossilized by an influx of sediment in the sea, covering modern-day Montana. In a paper recently published in Nature, Christopher Whalen at the Yale Department of Earth and Planetary Sciences describes this earliest known vampyropod\u2014which isa group of cephalopods that includes octopods and vampire squid. Now called Syllipsimopodi bideni, this squid lookalike pushes the fossil record of vampyropods back 81.9 million years. The genus name aptly means \u2018prehensile foot,\u2019 while the species name is a nod to Joe Biden\u2019s presidency. \u201cWe named it after Biden to celebrate his inauguration and because of his policies to fund science and address anthropogenic climate change,\u201d Whalen said.\nS. bideni had ten arms, each with two rows of suckers, with one pair of arms longer than the remaining four pairs. Whalen speculates that the longer arms were used to initially capture prey, while the shorter eight arms manipulated its prey during feeding. All known vampyropods other than S. bideni have eight functional arms, implying that one pair was lost somewhere in their evolutionary history. Another unique trait of this presidential vampyropod is the presence of a gladius, a sword-shaped remnant of an internal shell that only true squids and vampire squids still possess. \u201cThis has important implications for our understanding of the fossil record and how we model cephalopod interrelationships,\u201d Whalen said. The finding provides evidence against the prevailing model suggesting vampyropods descended from a group of Triassic squid-like cephalopods.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/oldest-known-octopus-ancestor-named-after-president-biden/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Dusting Off the Cobwebs\u2026 and the Chemicals",
            "author": "Sophia Li",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Li_Figure1-500x281.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nDust surrounds us constantly, invisible particles floating in the air before settling in fuzzy gray clumps. But instead of just being a harmless byproduct of life that gets swept up when you Swiffer your room, Yale researcher Krystal Pollitt, associate professor of epidemiology and chemical and environmental engineering, recently published a review revealing that there may be more dangerous chemicals settled on those hard-to-reach surfaces.\nPer- and polyfluoroalkyl substances (PFAS) are chemicals used in non-stick pans, carpets, cosmetics, and more than nine thousand other products containing the element fluorine. These chemicals can enter the body by inhaling or ingesting PFAS-containing substances such as dust. Once in our bodies, PFAS can cause behavioral issues in children, cancer, and obesity, among other diseases.\u00a0\n\u201cExposure to PFAS has most commonly been assessed in blood, but we are looking at environmental matrices to gauge exposure to a broader range of PFAS,\u201d Pollitt said. \u201cSettled dust can be incredibly informative at giving a signature of the environmental chemicals around us.\u201d\nPollitt estimates that adults ingest about three milligrams of dust per day while children ingest forty-one milligrams of dust per day since they spend more time near the ground and on carpets where dust can accumulate. Pollitt\u2019s group surveyed consumer products, food packaging, and building materials that may all contribute to PFAS in settled dust. Even though many materials around us contain PFAS, there are still steps we can take to limit our inhalation or ingestion of these compounds.\n\u201cThere are manufacturers that are addressing this issue by not using these fluorinated substances,\u201d Pollitt said. In addition, the Pollitt laboratory is developing wearable wristbands that can be used to detect personal exposure to PFAS as a way of further investigating the long-term health effects of PFAS exposure.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/dusting-off-the-cobwebs-and-the-chemicals/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Contrasting Climate: Should We Trust Computers or Fossils?",
            "author": "Chloe Nield",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/nield_climate_1-500x345.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Daniel Gaskill. \nWhen it comes to climate change, there has been a persistent discrepancy between what computer models predict and what history tells us. Though computer models forecast a rise in temperature at the poles, these predictions are nowhere as extreme as what previous fossil studies had suggested: Earth\u2019s poles may have been as warm as the tropics.\u00a0\nDaniel Gaskell, a micropaleontologist and expert in a field that studies microfossils, recently earned his PhD from Yale in the Department of Earth and Planetary Sciences. He emphasized the importance of ensuring that computer models are accurate since their predictions are used prevalently.\u00a0\nGaskell investigated the fossils of an amoeba-like single-celled organism called foraminifera to assess temperature patterns over the past ninety-five million years. Foraminifera shells form fossils found on the seafloor. When foraminifera are alive, their shells incorporate prevalent oxygen isotopes into their calcium carbonate. Water temperature determines what oxygen isotopes, or different forms of the oxygen element, are available for incorporation.\nUsing foraminifera shells from different time periods and locations as measurements for historical global temperature, Gaskell found that current computer models are more accurate than previously believed. The foraminifera data disagreed with past studies: temperatures at the poles did not match temperatures at the equator when global temperatures were hotter. \u201cOur data are saying that the poles did get warm\u2026 but didn\u2019t get nearly as warm as these previous reconstruction methods would predict,\u201d Gaskell said.\nGaskell emphasized that while it is unlikely that the Arctic will become a tropical destination, climate change is still an important issue with many uncertainties.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/a-contrasting-climate-should-we-trust-computers-or-fossils/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Magnesium? No, You\u2019re Not on the List",
            "author": "Lucas Loman",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/loman_membrane_1-500x335.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nWastewater is not something that most people in developed nations want to, or have to, think about. For most Americans, as soon as water goes down the drain, it is out of sight and out of mind. We view waste in our pipes in the same way we view the waste in our trash cans\u2014as depleted resources to eject from our homes and businesses.\nThe current process of wastewater treatment focuses on cleaning water to reintroduce it into the environment. Through a complex series of physical, chemical, and biological processes, engineers degrade and remove contaminants from wastewater to make the resulting water as safe as possible. However, this process creates solid waste of its own, ranging from organic materials to plastics to metals. These are typically addressed via conventional means, such as landfill disposal.\nRyan DuChanois, a researcher at the Yale Department of Chemical and Environmental Engineering, sought to challenge the idea that wastewater contaminants are simply pollutants to separate and discard. \u201cCurrently, there is no method to turn waste from wastewater into something beneficial,\u201d he said. This new strategy evokes the concept of a circular economy, where materials can restart the life cycle of manufacturing rather than being disposed of as waste by default.\u00a0\nUnfortunately, conventional wastewater treatment processes use membranes that cannot separate waste to the level of extracting valuable ions. Therefore, to achieve his vision of a circular economy, DuChanois and his team set out to develop membranes with inspiration from the material already capable of this level of specificity: our cells.\nBiological ion channels are built to maintain the delicate flow of ions in and out of cells, overseeing the exchange of nutrients and minerals. In addition to being designed to a much smaller scale than any human-made materials can be, biological ion channels have an extra special characteristic: \u201cBiological channels utilize the interactions between species of interest and the channel to obtain selectivity, and we don\u2019t fully leverage that in the synthetic membranes we use today,\u201d DuChanois said.\nThe team emulated the biological approach by constructing a film of polymers containing binding sites designed to interact with key ions favorably. They then layered the polymers on top of one another to create membranes of desired thicknesses. DuChanois tested the rate at which different ions in water could travel through the membranes, where the ratio between a desired ion, such as copper, and an unwanted ion, such as magnesium, indicated the level of specificity of the membrane. He discovered two surprising trends: first, conventional logic says that stronger binding interactions between an ion of interest and the membrane should cause it to get \u201cstuck\u201d in the membrane, thereby limiting its ability to flow through; on the contrary, DuChanois found that stronger binding interactions aided some ions in diffusing across the membrane, consequently increasing the membrane\u2019s specificity. The relationship between membrane thickness and selectivity was similarly counter-intuitive. When copper ions of interest traveled through a membrane, the diffusion rate decreased as membranes of larger thickness were tested, while unwanted ions diffused at a rate independent of membrane thickness. As a result, the selectivity decreased for thicker membranes.\nThese two new properties provide an important tool for engineers, potentially enabling the selection of certain valuable ions in wastewater and recovery for their use in manufacturing. The two-pronged effect of minimizing the amount of waste produced and increasing the supply of materials is particularly beneficial for substances that are energy-intensive to obtain normally. An example is lithium, which is required for energy storage in green technology and electronics. According to DuChanois, targeting certain wastewater streams from industrial facilities and oil-drilling sites could allow for more efficient reclamation due to the elevated presence of ions used in manufacturing.\nThere are still notable obstacles to applying these membranes and the concept of resource reclamation from wastewater. For instance, thinner membranes that are more selective are also more susceptible to mechanical stability concerns, such as breaking under water flow pressure. DuChanois has also identified the need to assess various materials to determine which ions are the most critical and viable for recovery. Additionally, he hopes to integrate ion-selective membranes into a more scalable process for industry usage.\u00a0\nModeling wastewater technology after the evolution-tested components of the human body has proven an effective method to foster innovation. Ion-selective membranes can join Velcro and aerodynamic trains as everyday necessities inspired by nature.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/magnesium-no-youre-not-on-the-list/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Group Discussions: When We Do and Don\u2019t Use Them",
            "author": "Elizabeth Lin",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/lin_groupproject_1-500x301.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay. \nPicture this. You have no clue how to solve an expert-level Sudoku puzzle and are given two options: you can either ask a group of five people to work together on it or ask five individuals to solve the puzzle independently. Which do you choose?\u00a0\nAt Yale, Professor of Psychology and Linguistics Frank Keil and PhD student Emory Richardson presented people with scenarios just like this, contrasting group discussion with crowdsourcing\u2013getting information from a large group of people. \u201cYou can think of this as a choice between two network structures: in the group, everyone can influence everyone else. In the crowd, you get independent answers, which means that you avoid groupthink, but you also miss out on the benefits of sharing information,\u201d Richardson said.\u00a0\nRichardson and Keil showed kids and adults three types of questions: questions they could answer conclusively through explicit reasoning (e.g., solving a sudoku puzzle), and two kinds of questions for which reasoning would not be enough\u2014popularity (e.g., what most people in the world say their favorite fruit is) and hard perceptual discrimination (e.g., determining whether an opaque box contains thirty or forty marbles just by listening to a recording of it being shaken). They found that even six-year-olds prefer reasoning in groups just as strongly as adults. However, while they are more likely to crowdsource to answer the \u201cnon-reasoning\u201d questions, younger kids are less sensitive to the risks of thinking as a group than adults. \u201cIntuitions about when to collaborate in groups and how to structure our groups could be part of what makes our species so successful,\u201d said Richardson.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/group-discussions-when-we-do-and-dont-use-them/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Personalized Fingerprint for Attention",
            "author": "Cindy Kuang",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/kuang_attention_1.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Shutterstock.\nIn a world where our attention is pulled every which way by strategic advertisements and technicolor screens, our attention may be our most valuable commodity. Our brains have limited cognitive capacity, and it would be impossible to attend to every visual or sensory stimulus we encounter in our daily lives. This means our brains have developed an elaborate system to selectively process the information most relevant to us at any given time.\u00a0\nBut how do we even measure attention? To date, attentional functioning is primarily measured through a flurry of surveys and hours-long questionnaires\u2014a costly and weary process. Given its fluctuations and multi-faceted nature, an individual\u2019s attentional functioning cannot be boiled down to a single number, so researchers have sought a quantifiable, standardized measure of attention.\nThe Visual Cognitive Neuroscience Lab, led by dean Marvin Chun, set out to answer this question precisely. Using a creative combination of functional magnetic resonance imaging (fMRI) neuroimaging and connectome modeling, Kwangsun Yoo, an associate research scientist at Yale, Monica Rosenberg, an assistant professor of psychology at the University of Chicago, and the rest of the team recently reported their fMRI-based general measure of attention in Nature Human Behaviour.\nTo cover multiple aspects of human attention, the team collected fMRI data from ninety participants. The researchers measured volunteers\u2019 brain activity while they performed three separate attention-demanding tasks. \u201cSince we aimed to predict general attentional function, we had to use multiple task-based fMRI data,\u201d Yoo said.\nLet\u2019s back up a bit. Using data from an fMRI scan, researchers can generate an individual\u2019s whole-brain pattern of functional connectivity or how certain signals in distributed brain regions fluctuate over time. This is called their connectome \u2013 almost like a brain fingerprint. Each person\u2019s functional connectome is unique and related to aspects of their abilities and behavior. Their \u2018brain fingerprint\u2019 can then be fed into a connectome-based predictive model (CPM) to predict your attentional ability.\n\u201cIt\u2019s kind of like listening to an orchestra, and all these instruments are going on at the same time, and there\u2019s a certain harmony and rhythm in the way the brain areas become active and inactive at any given time,\n\u00a0Chun said. \u201cOur model does something as simple as capturing all of that, and converting it into a matrix of numbers, where each cell is a correlation between two brain areas.\u201d\u00a0\nThe team trained nine CPMs on this fMRI correlation data, all of which demonstrated strong predictive powers of participants\u2019 attentional ability across all three tasks. The team could even re-train the CPMs on the mean of normalized performance scores across all three tasks, a \u2018common attention factor,\u2019 and use the models to predict overall attention ability rather than task-specific ability.\nNow comes a seriously creative part of this paper. Task-based connectomes collected while the participant actively engages in a task have much more predictive power than rest-based connectomes. However, rest scans collected while participants are simply lying still in the MRI scanner by nature are much easier to collect across different research studies and locations reliably. To this point, Yoo introduces connectome-to-connectome state transformation (C2C) modeling, a novel approach that seeks to capture the best of both worlds. C2C modeling can extrapolate from an individual\u2019s rest connectome and accurately generate their attention-task connectome without requiring the participant to engage in a task at all! This model-generated attention-task connectome was even found to improve subsequent behavioral predictions. The novel approach increases the predictive value of rest scans and may free future researchers from the burden of collecting multiple scans or ensuring every task is perfectly standardized across participants.\nFinally, the team combined all the above \u2013 the common attention factor, C2C transformation modeling, and CPMs \u2013 in a general attention model that can encapsulate an individual\u2019s overall attention functioning. Combining C2C and CPM allows researchers to estimate multiple cognitive measures from a single rest scan. Though the measure is far from complete, it certainly has the potential to be used for other mental traits such as intelligence, memory, depression, or anxiety.\n\u201cAttention is only a test vehicle,\u201d Chun said, pitching an example of someone who goes to the doctor for a depressive episode: \u201cInstead of having these long wait times and hours-long interviews, can we just put them in a brain scanner and pop out a computerized print-out of what kind of depression they have, what will the best treatment be? How powerful would that be? We\u2019re far away from it, but that\u2019s my dream.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/a-personalized-fingerprint-for-attention/",
            "captions": [
                ""
            ]
        },
        {
            "title": "I Want You: Modelling Microbial Recruitment and Peer-Aiding Bacteria",
            "author": "Patryk Dabek",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/dabek_microbes_2-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Marin Tomic.\nPicture yourself sitting down for dinner, perhaps facing a steamy plate of shrimp fried rice. The food on your plate makes its way into your mouth, down your throat, and into your stomach, where it will eventually make its way down the rest of your digestive tract. Picking up your fork for more, it may seem like you are enjoying this delicious meal all alone. In truth, however, you are less alone than you might have thought. From head to toe, microbes are all around and even inside you.\u00a0\nMicrobes play vital roles in the consumption of your favorite dish. These communities of microbes benefit our digestion by keeping our mouths and digestive tracts healthy. Beyond that, they also ensure the food we eat properly develops in the ground long before it even ends up on our plate. In fact, microbes in the gut help process a plethora of complex molecules in our food and play a critical role in immune health and individual reactions to medications. With all these different microbes playing such a vast range of roles, it can be complicated to understand how these separate communities interact.\nIn a recently published study, Yale ecologists developed a framework for how microbial communities restructure when joined together, providing an understanding of a powerful effect that causes microbes to recruit partners during invasions in a fight for resources and survival.\u00a0\nThough it can be challenging to visualize the importance of microbes, recent research has showcased an ever-increasing understanding of their role in health and human life. \u201cRight now, we don\u2019t really have a lot of tools to act on how these communities function and operate, but starting to understand how they assemble is the first step to understand how they function,\u201d Juan D\u00edaz-Colunga, first author of the study and postdoctoral associate at Yale, said. The Sanchez lab, where D\u00edaz-Colunga works, is on the cutting edge of this research, helping to develop our understanding of how microbial communities assemble and change in structure. Since microbial health is critical to human health, this understanding is vital in the effort to create therapies that restructure microbial populations and help sick patients.\nTheir new paper uncovered that there are essentially two realms of microbial community coalescence. The first realm showcases that even a few key species can determine the outcomes of whole communities as they come together and interact. This phenomenon is known as \u201ctop-down co-selection\u201d when dominant microbes can influence their partners in the same way a skillful soccer player might amid a team that includes a couple of younger players. Alternatively, the collection of interactions from less abundant species can alter the microbial community significantly. This alternative, known as \u201cbottom-up co-selection,\u201d is when less dominant microbes can determine the composition of their community in the same way that players who arrive earlier at the field \u2013 regardless of their level of experience \u2013 might get to choose who they want to include in their game. This creates an impactful change in the distribution of resources and determines which species survive.\u00a0\nA better understanding of this process could be leveraged to engineer healthcare therapies, impact agriculture, food fermentation, and many other technological sectors. \u201cOn the single species level, we do have tools to do this,\u201d D\u00edaz-Colunga said. \u201cStrategies like directed evolution allowed humans to select for specific traits and turn wolves into dogs.\u201d\u00a0\nEngineering microbial communities could increase agriculture yield and nutrition. In fact, it could be used to fortify the nutritional value of rice or to counter the presence of arsenic, which is created as a metabolic byproduct of certain microbes in rice. Seeing the diverse roles that microbes play, from our dinner plate to our gut, showcases all the future opportunities that microbial engineering will be able to impact.\u00a0\nAlthough natural microbial communities have a high degree of complexity, analyzing the fundamental interactions of microbial species can allow us to understand how microbes may interact with a vast number of different communities and environmental conditions. This could help set a framework for new technologies and innovations based on microbial recruitment and peer-aiding bacteria.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/i-want-you-modelling-microbial-recruitment-and-peer-aiding-bacteria/",
            "captions": [
                ""
            ]
        },
        {
            "title": "With HIV, A Little Goes a Long Way",
            "author": "Breanna Brownson",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/brownson_hiv_1-500x200.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nSince the start of the acquired immunodeficiency syndrome (AIDS) pandemic in the early 1980s, researchers have been working to combat the devastating health problems associated with the human immunodeficiency virus (HIV). One obstacle standing in the way of curing AIDS is the presence of HIV DNA in a transcriptionally inactive latent state, in which the virus temporarily stops making copies of genetic material needed for viral proliferation. In this state, HIV can evade immune cells. Current antiretroviral therapy medications inhibit HIV replication by blocking reactivated latent viruses. However, a small percentage of cells harbor latent HIV-1 proviruses, a form of viral genetic material incorporated into host cell DNA that escapes detection.\u00a0\nJack Collora, a graduate student in the Yale Department of Microbial Pathogenesis, is trying to understand how HIV-1, the most common type of HIV, can survive in the presence of antiretroviral drugs. His single-cell multiomics studies measure levels of different molecules in individual cells and analyze them to characterize cell types and functions.\u00a0\nCollora discovered that it could be possible to treat HIV-1 by targeting a type of immune cells called cytotoxic CD4+ T cells, which are infected by the virus, as well as factors that cause clonal expansion, which is a process in which normal cells accumulate disease-causing genetic changes. \u201cWe found a subpopulation of CD4+ T cells that harbor HIV very effectively,\u201d Collora said. \u201cThey might be expressing certain proteins that make them resistant to being killed by other CD4+ T cells and have a genomic profile that allows it to proliferate more readily.\u201d\u00a0Future research will aim to understand why CD4+ T cells are so good at harboring HIV, enabling the development of treatments that target these mechanisms.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/with-hiv-a-little-goes-a-long-way/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Stone-Age Social Networks",
            "author": "Dinara Bolat",
            "authorLogo": "",
            "date": "September 4, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/bolat_image_1-500x447.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Getty Images.\nSociety has evolved in many ways since the beginning of time, and it will continue to evolve in the decades to come. Given the inherently social nature of the human species, social networks are important in helping us understand this societal evolution.\nA study co-led by Yale anthropologist Jessica Thompson in collaboration with institutions across Africa, Harvard University, Rice University, and the University of Alberta studied the population structure of sub-Saharan African foragers. Their research provided new evidence of major demographic changes at the end of the Late Pleistocene epoch around 11,700 years ago and the beginning of the Holocene epoch, the current epoch which began approximately 11,650 years ago.\u00a0\nThe researchers obtained ancient DNA from six individuals from East and South-central Africa. They discovered that the ancestry of these individuals came from three source populations: two of them were the expected Eastern and South African lineages, but the third brought an unforeseen revelation. In it, they identified a central African rainforest hunter-gatherer lineage. This new piece of genetic evidence supports the hypothesis that the end of the Pleistocene epoch marked the onset of increased regionalization, indicating less residential mobility and more settlement establishment.\u00a0\nThis blend of archaeology and genetics is a rare find, with researchers from Malawi to Canada collaborating on this project. \u201cIt was a deliberate decision to do it this way,\u201d Alex Bertacchi, a graduate student part of the Yale research team, said. \u201cMonths of the discussion focused on how to put in true effort to place genetics and archaeology on equal footing\u2026and I think it [was successful]\u201d. Continuing to combine these two fields of study could lead to even more discoveries about how our world today came to be.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/stone-age-social-networks/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Electronically Conductive Protein Nanowires: An Electrifying Discovery for Healthcare Applications",
            "author": "Yusuf Rasheed",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/rasheed_nanowires_1-500x306.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Food Safety Magazine.\nThe latest advancements in synthetic biology allow researchers to engineer proteins with specific, desirable properties. These engineered biomaterials appear in implants, tissue generation, and drug delivery systems. However, most biomaterials are not electrically conductive, and most proteins that have been shown to be conductive are not well-characterized. Designing a protein-based biomaterial that is electrically conductive would be a large step in creating bioelectronic materials which can serve as an interface between organic materials, like the human body, and electronic materials, like implants or prosthetics. In a recent study published in Nature, researchers from Yale University engineered a highly electrically conductive protein nanowire that can be created and purified at scale from E. coli bacteria.\u00a0\nDaniel Shapiro YC\u201918, the first author of the paper, started this journey in his senior year at Yale College while working in Associate Professor of Molecular, Cellular & Developmental Biology Farren Isaacs\u2019 synthetic biology lab. As a physics major, however, he wanted to bridge the two seemingly disparate fields of genetic engineering and physics. \u201cI was walking along West Campus and saw a poster for a talk by Nikhil Malvankar, who was then a brand new professor, on electron conductance in bacterial proteins. I thought, \u2018This is quantum biology. This is exactly what I want to do,\u2019\u201d Shapiro said. Shapiro reached out to Malvankar, and the two worked with Isaacs to develop a collaborative project focused on making proteins more conductive than usual, using Shapiro\u2019s experience with synthetic biology to make mutations with non-standard amino acids (nsAAs).\nThe biomaterials Shapiro engineered in this research were E.coli pili, which are short, hair-like projections on the surface of the bacteria. They are a popular biomaterial to study because they can self-assemble into a robust filamentous shape, they show excellent material properties for a protein, and they can withstand a wide range of temperatures and pH conditions that normally degrade proteins. However, they are not electronically conductive. With this project, the researchers aimed to impart electrical conductivity into E.coli using three strategies.\nTheir first approach was to induce electronic conductivity in E. coli pili through amino acid mutations at the nanostructure level. The team tested protein building blocks of phenylalanine, tyrosine, histidine, and tryptophan. \u201cThis first part was [the hardest] because we had to figure out how to make, purify, store, and measure the conductivity of the protein,\u201d Shapiro said. Nevertheless, they found that adding tryptophan increased electrical conductivity by 80-fold.\u00a0\nThe team then came across a paper which showed that E. coli pili could be arranged into different geometric shapes, such as bundles, lattices, and cubes. \u201cNikhil saw this, and he was like, \u2018Okay, what if we try that with our proteins \u2013 if we bundle E.coli pili, will that increase conductivity?\u2019\u201d Shapiro said.\u00a0\nThe team found exactly that result. They aligned the pili into long, ordered bundles using a molecule called hexamethylenediamine (HMD). HMD can align the pili since it is positively charged at both ends while the pili is negatively charged, acting like a molecular \u2018glue\u2019 between the pili filaments. They found that assembling the pili increased long-range conductivity by five-fold. \u201cIf I had to guess why this happened, it\u2019s because if the electrons flow down the outside of the proteins, then having a bunch of channels close together makes it easier to flow between filaments,\u201d Shapiro said.\nFor the project\u2019s final step, the researchers hypothesized that turning the pili into a scaffold onto which they could attach inorganic molecules may allow for higher electrical conductivity. This property would enable them to attach conductive materials, such as gold nanoparticles, to the filaments. \u201cThe hybrid organic-inorganic biomaterial property means you can use [the pili] as a scaffold\u2026for gold nanoparticles to make it highly conductive, but in theory, you could attach it to whatever you want,\u201d Shapiro said. To create this transformation to a scaffold protein, the researchers inserted a nsAA called propargyloxy-phenylalanine (PrOF) into the bacterial pili. This allowed the newly formed hybrid pili to bind with gold nanoparticles, which increased conductivity by 170-fold.\u00a0\nThe applications for this research have widespread medical effects. \u201cHaving proteins that are electronically conductive lets you interface between your biological self and computers for medical care,\u201d Shapiro said. The team hopes that their work can be the foundation for upcoming breakthrough innovations in protein nanowires and electrical conductivity.\nShapiro is now at Duke University, pursuing a Ph.D. in Biomedical Engineering and studying how liquid-liquid phase separation of intrinsically disordered proteins can be used to control gene expression.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/electronically-conductive-protein-nanowires-an-electrifying-discovery-for-healthcare-applications/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Scanning DNA Barcodes",
            "author": "Hannah Han",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/CutandTag_SophiaZhao-500x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Sophia Zhao.\nWithin each cell of the thirty trillion that comprise your body, bundles of thread-like chromatin float in a nebulous shape defined by the nucleus. This collection of chromatin contains the human genome\u2014the catalog of genetic material that encodes every cell, from the neurons in your brain to the keratinocytes lining your skin. But if each nucleus contains the same catalog of genetic information, what differentiates one cell from another? The answer lies in the process of gene regulation\u2014which genes are activated and which are repressed. This concept is fundamental to the expanding field of epigenetics: the study of how cellular mechanisms can change the reading of genetic code without altering the sequence of nucleotides itself.\nPrevious technologies have allowed scientists to study these epigenetic changes on a single-cell level by analyzing gene or protein expression. However, these methods required scientists to dissociate the tissue section into individual cells and to break those cells down further for analysis. In doing so, researchers lost spatial information that indicated where the epigenetic regulations were occurring within the tissue\u2014details that were key to understanding cellular function.\nResearchers in the Fan Lab at Yale and the Gon\u00e7alo Castelo-Branco Group at the Karolinska Institute in Sweden have developed a novel technique called spatial-CUT&Tag. The method allows them to map out epigenetic gene regulation in the original tissue section using grids composed of 20-micrometer pixels, an area equivalent to a single neuron in the brain. This technique represents a huge leap forward in the field of spatial omics and was recently published in Science.\n\u201cWhat has been missing in terms of [past] technology is that you don\u2019t really see single-cell information in a kind of genome-scale, unbiased way, [while it is] still in the original tissue environment,\u201d said Rong Fan, a Yale professor of biomedical engineering and the principal investigator at the Fan Lab. \u201cOver the past couple of years, people realized how important that tissue spatial information is in the development of technology for spatial transcriptomics. Now, we can see [gene regulation] pixel by pixel, just like your TV.\u201d\nThe Importance of spatial-CUT&Tag in visualizing histone modifications\nFan and his colleagues focused on using spatial-CUT&Tag to identify a specific mechanism for epigenetic regulation, called histone modification.\nTo understand the process of histone modification, we first have to visualize how DNA is packaged within the nucleus. The average nucleus of a human cell is only six micrometers in diameter, less than half of the width of a human hair, but it must contain approximately six feet of DNA. To optimize space within the cell, the ribbon of DNA is first coiled around clusters of positively-charged proteins called histones, like a thread strung with beads. These histones are then grouped together, forming long ropes called chromatin fibers, which are condensed into chromosomes.\nIn histone modification, however, these histones are altered with chemical groups that cause sections of the DNA to unwind, leaving certain genes exposed and easily accessible to transcription complexes. Depending on whether the genes are unwound or wound, gene transcription may be activated, causing the production of proteins associated with the gene, or inhibited, resulting in the \u2018silencing\u2019 of the gene. Using spatial-CUT&Tag, the researchers achieved enough precision to see the histone modifications themselves in individual cells.\n\u201cThis is completely mind-blowing. You can see the mechanism that controls gene expression, rather than just the expression of the individual genes, pixel by pixel in a tissue matrix. So, once you have that, the greater impact is [that] you\u2019ll know what type of cells there are and what gene expression determines types of tissue [formation],\u201d Fan said.\nPreviously, one of the most commonly used methods to detect specific histone modifications was ChIP-Seq, which \u201cpulls down\u201d specific histones from the cellular mixture using antibodies and analyzes the DNA associated with those histones. However, Fan said that ChIP-Seq is a tedious, time-consuming process that requires a large sample of cells. Spatial-CUT&Tag expedites this process and provides an unimaginably large amount of data in comparison.\n\u201c[With spatial-CUT&Tag], the data now is equivalent to doing thousands of ChIP-Seq, but precisely from every tiny pixel of your tissue and doing thousands of those covering the entire tissue section. That was just science fiction a number of years ago,\u201d Fan said.\nAchieving this level of precision took three years of work, and the final version of the novel spatial-CUT&Tag technology required a combination of three existing techniques: microfluidic deterministic barcoding, CUT&Tag chemistry, and next-generation sequencing (NGS).\nHow spatial-CUT&Tag works\nTo carry out spatial-CUT&Tag, the researchers first performed standard CUT&Tag on mouse embryos and brain tissues. CUT&Tag is a common procedure used to analyze interactions between histones and DNA and determine which proteins are associated with which DNA binding sites. This process required tagging specific histone targets with antibodies, Y-shaped proteins with conformations that perfectly bind to histones of interest, marking them for further analysis. The next step of CUT&Tag involved cleaving the DNA strands coiled around the histone, isolating these protein-associated genes. Finally, synthesized DNA strands, called adapters, were added to the ends of the sectioned genes. These adapters proved to be important later on, as they served as \u201clanding docks\u201d for the attachment of lab-made DNA \u201cbarcodes.\u201d\nThe next step, called microfluidic deterministic barcoding, allowed scientists to track epigenetic modifications back to their locations within the original tissue sample. This novel technology, developed by the Fan Lab three years ago, provided researchers with crucial spatial epigenetic data that were lost when performing regular CUT&Tag. Microfluidic deterministic barcoding involves labeling cells containing specific histone modifications with \u201cbarcodes\u201d, which are unique combinations of DNA strands that the scientists can track to reconstruct a visual map of epigenetic modifications. To carry out microfluidic barcoding, the researchers developed two microfluidic devices.\nThe microfluidic devices contained fifty microfluidic channels each and were positioned atop each other at perpendicular angles to create a grid containing 2,500 intersection points, with the tissue sample placed underneath. The researchers then flowed fifty unique DNA strands through the microfluidic channels in each device, creating 2,500 distinctive combinations of DNA strands, or \u201cbarcodes.\u201d As Fan explained, each microfluidic channel forms a long, straight road with a particular street name, and every cell settled at an intersection sits like a unique house along this road. The \u201cbarcode\u201d functions as a cell\u2019s address: a sign-post declaring its location.\n\u201cIf we know the address code of every single pixel there, we know where that house, [or the cell], is located. Basically, we give every single tiny piece of tissue in a whole tissue section a unique address code,\u201d Fan said.\nIn the procedure, the \u201cbarcodes\u201d adhered to the adapters attached to the selected genes during the first step of CUT&Tag. The researchers then photographed the model to ensure that they could align the arrangements of different cell types in the tissue with the spatial data they gathered from spatial-CUT&Tag. Afterward, they performed next-generation sequencing, which allowed them to determine the DNA sequences of the selected genes. With this data, they conducted a robust computational analysis that required much trial and error to perfect.\n\u201cComputationally, there are no existing pipelines to analyze the spatial epigenomics data. It took a lot of effort to borrow the modules developed by others and generate the whole pipeline we needed to analyze the data,\u201d said Yanxiang Deng, a post-doc in the Fan Lab and the first author of the Science paper.\nAfter months of trouble-shooting and optimization, they compiled their results. The researchers found that the epigenomic map developed by spatial-CUT&Tag accurately distinguished between the distinct cell types present in embryonic and postnatal mouse tissues. In fact, in one experiment, the epigenomic data formed distinct stripes that correlated with the cortical layers in a mouse brain, demonstrating that spatial-CUT&Tag could differentiate cell types based on histone modifications. They validated the results by running ChIP-Seq tests on the same tissue samples.\nImplications in cancer research and next steps\nLooking ahead, Fan and Deng want to expand their study of histone modifications to other epigenetic mechanisms, including DNA methylation. The researchers are also thinking about developing 3D epigenomic maps, updating the 2D grids generated with spatial-CUT&Tag data.\n\u201cWe\u2019re working on combining with other modalities because these technologies are working [on] one molecular layer each time. We are working on co-profiling different layers of molecules [\u2026] to understand gene regulation networks,\u201d Deng said.\nDeng acknowledged that the development of spatial-CUT&Tag opens up a wide range of biological applications\u2014most notably, identifying epigenetic mechanisms underlying cancer.\nCancerous cells may arise due to epigenetic alterations, and the difference between a healthy and malignant cell can be traced back to histone modifications. \u201cPotentially, if you\u2019re looking at a disease, [you can use spatial-CUT&Tag to determine] what actually drives the disease,\u201d Fan said. \u201c[You can see what is happening at] the mechanistic level and can target specific histone modifications in specific loci to develop new drugs that really target the root of the disease initiation.\u201d\nYet there is still much to be explored; even with the development of spatial-CUT&Tag, questions about the future of cancer epigenetic research linger.\n\u201cNow the door is open,\u201d Fan said. \u201c[With spatial-CUT&Tag], you can begin to gather data and think about how to target the cancer with a completely new approach and [find] a potentially much more efficacious and much more personalized [treatment] one day.\u201d\nAbout the Author: Hannah Han is a first-year prospective HSHM and MCDB double-major in Grace Hopper College. Beyond writing and editing for YSM, Hannah conducts breast cancer research at the Yale School of Medicine, volunteers for Splash and HAPPY, and contributes to various literary publications on campus.\nAcknowledgments: The author would like to thank Professor Fan and Dr. Deng for their time and enthusiasm about their work.\nExtra Reading:\nDeng, Y., Bartosovic, M., Kukanja, P., Zhang, D., Liu, Y., Su, G., Enninful, A., Bai, Z., Castelo-Branco, G., & Fan, R. (2020). \u201cSpatial-CUT&Tag: Spatially resolved chromatin modification profiling at the cellular level.\u201d Science, 375(6581): 681\u2013686, https://doi.org/10.1126/science.abg7216.Liu, Y., Yang, M., Deng, Y., Su, G., Enninful, A., Guo, C. C., Tebaldi, T., Zhang, D., Kim, D., Bai, Z., Norris, E., Pan, A., Li, J., Xiao, Y., Halene, S., & Fan, R. (2020). \u201cHigh-Spatial-Resolution Multi-Omics Sequencing via Deterministic Barcoding in Tissue.\u201d Cell, 183(6): 1665\u20131681, https://doi.org/10.1016/j.cell.2020.10.026.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/scanning-dna-barcodes/",
            "captions": [
                "Processed with VSCO with dog3 preset"
            ]
        },
        {
            "title": "Putting Order in Disorder",
            "author": "Yale Scientific Magazine",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wave-in-the-Right-Direction-Noora-Said-374x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Noora Said.\nWhat is scattering?\n\u201cWhy is the sky blue?\u201d is perhaps one of the first, most vexing questions a kid can ask their parents. After all, how do you explain to a three-year-old that the answer lies in the scattering of light in opaque diffusive systems?\nIn our day-to-day lives, scattering occurs when particles pass through a medium\u2014such as air or water, for example\u2014and collide with other particles, resulting in a change in their trajectory. \u201cScattering of light is very common,\u201d said Hui Cao, a Professor of Applied Physics at Yale University, focusing on mesoscopic physics, nanophotonics, and biophotonics. \u201cThe sky looks blue because blue light is scattered [more] strongly than red light, and the reason why we look opaque is that there\u2019s strong scattering by the cells in biological tissues. That\u2019s why we cannot see through most biological tissues.\u201d We encounter many things in everyday life that we cannot see through or send information through\u2014all because of this strong scattering of light.\u00a0\nHowever, scattering can cause challenges in applications such as medicine, where the opacity\u2014or lack of transparency\u2014of human tissues can limit their visualization and manipulation.\u00a0\nIn recent years, researchers have explored different ways to transmit energy through diffusive systems. In medical applications, for example, it is critical to focus on delivering and depositing energy inside systems such as human tissue instead of simply sending energy through the system. Medical applications include procedures like photothermal therapy, which uses heat generated by near-infrared light to treat cancer, or deep tissue imaging, which allows researchers to image whole tissues without dividing them into thinner sections.\u00a0\nCan\u2019t we just send light into the system?\nOne of the greatest challenges in depth-targeted delivery of light\u2014in other words, sending light into a specific spot in the system\u2014is that energy scatters in multiple directions and diffuses upon entering the system.\u00a0\nPrevious research relied on controlling the wavefront of the input energy wave to limit diffusion, which allowed researchers to focus light on a specific spot in a scattering medium. A wavefront is an imaginary surface where all the points are at the same phase in their wave cycle (think of the ripples you see when you drop something in water). Shaping the wavefront involves controlling the distribution of wave intensities and phases in the input beam.\nHowever, this method was less practical for real-world applications because medical targets such as tumors or neurons often sprawl over a region rather than remaining in a single focal spot. The upper limit on energy deposition in a region at a certain depth in a diffusive system, which is important to know for practical applications of this technique, was also unclear using this method.\u00a0\nAnother difficulty lays in observing the delivery of light into the system. \u201cScientifically, it\u2019s really easy to study sending something into a system and measure something coming out of a system\u2014you just put a camera on one end and input on the other,\u201d said Nicholas Bender, formerly a Yale doctoral student in Cao\u2019s lab and now a postdoctoral researcher at Cornell University. \u201cWhat\u2019s hard to do is to understand what this light is doing inside a system because by observing the system, you may interfere with it.\u201d Simply put, trying to see what was going on in the system could mean inadvertently altering whatever process was underway within it.\u00a0\nLasers and Math\nTo confront this issue of targeted energy delivery into diffusive systems, researchers at Yale University performed a comprehensive series of experiments, numerical simulations, and theory. \u201cI like to call it \u2018creating and controlling disorder, randomness, and chaos with lasers,\u2019\u201d Bender said.\u00a0\nThe team began by defining a matrix that mathematically described the relationship between the laser beam input into a diffusive system and the way the light was distributed across a region of specific depth in the system. By running repeated simulations of virtual disordered systems, the research team plotted what different input beams would look like at various points within the system.\nThe maximum energy that could be delivered to the target region corresponded to the largest eigenvalue of the deposition matrix. Eigenvalues are factors representing the scales of eigenvectors, which are characteristic vectors in linear algebra. The input wavefront could be found from the eigenvector associated with that largest eigenvalue.\u00a0\nCausing Chaos (On Purpose)\nOne unique feature of this study was the experimental setup. The researchers devised an experimental platform consisting of a two-dimensional disordered structure (picture a rectangular slab with holes that randomly let light through) where the optical field could be analyzed by the researcher looking down at the platform from above (from the third dimension). \u201c\u200b\u200bThis is new,\u201d Cao said. \u201cBefore, people usually made a three-dimensional sample. With three-dimensional scattering, when you send in the light, you cannot see it, so you don\u2019t know [which wavefront is best] to deliver light. But by using this system, we\u2019re able to peek in, to take a look from the third dimension, and say, \u2018Oh, we see! This is where we can deposit and how much.\u2019\u201d For example, if you rolled a marble into a non-transparent box, you wouldn\u2019t be able to see its path or where it stopped. If you rolled that marble onto a sheet of paper, you would be able to look down onto the paper and track the marble\u2019s progress.\u00a0\nAccording to Cao, creating this experimental setup was not an easy process. \u201cIt\u2019s absurd how much effort we had to put into making this disordered system just the way we want it,\u201d he said. \u201cI mean, calibrating and controlling disorder is ridiculous\u2026it\u2019s crazy and great and horrible to do,\u201d Bender said. This breakthrough experimental technique allowed the researchers to observe scattering and light delivery with a degree of control that had never before been possible.\u00a0\nUsing a spatial light modulator, a device that controls the intensity and phase of light emitted, the researchers could shape the wavefront of a laser beam in one dimension. They found the two-dimensional field distribution inside the system\u2014the field of randomly scattered light in the platform.\u00a0\nThe two-dimensional sample consisted of a silicon-on-insulator wafer with photonic-crystal sidewalls to keep light inside the system. The team added random optical scattering to this system by etching a random array of holes in the wafer. When the laser beam was sent in, some of the scattered light would come out of the holes and into the path of a reference beam. A camera then recorded these interference patterns. \u201cBasically, by shaping the incident wavefront using a spatial light modulator, we can control how we\u2019re going to send the light in,\u201d Cao said. \u201cBy finding the correct wavefront, we can deposit light into different target areas deep inside.\u201d\nThis experimental platform allowed the researchers to directly map the diffusive system at any depth. \u201cOnce we have this system that allows us to see what light is doing inside a random disordered system, we can essentially say, \u2018Okay, instead of just describing the relationship from the input to the output, we can describe the relationship of the light from the input to anywhere inside,\u2019\u201d Bender said.\nThis experimental setup allowed the researchers to create a system where the disorder could be controlled, precisely tuned, and analyzed. By optimizing the laser input wavefront, they were then able to maximize energy delivery.\u00a0\nThis is a unique and novel set up\u2014one that has fundamentally changed the ways light can interact with opaque systems. \u201cWe\u2019re the only people who can actually do this study,\u201d Bender said. \u201cWe can control the input with very, very good precision using the spatial light modulators we have available. We can make the waveguides any way we want just because of the technical capabilities we have in the facilities at Yale.\u201d\u00a0\nThe Theory\nThe research team also built a theoretical model to predict the maximum amount of energy that could be delivered to a certain depth in the system. Theoretical modeling was important in showing the researchers the limits of their new technology. \u201cWhat\u2019s the fundamental limit? How well can we reach it, and what determines this limit?\u201d Cao said.\u00a0\nThrough mathematical calculations, the team found that energy enhancement depended on the sample thickness and depth of the region. Energy enhancement was also affected by the transport mean free path of the system, which is the distance light can travel in a random system before it loses all of the information about the initial direction of propagation. They then experimentally measured the internal field distribution at different depths to find the deposition matrix for regions in a diffusive system. They found that the highest possible energy enhancement occurs at three-fourths of the system\u2019s thickness.\u00a0\nMoment of Discovery\nThis research differs from previous studies in the field because it focuses on deposition instead of energy transmission. \u201cEverybody doing wavefront shaping was looking at the transmission matrix or some version of the transmission matrix,\u201d Bender said. Compared to transmission, having disorder after the region of light deposition can result in light traveling backward, interfering with the light going forwards, leading to a greater energy enhancement than in the case of transmission.\u00a0\nControlling Randomness\u00a0\nThe ability to control random wave scattering allows for energy deposition into specific regions of opaque systems. \u201cThis is interesting for medical applications or anything dealing with a real system because most systems are disordered to some extent,\u201d Bender said. Research into this type of targeted energy delivery could be used in applications ranging from the optogenetic control of neurons to tissue imaging. \u201cThere are people in [the] community trying to do imaging through the skull. They try to send the laser beams through the skull for both a diagnosis and also to try to simulate neurons,\u201d Cao said.\u00a0\nThis study pushes the boundaries of what was previously thought to be possible. \u201cTraditionally, people [think that] if something looks white, then you just cannot see through it,\u201d Cao said. \u201cI wish more people knew that actually, that is not true. Random scattering is not something just impossible to control.\u201d\nAbout the Author: Eunsoo Hyun is a junior in Berkeley College majoring in Biomedical Engineering. Outside of writing for YSM, Eunsoo enjoys painting, learning new languages, and dancing with the Yale Jashan Bhangra team.\u00a0\nAcknowledgments: The author would like to thank Professor Hui Cao and Dr. Nicholas Bender for their time and enthusiasm for their research.\nExtra reading:\nBender, N., Yamilov, A., Goetschy, A., Y\u0131lmaz, H., Hsu, C.W., and Cao, H. (2022). Depth-targeted energy delivery deep inside scattering media. Nat. Phys. 18, 309\u2013315. https://doi.org/10.1038/s41567-021-01475-x.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/putting-order-in-disorder/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Supercharged Killer Cells: Advances in CAR-T Cell Therapy",
            "author": "Shudipto Wahed",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Killer_Tcells_angry_Kuo-Malia-Kuo-e1662262636124-500x476.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Malia Kuo. \nEmily Whitehead\u2019s entire world turned upside down in 2010 when, at the age of five, she was diagnosed with B-cell acute lymphocytic leukemia (ALL), the most common childhood cancer. After two years of unsuccessful chemotherapy, all hope seemed to be lost. Her doctors recommended she be taken home to Philipsburg, Pennsylvania, to die peacefully with her family around.\nFortune was on the Whiteheads\u2019 side, however. A combination of persistence and perfect timing led their treatment search to the Children\u2019s Hospital of Philadelphia, which had just received approval for treating their first refractory ALL patient using a novel, yet promising approach: CAR-T cell therapy.\nChimeric antigen receptor (CAR)-T cells are an engineered variant of T cells\u2014white blood cells in our bodies integral to the immune response against infection. The term \u201cchimeric\u201d refers to how the antigen-recognizing part of the receptors derives from extracellular antibodies. These cells are equipped with T cell receptors (TCRs) on their surfaces, allowing them to recognize virus- or bacteria-infected cells. Similarly, cancer cells can display tumor-specific antigens (markers) that enable their recognition and destruction by this mechanism. A specific subset of these T cells, called CD8+ T cells, which are distinguished by expressing CD8 molecules on their surfaces, are referred to as \u201ckiller\u201d or \u201ccytotoxic\u201d T lymphocytes (CTLs) because they can trigger immunecell-mediated death of target cells.\nCould CTLs then serve as \u201cliving drugs\u201d against cancer? Over the past few decades, medical researchers have grown keen to answer this question, hoping to improve the rather lackluster survival rates of prevalent forms of cancer treatment such as surgery, chemotherapy, and radiation.\u00a0\nIsraeli immunologist Zelig Eshhar was the first to produce CD8+ T cells with genetically engineered TCRs modified to recognize the antigens of choice. These were the first-generation CAR-T cells.\u00a0\nCAR-T cells thus offered an exciting opportunity to harness the existing machinery of the immune system to target and kill cancer cells simply by engineering TCRs to specifically target antigens displayed by tumor cells. University of Pennsylvania immunologist Carl June pioneered the development of second-generation CAR-T cells, engineered to kill leukemia cells in mouse malignancy models. At this time, he encountered a hospice-referred Emily Whitehead.\nCAR-T Cell Therapy\u2014The Contemporary Landscape\nTo the delight of everyone involved, Emily\u2019s cancer went into remission immediately following the administration of June\u2019s CAR-T therapy. In June 2012, she was released from the hospital, and today, she remains cancer-free. This event marked a pivotal point in cancer immunotherapy: a later clinical trial showed that ninety percent of refractory ALL patients receiving CAR-T achieved complete remission for a disease that would have otherwise proven fatal.\nTo date, six CAR-T cell therapies have been FDA-approved for treating various blood cancers. The treatment process is similar for each type of CAR-T therapy. A patient\u2019s blood is first removed to isolate CD8+ T cells. These cells are then genetically engineered, often using CRISPR-Cas9 and/or lentiviral gene-editing technology, to remove the natural TCR and insert a CAR directed towards the antigen of choice. Other modifications, such as removing inhibitory molecules and introducing co-stimulatory molecules, are often performed. These CAR-T cells are then cultured in a laboratory setting to grow millions of anti-cancer T cells, which are finally re-infused into the patient to target and kill malignant cells.\nWhile CAR-T remission and survival rates have at times considerably exceeded other therapy options, access remains poor. Due to the complexity of the procedure, a singular infusion can cost up to $500,000, excluding other costs such as hospital stay and follow-up protocols. Additionally, geographic barriers can limit patients\u2019 access to this life-saving treatment as fewer than two hundred centers in the U.S. are authorized to administer the treatment.\nMoreover, several limitations have prevented widespread adoption and greater efficacy. While all currently approved CAR-T cell therapies target blood cancers, their effectiveness in solid tumors has been lackluster. A major challenge is improving the persistence and proliferation of CAR-T cells post-infusion since they often do not survive long enough to mediate long-term cancer control. Additionally, identifying and targeting \u201cneoantigens,\u201d antigens that are specifically expressed or overexpressed by tumor cells, has been challenging for CAR-T cells.\nCRISPR Engineering and the Next Generation\nTo further improve the function and specificity of CAR-T cells, researchers have experimented with the ability to boost T cell function via genetic engineering: whether by knocking out (deleting) inhibitory receptors or inserting co-stimulatory genes. The innovation of CRISPR-Cas9 gene-editing technologies vastly improved this capability. By using RNA as a guide to direct DNA cleavage at specific regions in the genome, CRISPR-Cas9-mediated editing tends to be more precise than previously used techniques, resulting in fewer off-target side effects.\nOver the past few years, researchers have mostly used CRISPR-Cas9 gene-editing technologies to screen the genome of CD8+ T cells for knockout targets by identifying genes that, when silenced, augment antitumor efficacy.\nAssociate Professor Sidi Chen, Associate Research Scientist Lupeng Ye, and their team at the Yale School of Medicine recently published a paper in Cell Metabolism outlining their development of a CRISPR activation (CRISPRa) gain-of-function (GOF) screen in CD8+ T cells. While previous CRISPR screens only focused on identifying knockout targets, a GOF screen would identify genes that, when overexpressed (\u201cknocked-in\u201d), would enhance CAR-T function.\u00a0\nThus, this novel platform helps identify a new class of gene-editing targets that can be harnessed as functional boosters for CAR-T cell therapy optimization. \u201cCRISPRa screen is very, very new in immune cells and completely different from prior knockout screens. We try to find several targets that can reprogram T cells and use CRISPR engineering to \u2018knock-in\u2019 these targets into engineered T cells so the CAR-T can have boosted function when killing cancer,\u201d Ye said.\nIdentifying Useful Targets for CAR-T Optimization\nWith a primary gain of function screening method, the researchers sought to identify genes that, when activated, would enhance the \u201cdegranulation\u201d ability of CD8+ T cells. Degranulation, the process of releasing cytotoxic molecules from internal secretory vesicles, is one of the primary mechanisms by which CTLs mediate the killing of their target cells.\u00a0\nA key characteristic of CRISPRa is that it uses truncated \u201cdead-guide\u201d RNA (dgRNA) instead of traditional \u201csingle guide\u201d RNA (sgRNA). Whereas sgRNA binds to Cas9 and cuts a specific target sequence, \u201cdgRNA [\u2026] can also complex with Cas9 and bind to targets, but cannot cleave DNA,\u201d Ye explained. Instead, the dgRNA is designed to contain two special loop structures that recruit proteins involved in DNA transcription, ultimately resulting in overexpression of the genes the dgRNAs are meant to target.\nThe authors of this study began by designing a mouse genome-scale dgRNA library targeting more than 22,000 genes, which will be delivered to CD8+ T cells isolated from Cas9-transgenic mice to conduct CRISPRa. Using an immunogenic mouse tumor model, researchers co-cultured dgRNA-transduced tumor-targeting CD8+ T cells with their target tumor cells. After four hours, the authors measured the levels of CD107a, a molecule expressed after degranulation. Then, the researchers used fluorescence-activated cell sorting to isolate CD8+ T cells with CD107a.\nGenetic sequencing revealed which dgRNAs were most significantly enriched in the CD107a+ population. \u201cIf the gene is highly enriched, the signal will be really strong. We picked the targets with the strongest signals to do our initial validation,\u201d Ye said. One of the screen\u2019s top hits, the PRODH2 gene, led to increased degranulation and more rapid proliferation in CD8+ T when overexpressed compared to control cells. Could PRODH2 serve as a functional booster for human CAR-T cells?\nMetabolic Reprogramming Supercharges CAR-T Cells\nIndeed, Chen\u2019s team confirmed that PRODH2 overexpression in human CAR-T cells, either by CRISPR knock-in or traditional lentiviral delivery, enhanced tumor killing and proliferation. These findings were validated in three in vitro cellular models: leukemia, multiple myeloma, and breast cancer. These effects were replicated in vivo, using human tumor xenograft models for the same three cancers in mice. PRODH2 overexpression led to reduced tumor growth and greater survival in CAR-T cell therapy.\nBut why? The authors performed various profiling techniques to gain insights into the mechanism underlying how PRODH2 overexpression enhances CAR-T cell antitumor efficacy. mRNA sequence analyses showed that PRODH2 knock-in significantly altered gene expression of the cell cycle, activation/effector function, and metabolism-related programs in CAR-T cells.\u00a0\nPRODH2\u2019s effects on CAR-T cell antitumor efficacy seemed to be driven by metabolic reprogramming related to proline, an amino acid building block. \u201cIf we overexpress PRODH2, then proline metabolism will be reprogrammed,\u201d Ye said. Metabolomics data of PRODH2-overexpressing CAR-T cells revealed increased biochemical activity of the pathway and alterations in other intersecting metabolic pathways, such as the metabolism of arginine, another amino acid. In fact, the cancer-killing ability was improved when direct substrates of PRODH2 were supplied to PRODH2-knockin CAR-T cells, but not in control CAR-T that normally lack the enzyme. This confirmed that the metabolic activity of PRODH2 was responsible for enhanced cytotoxic activity.\nHope for the Future\nChen\u2019s team established a novel, genome-wide GOF screening technique in primary CD8+ T cells that can identify desperately-needed functional boosters in a robust and unbiased manner. The beauty of the screen is its versatility. \u201cThis doesn\u2019t have to be T-cell or cancer-specific\u2014ours is a flexible and broad platform that can be utilized to perform screens on virtually any other type of immune cells,\u201d Chen said. \u201cThis platform can be a broadly enabling technology for us and everyone else in the world to utilize GOF screens in various systems, including stem cells, NK cells, macrophages, and even other cells relevant to other diseases.\u201d In the future, the authors wish to validate the other targets identified in their screen. They hope to ultimately translate their work into clinical practice by improving the anti-cancer efficacy of CAR-T therapies.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/supercharged-killer-cells-advances-in-car-t-cell-therapy/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How to Make a Hot Jupiter",
            "author": "Brianna Fernandez",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/hot-jupiter-Uriel-Teague-354x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Uriel Teague. \nIf you\u2019re reading this, you likely live in a solar system. I\u2019d venture to say that you live on Earth, too, making you a resident of its solar system. Given these assumptions, you\u2019re likely familiar with its structure: four rocky planets on the inside followed by four gaseous planets on the outside, all orbiting the Sun in nearly identical equatorial planes. This structure feels standard, safe. But every tellurian astronomer was forced to confront this biased assumption upon the discovery of the first extrasolar planet.\nIn 1995, astronomers Didier Queloz and Michel Mayor discovered planet 51 Pegasi b, the first known planet found outside of the solar system. This planet is large, hot, and extremely close to the sun-like star that it orbits\u2014much closer than Mercury is to the Sun. It is what is now called a \u201chot Jupiter,\u201d a gas giant planet with an orbit extremely close to its star. This single planet scrambled astronomers\u2019 understanding of solar system formation since they had previously assumed that gas giants orbited far from their stars, much like our beloved Jupiter. Now that over 5,000 exoplanets have been discovered, we can create a \u201cnormal distribution\u201d of solar systems, and ours is far from the center of the bell curve.\nThough they are familiar to us, our system\u2019s orbits, which transit the equator of the Sun, are just as extreme as orbits wherein a system\u2019s planets orbit from pole to pole. So while large, gaseous planets completing orbits around their stars in just a few days may seem foreign to us, it is frequently observed in other planetary systems. The only problem is that we don\u2019t understand how they do it.\nYale astronomy researchers Malena Rice and Greg Laughlin are tackling this issue head-on. Fifth-year Ph.D. student Malena Rice was studying how a warm Jupiter, a gas giant with an orbital period of over ten days, fit into existing planet formation theories when she noticed an interesting correlation. \u201cI made about a hundred plots looking at how this planet fits in with the bigger picture of all the [previous] measurements\u2026 and I realized that, no matter how you look at them, the eccentric planets tend to be more misaligned,\u201d Rice said. This misalignment of eccentric hot Jupiters, or those with more elliptical rather than circular orbits, could be the key to understanding how they form.\nHeat Your Jupiter to 2000 \u00b0F\nBut how did hot Jupiters get their characteristic elliptical orbits in the first place? This issue has separated astronomers into a few different camps. Perhaps hot Jupiters formed in their original places in a process called in situ formation. However, this is difficult to do because there isn\u2019t a lot of planet-forming material near the stars they orbit. Others argue that they might have formed farther out and migrated inward, shepherded by other planets in the solar system through gravitational interactions. In this process, the hot Jupiters would spiral slowly and gradually toward the inner orbits of the system. There is strong support for this latter theory in astronomical communities.\nThe third camp argues in favor of high-eccentricity migration, a framework in which hot Jupiters are born farther from their host stars or the stars that they orbit. Through scattering and nudging from other sources, the hot Jupiters are knocked onto highly elongated orbits and spiral inwards to reach much closer orbits over time. \u201cOne way to distinguish which of these is actually correct is by looking at whether or not hot Jupiters are aligned with the plane of their host star\u2019s equator,\u201d Rice said.\u00a0\nIn general, we expect host stars to spin in the same direction as their surrounding disks of dust, gas, and other debris. These disks form around newly-made stars to eventually form planetary bodies through collisions of the orbiting particles. In the beginning, everything should form in the same plane. So, planets that are misaligned or orbiting in directions different from their host stars could indicate that the system underwent a dynamically dramatic process. These misalignments require a kick hard enough to tilt entire systems, such as one planet tossing another into a different orbit, a star flying by and tilting the disk, or one planet being thrown into the host star and being engulfed. The fact that systems with hot Jupiters are rarely observed with other planets indicates that the Jupiters\u2019 would-have-been neighbors could have been thrown out early on or engulfed by the chaos caused by the dramatic inclination shift.\nObserve Your Jupiter Transiting Its Star\u00a0\nHot Jupiters are incredibly well-studied by astronomers because they are the easiest to observe. To detect these planets, astronomers use the transit method, a detection technique where astronomers measure how much light a planet blocks as it passes or transits its host star. \u201cYou get the size of the planet by looking at how much of the starlight has been blocked, you get the period by seeing how often it happens, and you get information about the orbit from the duration of the transit,\u201d said Greg Laughlin, Yale professor of astronomy.\u00a0\nOver the past decade, a lot of effort has gone into measuring the angles between planetary orbits and the stars\u2019 equators. Enough of these measurements have been collected such that patterns are now starting to emerge. One of the most interesting patterns is that stars that are more massive than the Sun by about twenty or thirty percent tend to show planets that are badly misaligned, whereas the stars that are less massive than the Sun tend to show better alignment.\u00a0\nExtrapolate Your Jupiter\u2019s Evolutionary History\nResearchers Malena Rice and Greg Laughlin found that when the planet\u2019s orbit had a higher eccentricity, there was more misalignment. This finding aligns with the idea that the planets get to their current locations through scattering rather than steady, slow disk migration. \u201cThat doesn\u2019t mean that high-eccentricity migration is the only process that could take place, but is probably dominant\u2014if you assume that it\u2019s the only mechanism at play, it is consistent with all of our observations,\u201d Rice said.\u00a0\nFor now, they need more data, but what they\u2019ve collected so far is promising, confirming that disks should be aligned with their hosts. If wide-orbiting warm Jupiter planets had started in misaligned orbits, they would continue to have those peculiar orbits since they orbit too far from their host star to be realigned over time. So, the fact that we mostly see aligned systems, particularly on wider orbits, further indicates that something drastic happened to the closer-orbiting hot Jupiters after they had all formed to become misaligned.\nThis result isn\u2019t what would be expected, as it implies that these hot Jupiters rely on random events rather than a systematic process. \u201cI had assumed either that the planets are forming in situ or that they\u2019re migrating, and I hadn\u2019t really appreciated the fact that we can explain the distribution simply through chaotic scattering and planet-planet interactions, kinds of one-off events,\u201d Laughlin said.\nBut what advantages does characterizing these planetary systems bring? Having two well-studied types of planetary systems is much better than just one, especially when those two systems are fringe-type oddballs on each end of the spectrum. From these systems, one can interpolate between the two extremes and extrapolate the evolutionary histories of more average systems. \u201cWhat\u2019s really exciting about this paper is that it gives us really good reason to believe that this very dramatic set of events, which are unlike anything that happened in the solar system, is actually happening on a regular basis,\u201d Rice said. \u201cIt\u2019s providing a completely new perspective on the different ways that planetary systems form; we are starting to piece together the possibilities and move away from being biased by our one exquisitely detailed data point.\u201d\nAbout the author:\u00a0Brianna Fernandez is a junior in Pierson College studying astronomy and earth and planetary sciences. In addition to writing for YSM, she is one of the magazine\u2019s layout editors. Outside of YSM, she researches exoplanets with Professor Debra Fischer and advocates for incarceration-impacted individuals with the Yale Undergraduate Prison Project.\nAcknowledgments: The author would like to thank Malena Rice and Greg Laughlin for their time and enthusiasm in sharing their research.\u00a0\nExtra reading:\nRice, Malena, et al. \u201cOrigins of Hot Jupiters from the Stellar Obliquity Distribution.\u201d The Astrophysical Journal Letters, vol. 926, no. 2, 2022, https://doi.org/10.3847/2041-8213/ac502d.\u00a0\nHamers, Adrian S., and Scott Tremaine. \u201cHot Jupiters Driven by High-Eccentricity Migration in Globular Clusters.\u201d The Astronomical Journal, vol. 154, no. 6, 2017, p. 272., https://doi.org/10.3847/1538-3881/aa9926.\u00a0\nKraus, Stefan, et al. \u201cSpin\u2013Orbit Alignment of the \u03b2 Pictoris Planetary System.\u201d The Astrophysical Journal, vol. 897, no. 1, 2020, https://doi.org/10.3847/2041-8213/ab9d27.\u00a0\nWallace, Spencer. \u201cUnraveling the Formation History of Hot Jupiters.\u201d Astrobites, 27 June 2019, https://astrobites.org/2019/06/27/unraveling-the-formation-history-of-hot-jupiters/.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/how-to-make-a-hot-jupiter/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Tortoises Then & Now",
            "author": "Sophia Burick",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Tortoise-Catherine-Kwon-1-e1662261900950-474x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Catherine Kwon.\nThe Galapagos Islands have been an archetypal example of evolution and natural selection since 1835, when famed naturalist Charles Darwin set foot on their remote shores. Upon arriving on the islands, Darwin discovered animals that were similar in many ways but differed in their adaptations to the unique environment of their respective home islands. These observations led Darwin to develop his revolutionary theory of natural selection, detailing how populations of organisms change and adapt to succeed in their specific environments.\u00a0\nOne of the most iconic residents of the Galapagos Islands is the Galapagos giant tortoise. After arriving at the Galapagos Islands from mainland South America millions of years ago, the tortoises slowly evolved into fifteen unique species across ten of the islands in the Galapagos, with twelve of these species surviving to this day. These species are all specifically adapted to succeed in the isolated environments they inhabit. For decades, researchers believed that the tortoises of San Crist\u00f3bal Island\u2014one of the oldest islands in the Galapagos archipelago\u2014belonged to a single lineage. However, Adalgisa Caccone, a Senior Research Scientist in Yale\u2019s Department of Ecology and Evolutionary Biology, along with a team of eleven colleagues, recently found evidence of a second, long-extinct lineage of tortoises on San Crist\u00f3bal Island. In her group\u2019s new study, published in Heredity in February, Caccone and her team sequenced DNA from museum samples of tortoises more than a century old, suggesting the existence of a previously unknown lineage of tortoises.\nA Long Time Coming\nThe story of this groundbreaking discovery began nearly three decades ago when Caccone and her husband, Professor Jeffrey Powell of the Department of Ecology and Evolutionary Biology, first became interested in studying the giant tortoises to save them from extinction. This threat has haunted the tortoise population since the arrival of humans to the Galapagos. To early fisherman and whalers, the turtles were a meal, not an evolutionary miracle. \u201cThey were a good source of fresh food because you can keep them on the boat without food or water for up to six months,\u201d Caccone said. \u201cIt\u2019s been estimated that 250,000 tortoises were taken across the islands.\u201d\nCaccone was confident that the key to managing endangered tortoise populations lay in piecing together the puzzle of their evolutionary origins. In collaboration with the Galapagos National Park and the Charles Darwin Foundation, she began collecting samples from the surviving populations of Galapagos tortoises.\u00a0\nThe next step in uncovering the story of the tortoises\u2019 evolution was interrogating their DNA. \u201cWe started sequencing small fragments of genes, like the mitochondrial DNA, some nuclear genes, and genotyping microsatellite loci,\u201d Caccone said. \u201cWe started building the story.\u201d By comparing the DNA data of the living populations, Caccone could identify similarities and differences, generating new understandings of how the tortoises might have spread across the islands and adapted.\u00a0\nHer efforts in uncovering these patterns led her to San Crist\u00f3bal Island. \u201cSan Crist\u00f3bal is one of the oldest islands of the Galapagos Islands, so it likely plays an important role in understanding how the colonization of the islands started,\u201d Caccone said.\nStill, a piece of the evolutionary puzzle was missing. \u201c\u200b\u200bWe soon realized that there were some questions that we could not address because we needed the DNA of the extinct species,\u201d Caccone said.\u00a0\nA Surprising Solution\nCaccone and her team found their solution in unexpected places: historical samples from a single living tortoise and tortoise bones collected from a cave during an expedition to San Crist\u00f3bal in 1906, which had been stored away in museum collections more than a century ago. Caccone set to work sequencing DNA from these samples\u2014a particularly challenging task due to the age of the samples.\u00a0\nUsing micro-CT scans, which use x-rays to build a 3-D image of the interior of an object on a very small scale, Caccone and her team could determine the sections of the old bones most likely to contain preserved DNA. They sequenced small sections of DNA from each bone, overcoming the challenges of working with tortoise bones that were hundreds of years old and highly degraded. \u201cWhat you want to get is a sample that has a good amount of DNA preserved in it,\u201d Caccone said. \u201cUsually, bones are much better than tissues, because the external mineralized portion of the bone protects the DNA.\u201d\nCaccone expected to find a variety of DNA sequences related to the single existing haplotype, or set of DNA variations, found in the living tortoises from San Crist\u00f3bal. Instead, she found something very surprising. \u201cWe found that unlike in the existing population, there was variation, and that the variation was not related to the existing haplotype,\u201d Caccone said. \u201cIt was something different. That\u2019s when we said, okay, there\u2019s something interesting here. Let\u2019s get to work.\u201d\nAnd work they did\u2014Caccone and her team convinced the Galapagos National Park, with which they are working in close collaboration, to organize a field expedition over San Crist\u00f3bal Island to check if there were any tortoises related to the lineage from the cave samples. The team collected hundreds of samples across the island, searching in remote places never previously sampled before. Caccone and her team selected a random collection of 129 blood samples from living tortoises to test if any showed signs of relatedness with the samples collected in the cave.\u00a0\nThe genome-wide analyses of samples from living tortoises did not reveal any intermixing between the two lineages, suggesting the existence of an entirely different, long-dead lineage of tortoises on San Crist\u00f3bal Island. \u201cThe key finding is that the mitochondrial haplotypes for these cave specimens are highly distinct from the haplotype that\u2019s in the living population,\u201d Evelyn Jensen, first author on the Heredity paper and lecturer at Newcastle University, said in a podcast with Heredity. \u201cThe common ancestor of the cave and the living lineages diverged probably about 700,000 years ago. So, the tortoises that died falling into the cave are of a totally different lineage from the tortoises that live on the island today.\u201d\nNew Ideas from Old Bones\nJensen and Caccone\u2019s discovery has brought scientists closer to completing the puzzle of giant tortoise evolution and colonization in the Galapagos Islands. It has also powerfully demonstrated the importance of analyzing both historical and contemporary samples when studying these tortoises. \u201cIf we\u2019re just looking at the populations that have survived to the present day, we\u2019re missing some important pieces of the puzzle for reconstructing evolutionary patterns,\u201d Jensen said in the Heredity podcast. \u201cJust when we think we have the story worked out, we look at some dusty old bones in the museum. Now we\u2019re potentially having to do a major rethink of our understanding of how these species arose and colonized the Galapagos archipelago.\u201d\nCaccone and her team are already working on their next step\u2014obtaining more comprehensive DNA samples from the historical samples. The DNA data from this study is limited to mitochondrial DNA, a form of DNA that is more abundant and easier to isolate. However, this subset of DNA lacks much of the broader genetic information of the tortoises, limiting options for genetic analysis. In the future, Caccone hopes to isolate and sequence nuclear DNA, or DNA from the tortoise\u2019s chromosomes, which will provide a much more complete picture of the genetic differences between the cave tortoises and the existing population. The ability to compare full nuclear DNA sequences between extinct and living populations holds the potential to elucidate new knowledge about the relationship between these two tortoise lineages. Further sequencing might even confirm that this unique lineage is an entirely new tortoise species\u2014the evolutionary secrets within these bones have yet to be fully revealed.\nAbout the Author: Sophia Burick is a first-year Molecular Biophysics and Biochemistry major in Timothy Dwight College. In addition to writing for YSM, Sophia sings with the New Blue, Yale\u2019s oldest women\u2019s acapella group, and works as a research assistant at the Yale School of Medicine.\nAcknowledgments: The author would like to thank Adalgisa Caccone for her time and enthusiasm for her research.\nExtra reading:\u00a0\nJensen, E. L., Quinzin, M. C., Miller, J. M., Russello, M. A., Garrick, R. C., Edwards, D. L., Glaberman, S., Chiari, Y., Poulakakis, N., Tapia, W., Gibbs, J. P., & Caccone, A. (2022). A new lineage of Galapagos giant tortoises identified from museum samples. Heredity. https://doi.org/10.1038/s41437-022-00510-8 \u00a0\nCitations:\nJensen, E. L., Quinzin, M. C., Miller, J. M., Russello, M. A., Garrick, R. C., Edwards, D. L., Glaberman, S., Chiari, Y., Poulakakis, N., Tapia, W., Gibbs, J. P., & Caccone, A. (2022). A new lineage of Galapagos giant tortoises identified from museum samples. Heredity. https://doi.org/10.1038/s41437-022-00510-8\u00a0Burgon, J., & Jensen, E. (2022, March 16). Gal\u00e1pagos giants. Heredity Podcast.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/tortoises-then-now/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Robots",
            "author": "Alex Dong",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Dong_Figure1-1-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Andrew Morgan\nLet\u2019s say that you\u2019re watching a video on your phone sideways when you receive a phone call. Instinctively, you use your hand to turn the phone upright, then bring it to your ear. While this may seem simple, the human hand, complete with its twenty-one joints, is incredibly sophisticated. In fact, it is one of the defining features that distinguish us from other mammals.\nSpearheading the effort to mimic human dexterity in robots is Andrew Morgan, a PhD student working in Professor of Mechanical Engineering and Materials Science and Computer Science Aaron Dollar\u2019s lab\u2014the GRAB lab. Morgan described modern advancements in various areas of robotics, including computer vision and locomotion, but emphasized the decades-long challenges facing in-hand object manipulation, especially with the inherent uncertainty in any environment.\nIn their study, Morgan and his team developed an algorithm that enabled a four-fingered robotic hand to manipulate objects using a \u2018finger gaiting\u2019 process. \u201cFinger gaiting is getting each finger to independently remove its contact from an object, move to a new location, then re-establish contact there, considering the timing of each event,\u201d Morgan said. Furthermore, their programs could be applied to objects of diverse geometries, from simple cubes to complex concave objects. Being able to manipulate, re-grasp, and reposition objects is the key to performing tasks with the same flexibility as a human hand.\nThe implications of Morgan\u2019s study are far-reaching. \u201cBeing able to mimic human dexterity will allow us to create human-like robots that can work in service settings [\u2026] such as folding laundry and washing dishes for elderly communities, and even for search-and-rescue missions,\u201d Morgan said. Ultimately, Morgan and the GRAB Lab are on the path to developing robots that go beyond fixed roles like factory assembly lines, instead making them familiar with environmental uncertainties so they can serve more general and meaningful purposes.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/robots-youve-gotta-hand-it-to-them/",
            "captions": [
                "The Dollar Lab\u2019s robotic hand manipulates and reorients a toy rabbit."
            ]
        },
        {
            "title": "Long-Acting Formulations of Synergistic HIV-1 Drugs",
            "author": "Sydney Hirsch",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Hirsch_Figure1-1-500x337.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of NIAID. \nWhile the world faces the novel SARS-CoV-2 virus, another pandemic continues to afflict nearly forty million people worldwide: human immunodeficiency virus (HIV), the cause of acquired immunodeficiency syndrome (AIDS). Though incurable, HIV is treatable, and many successful antiretroviral (ARV) therapeutic options exist. However, due to the chronic nature of the illness, treatments must be lifelong, and as a result, many struggle with nonadherence. Long-acting HIV medications have the potential to alleviate the burden of daily dosing, but most approved ARVs are not well-suited for conversion into extended-release formulations due to issues with solubility and toxicity. An interdisciplinary team of Yale researchers, including Professor of Pharmacology and of Molecular Biophysics and Biochemistry Karen Anderson, Sterling Professor of Chemistry William Jorgensen, Associate Professor of Infectious Diseases and of Microbial Pathogenesis Priti Kumar, and Goizueta Foundation Professor of Biomedical Engineering, Chemical and Environmental Engineering and Physiology W. Mark Saltzman, have developed two forms of a synergistic HIV two-drug combination to combat the aforementioned concerns: a biodegradable removable implant and an injection.\nBoth the implant and the injection contain two investigational drugs: a Merck-made nucleoside inhibitor called EFdA and a non-nucleoside inhibitor called Compound I that was previously developed by the Yale team. Both target HIV\u2019s reverse transcriptase enzyme \u2013 an essential protein responsible for replicating the virus\u2019 genome. Thus, inhibiting its activity allows for the suppression of disease manifestation. \u201c[EFdA and Compound I] have different mechanisms, and \u2026 in a structural sense, they\u2019re binding to two different parts of the HIV reverse transcriptase protein,\u201d Anderson said. Kumar also explained that HIV is highly mutable when allowed to replicate. Thus, two inhibitors binding a protein at different positions provide compounded activity resulting in better inhibition of the virus. As a result, viral load is suppressed, and the virus cannot mutate as easily.\nThe injection and the implant demonstrated successful extended-release activity for the duration of the study. Each method offers numerous benefits. Injection provides direct delivery to allow the particles to form deposits in the deep, innermost tissues such as lymph nodes and bone marrow. Here, the drug is delivered in large quantities and can be released for long periods without toxicity. Injections, however, have one key flaw: permanence. For drugs with well-established safety profiles, this factor is a non-issue. For novel compounds, however, or those with a propensity for viral resistance, the implant provides the benefit of removability should toxicity or adverse reactions arise. In addition, the implant itself is both safe and biodegradable.\u00a0\nRegarding future directions for this research, scientists are increasingly interested in developing long-acting modes of drug delivery. \u201cEventually, you want this kind of research going to high-risk areas like in Africa, where it\u2019s difficult to get oral tablets out to the public for daily doses of antiretroviral therapy,\u201d Kumar said. These extended-release therapies have significant implications for conditions other than HIV as well. In the short term, however, further research aims to optimize multiple antiretroviral drug combinations to allow for maximal loading and at least a year-long extended release.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/long-acting-formulations-of-synergistic-hiv-1-drugs/",
            "captions": [
                "The implementation of long-acting antiretroviral therapy, such as the implants and injections developed in this study, would eliminate the need to take daily pills, such as those in the image. This has the potential to improve the common concern of nonadherence in HIV patients."
            ]
        },
        {
            "title": "The Eternal Naked Mole-Rat",
            "author": "Cindy Mei",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Mei_Figure1-1-500x343.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "For millennia, the pursuit of eternal youth and immortality has been the quest of adventurers and scientists alike, whether through the search for the fabled fountain of youth or the elusive recipe for the elixir of life. Unfortunately, these efforts have had limited success. Instead, as mutations accumulate within DNA over time, we are condemned to the inevitable reality of aging and the increased risk of death and maladies.\u00a0\u00a0\nNot for the naked mole rat, though. In the burrows of East Africa, these pink and wrinkled rodents (nicknamed NMRs) thrive within eusocial colonies of workers and queens, outliving their life expectancy based on body mass by over five times. Demographically, the NMR is non-aging, meaning that its risk of dying doesn\u2019t increase as it ages, and cancer is a rare occurrence in the species.\u00a0\u00a0\u00a0\nQuantifying aging in mammals has been explored via epigenetic clocks, which measure DNA methylation in CpG sites, regions where methylation is most common, as a marker for epigenetic age. In a Nature Communications paper published earlier this year, researchers in Vadim Gladyshev\u2019s lab at the Harvard Medical School analyzed three million common CpG sites in 107 NMRs to investigate if and how the NMR ages epigenetically.\u00a0\nThe sequencing libraries used to analyze CpG sites were designed by Yale researcher Margarita Meer, who first studied NMRs in Gladyshev\u2019s lab and began developing the NMR epigenetic clock. \u201cWe weren\u2019t sure whether it\u2019d be possible to see the same kind of epigenetic aging [in NMRs] that we see in other mammals. Now we and two independent research groups led by Steve Horvath and Robert Lowe showed that yes, you can construct this epigenetic clock,\u201d Meer said.\u00a0\nCsaba Kerepesi, a PhD research fellow at the Institute for Computer Science and Control, completed the project. Kerepesi found a gradual age-related increase in DNA methylation entropy, i.e., randomness, and the NMR clock correlated well with chronological age, revealing evidence of epigenetic aging in NMRs. The clock also showed decelerated aging in older queens, a finding consistent with analyses by array-based DNA methylation clocks.\nAnalysis of the twenty-six CpG clock sites found that genes associated with these sites are linked to aging, such as the aging gene Tert and the DNA repair gene Prpf19, a possible explanation for NMRs\u2019 resistance to disease and aging. For Kerepesi, making discoveries from a gene-level analysis was extremely rewarding. \u201cI felt very special that I could see this special animal\u2019s epigenome. So what\u2019s in that? What\u2019s the secret of the long life of this animal, and possible non-aging?\u201d Kerepesi said.\u00a0\nWith current research focusing on rejuvenating cells and reversing epigenetic age with stem cells, understanding the NMR epigenome has immense potential in developing medicine. \u201cWe want our cells not just to live but also to be younger, which also includes having younger epigenomes,\u201d Meer said. Kerepesi echoed the far-reaching implications of this work. \u201cIf we can learn something from a non-aging animal, maybe we can live longer. If you solve the problem of aging, you can solve and defeat all of the aging-related diseases and even most cancers.\u201d\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/the-eternal-naked-mole-rat/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Earth\u2019s Nearest Black Hole Turns out to be a Rare Binary System",
            "author": "Crystal Liu",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Liu_Figure1-1-500x313.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of European Southern Observatory/L. Cal\u00e7ada.\nWhere is Earth\u2019s nearest black hole? Scientists thought they knew the answer\u2014a celestial object called HR 6819, 1120 light years from the sun. However, a recent study in Astronomy & Astrophysics refuted this hypothesis with higher-resolution observations and mathematical models, yielding findings that are nevertheless just as exciting.\u00a0\nIn 2020, Thomas Rivinius and colleagues at the European Southern Observatory (ESO) claimed that HR 6819 was a triple system with a black hole, a closely orbiting star, and another star orbiting farther from the center. According to this model, HR 6819 would include the closest black hole to Earth.\u00a0\nIt was reasonable for the Rivinius team to come to this conclusion. Astronomers classify stars into O, B, A, F, G, K, or M classes, a sequence of decreasing mass and temperature. Stars in different classes yield different spectra of electromagnetic radiation, a characteristic widely used to study celestial objects. A binary system with two typical B stars wouldn\u2019t produce the spectrum that was observed. \u201cLooking at the motion of the [spectral emission] lines, they thought that there was an unseen companion in the system,\u201d said Abigail Frost, a postdoctoral researcher at KU Leuven in Belgium and the first author of this newly published study.\u00a0\nFrost and colleagues, however, recalled another system, LB1, which was initially thought to contain a black hole but turned out to be a rare binary system with a stripped B star and a B emission star (Be star). One hypothesis for its formation starts with a binary system of two B stars. Stars expand over time, and the more massive a star is, the faster it expands. At some point, the larger star in the system, the primary star, gets so big that the secondary star strips away some of its mass. The primary star is left with only its core, a stripped B star, and the secondary star becomes a Be star. \u201c[A Be star] spins so fast that at the equator, the centrifugal force due to rotation is equal to gravity, so the star flattens, creating a disc,\u201d said Hugues Sana, an associate professor at KU Leuven and senior author of the paper.\u00a0\nThe two models for HR 6819 predict the stars to have different angular separations. In the triple system, the B star is close to the black hole, but the Be star is on a wider orbit, while the binary system predicts that the stars are close to each other. Existent observations were insufficient to distinguish between these two scenarios, so the Sana team and the Rivinius team decided to collaborate to collect more data.\u00a0\nThe two teams used the Very Large Telescope (VLT), a four-unit telescope facility operated by the ESO, allowing for more highly resolved measurements. With the new data, Frost and colleagues determined that there were only two bright sources at small separations in the region and identified the disc indicative of Be stars.\u00a0\nDirect observations of binary systems briefly after mass transfer are scarce, so this finding provides precious evidence that Be stars can form through such interactions. This story is yet another illustration of scientific knowledge not as a collection of facts set in stone but as a rapidly evolving understanding of our world as new information comes to light.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/stepping-into-the-light-earths-nearest-black-hole-turns-out-to-be-a-rare-binary-system/",
            "captions": [
                "New research using data from ESO\u2019s Very Large Telescope and Very Large Telescope Interferometer has revealed that HR 6819, previously believed to be a triple system with a black hole, is in fact a system of two stars with no black hole. The scientists, a KU Leuven-ESO team, believe they have observed this binary system in a brief moment after one of the stars sucked the atmosphere off its companion, a phenomenon often referred to as \u201cstellar vampirism\u201d. This artist\u2019s impression shows what the system might look like; it\u2019s composed of an oblate star with a disc around it (a Be \u201cvampire\u201d star; foreground) and B-type star that has been stripped of its atmosphere (background)."
            ]
        },
        {
            "title": "The Theft of 800 Million IQ Points",
            "author": "Lucy Zha",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Zha_Lead_Image-500x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nAfter a night of pouring rain and howling winds, when you open your window and take a deep breath of crisp morning air, does it occur to you that the air could contain tiny lead particles?\u00a0\nUnfortunately, the air from the 1960s to 1980s surely contained alarming concentrations of lead. Due to the rampant use of lead in gasoline, pipes, and paints, which leaked lead into airways, water, and soil, the average blood\u2013lead level (BLL) for the general US population was three to five times higher than the level that posed a clinical concern. Because of this, millions of American adults today were exposed to dangerous levels of lead in childhood.\u00a0\nWhile reading the book What the Eyes Don\u2019t See, which describes the shocking tragedy of the Flint Water Crisis, Sociologist Michael McFarland recalled seeing a graph illustrating how much lead was added to gasoline in the U.S. over time. Previous literature had already established the negative health consequences of heavy metal pollution, such as cardiovascular diseases and loss of cognitive functions. McFarland was startled by the sheer number of people that were exposed to adverse lead levels in childhood. \u201cHow are we not talking about this? How is this not taught in the curriculum of population health?\u201d he said.\nHigh blood levels of lead can pose serious consequences to one\u2019s quality of life and society as a whole. Studies have shown that lead can disrupt healthy organ development, negatively impacting a person\u2019s cognitive ability, fine motor skills, and emotional regulation. The researchers of this study estimated that high lead exposures had already cost a total of 824,097,690 million IQ points to be lost among populations in 2015. Significant IQ loss can broadly impact economic development, criminal behavior, social mobility, psychopathology, and more. On an individual level, even small deficits in achieved IQ can impact one\u2019s educational and occupational attainment, health, wealth, and happiness.\u00a0\nTo provide a better estimate of the scope of the lead contamination problem, McFarland and his colleagues predicted the blood lead levels of American populations based on data from the U.S. Bureau of Mines, which recorded the yearly consumption of lead-based gasoline from 1933 to 1993. Alarmingly, the researchers found that more than half of Americans had childhood BLL above the threshold that caused clinical concern in 2015, sometimes 3 to 5 times more. The cohort with the highest childhood BLL consisted of middle-aged adults born in the 1950s to 1980s. Levels gradually decreased among the younger and older cohorts. This finding corresponds with the boom in gasoline use in the 60s to 80s, which led to massive lead contamination.\u00a0\nBy quantitatively calculating the demographic estimates of lead exposure and cognitive deficits among U.S. populations in this study, the researchers highlighted the scope and importance of lead contamination. This issue, however, did not stay in the past. Although younger populations born after the 1980s experienced much lower lead exposure, their BLLs are still much higher than their pre-industrial counterparts. Therefore,\u00a0 researchers concluded that future research into the impact of lead contamination is critical, for there are still many unknowns for this urgent yet latent public health crisis.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/the-theft-of-800-million-iq-points/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Breaking New Ground in Geological Sciences: How Earthquakes Stop",
            "author": "Maya Khurana",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Khurana-earthquake-pic-1.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\u00a0\nEarthquakes are common and sometimes deadly occurrences that can have catastrophic consequences on humans and the environment alike. However, despite their prevalence, the mechanics of earthquakes remain largely unknown. Chun-Yu Ke, who received a Ph.D. in Civil and Environmental Engineering from Cornell University, and his colleagues are interested in developing more accurate earthquake models to better understand how earthquakes stop. Using a dynamic numeric model of a two-dimensional planar fault embedded in a three-dimensional, uniform elastic medium, these researchers could study key seismological quantities and examine how they behave in earthquake arrest.\u00a0\nEarthquakes occur when energy within the Earth\u2019s crust is released and radiates seismic waves, fractures, and heat into the surrounding land. These quakes continue radiating energy and causing fault slips until there is no more available energy for the rock on either side of a fault to continue to move. Ke and his colleagues investigated one particular seismological quantity in earthquake mechanics: breakdown energy. The breakdown energy is the estimated amount of energy dissipated by fault weakening averaged over the rupture area, and it scales approximately linearly with the average fault displacement of the earthquake. Historically, breakdown energy has been regarded as a proxy for fracture energy, the amount of energy it takes to break a particular unit of the surface into entirely separate parts. Researchers previously believed that larger earthquakes, which involve more breakdown energy, also involved more energy in breaking apart units of surface area\u2014that is, bigger earthquakes were thought to have bigger fracture energies.\u00a0\nBut Ke\u2019s research turns this idea on its head. When it comes to fracture energy, it is more important to focus on the type of rock being fractured than the amount of energy being applied to the rock. Certain types of rock will require larger fracture energy to break while others will require less\u2014this should not be ubiquitously affected by the magnitude of the earthquake. \u201cWhen the earthquake hits the rock, the rock doesn\u2019t know how big that earthquake is,\u201d Ke said. \u201cSo it shouldn\u2019t be harder or easier to [break] because it\u2019s the same rock.\u201d Indeed, Ke\u2019s findings back this claim. Using a dynamic model, Ke and his colleagues demonstrated that while breakdown energy scales with the size of the earthquake, the fracture energy remains constant throughout. Thus, the amount of energy it takes to break down the rock on the outer rim of an earthquake could be the same regardless of the earthquake\u2019s magnitude. This research suggests that it is time to rethink current seismological models of earthquakes to match this new evidence.\u00a0\nThough Ke\u2019s research lies within somewhat complicated geological processes, it has significant implications for everyone. Ke explains that these mathematical models can ultimately help produce an algorithm that can predict earthquakes. \u201cThe definition of an earthquake [prediction] is that you have to determine the time, the location, and the magnitude of an earthquake,\u201d Ke said, \u201cand nobody has ever done that.\u201d Now that the mechanical behaviors and physical properties of earthquakes are becoming better understood with the help of computational models and technologies, the ability to predict earthquakes is within sight. \u201cMaybe one day we can forecast earthquakes like people forecast weather,\u201d Ke said. As earthquake models become more refined with the research of Ke and his colleagues, that hope may become a reality.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/breaking-new-ground-in-geological-sciences-how-earthquakes-stop/",
            "captions": [
                "This image depicts the epicenter of an earthquake on a map of Jakarta."
            ]
        },
        {
            "title": "A New Tool to Predict COVID-19 Outcomes",
            "author": "Abigail Jolteus",
            "authorLogo": "",
            "date": "September 3, 2022",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Jolteus_Covid-500x243.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nWhat if an algorithm was capable of predicting disease outcomes? A team of researchers at Yale, including MD/Ph.D. student Manik Kuchroo and Associate Professor of Genetics and Computer Science Smita Krishnaswamy, devised a new visualization tool called Multiscale PHATE. The tool accurately predicted mortality outcomes from fifty-four million blood cells harvested from 163 hospitalized patients with severe COVID-19.\u00a0\u00a0\nMultiscale PHATE creates abstracted cellular features from datasets to produce visualizations at different scales. There are so many different features and cells that a researcher can analyze, which is why dimensionality reduction\u2014the process by which the number of input variables in a data set is reduced\u2014is important. \u201cDimensionality reduction condenses the variability in the overall data set down to two to three dimensions, essentially creating a scatter plot of the data,\u201d said Kuchroo. The position of the cells in the scatter plot details how similar or different they are. This allows researchers to identify what immune cell types and subsets are present in a sample, and can help predict outcomes.\u00a0\nCurrently, there are other tools, such as t-distributed stochastic neighborhood embedding (tSNE), uniform manifold approximation and projection (UMAP), and principal component analysis (PCA), that also perform dimensionality reduction. However, Multiscale PHATE is a more effective way of learning cell relationships in massive datasets. \u201cThis computational tool is a better way to approach your analysis if you have massive data sets because it is scalable and can yield interesting insights across scales,\u201d said Kuchroo.\nMultiscale PHATE was showcased on blood samples from patients infected with the novel coronavirus, SARS-CoV-2, measured across different flow cytometry panels. Flow cytometry analyzes the proteins found in cells, and the panels display the results of this analysis.\u00a0\nWhen the cellular responses to infection with SARS-CoV-2 were analyzed, comparing those of patients that died to those of patients that survived hospitalization, researchers discovered that while immune cells such as T cells are broadly protective against infection, some subsets are not. An enriched T cell type was a subset of Th17 called IFN\u03b3+ GranzymeB+ Th17 cells, which suggests that the Th17 cell subset could be pathogenic, or disease-inducing.\u00a0\nMultiscale PHATE creates cellular groupings, summarizing which cell types and subsets are elevated in patients with adverse outcomes. This enabled the researchers to predict the COVID outcomes of patients and discover that older males were more vulnerable to poor outcomes. While these results help understand the pathogenesis of COVID-19, they also demonstrated the effectiveness of Multiscale PHATE. \u201cThis was to show that the features and cellular subgroups we picked out were meaningful,\u201d said Krishnaswamy.\u00a0\nWith an increasing number of datasets integrated from patient samples, Multiscale PHATE could become a crucial method in uncovering the biological meaning of datasets from a myriad of diseases. Further studies may find it beneficial to use Multiscale PHATE to analyze data sets and predict disease outcomes, providing pivotal information to aid patients afflicted by these diseases.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2022/09/a-new-tool-to-predict-covid-19-outcomes/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Electronic Skin",
            "author": "Risha Chakraborty",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/charlotteelectronicskin-Charlotte-Leakey-1-372x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Charlotte Leakey.\nOur world is being increasingly defined by a series of ones and zeroes. From the smallest phone gyroscope capable of detecting body movement to metal detectors at the airport to automatic PCR machines that test for the SARS-COV-2 virus in a matter of hours, the technology that acquires and transmits this data has made human lives much easier. Over the last two decades, practical artificial intelligence (AI) usage has led to expanding roles for computers in detecting danger, predicting scores, and advising outcomes in fields ranging from security to medicine\u2014often beyond the scope of its original creation and with limited human intervention. Of course, popular debate and science fiction warns about how AI may eventually replace humans across many fields and make human effort obsolete. However, Wei Gao, a professor of Medical Engineering at the California Institute of Technology, sees the advancement of AI as an opportunity rather than a threat.\u00a0\nGao received his bachelor\u2019s degree in mechanical engineering and his master\u2019s degree in chemical engineering at the University of California, San Diego. He completed a postdoctoral fellowship in electrical engineering at the University of California, Berkeley. Because of his diverse educational background, he pursued the creation of robots imbued with functionalities beyond traditional ones. \u201cIn our minds, robots are industrial-level, capable of doing dangerous tasks in agriculture, defense, and space exploration because they can move and perform repetitive tasks, but we are thinking about the future. How can we build a better robot [by giving it] better functionalities and making it smarter? How can we give it more powerful sensing capabilities?\u201d Gao pondered.\u00a0\nInspired by human skin\u2019s ability to detect temperature, touch, texture, and even certain chemicals, for example, an allergic skin response after rolling around in the grass, Gao set out to develop \u2018electronic skin.\u2019 In the past, researchers have developed robots to detect and respond to physical parameters such as temperature and pressure. However, they were unwieldy and impractical\u2014not much more than a thermometer on a remote-controllable stick. Moreover, Gao wanted to diversify the sensors in his robot so that the electronic skin could have an even greater range of sensory capabilities than human skin. In particular, he hoped to detect infectious pathogens for medical applications, neurotoxins or bomb debris for security purposes, and chemical pesticides for agricultural uses\u2014all harmful or dangerous for humans to handle.\nThe main problem was designing a method to make electronic skin emulate human skin. Scientists are only beginning to understand how human \u2018sensors\u2019 such as mechanoreceptors and thermoreceptors work. In fact, the 2020 Nobel Prize in Medicine and Physiology was awarded to two scientists for discovering the neural mechanisms behind human sensations. What would be the technological equivalent of millions of nerve endings in human skin conferring incredible sensitivity and a wide range of detecting abilities, and how could such a system be built in a reproducible, scalable way?\u00a0\nWith the help of colleagues with expertise in materials science and nano-engineering, Gao developed electronic skin, which he called E-skin-H. \u201cMy primary inspiration comes from human skin,\u201d Gao said. Touch and pressure cause electrical changes that can then be converted to computer signals. To mimic the vast nerve network of human skin, Gao created sensor arrays with microscopic radii of detection, increasing both the sensitivity and strength of a signal compared to using a single large sensor. These properties are helpful in complex applications like detecting the presence of a specific chemical out of a large mixture.\u00a0\nEmbedding such minuscule sensor arrays in a highly flexible matrix is a technically easier way to create a bridge between sensors and robots than integrating the existing large chemical sensors meant for analysis of dry particles on robots. The flexibility of the sensor array material enables E-skin-H to retain its sensing capabilities regardless of how the actual robotic hand or arm on which it is mounted moves. Moreover, by using a hydrogel underneath the e-skin interface, the robotic skin can test for chemicals like they are in solution even though the sensor array is technically in a solid state. For example, biochemical tests like ELISAs can detect specific proteins, like those marking the surfaces of a SARS-COV-2 virus, in a solution. But now, with the hydrogel, the sensor array can detect proteins from a solid surface. Perhaps the most brilliant facet of Gao\u2019s e-skin is that it can be printed with an inkjet printer. It requires only a series of nano-material metal inks such as gold, silver, and platinum to decorate graphene electrodes and a 3D-hydrogel printer. The ease of production vastly increases the scalability, adaptability, and replaceability of the sensor arrays. It also decreases production costs, allowing for the creation of larger sensor arrays that can be modified to test for various new compounds.\u00a0\nIn his article published in Science Robotics, Gao built a robot called M-bot, which used machine learning to learn how human muscles, specifically hand and arm muscles, move in response to detecting certain tactile or chemical threats. Gao evaluated E-skin-H to see how the skin\u2019s sensing capabilities could assist robots in making AI-based decisions the same way a human would. He concluded that M-bot could be used to detect compounds in a contaminated environment and track the source of trace amounts of hazardous compounds. In an early demonstration, M-bot tracked a nerve agent leak in an open field by detecting a gradient of the compound across the sensor array. By tracking the location of the highest concentration of the compound, the AI algorithm within M-bot was able to signal to the motors within the robot arms and fingers to extend towards the location of the highest concentration to grasp objects and collect samples. \u201cIt was pretty impressive since it was fully automatic,\u201d Gao said.\u00a0\nGao sees E-skin-H being used in medical and defense applications within the next five to ten years. \u201cYou don\u2019t want to send a human into a danger zone to detect explosives or biohazards. Electronic skin can be used in military, environmental, and agricultural applications. We just have to make the robots [that use e-skin] smarter and more automatic\u2014with the help of materials science, chemistry, and data processing.\u201d Gao said.\u00a0\nWith the foreseeable future wrought by AI applications and robotic sensing technologies, Gao encourages anyone interested in robotics and technology to nurture this interest by identifying a problem, understanding where there is a gap in current technologies that attempt to address this problem, and imagining potential solutions. \u201cBecoming involved in engineering or robotics is not a problem about technology, but more about developing a pattern of thinking. Trying competitions like FIRST Lego League and VEX Robotics inspires young students to imagine the fullest potential of robots,\u201d Gao said. With this principle in mind, Gao combines chemical, medical, electrical, and mechanical principles to create solutions to the problems that fascinate him. As he expands his projects, from robots that use electronic skin in defense applications to nano-robots that deliver drugs to cells in the body, Gao is convinced of their increasing necessity in the future. \u201cI\u2019m excited to see how we interact with robots in our daily lives going forward,\u201d Gao concluded.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/electronic-skin/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Paper Power",
            "author": "Cindy Mei",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Paper_Power2-Luna-Aguilar-500x387.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Luna Aguilar.\nWith great power comes great responsibility. In an age where the world has become increasingly reliant on technology, the threat of electronic waste or e-waste\u2014including many discarded products containing batteries\u2014has become increasingly dire. In 2019 alone, an estimated 48.6 million tons of e-waste was generated worldwide, a rapidly expanding issue that has only continued to grow. Because standard lithium batteries contain non-biodegradable and often toxic rare earth metals, the accumulation of e-waste releases harmful chemicals that can contaminate groundwater and the air, putting the environment and the health of billions at risk.\u00a0\nThe quest for green power seeks to eliminate the threat of e-waste by harnessing sustainable materials. This pursuit fascinated Gustav Nystr\u00f6m, head of cellulose & wood materials at the Swiss Federal Laboratories for Materials Science and Technology. By harnessing natural, environmentally-friendly materials, researchers in Nystr\u00f6m\u2019s lab were able to power the crystal display of a LED alarm clock using a disposable paper battery activated by just two drops of water.\u00a0\nThe project, which also involved postdoctoral researcher Alexandre Poulin and doctoral researcher Xavier Aeby, sought to search for an environmentally-friendly battery high in density, important for a longer run time, that would be suitable for single-use devices such as sensors. \u201cFor instance, in biomedical industries, where many diagnostic tests are discarded after a single use due to hygienic and ethical reasons, there is a lot of plastic waste being generated,\u201d Nystr\u00f6m said.\nAn electrochemical battery stores and discharges energy through a series of oxidation and reduction reactions that occur at the anode and cathode, respectively. In addition to these components, a separator prevents the electrodes from coming in contact and short-circuiting, while the electrolyte facilitates the movement of ions between the anode and cathode. In battery fabrication, the material choice for these components is especially important for optimized, reliable function. \u201cWe made a strict selection based on what we thought were the most promising materials in terms of energy density and stability for this development,\u201d Nystr\u00f6m said. \u201cIt\u2019s about choosing the right type of materials that are not harmful to our environment. That\u2019s a big and important goal for us.\u201d\nThe ideal material is stable and highly conductive, with low contact resistance, high energy storage capacity, and a fast charging rate. After testing many combinations, the final design used a zinc anode, a graphite carbon air cathode, a paper separator, and a water-based salt electrolyte. The electrodes were stenciled onto the paper using multi-material inks that contained a mixture of ethanol, shellac, and sodium chloride ions which are required to form the conductivity needed in the battery for electron flow. The dry batteries can then be stored indefinitely until water is added, which permeates the paper membrane, dissolving the salt ions and activating the battery within twenty seconds.\u00a0\nThe battery inks were characterized by shear thinning behavior and yield stress, physical factors important in additive manufacturing. This method adds components by layering them and has great advantages in reducing manufacturing waste. \u201c[Our goal is] also being responsible with the amount of material used,\u201d Nystr\u00f6m said. \u201cWhen you manufacture, you only need to use exactly the amount of multi-material inks that you need for those different components.\u201d\nThe researchers also performed electrochemical tests on the battery. A single cell demonstrated a 1.2 V potential, which is proportional to the energy delivered to the cells. Power capability was measured to reach 150 \u03bcW, enough to power an alarm\u2019s LCD crystal display, hearing aids, and electronic watch calculators. With more printed batteries added in series, the voltage increases, accommodating devices with greater power usage. After one hour of operation, the voltage decreased as the paper substrate dried. However, upon the readdition of water, the performance was recovered, allowing for extended battery life by increasing how much water the paper could hold.\nIn the future, the researchers hope to study the length of battery life following rehydration of the battery and explore further implementations of organic materials. Nystr\u00f6m believes that it has the potential to play a valuable part in the reduction of e-waste in powering single-use diagnostic tests and sensors, but there is still much work to be done. \u201cWe have had a lot of academic developments, and now is really the time to see what and how much can be transferred into real products,\u201d Nystr\u00f6m said. \u201cI think [paper] is quite a promising material, but we need to see what is feasible and where the best applications will be.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/paper-power/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The World in Proteins",
            "author": "Krishna Dasari",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/biodiversity-500x281.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Malia Kuo.\nInto the world of proteins\nYou, me, a worm, and a cow. What makes us different? Shape, size, personality, and innumerable other characteristics create visible differences, of course\u2013\u2013but all of that is ultimately founded on the invisible world of proteins.\u00a0\nProteins are the microscopic tools of life, each one serving a specific function related to communication, catalysis, structure, storage, and every other aspect of cellular business. By interacting with other proteins and biological molecules, proteins generate all of life\u2019s characterizing features: birth, death, cognition, and reproduction, just to name a few.\u00a0\nWe can imagine understanding an organism as a composite of its protein inventory. Almost all of its characteristics and behaviors depend on the type, number, and activity of its proteins. In fact, although we often think about evolution solely in terms of DNA mutations creating new characteristics, that relationship between DNA and tangible features depends entirely on proteins, meaning proteins play a crucial role as mediators of evolution.\nA serendipitous encounter\nPropelled by a protein-focused perspective, Yansheng Liu found himself watching Gunter Wagner\u2019s presentation on the curious case of cow cancer at a seminar on Yale\u2019s West Campus. Wagner, an evolutionary biologist, was interested in understanding cancer by comparing it between species. To understand why cows are less prone to cancer than humans, Wagner had been studying their gene expression\u2014an indirect measure of protein levels\u2014to draw connections between changes in expression and resistance to cancer.\nGene expression can be used to approximate protein levels because of the \u201ccentral dogma\u201d of molecular biology: a single sequence of DNA, the primary set of instructions, is transcribed into many copies of RNA, the same instructions in a slightly different language. The RNA is then read and used to build proteins\u2014the final, functional product. Measuring gene expression normally means measuring RNA levels, and it had long been conveniently assumed that protein levels were proportional to RNA levels due to the central dogma.\nBut this is not always the case. Protein levels don\u2019t always follow RNA levels, and Wagner was well aware of the long-standing debate about how well RNA and protein levels correlate. He knew the value of measuring protein levels themselves. However, at the time, there was no practical method to quantify protein levels across the whole collection of proteins in a cell. This lack of technology forced him and almost everyone else in the field to rely on RNA-based gene expression to approximate protein levels.\nThis is where Liu comes in. As a proteomicist or someone who studies the world of proteins, he, like Wagner, had a keen interest in the biodiversity of proteins. \u201cI was so inspired by Gunter\u2019s talk,\u201d Liu said. \u201cHe\u2019s using this very different angle to compare species to get a clue about human beings\u2026and I quickly related [it] to some of my previous work about the diversity between human individuals and suggested that we could\u2026cover different species [with proteomics].\u201d\nLiu wanted to go further than gene expression. Rather than approximate protein levels with gene expression, why not study biodiversity at the protein level itself? And for the first time, he brought the technology to answer this question. He had been part of a team building a tool to measure protein levels called DIA-MS, a variant of standard mass spectrometry that offers advantages in reproducibility and accuracy. With this method, he brought the tools and the experience to explore a new frontier with Wagner: investigating biodiversity not with approximations of protein levels but with direct measurements.\nWhere to go and what to do?\nWhile Wagner\u2019s original presentation focused on cancer, the two saw value in expanding their scope to perform an initial survey of protein-centric biodiversity across mammals. With the powerful ability to quantify complete protein profiles across species, Liu and Wagner were now faced with the difficult task of choosing what questions to ask.\nTo both, it was clear that they must provide an answer to the fundamental debate: how well does RNA-based gene expression correlate with protein levels? They could test the validity of an assumption that the field had been relying on for decades, now in multiple species.\nBeyond this highly practical aspect of the RNA-protein relationship, they also wanted to investigate the evolutionary history of the RNA and protein profiles. Could these two intimately intertwined yet distinct bodies evolve together across the tree of life? Or do intervening mechanisms disrupt the tethers between the two, separating the evolution of RNA levels from protein levels? We know of many possible sources of disruption, such as those that affect RNA stability or modify or degrade protein independently of RNA levels. Even further, we must consider the most significant difference between proteins and their nucleic acid cousins, DNA and RNA: proteins are the final, functional product! They\u2019re made to interact with molecules or other proteins; can these interactions selectively constrain or accelerate only protein evolution and not RNA?\nConsistent with their interest in protein biodiversity, the researchers were also curious about how their answers to these previous questions might vary between different species and individuals of the same species. Liu had previously revealed significant variability in the protein profiles of different humans, and they now had the chance to extend this work across species.\nFinally, they considered what unique insight they could gain from proteins as opposed to DNA or RNA. Liu expressed interest in phosphorylation sites\u2014spots on proteins that can bind or release phosphate molecules to activate or deactivate the protein. These sites are responsible for complex signaling pathways that regulate everything from cell growth and death to movement and secretion, so they receive much attention for understanding cell regulation or designing protein-inhibiting drugs. Liu and Wagner now had the rare opportunity to catalog the biodiversity of phosphorylation sites based on actual proteins rather than DNA or RNA.\nFrom fundamental questions of molecular biology to structural biochemistry to evolution, the new technologies and the unexpected collaboration between an evolutionary biologist and proteomicist thrust a new probe into previously murky waters of biology. With so much inbuilt potential, they had no reason to constrain themselves to one field of questions. \u201cYou have to use your biological intuition to understand what nature is trying to tell us here, and that\u2019s fundamentally a creative process,\u201d Wagner said. The world of proteins had much to tell about every field of biology, and Liu and Wagner were there to listen.\nDiscoveries from the protein world\nFrom their venture, the team recorded an invaluable dataset of protein diversity amongst mammals. With this in hand, we can finally understand what differentiates you and me from cows on the protein level, with applications to tracking our evolutionary histories or informing medical research. They also used this data to determine that RNA and protein levels are moderately well correlated, though far from perfect. The good news is that the correlation does not invalidate decades of prior gene expression work, but it still sheds light on the importance of going directly to the source: proteins.\nFurther, they discovered correspondence between variability in RNA and protein levels, suggesting that despite the many possible disruptions, RNA and protein levels do tend to coevolve. The tethers between these two spheres of molecular biology overall remain strong, though the exact relationship is protein-function-dependent.\nFor example, some classes of proteins\u2014such as those involved in protein degradation\u2014show little variation in both RNA levels and protein levels, while other classes\u2014such as those filling the extracellular region\u2014feature high variation in both, contributing to increased evolvability. However, certain proteins defy this trend. Proteins involved in large protein complexes feature less protein variability than RNA variability because intimate dependence on other proteins pressures individual proteins to be less variable.\nOverall, protein profiles were slightly more variable than their RNA counterparts, suggesting that evolution can occur on the scale of proteins rather than solely on DNA/RNA. Furthermore, Liu and Wagner discovered more variability amongst phosphorylation sites relative to protein profiles. This variability may reflect the evolutionary value of tightly regulating protein activity or of generating new cell signaling possibilities. The team also constructed a network of coevolution amongst phosphorylation sites, providing insight into the complex interactions between signaling pathways.\nFinally, Liu and Wagner established that variability in protein profiles between species mirrors variability within species. In other words, if levels of a protein are highly variable between humans, they are also likely to be variable between humans and other species.\nReturning home\nWe have learned much about the protein world, but what do these results mean for biology on a broader scale? For one, they tell us that we can reasonably trust gene expression while still acknowledging that protein levels are more variable because of their functional role. The data also reveals significant diversity in protein profiles not only between species but between individuals as well. And most importantly, Liu and Wagner have opened doors for an incredible array of studies. Evolution can now be interpreted not just from scars in the genome but by studying the proteins themselves\u2014the tools that perform the tasks that evolution evaluates. Biodiversity, disease, and cell biology can all be approached from a more protein-function-centric perspective. In essence, a new method of understanding biology awaits us.\nPondering the future of the field, Wagner concluded, \u201cIt\u2019s still very difficult. It\u2019s pioneering, but it\u2019s clear that this is the direction it has to go in the long run.\u201d Trekking through the protein world may remain challenging for years to come, but it promises to light the way toward a pivotal new understanding of diversity and evolution.\nFurther Reading\nBa, Q., Hei, Y., Dighe, A., Li, W., Maziarz, J., Pak, I., Wang, S., Wagner, G. P., & Liu, Y. (2022). Proteotype coevolution and quantitative diversity across 11 mammalian species. Science Advances, 8(36). https://doi.org/10.1126/sciadv.abn0756\nWagner, G. (2019, November 25). Can Cows Teach us how to beat Cancer Malignancy? Nature Ecology and Evolution. Retrieved October 12, 2022, from https://ecoevocommunity.nature.com/posts/56631-can-cows-can-teach-us-how-to-beat-cancer-malignancy\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/the-world-in-proteins/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Turning the Knots in Resonators",
            "author": "Yusuf Rasheed",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/charlotteresonance-Charlotte-Leakey-1-372x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Charlotte Leakey.\nWhat do piano strings, air particles, and colliding comets have in common? Each of them is an oscillator, broadly defining anything that can vibrate. Oscillators are ubiquitous\u2014they can be electrical, mechanical, optical, and astronomical, varying from smaller than an atom to larger than a planet.\u00a0\nEvery oscillator has a discrete set of frequencies at which it naturally vibrates. These are known as its resonance frequencies or eigenfrequencies, collectively known as the object\u2019s spectrum. You may have encountered these in physics class in the form of standing waves, which are the various waves that naturally \u201cfit\u201d into a given object. For a very simple object like a guitar string, these are just sine waves, which \u201cfit\u201d whenever a half-integer number of their wavelength fits into the length of the string. Each wave will vibrate with its own frequency or eigenfrequency, which can be changed by adjusting anything that affects the system. In the case of a guitar, factors such as the tension of guitar strings, the type of wood, and the temperature of the environment can be used to tune its spectrum.\nPhysicists know that any oscillator\u2019s resonance frequencies are always given by the roots of a polynomial equation. When the oscillator is free from friction, all of the roots of this polynomial are real numbers (which is quite reasonable given that frequencies are usually thought of as real numbers). However, when friction is considered in the model, these roots become complex. This means that the root contains an imaginary number i, equivalent to -1. When the model for an oscillator\u2019s resonance frequencies includes friction, it is known as a non-Hermitian system. In contrast, a Hermitian system does not include friction in its model. The complex root takes the form (a + bi), where a is the real part of the root representing the resonance frequency, and b is the decay rate, or how quickly the oscillator stops oscillating. One example is a guitar\u2019s strings coming to rest after being plucked.\nTo visualize the relationship between a system\u2019s parameters and its spectrum of resonance frequencies, it is helpful to use two graphs: one showing the parameters that are being changed and the other showing the system\u2019s resonance frequencies (with each frequency being a point in the complex plane). This pair of two graphs can be seen in the figure below with pairs of plots \u201cc\u201d and \u201cf,\u201d \u201cd\u201d and \u201cg,\u201d or \u201ce\u201d and \u201ch,\u201d where plots \u201cc,\u201d \u201cd,\u201d and \u201ce\u201d are the parameter graphs, and plots \u201cf,\u201d \u201cg,\u201d and \u201ch\u201d are the resonance frequencies graphs. Continuing the example of a guitar, the parameter graph would have the tension in its strings, the type of wood, and the temperature of the environment, while the spectrum graph would have time as its vertical axis, representing how far along the control loop we are, and the complex eigenfrequencies in the horizontal plane. The spectrum graph can be thought of as plotting the complex eigenfrequencies in the horizontal plane and then stacking these planes on top of each other as time passes. When the parameters are gradually changed and then returned to their original values, a loop is formed in the first graph,\u00a0 known as a control loop. This control loop can be seen below in the figure as the green, red, or blue loop in plots \u201cc,\u201d \u201cd,\u201d and \u201ce,\u201d respectively. Such a loop may or may not enclose points corresponding to a choice of parameters that would produce a spectrum in which two or more eigenvalues are equal, known as a degeneracy. These points can be seen below in the figure as the points along the yellow \u201ctrefoil knot\u201d-shaped structure in plots \u201cc,\u201d \u201cd,\u201d and \u201ce.\u201d When the parameters are varied around a control loop, a \u201cbraid\u201d topological structure is created in the spectrum graph. Much like one can braid hair into different styles, these spectral braids also can twist and turn in a variety of ways. The specific braid that is created depends on the manner in which the control loop encloses the degeneracy points. These braids can be seen below in the figure as the triplet of green, red, or blue lines in plots \u201cf,\u201d \u201cg,\u201d and \u201ch,\u201d respectively.\u00a0\nThis relationship between polynomials and their roots was previously well-understood for a system with two oscillators (N=2). The braid would twist once if the control loop encloses a \u201cdegeneracy\u201d\u2013a point in the parameter graph at which two or more resonance frequencies of the system are equal. If the control loop does not enclose a degeneracy, the braid, in turn, does not twist.\u00a0\nThe relationship becomes more complex for a system with three oscillators (N=3). Mathematicians have known for a long time that the degenerate solutions of polynomial equations result in a curve/structure with non-trivial \u2018topology\u2019\u2013the degeneracy curve forms a trefoil knot in the parameter graph for N=3. Topology is the branch of mathematics that deals with the shapes of geometric objects. For example, a donut has a different topology than a sphere, as the former has a hole while the latter does not. This topology had historically been almost exclusively explored in mathematics, not physics. Physicists knew that the braids twisted in various ways, but they did not know why, though they knew it had something to do with degeneracies.\u00a0\nThis project changed that through the combined forces of the Harris Lab and the Read Lab, whose researchers elucidated how this mathematical relationship defines systems with any number of oscillators. In other words, N is arbitrary. In addition, they showed systems with N = 3 already exhibit several striking features that are absent from the N =2 case. Lastly, they demonstrated these features in the measurements of a system with three oscillators. Jack Harris and Nicholas Read are both Professors of Physics and Applied Physics, but Harris is an experimentalist, while Read is a theorist. Read was familiar with the mathematics of degeneracy curves forming a trefoil knot in the parameter graph for N=3 and thus provided the missing piece to Harris\u2019s exploration of how the braids twist. \u201c[Read\u2019s] the one who explained all the math to us. It happened because I had heard about this field and was confused about it\u2026 and I knew that [Read] knew a lot about math. After multiple conversations, we both agreed that this was something really interesting and we should try and pursue it.\u201d Harris said.\nThe groups found that the braiding process was defined by how the control loop encircled the trefoil knot of degeneracies. In the figure from the Nature paper below, graphs \u201cc\u201d, \u201cd\u201d, and \u201ce\u201d show the trefoil knot topological structure and the control loop, which is colored green, red, and blue, respectively. When the control loop doesn\u2019t enclose the trefoil knot, a trivial braid is formed\u2014mathematically, a braid without twists and turns is still a braid, just a trivial one (graph \u201cf\u201d). When the control loop does enclose the trefoil knot, the braiding depends on how many times the control loop encloses the trefoil knot (once in graph \u201cg\u201d and twice in graph \u201ch\u201d). \u201cRelating this topology of the degenerate roots of polynomials to the physics of resonators, and realizing that the twists and turns of the braids [in the spectrum graph] are intimately related by a mathematical correspondence to how the control loop [in the parameter graph] entwines with that topological structure took us some time to develop and appreciate, and then experimentally verify,\u201d Patil said.\nThe researchers have also experimentally confirmed their findings using an optomechanical system of three oscillators (N = 3). The apparatus they used was a radiation pressure system with three lasers that is analogous to a solar sail. Solar sails use large mirrors to reflect photons from the sun while traveling in space\u2014each photon has momentum that it transfers to the solar sail upon impact, resulting in the propulsion of the whole spacecraft. Similarly, the apparatus they used had three lasers with differing powers that were pointed at a vibrating membrane of silicon nitride, allowing the researchers to control the membrane\u2019s stiffness and damping and, thus, its resonance frequencies. Three different colors were also used; red, green, and blue, adding another dimension to the experiment. The researchers empirically saw for this system of N=3 oscillators that the topological structure of degeneracies in the parameter graph is indeed a trefoil knot. They saw that the twists in the experimentally realized braids indeed correlate with how the control loop entwines this trefoil knot.\nIn addition to Professor Harris and Professor Read, both Dr. Yogesh Patil and graduate student Judith H\u00f6ller played key roles in the project\u2019s success. Patil ran the experiments, working with the lasers and oscillators. \u201c[The project] was very demanding in terms of the sheer amount of time and [precision] with how the system needed to be controlled. [Patil] provided two years of solid leadership and guidance through the pandemic. This whole project happened during lockdown because he was able to take [it on].\u201d While Patil was in the lab, H\u00f6ller was a crucial bridge between Harris and Read. \u201cIt was clear from the start that Nick\u2019s elegant story about the math could\u2013in principle\u2013be realized with the equipment in our lab. But making this translation was too complicated at first. It was Judith who made this translation possible. The three of us had many long conversations in which Nick would describe the theory, and then Judith would explain it to me. Then I would describe what we could do with the lasers, and Judith would explain it back to him. She was a key catalyst,\u201d Harris said.\u00a0\nGiven the ubiquity of oscillators, this discovery opens the door to future improvement of\u00a0 any system that contains them, including computers, radios, and watches. Technological advancements in this area no longer need to be limited to systems with only two oscillators.\nSources\nPatil, Y.S.S., H\u00f6ller, J., Henry, P.A. et al. Measuring the knot of non-Hermitian degeneracies and non-commuting braids. Nature 607, 271\u2013275 (2022). https://doi.org/10.1038/s41586-022-04796-w\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/turning-the-knots-in-resonators/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Using Fireflies to Measure HIV Replication",
            "author": "Connie Tian",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Using-Fireflies-to-Count-HIV-Replication-Kara-Tao-1-375x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Kara Tao.\nHave you ever seen a field of fireflies? If you have, you were probably thinking about how magical the experience was. Or maybe you were wondering how these insects somehow evolved the ability to bioluminescence. But chances are you were not thinking about how firefly luminescence would be a great tool for measuring protein-protein interactions.\nThe phenomenon of bioluminescence, which is the biochemical emission of light by living organisms, has fascinated humans for millennia and has been exploited for just as long. Roman naturalist Pliny the Elder wrote that one could create a torch by rubbing the slime of a luminous jellyfish onto a walking stick. In the 17th century, physician Georg Rumphius documented how indigenous peoples of Indonesia used bioluminescent fungi as flashlights in forests. Then, in 1875, Raphel Dubois reported the first in vitro demonstration of bioluminescence.\u00a0\nDubois made two extracts of the bioluminescent clam Pholas, one with hot water and another using cold water. The light in the cold sample eventually disappeared. Furthermore, when he heated the hot sample to near boiling, the glow stopped. But when he mixed those two samples together, he observed light emission once again. Dubois concluded from his observations that a key aspect of bioluminescence comes from a heat-stable organic molecule he named luciferin and an enzyme called luciferase. Today, we understand that luciferase is an enzyme that catalyzes a light-producing reaction in the presence of oxygen and the naturally occurring substrate, luciferin. But scientific interest in the chemistry of the luciferin-luciferase reaction didn\u2019t stop there.\nCurrently, there are dozens of assays that rely on the activity of luciferase enzymes. For example, the split firefly luciferase complementation assay (SLCA) uses bioluminescence to quantify protein-protein interactions within living cells. The assay uses modified firefly luciferase (FFLUC) split into two pieces, named N-FFLUC and C-FFLUC. On their own, the two pieces of FFLUC are inactive and do not luminesce. When the N-FFLUC and C-FFLUC are brought into close proximity in the presence of oxygen, ATP, and magnesium, the FFLUC will oxidize to produce light. This system can be adapted to measure the interactions between any two small proteins by fusing each of the two interacting proteins to the N or C terminus of luciferase. When the two proteins bind and interact, it brings the N-FFLUC and C-FFLUC close together so that FFLUC will luminesce. The luminescence can then be quantified with a machine called a luminometer, which will provide insight into the level of protein interaction.\nRecently, Yale undergraduate Tucker Hansen YC \u201922 and his mentor Richard Sutton developed an SLCA to quantify the Human Immunodeficiency Virus type 1 (HIV-1) Rev-Rev interaction. The assay will identify inhibitors that specifically prevent the Rev-Rev interaction of HIV-1 to stop infections.\nHuman immunodeficiency virus (HIV) is a virus that attacks the body\u2019s immune system. While there are two common subtypes, HIV-1 and HIV-2, most people living with HIV have HIV-1. The virus infects CD4+ T cells, a type of white blood cell also known as helper T cells. These cells help fight infection by triggering the immune system to destroy pathogens in the body. In active CD4+ T cells, infection is caused by the insertion of the viral DNA into the host genome and its subsequent expression into new viral particles. When left untreated, HIV-1 replication causes progressive loss of CD4+ T cells, raising the infected individual\u2019s susceptibility to infectious diseases that would not usually cause illness in a healthy individual.\u00a0\nThere are currently over thirty-eight million people living with HIV-1. Most patients can maintain undetectable viral loads and near-normal life expectancy with the help of antiretroviral medications that inhibit HIV-1 replication. There are currently dozens of FDA-approved medications against HIV-1, including protease, reverse transcriptase, and integrase inhibitors. So why would there be a need for more inhibitors?\nViral suppression through existing medications enables immune recovery and the near elimination of the risk of developing AIDS, the more severe and life-threatening stage of HIV infection. However, due to drug resistance, some patients do not respond to the existing medications well.\u00a0\nHIV-1 drug resistance is caused by changes in the genetic structure of HIV-1 that interfere with the ability of medications to block viral replication. Since RNA viruses such as HIV-1 have an especially high mutation rate that allows for quicker evolution, all retroviral drugs risk becoming ineffective due to the emergence of drug-resistant viral strains. Furthermore, drug resistance can more easily arise if there is poor adherence to prescribed medications. \u201cAs with any chronic disease, there is always a need for improvement in current medications, as well as the development of new antivirals,\u201d Hansen said.\u00a0\nRevving engines\nThe Rev protein is highly conserved in all subtypes of HIV and is necessary for transporting copies of viral RNA out of the nucleus of the host cell. Without Rev, HIV would not be able to replicate in its host. An essential property of Rev activity is that it must multimerize on the Rev-Response Element (RRE) of HIV RNA to successfully export that RNA from the nucleus to the cytoplasm of the host. This means that multiple Rev proteins must interact with each other to form a multimer. Since the multimerization of Rev is key to its mechanism of action, it could serve as a small molecule drug target.\nSutton, an expert studying HIV for years, knew that the Rev protein was essential to HIV survival. But there are currently no HIV antiviral drugs that target the Rev protein. \u201c[A Rev inhibitor could] be a first-in-class antiviral,\u201d Sutton said.\u00a0\nHansen began his project by developing an SLCA that could quantify Rev-Rev interaction in cells. Hansen fused each of the luciferase domains, NLUC and CLUC, to a Rev protein. The fused protein was created by genetically engineering a fusion gene that combined the sequence of the specific luciferase domain with the sequence of the Rev protein. Through a series of experiments, Hansen and Sutton eventually developed a highly sensitive screen for measuring Rev-Rev interaction. When Rev proteins were close enough to multimerize, the NLUC and CLUC would be brought close enough to luminesce. This assay works inside and outside of cells. Thus, even when using just the inner contents of cells, the assay can still accurately quantify Rev-Rev interaction.\u00a0\nThe goal of developing this assay is to find a small molecule inhibitor that can disrupt the Rev-Rev interaction. Hansen demonstrated that this assay could help by testing whether mutant Revs, which would inhibit the wild-type Rev interaction, reduce luminescence levels in the assay. Performing the assay with mutated Rev proteins fused to NLUC and CLUC resulted in much lower luminescence, indicating that this SLCA can be used to screen for an inhibitor that disrupts the Rev-Rev interaction. Similar to how a mutant Rev would not be able to multimerize, a putative inhibitor would be able to disrupt this interaction and result in a much lower luminescence reading. Thus, researchers could use this system to test an unlimited number of small molecules to see whether any can effectively prevent Rev-Rev interactions without being an inhibitor of the luciferase enzyme itself.\u00a0\nWhen asked whether he could find such an inhibitor, Sutton admitted that it was unlikely. \u201cHonestly, I don\u2019t think our lab could ever do this,\u201d Sutton said. \u201cIt really takes a commercial entity to do it. Can you imagine Tucker screening 200,000 compounds on his own?\u201d A pharmaceutical company, however, has the means and methods to perform large-scale screens to identify potential inhibitors of the rev-rev interaction.\u00a0\nSutton is currently applying for a grant from the NIH to fund the next steps of this project. With this funding, he is considering partnering with the local pharmaceutical company, ViiV Healthcare, which focuses on delivering new treatment options for people living with HIV. Sutton and Hansen are hopeful that the potential Rev inhibitors identified through this partnership could serve as a new class of HIV antivirals and present another line of defense for HIV patients with drug-resistance complications.\nThe work done by Hansen and Sutton is only one of many examples demonstrating the versatility in applications of firefly luciferase. This story highlights the ingenuity of using phenomena in the natural world to create tools and technologies that can facilitate our understanding of biological processes. As we continue to explore and rationalize more of the natural world, Hansen and Sutton\u2019s work reminds us that existing biological processes can be the key to unlocking a whole new world of technology and discovery with innumerable benefits to mankind.\u00a0\nFurther Reading\nJabr, F. (2016, May 10). The Secret History of Bioluminescence. Hakai Magazine. https://hakaimagazine.com/features/secret-history-bioluminescence/\nRinaldi, A. (2007). Naturally better. Science and technology are looking to nature\u2019s successful designs for inspiration. EMBO Reports, 8(11), 995\u2013999. https://doi.org/10.1038/sj.embor.7401107\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/using-fireflies-to-measure-hiv-replication/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Personal Matters on Abortion",
            "author": "Van Anh Tran",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/personal-matters-abortion-colored-bkgd-Luna-Aguilar-1-405x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Luna Aguilar.\nOn June 22, 2022, the United States Supreme Court overruled Roe v. Wade, which provided constitutional protection for the right to abortion for nearly half a century. Two months after the decision was overturned, over twenty million women in the United States lost access to elective abortions in their home states.\u00a0\nThe New York Times published a piece sharing the stories of people who got abortions before Roe stating that an important part of advocating for abortion is learning from the experiences of Americans who have had unsafe abortions before the court decision. On Twitter, Representative Alexandria Ocasio-Cortez trended for sharing her personal sexual assault story during an abortion rally. In the video, she told the crowd that she was glad to know she at least had a choice if she did end up being pregnant because of readily accessible abortion care in New York City.\nIn 2017, Abigail Cutler SPH \u201919, a doctor and clinical instructor in the Department of Obstetrics and Gynecology at Yale School of Medicine, noticed the increased prevalence of abortion storytelling in social media campaigns. Many of these campaigns\u2019 messages were to normalize abortions and denounce the stigma associated with it so that those who had or were seeking care felt like they were not alone in their experience.\u00a0\nThese campaigns inspired Cutler to examine whether forms of public storytelling\u2014in which storytellers don\u2019t necessarily know their audience\u2014could decrease community-level abortion stigma or the stigma people feel towards others who seek or have abortions. This stigma commonly manifests as discrimination against people who have abortions and as structural barriers against abortion care.\u00a0\nEvidence from years of polling research shows clearly that the public tends to be most supportive of abortions involving rape, incest, threats to maternal life, and fetal anomalies\u2014none of which reflect the most common reasons people seek an abortion.\u00a0\n\u201cWe know these stories are already effective for warming public opinion,\u201d Cutler said. However, she endeavored to know whether \u201cnon-exceptional\u201d stories\u2014stories centered on the most common circumstances for seeking abortion\u2014would impact the hearts and minds of the public.\u00a0\nFormation of the Study\nTo test this, Cutler\u2019s team conducted a randomized trial on a large, nationally representative set of US adults selected using the Ipsos Knowledge Panel. They showed the subjects three videos of people sharing their abortion experiences. They then measured community-level stigma immediately after showing the videos and then in a three-month follow-up.\u00a0\nThe authors developed a conceptual model to measure community-level abortion stigma and its facets. This model measures stigma through three scales: one primary scale measuring judgment (Community Abortion Attitudes Scale), one measuring how the context of an abortion affects opinion (Reproductive Experiences and Events Scale), and one measuring expectations of silence and secrecy surrounding abortion experiences (Community Level Abortion Stigma Scale).\nThe crucial part of this experiment was the selection of the three videos of people telling their experiences, which would be shown to the audience. Cutler recognized that, as a cis white woman leading a research team of white women, the group needed to be mindful of how their biases could adversely affect their study design. They formed an advisory board with racially and ethnically diverse members with professional or personal backgrounds in abortion stigma and storytelling, including several non-profit abortion organizations.\nThe essential qualities welcomed an intersectional analysis and would include speaking to the common reasons for seeking abortions, the ease or boundaries faced with healthcare, and whether the speaker told their story in a fluid and thoughtful manner. They sought to curate videos that would give the viewer a different perspective on abortions. \u201cWe wanted to make the watcher look at abortion in a different way, in a way not highlighted every day in the media,\u201d Cutler said.\u00a0\nAfter developing a scoring matrix for the videos based on these essential qualities, the advisory board members selected three final videos to showcase various abortion stories. One video talked about a parent who had multiple abortions before. Another video was about a woman who spoke about the barriers to obtaining an abortion in Texas and who traveled to California for the procedure. The final video was on a Latina woman who attempted to acquire birth control through the military and was facing difficulties doing so. Before she got deployed, she became pregnant. She spoke about how she made the decision to get an abortion in the context of her family and her values.\n\u201cPeople don\u2019t make these decisions in a vacuum, they don\u2019t make it by themselves,\u201d Cutler emphasized. These videos were chosen because they reflected the intersectionality and politicized nature of the abortion conversation through real, lived experiences of the most common demographics that seek an abortion.\u00a0\nReflecting on the Results\nThe results of the study showed that intervention exposures to these three videos both immediately after watching and three months later showed no association with decreased stigma by the judgment scale (CAAS) or the silence and secrecy scale (CLASS). This means that exposure to these three different abortion stories did not lower community-level stigma. Although there was a decrease in stigma in the context scale (REES) immediately after watching the videos, it was not significant after a three-month follow-up.\u00a0\nThis study approached the question of non-intimate storytelling and community-level stigma from a neutral standpoint, meaning that stories were not chosen because of their potential to elicit a response but to represent non-exceptional abortion stories. Furthermore, lack of an effect could mean that intervention exposure could be dose-dependent and that a single exposure to storytelling would not be enough for a long-term change in community-level stigma but rather should be more frequent and prolonged. For instance, a social media campaign, such as #ShoutYourAbortion, could prolong exposure to abortion stories over the period of time that it is trending. Furthermore, newspapers such as The New York Times creating a section called Abortion News could also keep the abortion conversation present in the public\u2019s mind.\u00a0\n\u201cI think it\u2019s important to acknowledge the limitations of this study,\u201d Cutler said, \u201cI don\u2019t think a takeaway from the findings of this study is that abortion storytelling does not have the power to change hearts and minds. It was one study, and it was conducted several years ago. The legal landscape is really different now.\u201d She mentioned that repeating this study, especially now post-Dobbs, would be interesting to see.\u00a0\nCutler emphasized that the results of this study do not mean that abortion storytelling isn\u2019t important for other reasons. It is essential to recognize that the purpose of abortion storytelling is not just to change public opinion. People who decide to disclose their abortion experiences to the general public do so for various reasons, such as to feel empowered and take the reigns over an experience that ought to be discussed more.\u00a0\n\u201cAbortion storytelling can also help other people who have abortions who happen to see that story to feel less alone,\u201d Cutler said. \u201cAnd that is arguably equally, if not more important, than changing public opinion.\u201d\nSources\nCutler, A. S., Lundsberg, L. S., White, M. A., Stanwood, N. L., & Gariepy, A. M. (2022). The Impact of First-Person Abortion Stories on Community-Level Abortion Stigma: A Randomized Trial. Women\u2019s health issues : official publication of the Jacobs Institute of Women\u2019s Health, S1049-3867(22)00059-7. Advance online publication. https://doi.org/10.1016/j.whi.2022.06.006\nFurther Reading\nCutler, A. S., Lundsberg, L. S., White, M. A., Stanwood, N. L., & Gariepy, A. M. (2021). Characterizing community-level abortion stigma in the United States. Contraception, 104(3), 305\u2013313. https://doi.org/10.1016/j.contraception.2021.03.021\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/personal-matters-on-abortion/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How to Grow a Heart",
            "author": "Catherine Zheng",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/HeartWithBG-Kiera-Suh-1-347x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Kiera Suh.\nImagine a world where any organ could be grown in the lab. A sample from a cheek swab could become a functioning heart in just a matter of weeks. New hearts would be grown from patients\u2019 stem cells whenever they were needed, and organ transplant lists and waiting times would virtually disappear.\nWhile this world is still far in the future, researchers at the lab of Stuart Campbell, Yale Associate Professor of Biomedical Engineering & Cellular and Molecular Physiology, have taken major strides in accelerating the maturation of stem-cell derived cardiomyocytes (iPSC-CMs) to grow engineered heart tissues (EHTs) in the lab that can even contract in response to electrical stimuli.\nGrowing Fetal Heart Cells\nThe primary function of EHTs is to provide a model of the human heart to study its features and responses to stimuli without having to access a human heart directly. These models are created by differentiating induced pluripotent stem cells into cardiomyocytes\u2013specifically, stem-cell derived cardiomyocytes (iPSC-CMs). This process involves first washing a thin slice of a pig heart in a detergent to clear away pig cells. The extracellular matrix is then used as a template for seeding a mixture of human heart cells, including iPSC-CMs and human cardiac fibroblasts.\nHowever, since stem cells can differentiate into any type of cell, iPSC-CMs are still relatively immature, representing fetal cardiomyocytes rather than mature ones. This limits their functionality as studies on them may not represent the characteristics of a fully grown human heart. Thus, to accurately represent mature heart tissue, iPSC-CMs need to undergo a maturation protocol that can currently take anywhere from forty days to six months.\nOne proposed technique for speeding up the maturation of iPSC-CMs is progressive electrical ramp pacing, which involves exposing the cells to an increasing rate of electrical current pulses over time. Previous studies have shown that this leads to heart cells that are more mature as they have more advanced electrophysiology and better calcium handling.\nCalcium is also known to play a large role in cardiac physiology, as it is essential in inducing the contraction of the heart. When a membrane potential reaches the cardiac muscle, calcium channels open, allowing calcium to flow in and bind to troponin, which triggers the heart muscle cell contraction. Greater calcium levels increase contractile force. However, calcium\u2019s role in the maturation of EHTs has not been previously considered. Most EHTs were grown in solutions containing only a fraction of the calcium concentration normally found in the heart.\n\u201cWhen our group realized how underutilized and underrated those calcium mediums have been across the field, we thought it might be interesting just to try it out,\u201d said Shi Shen, the primary researcher on this study. This curiosity led to the discovery that differences in response to calcium in these early stages can be a key driver in cardiomyocyte differentiation: results show that the amount of calcium present in the cell culture medium produced a significant change in the maturation of iPSC-CMs.\nGrowing Mature Heart Tissues\nTo further advance the maturation of iPSC-CMs, researchers tested whether the combination of electrical ramp pacing and an increase in free calcium ions, Ca2+, in culture could produce a scalable improvement in the maturation of EHTs compared to the standard maturation protocol.\nFour groups of EHTs\u2014high-Ca2+ non-paced (HC-NP), low-Ca2+ non-paced (LC-NP), high-Ca2+ ramp-paced (HC-RP), and low-Ca2+ ramp-paced (LC-RP)\u2014were studied to determine the effects of electrical pacing and calcium level on their own and in conjunction. The team performed the ramp pacing at frequencies higher than that of a regular human heart rate. \u201cThe regular human heart rate would fit between one to two hertz, so putting it at three hertz is like putting a YouTube video at two times speed,\u201d Stephanie Shao, an undergraduate researcher on this study, said. \u201cYou can really increase the frequency and speed it up without harming it. In this case, it benefits it because it makes the EHTs mature at an accelerated rate.\u201d\nTo test the functionality of these heart tissues, a variety of metrics were measured, ultimately showing that the HC-RP group performed much better than the other groups. One of the most notable improvements was the force-frequency relationship (FFR). FFR reflects increases in the\u00a0 contractile force of the heart with increasing frequency stimulus. \u201cThis is one of the key results to determine whether our experiments are successful because healthy humans need this particular phenomenon to function, [\u2026] and one of the hallmarks of a cardiac disease is the lack of increase in force,\u201d Shen said.\nFFR is measured using a mechanical testing apparatus that measures force in response to 0.25-Hz increases in frequency from 1 to 3 Hz. While high calcium marginally improved the FFR of the groups with no ramp pacing, both groups still showed a negative FFR, meaning the force continuously decreased rather than increasing to a systolic peak force and dropping again. However, once the researchers induced a ramp pacing, they saw a positive FFR in the group with high calcium, whereas the FFR of the low calcium group was still negative. Healthy human myocardium has a positive FFR of up to 2-2.5 Hz, similar to that of the HC-RP group, which exhibited a FFR around 2 Hz.\nOther metrics that measure heart tissue functionality are time-to-peak (TTP) and time to-fifty percent relaxation (RT50). TTP is the time it takes for the tissue to reach its peak contractile force, and RT50 is the time it takes for the tissue to reach fifty percent relaxation after its peak force. Human tissues exhibit TTP and RT50 values at around 200 ms and 120 ms, respectively. The HC-RP group showed a similar TTP of around 290 ms and RT50 of around 120 ms, which is significantly faster than the other EHT groups.\nThe effect of isoproterenol (ISO) on the EHTs was also observed by measuring FFR after exposure to ISO. ISO is a drug that increases the contractility of the heart. It is used for patients with weakened hearts to improve cardiac output. The increase in the systolic peak force for the HC-RP group was much more significant compared to the increase in the systolic peak force for the LC-RP group. These results indicate that the HC-RP group behaves more similarly to actual mature heart tissue in the presence of ISO.\nOn top of these metrics, western blots and RNA sequencing were performed to analyze changes in protein and RNA levels on a molecular level that may have influenced improvements seen in the different groups. The results showed that markers associated with mature heart tissues were elevated in the HC-RP group. They also found that the genes expressed in the HC-NP and LC-RP groups were not the same, indicating that both electrical ramp pacing and high calcium are needed to produce the mature characteristics achieved in the EHTs.\nGrowing Hearts\nWith this improved protocol, the maturation of iPSC-CMs can be significantly shortened relative to previously published techniques. While EHTs cannot be used to grow hearts directly from stem cells, this advancement has significant implications for future research. Given that many researchers around the world are using iPSC-CMs for a variety of purposes, this technique has the potential to find widespread use and make mature, functional EHTs more readily available.\n\u201cFor something like a drug study, a lot less compound would be used,\u201d Shao said. \u201cEspecially if it\u2019s a drug that\u2019s not out yet, you have to have a chemist make it, and that\u2019s not easy to make large quantities of, which is what you would need for an in vivo study.\u201d\nAnother major advantage of using EHTs is that they are grown from stem cells derived from a specific patient. This means that any testing a patient may need to undergo can be performed on an EHT grown from their stem cells, which will more accurately represent the characteristics of their own heart.\nThis study is a catalyst for future cardiac research exploring the vast applications of EHTs. \u201cThere\u2019s a large segment of work that\u2019s being done targeted towards implanting cells back into patients to repair the heart to replace or regenerate heart muscle,\u201d Campbell said. \u201cI would hope that the field takes notice of our protocol because if you\u2019re repairing the heart, for instance, you want to generate a lot of mature cells, so someone\u2019s going to have to decide how to treat those cells so that they\u2019re as mature as possible.\u201d Campbell hopes this paper will contribute to the growing body of literature for the most optimal maturing conditions.\nMoving forward, there are still other factors to investigate that may further improve the maturation of stem cells for EHT growth. \u201cSomething that we haven\u2019t tried is combining a realistic pattern of mechanical loading, or maturation of mechanical loading\u2014so what a fetus experiences in terms of the fetal heart versus a newborn versus an adult heart\u2014modulating the mechanical load in conjunction with those heart rate changes\u201d, says Campbell. While growing a functioning adult human heart is not yet in the cards, we are getting closer to a future where that is possible.\nAcknowledgments\nThe author would like to thank Professor Campbell, Dr. Shi Shen, and Stephanie Shao for their time and enthusiasm in sharing their research.\nFurther Reading\nShen, S., Sewanan, L. R., Shao, S., Halder, S. S., Stankey, P., Li, X., & Campbell, S. G. (2022). Physiological calcium combined with electrical pacing accelerates maturation of human engineered heart tissue. Stem Cell Reports, 17(9), 2037\u20132049. https://doi.org/10.1016/j.stemcr.2022.07.006\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/how-to-grow-a-heart/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Molecular Clock",
            "author": "Chris Esneault",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/esneault_image2-500x478.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nFamous physicist Albert Einstein once said: \u201cThe distinction between the past, present, and future is only a stubbornly persistent illusion.\u201d Time is an idea that has been talked about and debated for centuries. For physicists, philosophers, and others in between, the meaning of time and space and temporality has kept, and will continue to keep, people wondering.\u00a0\nThough some may believe that judgment of time is only left to complex, multicellular organisms, that is not quite true. In fact, researchers in Andre Levchenko\u2019s lab at the Yale University Systems Biology Institute are currently looking into the cellular mechanisms that drive the molecular clock: a new way of conceptualizing time on a cellular level.\u00a0\nResearchers found this clock is controlled by two negative feedback mechanisms mediated by microtubule polymerization, GEF-H1, and GTPase RhoA. GTPase RhoA is a Ras homolog family member A that regulates actin reorganization, a mechanism that plays a role in cell migration and motility. Sung Hoon Lee, a postdoctoral researcher from the Levchenko Lab, said that though his background is actually in electrical engineering, he wanted to help build a systems-level understanding of a biological network.\nWhy do cells actually migrate? Lee said that it is because cells are dynamic in nature, and thus, cells migrate, proliferate, communicate, and die. For example, in the case of extreme and unwanted cell dynamism, metastatic cancer cells migrate throughout the body to invade other tissues. Levchenko joined in this explanation, saying that, \u201cwhen an organism develops, there are many cases of cells undergoing movements to undergo relocalization.\u201d This dynamic cellular movement and reorganization rarely occur in adults, where cells are generally pretty settled in the body. However, \u201cthe general idea for the cells is to figure out how to move and successfully relocalize to the desired location,\u201d Levchenko explained.\nWhile cell movement is normally studied in two-dimensional settings like Petri dishes, very little research has dug into the mechanisms of movement in three-dimensional settings like the body. In these 3-D settings, cellular activity is controlled by a squeezing motion from the posterior end of the cell that propels the cell forward. However, little is understood about how this squeezing movement operates.\nLee found that cells navigate the three-dimensional extracellular matrix \u2014  the complex network of molecules and proteins that forms the connective tissues between cells \u2014  using a periodic squeezing movement. The molecular clock controls the frequency of these squeezing movements and, consequently, the speed of cell movement. Furthermore, this clock is mediated by two coupled negative feedback loops. \u201cMicrotubule polymerization is an important component that can enhance the abundance of the molecule GEF-H1,\u201d Lee said. This rapid polymerization of tubulin inside the cell underpins the dynamics of cell movement. \u201cMicrotubule polymerization can also inhibit the activity of GEF-H1. These two feedback loops modulate the molecular clock\u2019s frequency,\u201d Lee continued.\u00a0\nFurthermore, Lee found that cellular migration was mediated by cyclic changes in a small molecule called GTPase RhoA. And this GTPase RhoA is dependent on the activity and abundance of GEF-H1. By understanding the players underpinning cell migration, Lee was able to manipulate the frequency of the clock and make cells move, in some cases, three times as fast as they normally would. Funnily enough, Levchenko said, \u201cFor a while, the American Society for Cell Biology had an annual cell race where you could put engineered cells on race tracks and compete with other cells. While the competition does not take place anymore, Sung Hoon would likely win the competition.\u201d\u00a0\nAnd while the research conducted by Lee has proven valuable in our present understanding of the dynamics of cell movement, the implications of his findings are arguably even more valuable. Through perturbation of the molecular clock\u2019s frequency, they can potentially find new ways of controlling the speed of cell movement. In theory, manipulation of this clock could speed up the rate at which the repair of cell tissues occurs. Conversely, in the case of cancer metastasis, this same clock that controls aggressive tumor cells could be slowed down.\nLooking towards the future, it is clear that, with the help of the scientific progress made by Lee and Levchenko, the field is on the brink of tremendous possibilities regarding systems biology and the molecular clock.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/the-molecular-clock/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Zombie Cells: When Fiction Bleeds Into Reality",
            "author": "Mia Gawith",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/gawith_image1-383x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of David Andrijevic.\nImages of the \u201cliving dead\u201d linger in our minds: Frankenstein resurrecting his monster, zombies stumbling around with contorted limbs, and what seems to be a never-ending stream of episodes of \u201cThe Walking Dead\u201d. But is it possible to bring a mammal back from the dead? A research team at the Yale School of Medicine says yes, at least on the cellular level. Using a new technology termed OrganEx, scientists have successfully restored cellular functions in dead pigs.\nA team of scientists explored the possibility of preventing cell death in large mammalian bodies. Per Yale University\u2019s ethical guidelines, the scientists induced fatal cardiac arrest in female pigs. An hour after their death, these same pigs were hooked up to the OrganEx system, a two-part device equipped with oxygenation machines and a synthetic solution. Since cells do not die instantly, this technology allowed researchers to intervene during the cell death process and reverse it. The changes were remarkable: oxygen and metabolic levels went back to normal, circulation was restored, and organs showed fewer signs of damage than with previous technology.\nWhile not the key to zombies, this discovery answers important issues in healthcare. For David Andrijevic, a leading co-author from the department of neuroscience, the potential applications are staggering. \u201cIf you can recover the organs after loss of blood flow for so long, then we might actually increase an organ donor pool for organ transplantation,\u201d Andrijevic said. Future developments will focus on expanding these results to the clinical setting. Perhaps zombies should take a hint from scientists\u2014how else will fiction become a reality?\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/zombie-cells-when-fiction-bleeds-into-reality/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Expanding Chemistry",
            "author": "George Karadzhov",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Karadzhov_Image1-378x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nLast August, a collaboration between the Hammes-Schiffer and Mayer groups at Yale and researchers from the Hammarstr\u00f6m group at Uppsala University led to the discovery of a new fundamental photochemical reaction relevant to our understanding and application of chemistry.\u00a0\nThe finding follows unexpected results the groups observed in 2019 when working with the motif anthracene-phenol-pyridine (An-PhOH-Py), which contains the three chemical groups connected by single bonds. The teams found that when different variations of the An-PhOH-Py motif are excited with light, the only some of their molecules go through a known pathway: the molecule starts at the ground state, the anthracene subunit absorbs light energy, and that new energy promotes an electron to move from the phenol subunit to the excited anthracene (*An). At the same time, a proton transfers to the pyridine unit to form a new charge-separate state (CSS). This CSS represents a different arrangement of charge and energy in the molecule that can be utilized later in reactions like photosynthesis. The researchers discovered that molecules return from the CSS to the ground state through a proton-coupled electron transfer (PCET) process that is slowed down by increasing the driving force. Surprisingly, the groups did not observe any CSS for certain variations of their molecules. Speculating that there was some other way for these molecules to react to light and yield a lower energy product, researchers computationally predicted and experimentally detected the formation of a local electron-proton transfer (LEPT) excited state in place of a CSS for some of their reagents.\nThe LEPT itself isn\u2019t new. A PhOH-Py molecule can be excited to trigger an excited-state proton transfer and give us a *PhOH-Py LEPT species. Similarly, the PhOH-Py fragment in the An-PhOH-Py triad can be excited to a LEPT state (*PhOH-Py). The direct transformation from the excited anthracene fragment in the An-PhOH-Py triad to the excited PhOH-Py fragment LEPT (as confirmed by further experiments), however, goes beyond existing theories, hinting at a new photochemical reaction responsible for these observations.\u00a0\u00a0\nWith further research, it became clear that that was exactly the case! Researchers described a new reaction where a proton transfer within the PhOH subunit is coupled to an energy transfer from the *An to the PhOH subunit without a charge separation. Rather than the reaction involving proton and electron movement, it relies on a proton and energy moving throughout the molecule in a new way that had never been observed.\nThis reaction, appropriately coined a proton-coupled energy transfer (PCEnT), also challenges our rules about light absorption and fluorescence. Since the energy to excite the LEPT state comes from the *An, the fluorescence energy from the *An has to match the absorption energy of the PhOH-Py. However, according to Coraline Tao, a senior PhD student in the Hammes-Schiffer Lab at the time of the project and now a postdoctoral researcher at the University of Pennsylvania, the observed fluorescence of LEPT from *An runs counter to expectation.\u00a0 \u201c[LEPT\u2019s fluorescence [is] counterintuitive because [the] energy giver has to have enough energy to charge the acceptor, but here they don\u2019t,\u201d Tao said. Where does that extra energy come from? The groups show that the proton transfer can physically reconfigure the molecule, making this fluorescence possible. The details of how the transferring proton couples with the energy transfer process, however, are still unclear, prompting questions about how spatial relationships contribute to energy movement across molecules.\nOften, fundamental discoveries have a curious tendency to pop up in many unexpected places\u2014think the Schr\u00f6dinger equation used in economics. This is no different. PCEnT describes a powerful process that could have significant future applications. Since the LEPT product is closer in energy to the *An intermediate than other reagents we could use to get the same thing, there is now a way of executing this chemical transformation using lower excitation energy. According to Tao, this could have important implications for designing molecules for solar dyes, solar panels, and other technologies to store and use photochemical energy. PCEnT may also already be present in photosensitive biological systems, and we haven\u2019t thought to look! It could be the case that differences between PCET, PCEnT, and other photochemical reactions serve as regulatory mechanisms for biological pathways. This new knowledge of PCEnT also allows researchers to access new configurations and arrangements of molecules that could be synthetically or technologically useful.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/expanding-chemistry/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Hummingbirds: Masters of Color",
            "author": "Sheel Trivedi",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/trivedi_hummingbird-500x329.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nWhat comes to mind when you think of hummingbirds? You might think of their rapid heart rate. Or maybe their lightning-fast wing speed. But hummingbirds have another superpower under their beak: color.\u00a0\nBird feathers, known as plumage, display many hues. Researchers at Yale University calculated the hummingbird plumage color gamut, a value representing the color diversity of hummingbird plumage as seen by other birds. Birds see ultraviolet and visible light, whereas humans can only see the latter, so human vision falls short when considering hummingbird plumage.\nGabriela Venable (YC \u201919), a researcher on the study, spent hours at the Peabody Museum and American Museum of Natural History using a spectrometer to gather colorful spectra from 1,600 plumage patches on 114 hummingbird species. \u201cWe can plot the spectra into a [model accounting for bird vision] and calculate the volume from all the points in the model, and that can measure color diversity,\u201d Venable said.\u00a0\nThe data revealed that the hummingbird gamut was, in some aspects, more diverse than the previously calculated gamut of all other birds combined. One justification points to hummingbird barbules, which are micro-structures in a feather. \u201c[Barbules] allow [hummingbirds] to make saturated colors and many different color combinations,\u201d Venable said. This strengthens hummingbird evolutionary benefits, like defending floral patches or attracting mates.\u00a0\nThough they discovered new information about coloration mechanisms in birds, there is still work to be accomplished. As the first study targeting one family of birds, this research facilitates more in-depth analyses of plumage color diversity and increases the accuracy of the calculated avian color gamut.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/hummingbirds-masters-of-color/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Solving the Unsolvable",
            "author": "Emily Shang",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/shang_image1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of iStock.\nHave you ever wondered about the math behind a radio signal? Or telephones? Scientists who study electromagnetic physics and mathematics constantly are: their work is founded upon partial differential equations. These equations are unlike the differential equations we encounter in calculus: they are three-dimensional and extremely difficult to solve because they vary with both time and space, even for simple shapes. As a result, designing cell phone antennas and radio telescopes is extremely challenging. To solve these wave equations, scientists use a technique that separates the part which varies with time and the part which varies with space, also known as \u201cHelmholtz\u2019s equation.\u201d However, Helmholtz\u2019s equation is still a differential equation, which is hard to solve. Scientists have been using a trick called Green\u2019s functions to solve these sorts of problems for over a hundred years. Green\u2019s functions are powerful techniques that let you solve a differential equation by computing an integral, making the solution easier to attain. However, even though they can convert these problems from differential equations into integral equations, they still have to do it in 3D, which is extremely hard.\u00a0\nHowever, for certain types of symmetric objects, like a radar dish, there is a trick that turns a 3D problem into a 2D problem. However, it comes at a price. The Green\u2019s function would have to be split up into its individual frequencies using the Fourier series technique. For each frequency, a very difficult integral, called \u201cthe modal Green\u2019s function,\u201d would have to be computed. This Green\u2019s function is tricky: it oscillates incredibly quickly between massive positive and negative values, but somehow, they all end up adding up to something tiny. Any attempt to estimate the integral by \u201cadding it up\u201d essentially adds and subtracts infinity trillions of times, causing so much error that the estimate is useless. Scientists have been struggling with how to compute this integral since the 1960s.\nTo handle difficult integrals, mathematicians will often solve them using complex analysis, the field of math that studies imaginary numbers. Real numbers are plotted on the \u201creal line,\u201d ranging from negative to positive infinity. In contrast, complex numbers have real and imaginary components, meaning they live in a 2D space called the \u201ccomplex plane.\u201d Amazingly, for many functions, the integral can either be computed along the real line or as a \u201ccontour integral\u201d through the 2D complex plane, a technique invented by the mathematician Augustin-Louis Cauchy in the nineteenth century. By carefully choosing the contour, sometimes those integrals can be made very simple. For example, some functions oscillate between negative one and positive one on the real line, but in the complex plane, they never oscillate.\u00a0\u00a0\nFor decades, scientists had written off using this contour trick because no matter which contour they picked, part of the Green\u2019s function wildly exploded and oscillated. James Garritano, along with his mentors Yuval Kluger, Vladimir Rokhlin, and Kirill Serkh at the Kluger Lab in the Yale School of Medicine, recently overcame the oscillations of Green\u2019s function by ignoring the real line and integrating it into the complex plane by using a contour invented in 2010 by a scientist named Mats Gustafsson. The key idea of their paper was to replace part of the Green\u2019s function with an approximation that does not grow in the complex plane. Then, they could use Gustafsson\u2019s contour and avoid wild oscillations.\n\u201cDr. Kluger and Dr. Rokhlin, who I work for, are both famous for creating fast algorithms to solve problems in physics and genomics,\u201d Garritano said. For example, with his student Leslie Greengard, Rokhlin created the fast multipole algorithm, named one of the top ten algorithms of the twentieth century. It became the basis for a wide range of physics simulations ranging from modeling gravitational bodies to electrons. Kluger recently developed the fastest method for clustering data in single-cell experiments by using insights from computational physics to accelerate one of the key algorithms of data science.\nThis work has paved the way to create ultra-fast physics solvers for rotationally symmetric objects such as antennas and radar dishes. Also, their work showed that Cauchy\u2019s contour-trick could be applied to more problems than previously thought.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/solving-the-unsolvable/",
            "captions": [
                "colorful Audio waveform abstract technology background ,represent digital equalizer technology"
            ]
        },
        {
            "title": "Repurposing the Urban Forest",
            "author": "Elise Wilkins",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2_-Repurposing-the-Urban-Forest-1-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nTrees in urban areas contribute to pollution control and enhance biodiversity. But what happens to dead leaves, fallen branches, and other forms of tree waste that pile up along curbs? Typically, tree waste is sent to landfills or incinerated, what experts call the \u201cend-of-life\u201d states. Each year, these methods release much of the twenty million metric tons of carbon generated by the urban forest as methane and carbon dioxide, contributing substantially to global warming.\u00a0\nTo explore the possibilities for circular utilization of tree waste, researchers at the Yao Lab at Yale studied five methods of tree waste repurposing. Researchers found that the optimal scenario consisted of composting leaf waste, selling lumber as logs or wood chips, and using residue to produce biochar\u2014a substitute for traditional charcoal. Kai Lan, a postdoctoral associate on the study team, told the Yale School of the Environment, \u201cThis aligns with the circular economy concept\u2014turning waste into something of value. But it\u2019s not just traditional waste like paper and plastic. Tree waste is very important, too.\u201d This valuable process can reduce global warming and eutrophication\u2014when water sources become overrun with nutrients and algal growth, deteriorating water quality. Additionally, the benefits extend to stimulating the economy through lumber sales and the possibility of new jobs to facilitate tree waste management.\u00a0\nWhile cities may see differing benefits depending on their abundance of tree waste, the study offers new insight into the benefits of implementing a circular economy in a surprising area, demonstrating that even plants in their \u201cend-of-life\u201d state still have much to contribute.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/repurposing-the-urban-forest/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Tale of Two Galaxies",
            "author": "Hanwen Zhang",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/YSM-Article-Figure-1-1-500x333.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nGalactic collisions usually resemble a carefully choreographed ballroom dance: picture a pair of galaxies pinwheeling into each other\u2019s arms, their gravitational centers merging together. But in the case of the two dwarf galaxies DF2 and DF4\u2014initialed in honor of the Dragonfly telescope that captured them\u2014researchers suspect the cause of their formation might have been closer to a collision between two bullets.\nThe van Dokkum Lab, a Yale astrophysics research group, proposed a bullet-dwarf collision model which describes an event where a pair of galaxies run into each other with enough speed to form two entirely new ones in their wake. The model is a culmination of years of observation and careful telescopic tracking. Van Dokkum\u2019s research team first discovered DF2 and DF4 sometime around 2018. Both galaxies are members of a space neighborhood roughly sixty-seven million light years away from Earth.\nWhat surprised the group was the virtual absence of any dark matter in both DF2 and DF4. The researchers were baffled by the speeds of the galaxies\u2019 stars. \u201cThey [had] very low velocity dispersion, which means that [\u2026] these galaxies don\u2019t contain a lot of dark matter,\u201d said Zili Shen, a graduate researcher in the lab. The intensity of gravity directly dictates the motion of stars, and since most of a galaxy\u2019s gravitational force comes from dark matter, both DF4 and DF2 must be strikingly devoid of it.\nDark-matter deficient galaxies are uncommon\u2014they are so rare, in fact, that DF4 and DF2 remain just a few of the handful scientists currently know. This is because most galaxies depend on dark matter for their creation. Clumps of dark matter\u2014a substance virtually undetectable except by its gravitational presence\u2014often serve as whirlpool-like centers that collapse clouds of gas. There, temperatures can rise to levels nearly double the sun\u2019s surface temperature, giving birth to a sizzling new galaxy.\nWithout dark matter to create its stars, DF4 and DF2 must have come into existence following a script of their own. Analyzing the data, the team reasoned that two-parent dwarf galaxies met side-on in a high-speed collision, generating an extraordinary amount of force that compressed their clouds of gas. This might have been enough to form DF2 and DF4. \u201cHigh-speed collision of dwarf galaxies is a viable explanation for galaxies without dark matter,\u201d Shen said.\nUnder normal conditions, the comparatively lower speeds would have trapped the dark matter of both parent galaxies and caused them to merge. But for DF4 and DF2, the collision likely occurred with so much velocity that the two haloes of dark matter simply bypassed each other. With nothing left to bind their constituent star clusters together, the once-organized parent galaxies scattered apart. The result: diffuse clouds of gas and stars strewn across space, the DF2/DF4 duo among them.\nTheir data seems to confirm this. The group\u2019s most recent paper identified a linear arrangement of seven to eleven dimly-lit objects, exactly the kind of structure they would expect to find from a cosmic collision like this. Most structures were also abnormally large for their relative brightness, offering further evidence that they might be the galactic shrapnel of interest.\nBut like the star clusters of newly formed galaxies, the model remains hazy. At least two other competing theories have attempted to explain this phenomenon. One suggests that DF4 and DF2 simply arose after a normal dwarf galaxy drifted too close to a larger galaxy and lost its dark matter. It fails, though, to explain the presence of two dark-matter deficient galaxies. The second\u2014the tidal dwarf theory\u2014proposes that they arose from gas that was stripped off from larger galaxies, but the lab has since disproven this through the age and metallicity of both galaxies\u2019 constituent stars.\nFor now, the bullet-dwarf collision remains a tentative\u2014if attractively convincing\u2014hypothetical scenario. \u201cThis is mostly a theory that explains the data we already have,\u201d Shen said. Confirming the bullet-dwarf collision will require more empirical evidence, which includes calculations of the individual clusters\u2019 velocities and positions. The group has already started processing data from the Hubble Telescope to further validate their theory.\nStudying dwarf galaxies like DF2 and DF4 has its benefits. Shen explained that dwarf galaxies, being almost one thousand times smaller than our Milky Way, are relatively easier to model. That doesn\u2019t make piecing together our strange cosmic past any simpler, but it might just help reveal new ways of being and of becoming that we had previously not known.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/a-tale-of-two-galaxies/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Tiny Origami Robots",
            "author": "Ignacio Ruiz-Sanchez",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/OrigamiRobot-Catherine-Kwon-1-386x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Catherine Kwon.\nBlack Mirror. Ex Machina. The Terminator. Why does television seem to vilify robots and artificial intelligence as a human invention bound to go wrong? Why are robots always portrayed as a perilous design destined to eradicate the human species? We see this smear of these intelligent machines in the media and pop culture, from movies that follow the expedition of an assassin robot to dystopian shows that alarm their audiences about the dangers of unrestricted technological advancements. However, let us not forget that robots are designed to facilitate human conventions and tasks, with great potential to revamp and advance biotechnology, medical procedures, and clinical treatments.\u00a0\nIn one of the latest clinically transformative cases, researchers at Stanford University designed a tiny origami robot capable of various movements in physiological environments to deliver organic cargo and liquid medicine. We often attribute origami to the Japanese paper-folding craft, but this technology fulfills the robot\u2019s multifunctionality based on the geometric features of a specific origami structure: the Kresling. The Kresling is a triangulated hollow cylinder where \u2018twist buckling\u2019 a thin cylindrical sheet creates triangular elements throughout the structure. The twist buckling mechanism can be created by folding one sheet slightly higher than the next sheet, then repeating this process along the direction of the twist. Because the Kresling structure is always curved at the folds, the junctions between folds can be radially cut for liquid drug release. The buckling effect and high geometrical symmetry of the design allow for the robot\u2019s sphere-like ability to roll, flip, and spin.\n\u201cThe Kresling origami is a special design that couples torsion\u2014a twisting motion\u2014and compression, which provides us with the foldability to develop a pumping mechanism for targeted drug delivery,\u201d said Renee Zhao, assistant professor of mechanical engineering at Stanford University and one of the leading scientists on the project. The robot is prepared by attaching thin magnetic plates to the ends of the Kresling structure, which generates a twisting force as the robot\u2019s rigid body rotation aligns with the magnetic field.\nThis all sounds very compelling and groundbreaking, but how does the robot\u2019s origami structure improve the drug delivery process? After all, the robot is not being introduced to a generally dry environment, so why is on-ground locomotion relevant? Zhao and her team at Stanford characterize the tiny robot as amphibious in functionality, meaning that the robot can navigate both complex ground and aqueous environments. \u201cOn-ground locomotion is based on the robot\u2019s interaction with a solid surface by rolling and flipping, and aquatic locomotion is based on the spinning mechanism that creates propulsion for the device to swim,\u201d Zhao said. The magnet plates also activate the pumping mechanism to release liquid medicine into the body. For drug delivery, a needle and a liquid medicine container are inserted into the internal cavity of the robot. Once the device reaches the target area, the magnetic plates activate a rotational force to contract the robot, during which the needle punctures the liquid container. Gradually, the Kresling\u2019s internal cavity shrinks and squeezes the liquid medicine out through the radial cuts into the environment. Similarly, the spinning-enabled feature from the magnets also allows for cargo loading and release, which follows the same locomotive process as the pumping mechanism. However, it first propels the robot to absorb solid objects from an environment, stores those objects in the internal container, and finally releases them via pumping once the robot reaches the target area.\nDespite the relatively small size of the millirobot, the internal cavity of the Kresling is still widely unoccupied, even after installing the needle and liquid container. Researchers have thus built sensors and cameras in the cavity to direct movements and record specific environmental conditions. \u201cThe internal cavity of the robot can actually be used to integrate other functional components, like cameras for biopsies and biosynthetic tissues to stop internal bleeding,\u201d Zhao said. The potential biomedical applications for using the robot and its internal compartments are vast.\nVersatility, agency, and efficacy all seem to be leading features in the architecture of these innovative devices. Robots like the Kresling origami should remind us that robots were created to help us, not harm us. To this point, let\u2019s stop giving robots such a bad rap in pop culture, especially if these cute, foldable robots could be designed to ultimately save our lives.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/tiny-origami-robots/",
            "captions": [
                ""
            ]
        },
        {
            "title": "What Can a Computer Learn from a Baby?",
            "author": "Nathan Wu",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/AIBabies-Catherine-Kwon-1-500x324.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Catherine Kwon.\nBefore we turn three months old, humans have already developed an intuitive sense of how the physical world works. If an infant knocks over a block tower, they know the blocks will tumble spectacularly down to the ground. If the blocks float in the air or fall straight through the floor, the infant might cry out in surprise.\nThis sense of common intuition is dubbed our \u2018intuitive physics engine,\u2019 fundamental to both biological and artificial intelligent systems operating in the real world. Understanding how a system\u2019s physical actions will affect the world around them can guide what decisions and movements they must execute to carry out their intentions. In biological systems, the intuitive physics engine develops extremely rapidly, suggesting its importance for survival in the physical world.\nDespite the ubiquity of intuitive physics in intelligent biological organisms, the best artificial intelligence (AI) systems still struggle to replicate the same understanding of physics that even very young children have mastered. This difficulty continues despite the great progress made in the field. AI systems easily best humans in complex games, like Chess and Go, and have solved some of the most complicated scientific problems, like protein folding. The challenge of teaching intuitive physics to an artificial system lies within its pervasiveness. \u201cIntuitive physics is everywhere, and when something is everywhere, it becomes hard to analyze because it\u2019s interacting with so many things,\u201d said Luis Piloto, a research scientist at DeepMind, a subsidiary of Alphabet, Google\u2019s parent company. However, Piloto\u2019s team has recently made great strides toward finding a solution by taking inspiration from the methods and findings of developmental psychology, ultimately creating an AI system that learns intuitive physics from visual data.\nPerhaps the most important novelty of Piloto\u2019s work was how their AI model\u2019s understanding of intuitive physics was probed and evaluated. In developmental psychology, intuitive physics is separated into several distinct concepts, such as object permanence or object solidity. For each concept tested individually, human subjects are shown relevant scenes that are either consistent or inconsistent with the concept of interest. If subjects show surprise after seeing inconsistent scenes, which is usually measured by gaze duration, there is evidence that the subject understands that concept. This method of evaluating intuitive physics knowledge is known as the violation-of-expectation (VoE) paradigm.\nInspired by these methods used in developmental psychology, Piloto and his team constructed the Physical Concepts dataset. This dataset contains videos generated by a physics engine, each consistent or inconsistent with one of five distinct concepts from intuitive physics. These concepts included object permanence (objects will not simply disappear), object solidity (objects will not pass through one another), continuity (objects will have continuous paths and cannot teleport from one place to another), unchangeableness (objects retain their properties over time), and directional inertia (objects will stay in their path unless a force acts upon them). Every video that abided by a concept was paired with a visually similar one that violated that concept, both starting with identical scenes but deviating over the course of the video. The amount of \u2018surprise\u2019 that a model exhibited was determined by the model\u2019s prediction error\u2014how different a future scene predicted by the model is compared to the real future scene in the accompanying video. Thus, the model\u2019s understanding of a concept can be evaluated by examining the difference in the model\u2019s surprise in response to physically plausible and implausible pairs of videos.\nThis VoE paradigm is a departure from standard methods of evaluating AI\u2019s performance on intuitive physics tasks. One common approach utilizes video prediction on physically plausible situations alone to evaluate learning progress. In the VoE paradigm, the model should, in theory, make incorrect predictions about physically implausible videos, enabling researchers to better understand whether a concept is truly being learned. Another common approach employs reinforcement learning tasks, whereby models plan actions to interact with the environment around them to receive a reward. However, the complexity of these tasks makes it difficult to isolate the true cause of failure because success requires intuitive physics knowledge and knowledge of how to navigate the given space.\u00a0\n\u201cIf we want to evaluate intuitive physics knowledge, let\u2019s break it down into these different concepts, and let\u2019s build stimuli that are really about the concepts\u2026 You can do well on benchmarks, but if they don\u2019t reflect the capabilities that you\u2019re actually trying to measure, then increasing your performance on those benchmarks doesn\u2019t necessarily get you closer to the capabilities that you want,\u201d Piloto explained.\nThe next key insight from developmental psychology incorporated by Piloto\u2019s team was an object-based conception of physics. Infant intuitive physics behavior involves segmenting the visual field into distinct objects with their own properties (object individuation), tracking these objects across space and time (object tracking), and then processing how these objects interact with each other (relational processing). These three processes were implemented in a model called Physics Learning through Auto-encoding and Tracking Objects, nicknamed PLATO. Rather than only looking at patterns of pixels in a visual scene as other visual prediction models do, each frame that PLATO processes is broken down by masking specific parts of the scene so that the model can learn representations of individual objects. Indices assigned to each object enable them to be tracked through time. Lastly, a separate module is used to process how these objects interact with one another and predict future scenes.\nAfter just twenty-eight hours of visual training with physically plausible videos from the physical concepts dataset, PLATO demonstrated a grasp of all five concepts by exhibiting greater surprise in response to physically implausible videos. This result outperformed AI models that do not rely on object-based representations as PLATO does. The model also performed well on a different dataset developed independently by a team at the Massachusetts Institute of Technology, suggesting that PLATO\u2019s understanding of intuitive physics is robust.\nThe quest to build an AI system that can learn intuitive physics is far from over. While Piloto\u2019s team at DeepMind has taken a great step forward, there is still much room for improvement. In particular, PLATO did not learn how to segment and label the visual field into distinct objects by itself. Instead, the researchers spoon-fed the model a series of masks that told it where each object was. Other recent work has successfully tackled this challenge, introducing methods for object discovery in an unsegmented visual field. Integrating this research with the relational processing module of PLATO would result in a seamless model that can understand intuitive physics with nothing but a video.\u00a0\nPLATO\u2019s success as a machine learning model inspired by biological brains speaks to artificial intelligence\u2019s close relationship with neuroscience and psychology. \u201cAI and neuroscience are attacking the same problem from different sides,\u201d Piloto said. \u201cThe analogy that I like to use is that AI is building intelligence from scratch, and neuroscientists are saying, \u2018Wait, hold on, we\u2019ve got this intelligent system right here, why don\u2019t we try and reverse-engineer what\u2019s going on?\u2019\u201d\nAlthough PLATO is far from being an accurate model of intuitive physics learning in children, the study still presents important implications for developmental psychology. PLATO\u2019s success proves that intuitive physics knowledge is not necessarily innate\u2014it can be rapidly acquired through visual learning. Additionally, Piloto\u2019s team proposes using models like PLATO to investigate the order in which different intuitive physics concepts are acquired throughout development. This study demonstrates that the brain sciences and artificial intelligence have much to gain through work at the intersection of the two fields.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/what-can-a-computer-learn-from-a-baby/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Lightning\u2019s Achilles Heel",
            "author": "Kayla Yup",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Lightnings-Achilles-Heel-Final-Draft-Emily-Poag-498x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Emily Poag.\nIn Greek mythology, any site struck by lightning is considered sacred. By that logic, the Earth\u2019s land must be divine\u2014a whopping 90 percent of lightning strikes land, leaving only a measly ration for oceans worldwide. Thanks to a study recently published in Nature Communications, we now know the secret to this phenomenon. Above the ocean, wind and water interact to form sea spray: salty particles suspended in the air. Scientists in Israel, China, and the US discovered that this spray could reduce lighting by up to 90 percent.\nClouds are composed of droplets that typically form when water vapor condenses onto aerosols. The term \u2018aerosol\u2019 refers to any small solid particle suspended in the air. Previous research found that \u2018fine aerosols,\u2019 such as smoke, can encourage lightning formation by serving as sites for condensation. This has been used to link rising rates of air pollution to increased lightning.\u00a0\n\u201cLightning is sort of the byproduct of clouds,\u201d said Yannian Zhu, study co-author and associate professor at Nanjing University. \u201cNormally, if you don\u2019t have clouds, you don\u2019t have lightning.\u201d\nFor clouds to become \u2018electrified,\u2019 they must reach a certain elevation. Rising currents of air\u2014updrafts\u2014help clouds grow to a height at which the temperature is below zero degrees Celsius. At this level, water droplets can freeze into ice crystals. Some of these ice crystals then collect the rest of the water droplets, forming larger sleet-like particles known as \u2018graupel.\u2019 The other ice crystals remain small and positively charged and continue to be pushed by updrafts toward the top of the cloud. Meanwhile, the graupel descends, carrying a negative charge. Electrical charge is transferred from the crystals to the graupel when they collide. Over time, an electrical field builds from the constant transfer of electrical charges between the oppositely charged particles. After sufficient buildup, the power of the electricity is strong enough to penetrate through the atmosphere, discharging as a flash of lightning.\nOn land, fine aerosols are much more concentrated, largely due to air pollution, making them the main source for cloud formation. Over oceans, sea spray frequently serves as a condensation site, forming water droplets bigger and heavier than their fine aerosol counterparts.\u00a0\nFine aerosol particles are small and abundant, forming clouds with numerous small droplets. These droplets are slow to combine into raindrops, remaining small enough to ascend easily to a high enough level for freezing to occur. However, sea spray, which is considered a \u2018coarse aerosol,\u2019 has the opposite effect: large droplets form and quickly coalesce into rain.\nThe large salt particles in sea spray can absorb water quicker and easier, forming large droplets that eagerly collect other droplets. As a result, these clouds will rain out too soon before reaching the sub-zero temperature height at which ice can form and electrify the cloud. This phenomenon also helps explain why small rain showers are more frequent over the ocean than on land.\n\u201cIf you live beside the sea, you will see that there are many [rain] showers every day without thunderstorms\u2014just showering,\u201d Zhu said. \u201cIt is a cycle, water vapor becomes clouds, and then the clouds become rain [and so on] \u2026 this energy transition between surface and atmosphere is very fast.\u201d\nThe researchers drew upon over four years of satellite data measuring clouds, precipitation, aerosols, and meteorology. \u201cIn principle, people knew that the added sea spray particles enhanced rainfall, but they never had such comprehensive measurements from satellites to actually [demonstrate] the effect on a global scale,\u201d said co-author Daniel Rosenfeld, a meteorologist and professor at the Hebrew University of Jerusalem. \u201cIt\u2019s one thing to know that something, in theory, could happen; it\u2019s another thing to see that it is [in fact] really significant and has a large effect.\u201d This study ultimately differentiated the contrasting effects of fine and coarse aerosols on clouds.\u00a0\nCurrent weather prediction and climate models fail to consider the effect of sea spray on weather patterns. Knowing how aerosols can change the cloud\u2019s physical processes will enable us to monitor convective clouds more accurately and potentially artificially alter them to avoid natural disasters, such as hail and tornadoes. Simply by deploying the right aerosols into the air, the practice of \u2018cloud-seeding\u2019 has facilitated China\u2019s attempts to trigger more rainfall for agriculture.\n\u201cOur responsibility is to understand the whole aerosol-cloud interaction microphysical process and to give that knowledge\u2026to help people do future climate predictions more accurately,\u201d Zhu said. \u201cWe\u2019re trying to save the world in a different way.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/lightnings-achilles-heel/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: The Not So Forever Chemicals",
            "author": "Matthew Zoerb",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Zoerb_Fig_1-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nIn 2018, Robert Bilott filed a lawsuit against three major chemical companies, 3M, DuPont, and Chemours, on behalf of every American exposed to per- and poly-fluoroalkyl substances (PFAS). PFAS are used in many water-resistant products ranging from waterproof jackets to non-stick pans. Since 1951, hundreds of thousands of tons of waste containing perfluorooctanoic acid (PFOA), a specific type of PFAS, have been dumped into the Ohio River and spread throughout the global biosphere. The ongoing litigation alleges that these companies have spread PFASs into the bloodstreams of ninety-nine percent of Americans while withholding information about their harmful side effects. Unfortunately, PFAS are resistant to degradation, and due to their long-lasting environmental presence, they are known as \u201cforever chemicals.\u201d\nTraditional methods to break apart PFAS involve pressurized incineration at one thousand degrees Celsius. However, these techniques are costly and can spread the toxic compound into the atmosphere. A team at Northwestern University and UCLA recently discovered a new method to decompose PFAS. The researchers noticed an irregularity among the chain of tightly-bound atom clusters: a hydroxyl group, or a chemical group composed of oxygen bonded to a hydrogen atom. This group could be broken off when mixing PFAS with two common solvents: DMSO and sodium hydroxide. By targeting the weakest bond and sequentially disassembling the PFAS at only one hundred degrees Celsius, the study suggests it is possible to convert PFAS into environmentally harmless products efficiently. This technique has limitations since bulk quantities of DMSO are prohibitively expensive for widespread use. Still, this result suggests that pollution from PFAS may not truly be around \u201cforever.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/qa-the-not-so-forever-chemicals/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: A True Love Story: Mosquitoes x Us",
            "author": "Lea Papa",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Papa_Fig_1-500x345.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nMosquitoes are perhaps most well-known for causing 725,000 human deaths annually and being extreme nuisances. The blood-suckers appear and are attracted to unique human odors. They then pierce human blood vessels and feed.\nThe solution seems simple: to find a way to disable the mosquitoes\u2019 sense of smell. However, according to a recent Rockefeller and Boston University study on the mosquito olfactory system, it may not be so straightforward. When researchers deleted chemoreceptors\u2014channels on the mosquitoes\u2019 cells stimulated by human odors\u2014from the mosquito genome, they found that the mosquitoes were still attracted to humans.\nTypically, an animal\u2019s olfactory neurons allow it to smell and express one type of chemoreceptor that detects one odor. In the mosquitoes\u2019 case, researchers found that the antenna receptors detecting the human odor 1-octen-3-ol, a chemical in breath and sweat, are also stimulated by amines found on human skin and sweat. The expression of multiple chemoreceptor genes in olfactory neurons provides them with a fail-safe for finding human blood, even when their human-smelling sensors are blocked.\nFor this reason, simply removing or blocking olfactory receptors from the mosquito genome will do little to prevent them from detecting humans. Still, this finding may be a step toward finally breaking free from the age-old relationship between humans and mosquitoes.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/qa-a-true-love-story-mosquitoes-x-us/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Sky is for Everyone",
            "author": "Celina Zhao",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Zhao_Fig_1-500x315.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Public Domain Pictures.\nThe Sky is for Everyone: Women Astronomers in Their Own Words is a newly published collection of autobiographical excerpts from renowned women in astronomy, detailing their challenges and triumphs in this historically male-dominated field. It features two prominent Yale astrophysicists: Meg Urry, Israel Munson Professor of Physics and Director of the Yale Center for Astronomy and Astrophysics, and Priyamvada Natarajan, Joseph C. and Sofia C. Futon Professor of Astronomy and Physics and Director of Yale\u2019s Franke Program in Science and the Humanities.\nIn her chapter titled \u201cThe Gentlemen and Me,\u201d Dr. Urry speaks about the few times this field felt unwelcoming. As one of two women in her graduate astronomy program, she was never invited to weekly study sessions and was cruelly pranked with a Playgirl magazine by her male classmates. Dr. Natarajan\u2019s chapter focuses on her background, work, and personal journey through academia and how her love for science developed.\nWhat was your reaction when asked to contribute to this book?\nUrry: I actually told them I couldn\u2019t do it at first, but then shortly after Covid hit, while I was sitting at home, I was reflecting about where I was and how I\u2019d gotten there and thought, \u201cWow, this is really something I\u2019d like to do.\u201d\nNatarajan: I was very honored but also kind of surprised and intrigued because they made it explicit that they wanted something about my personal experience and journey, and I didn\u2019t think that would be something of interest.\nWhat was your writing process?\nUrry: In two days, I\u2019d actually written eighteen thousand words while the editors had only wanted three thousand. So, I spent time cutting it down\u2014the whole process actually inspired me to write and tell more of my stories.\nNatarajan: I like writing, and I do a lot of different kinds of it, but it was very challenging because I don\u2019t ever write explicitly about myself\u2026 It was also interesting to go over my path and look back\u2014I tend not to reminisce much as there is so much more science that I want to do.\nWhy do you think these stories are important?\nUrry: Sadly, I think it\u2019s because there hasn\u2019t been enough change. When I came to Yale in 2001, I was the only woman in the physics department faculty. Now we have six so there\u2019s been a positive change there, but I still hear younger women talking about similar experiences [that I talk about in the book].\nNatarajan: It was quite amazing to hear about how others had found their way into academia and what motivates them. It\u2019s so important for people to see that there\u2019s no one way to be a scientist\u2026. But what\u2019s really sobering is that you can see that a lot of women have had more challenging paths through intellectual life [than men], and it\u2019s important to see all the different kinds of struggles and how they persevered for the love of the subject.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/the-sky-is-for-everyone/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Worlds We Don\u2019t Realize",
            "author": "Kelly Chen",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Chen_Fig_1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of on Flickr.\nClose your eyes and take a deep breath. Imagine that you can suddenly hear the hum of two insects communicating, smell every scent trail, or even feel the Earth\u2019s magnetic field. Supersonic hearing, enhanced smell, or an internal sense of direction\u2014traits we think of as superpowers, but animals have long possessed them.\nJoin Ed Yong in his book An Immense World: How Animal Senses Reveal the Hidden Realms Around Us as he takes you on journeys you may literally never be able to see. For example, most animals can see ultraviolet (UV) light. With UV vision, rodents are better able to see birds in the sky, fish can easily identify plankton in water, and reindeer can comfortably find mosses and lichens to eat, all because of UV light detection. Yong\u2019s curiosity will pull you in as he shows you discoveries made by scientists over the years, as well as his own encounters with the animal world; his easy-going language yet detailed imagery transports you right to the middle of other animals\u2019 worlds while also teaching you about the science behind it all.\nAs you dive into the book, you\u2019ll learn about different Umwelts\u2014a German term popularized by the Baltic-German zoologist Jakob von Uexk\u00fcll\u2014defined as \u201cthe part of [the animal\u2019s] surroundings that an animal can sense and experience\u2014its perceptual world.\u201d Yong writes, \u201cNothing can sense everything, and nothing needs to.\u201d From hearing about everything from snakes and elephants to mosquitoes and dogs, you\u2019ll realize that the sensory skill sets between animals are widely different, and for good reason. If we were to sense everything, Yong explains, \u201c[we] would be overwhelmed by the flood of stimuli, most of which would be irrelevant.\u201d The things we perceive are special to our Umwelt with unnecessary information filtered from our senses as we evolve.\nAnd though we might wish for some of the senses other animals possess, human senses have advantages. For example, humans are one of the most visually adept species. While we may not be able to track scents with our noses, we are one of the best species at differentiating between scents.\nHowever, most of all, we have the technology to explore the Umwelts of the world. \u201cThis ability to dip into other Umwelten is our greatest sensory skill,\u201d says Yong. Though we may never be able to truly experience the Umwelts of other animals, our growing knowledge enables us to understand and choose to see the world from realms that are not our own. By reading Yong\u2019s engrossing novel, the world as we know it suddenly becomes much more vibrant. As Yong puts it, \u201cIt is not a blessing we have earned, but it is one we must cherish.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/the-worlds-we-dont-realize/",
            "captions": [
                "These four great blue heron siblings had not yet left the nest and still relied on Mom and Dad for food.  Although they seem to be calmly and patiently waiting for now, as soon as one of the parents is spotted approaching the nest they become very agitated and started the competition for food with siblings.  When the adult actually arrives, the nestlings will grab it by the beak, face or neck and try to wrestle its head to the bottom of the nest to get at the food while fighting with the others for the biggest share.  It is surprising to me that they all still have their eyes.\n\nHeron Pond,  Williamson County,  Tennessee, USA.    May 14,  2019"
            ]
        },
        {
            "title": "Graduate Profile: Tyler Myers",
            "author": "Sophia Burick",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Organic Chemistry is one of the most notoriously difficult classes at Yale. Pre-med hopefuls and chemistry whizzes alike spend long nights learning reaction mechanisms and drawing energy-level diagrams. But last year, one Yale teaching fellow (TF) went above and beyond by making Organic Chemistry a much more manageable, even enjoyable experience. Tyler Myers, a Chemistry Ph.D. candidate in the Miller Lab, is making an impact on his students through his palpable passion for chemistry.\nMyers discovered his love for the subject in high school, spending three years learning chemistry with a phenomenal teacher named Ms. Bell. His interest brought him to the University of Wyoming, where he was a chemistry major. After one of his general chemistry exams, his professor, David Anderson, passed him a note which read: Big-T, you should talk to me about research! \u201cResearch was completely foreign to me\u2014but it was one of the best experiences I\u2019ve ever had,\u201d Myers said. In Anderson\u2019s lab, Myers synthesized complexes to help construct hydrogen-based fuel cells. After taking Organic Chemistry with Robert Corcoran and loving it, Myers switched to Michael Taylor\u2019s lab, where he worked on selective modifications of the amino acid residue tryptophan in peptides and proteins.\nThe next stop for Myers was Yale\u2014as a graduate student in Scott Miller\u2019s lab. He remembers sitting in the airport before flying to New Haven for an admitted students visit when he saw that the Miller Lab had recently published a paper on the selective modification of Geldanamycin, a biologically active natural product. \u201cLate-stage diversification of natural products was fascinating to me,\u201d Myers said. While at Yale, he attended a meeting with Miller and heard more about his research. \u201cAll I remember was that my chest got really fuzzy,\u201d Myers said, \u201cI knew that this was the place for me.\u201d\nNow, Myers researches asymmetric catalysis\u2014working to preferentially synthesize one enantiomer of a chemical compound over the other. Enantiomers are chemical structures that are non-superimposable mirror images of each other, and it can be challenging to selectively synthesize one enantiomer of a compound. \u201cThe most common example we use is our hands,\u201d Myers said, \u201cJust how you can write better with one hand, drugs experience a very similar phenomenon with biological activity, where one enantiomer of a drug is often more biologically active than the other.\u201d Myers, now a third-year Ph.D. candidate, recently received the prestigious NSF Graduate Research Fellowship for his potential to contribute to the field of chemistry and broaden access to science and research.\nMyers is equally excellent in his work as a teaching fellow. As students in First-Year Organic Chemistry, CHEM 174, last fall will tell you, Myers was a saving grace. He has loved teaching since he was an undergraduate, working as a tutor, a teaching assistant, and even traveling across Wyoming to deliver engaging scientific demonstrations to students to encourage them to pursue a STEM education.\n\u201cI thought being a teaching fellow would be great practice since I want to go into academia, and it was another opportunity to interact with students. It was really fun. I met some phenomenal students that are really passionate,\u201d Myers said. His work as a TF won him a Yale Prize Teaching Fellowship\u2014one of the highest honors a graduate student at Yale can receive. He was nominated for the award by the many appreciative students in CHEM 174. \u201cTyler was a great TF and also such a great mentor. He encouraged me to pursue chemistry research and was a friendly face this summer when I was in a lab near his,\u201d said Lizbeth Lozano, one of Myers\u2019s past students.\n\u201cI got to read the reviews that students wrote,\u201d Myers said, \u201cI remember leaving work just ecstatic.\u201d Knowing his students truly enjoyed his work as a teaching fellow was the most rewarding thing for Myers.\nAfter graduating, Myers hopes to become a professor at a primarily undergraduate institution. His goal is to dismantle the reputation of organic chemistry as an intimidating, inaccessible science and help others appreciate the beauty and potential it holds. \u201cI am fortunate to have so many great opportunities and supportive people in my life,\u201d Myers said, \u201cI think teaching at a primarily undergraduate institution would be an excellent opportunity to give back to the community.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/graduate-profile-tyler-myers/",
            "captions": []
        },
        {
            "title": "Undergraduate Profile: Shervin Dehmoubed (YC\u201925)",
            "author": "Sherry Wang",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wang_fictureP1000174-262x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Shervin Dehmoubed\u2013\u2013sophomore at Yale and stellar tennis player\u2013\u2013is also a CEO, having started his entrepreneurial journey when he was just fifteen. He launched a children\u2019s toy company specializing in products for kids diagnosed with ADHD/ADD, making a six-figure revenue within the first three years. This success fueled his following projects, Pik \u2018le\u2019 Ball, a pickleball accessory and clothing line, and a software company that built iOS apps for health and fitness. These experiences gave him the unique perspective and required expertise to launch his latest and most successful company, EcoPackables.\nDehmoubed was shocked to discover how much plastic waste even a small brand could produce when working on Pik \u2018le\u2019 Ball. Thus, he launched a sustainable packaging company that sells packaging films made from recycled or compostable materials, aiming to find solutions to promote sustainability within the private sector. \u201cThis was during Covid, and e-commerce was booming, so I decided I wanted to do something about this,\u201d Dehmoubed said.\nThe key technology is a compostable film made from a blend of polylactic acid (PLA) and a bio-based polymer (PBAT). These films could eliminate \u201cgreenwashing\u201d when an organization spends more time and money marketing itself as environmentally friendly than minimizing its environmental impact. PLA and PBAT are already used in biodegradable plastics such as waste bags. However, to make the films more suitable for packaging, Dehmoubed made them thicker and added certain proportions of different renewable elements to make them more sustainable. Now, their compostable film, called D42, is certified to degrade in home compost environments within 180 days and industrial compost environments within 90 days. Dehmoubed claims that EcoPackables is the most sustainable packaging company because they have the highest proportion of renewable resources (organic materials) to PBAT while still breaking down into organic biomass, water, and CO2, leaving behind zero plastic waste. \u201cI\u2019ve been very passionate about reducing plastic waste and stopping climate change. Specifically, how you can reduce your carbon footprints based on how you produce packaging material and handle proper end-of-life disposal,\u201d Dehmoubed said.\nHistorically, the packaging industry has been one of the most commoditized\u2013\u2013no company owns more than five percent of the market share. For a younger entrepreneur like Dehmoubed, building a brand in such an environment was challenging. Thus, he built a brand focused on sustainability instead of being a direct competitor of packaging companies. He was not interested in cutting costs or taking shortcuts to increase the bottom line, or the company\u2019s net profit, but rather wanted to hit the triple bottom line: good for the customer, good for the planet, and good for the company. His biggest challenge was selling his vision to traditionally archaic buyers hyper-focused on net profits. However, by convincing companies to look towards the younger generations for future sustainable operations, Ecopackables is being used by brands such as Ivory Ella, Beats, and Bud Light.\nDehmoubed envisions that EcoPackables will become a globally recognized brand for its sustainable practices. He hopes to become a one-stop shop for brand-oriented companies looking to clean up their operations. Currently, they have two more products in the works: food-safe packaging developed using post-consumer recycled content and curbside recyclable Ocea\u2122 brand polythene bags. The thin Ocea\u2122 plastic bags are made from Forest Stewardship Council certified mixed paper, ensuring that products come from responsibly managed forests that provide environmental, social, and economic benefits. Ocea launched their product earlier this year to eliminate plastic from accumulating in our oceans. \u201cPackaging is extremely important because it\u2019s the first part of your product the customer interacts with. And we know how important first impressions are,\u201d Dehmoubed said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/undergraduate-profile-shervin-dehmoubed-yc25/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Counterpoint: Eye Spy: A New Way of Detecting Alzheimer\u2019s",
            "author": "Abigail Jolteus",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Jolteus_Fig_1-334x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nImagine progressively losing the memories you cherish deeply, eventually no longer being able to learn new things, read and write with ease, or recognize loved ones. People with Alzheimer\u2019s, a form of dementia, lead lives with these worsening symptoms. With no cure and a short lifespan after diagnosis, Alzheimer\u2019s is a devastating, progressive neurological disorder that affects memory, behavior, motor skills, and thought processes.\nInitially, scientists could only diagnose Alzheimer\u2019s by performing an autopsy after death. Since then, many advances have been made. Clinicians can now detect early signs using remarkable technology, such as positron emission tomography (PET), a type of diagnostic technology used to show the metabolic activity of the brain, and various tests on cerebrospinal fluid (CSF) \u2014 the clear, watery fluid around the spinal cord and brain. Some hallmarks include decreased glucose uptake and the accumulation of beta-amyloid plaques, proteins that aggregate between neurons and disrupt their normal function. However, these methods can be quite invasive. For example, a PET scan requires the injection of radioactive material into the bloodstream, and the extraction of CSF involves inserting a needle into someone\u2019s back. These diagnostic tools are uncomfortable and expensive, making these procedures inaccessible to many people.\nAlzheimer\u2019s is characterized by plaques of beta-amyloid in the brain, yet new evidence suggests these plaques also accumulate in the retina. The retina, which is closely related to brain tissue, is routinely examined to detect eye diseases through a process called fundus photography or digital retinal imaging. A similar technique may soon provide a non-invasive and cost-efficient method of identifying early signs of Alzheimer\u2019s.\nRobert Vince, Swati More, and their colleagues at the University of Minnesota discovered a technique called hyperspectral imaging. They used the technique to detect clumps of beta-amyloid in mouse retinas at the early stages of the disease. In hyperspectral imaging, standard eye examination equipment, like an autorefractor, is combined with a hyperspectral camera\u2014a special camera that captures light from across the electromagnetic spectrum. Then, artificial intelligence compares the data-rich images with other images with similar physical properties associated with Alzheimer\u2019s disease.\nClinical trials are currently underway across North America to test the efficacy of this technique, and there have already been promising results. In a cohort of 108 participants who were either at risk of Alzheimer\u2019s or already had preclinical Alzheimer\u2019s, the technique correctly identified people with beta-amyloid plaques in their brains eighty-six percent of the time. PET scans and CSF results validated these retinal screening tests. They also observed beta-amyloid clumps in the brain at later stages, suggesting that the presence of beta-amyloid plaques in the retina may also be an early detection marker in humans.\nThough these results are promising, more studies with diverse participants and larger cohorts are needed before physicians can use this technique as an official diagnostic tool. Moreover, some researchers have noted that amyloids can be present in the retinas of people that do not develop signs of cognitive decline.\nWhile there are issues with this technique that need to be resolved, early detection of Alzheimer\u2019s using retinal imaging has the potential to become a widely-used diagnostic tool. Other retinal signs may help with the early detection of Alzheimer\u2019s, including retinal thickness and changes in blood vessels. A longitudinal trial called Atlas of Retinal Imaging in Alzheimer\u2019s Study (ARIAS) is examining these retina-based biomarkers in hopes of improving the early diagnosis of Alzheimer\u2019s. This project is still in the recruiting phase, but if proven successful, researchers may seek to develop more types of retinal-based tests. Earlier treatment of Alzheimer\u2019s may alleviate symptoms and help scientists better understand the pathogenesis of this condition with the hope of developing a cure.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/counterpoint-eye-spy-a-new-way-of-detecting-alzheimers/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Hidden Histories: Bessie Blount Griffin",
            "author": "Ilora Roy",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Said_YSM-Bessie-Blount-Griffi-Noora-Said-348x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Noora Said.\nBessie Blount Griffin was an inventor, nurse, physical therapist, forensic handwriting and document analyst, and avid public speaker. However, unlike many in her field, she was Black, left-handed, and a woman. Blount was born on November 24, 1914, in Hickory, now Chesapeake, Virginia, to parents George Woodard and Mary Elizabeth Griffin. In elementary school, her teachers constantly reprimanded her for writing with her left hand. After having her knuckles rapped countless times, Blount protested: if it was wrong for her to write with her left hand, then it must also be wrong to write with her right! She then taught herself how to write with her teeth and toes in response to her teacher\u2019s disapproval.\nBlount studied nursing at Keney Memorial Hospital and physical therapy at Union Junior College and Panzer College of Physical Education and Hygiene. After obtaining her degree from Union, Blount became a licensed physiotherapist at the Bronx Hospital in New York, where she helped World War II veterans with amputated limbs. She was not your average nurse. In addition to supporting amputee patients in recovering their balance and mobility, she also helped them reclaim their independence. Blount took a page out of her own book and taught the veterans how to write with their teeth and toes. \u201cYou\u2019re not crippled, only crippled in your mind,\u201d she said.\nShe continued to look for ways to give veterans autonomy over their bodies, for example, inventing a device called the Invalid Feeder to help. Patients would bite down on a tube that would activate a motor, and food would dispense through a mouthpiece in the shape of a spoon. The device shuts off after each cycle to ensure the patient would not choke. While Blount continued to work as a nurse during the day, she would work late hours in the night from 1:00 AM to 4:00 AM building her instruments. Blount did not have a degree in engineering, yet she was able to construct ingenious devices because of her passion for helping patients.\nContinuing to invent, Blount created more apparatuses, such as disposable kidney-shaped basins to dispose of bodily waste and the \u201cportable receptacle support,\u201d similar to the \u201cinvalid feeder,\u201d with the addition of a neck brace with a bowl. The latter received a patent under her name on April 24, 1951, making Blount one of the first officially recognized inventors in physical therapy. She had many other accomplishments from becoming a handwriting analyst for several police departments\u2013\u2013including Scotland Yard in England, where she was the first Black American woman to have trained there\u2013\u2013to starting her own consulting business in her hometown.\nHowever, Blount\u2019s accomplishments did not come without challenges. After inventing the \u201cinvalid feeder,\u201d she wanted to bring relief to others around the country, but the US military refused to pay Blount a fair amount. She also tried to sell her devices to the American Veterans Association, but they did not want to support her due to her race and gender. Blount wanted to prove that her inventions themselves were impressive and did not want to tie her inventions to her identity as a Black woman. She was not driven by financial motivation but rather by the idea of helping society progress through her innovations. Even after being turned down by many different organizations, she eventually donated the \u201cinvalid feeder\u201d to France, where the French used it in military hospitals. Belgium also bought her disposable basins.\nAt first glance, Bessie Blount Griffin is an accomplished inventor and nurse. However, to those who know her story, she is a humanitarian who worked for the advancement of society. Today, her influence on the medical field can be seen in hospitals worldwide. Her basins inspired many of those that are used today, and European hospitals still use the \u201cinvalid feeder.\u201d Despite the challenges, discrimination, and inequity she faced as a Black woman, Blount leaves a long-lasting legacy as her inventions continue to benefit mankind.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/hidden-histories-bessie-blount-griffin/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Forgotten Victims of Fracking",
            "author": "Aiden Wright",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wright_fracking_graphic-332x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of David R. Tribble.\nAs the consequences of unconventional oil and gas development (UOGD) devastate our environment, children are paying the ultimate price. This rapidly expanding form of nonrenewable energy, also known as hydraulic \u201cfracking,\u201d involves injecting pressurized water into the ground to create fissures and release natural gas. Researchers have found that, throughout this complex process, chemical contaminants associated with leukemia are present in both the injected water and subsequent wastewater, as well as UOGD-related air emissions.\nIn order to further study this phenomenon, a team of researchers at Yale, including Nicole Deziel and Cassandra Clark, performed a case-control study of children diagnosed with leukemia between the ages of two to seven in Pennsylvania from 2009 to 2017. They began their research by compiling cases from the Pennsylvania Cancer Registry and linking them to birth records. To assess exposure to UOGD air and water contaminants, the researchers considered two exposure windows: the period from three months before conception to one year before a cancer diagnosis, known as the \u201cprimary window,\u201d and the period from three months before conception to birth known as the \u201cperinatal window.\u201d\nThe team found that children living near UOGD had up to two or three times the likelihood of developing leukemia. Their findings also indicated that children could be impacted by UOGD-related contaminants in the womb. \u201cSince we published our research, we have received several invitations to speak to community groups and non-governmental environmental organizations,\u201d Deziel said. \u201cThat has been rewarding because it shows our work has value and relevance to public health policy.\u201d\nTheir research adds to a growing body of work on UOGD exposure used to influence policy. \u201cMy goal is to continue to conduct policy-relevant research that highlights impacts to underrepresented and vulnerable communities,\u201d Clark said. While no policy changes have been made in response to their findings, one thing is for certain: these researchers know that their work is far from done. In the future, they hope to conduct a similar study in a larger population and continue examining water as a route of exposure to UOGD.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/the-forgotten-victims-of-fracking/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Deep Learning Brings Eyesight Into Focus",
            "author": "Katherine He",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/He_Figure2-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nYou notice a building out of the corner of your eye, but something is off: it looks misplaced. You walk closer and notice cracks in some windows. A few more steps, and you come face-to-face with a splattering of stains on the window tiles. To better inspect each feature of the structure, we intuitively zoom in by walking closer. But what happens when we swap out our looming building for something much smaller? For instance, consider the human eye.\nLike the building\u2019s range of imperfections, eye imaging defects can occur at every level: an uncentered image, vessels that appear detached, and noise around minuscule capillaries. These defects challenge the otherwise promising optical coherence tomography angiography, a technique that separately zooms in on each layer of an image. In his recent publication in Scientific Reports, researcher Rahul M. Dhodapkar of the Yale School of Medicine Department of Ophthalmology developed a deep learning model to accurately classify whether medical images are high-quality enough for different clinical use cases despite defects. The model was trained on 347 scans collected by the Yale Eye Center from 134 patients, representing a diverse group with and without retinal diseases.\n\u201cAn important thing about research in medicine [is that] you have to always remember why you\u2019re doing it,\u201d Dhodapkar said. In this case, image defects may force patients to undergo imaging multiple times, but not everyone lives near an academic setting or hospital where repeated imaging is accessible. \u201cWe can make specialized models for each clinical purpose and integrate them directly into the image capture technology,\u201d Dhodapkar said. These advancements would provide technicians with real-time feedback to decide whether they should retake an image. Through its plethora of insights, this research provides a framework to improve how diverse communities receive diagnoses and treatments in the medical system.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/deep-learning-brings-eyesight-into-focus/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Cytochrome Nanowires: An Electronic Freeway",
            "author": "Lawrence Zhao",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Zhao_Figure2-500x396.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nThe future of technology might be in bacteria. Geobacter sulfurreducens, a species of soil bacteria, survives by growing protein filaments called cytochrome nanowires. These structures are hidden highways, shuttling electrons at incredible speeds over hundreds of nanometers, but the mechanism behind the nanowires\u2019 high conductivity has been a mystery. Previous work showed that heme groups inside the proteins were responsible. A team of Yale researchers, led by Professor Nikhil Malvankar and graduate student Peter Dahl in the Department of Molecular Biochemistry and Biophysics, investigated how hemes transport electrons. Their data ruled out electron \u201ctunneling.\u201d Instead, the nanowires work through \u201chopping,\u201d where electrons and electron holes (spaces where there could be an electron but aren\u2019t) jump from place to place\u2013a phenomenon similar to semiconductors.\nWhile semiconductors become worse at moving electrons at lower temperatures, the nanowires showed a different trend\u2014after cooling, the wires became three hundred times more conductive than at room temperature, puzzling the researchers. \u201cWe were chasing down different hypotheses for a few years,\u201d Dahl said. \u201cThen Victor Batista [Professor of Chemistry at Yale] suggested looking at the hydrogen bonding network around the hemes.\u201d\nHydrogen bonds play a key role in influencing protein structure. Dahl found that the \u201cmagical\u201d increase in conductivity upon cooling vanished after experimentally weakening hydrogen bonds by replacing hydrogen atoms with deuterium, a heavier form of hydrogen. Then, Dahl ran computer simulations and discovered that changes in hydrogen bonding at colder temperatures caused the hemes to flatten. This resulted in a stronger electric field, leading to higher conductivity. The predicted heme geometry matched experimental data. \u201cIt\u2019s a great example of why we need both experiments and computation working together,\u201d Malvankar said. Because bacterial nanowires are sensitive to temperature changes, these nanowires could be implemented in biological sensors or sustainable electronics in the future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/cytochrome-nanowires-an-electronic-freeway/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Sun As A Water Purifier",
            "author": "Pranet Sharma",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Sharma_disinfection_graphic-500x363.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of M. Kowalski.\nWater insecurity is one of the most pressing problems in developing countries. In places where waterborne diseases are prevalent, it is essential to find sustainable, cost-effective solutions to disinfect water. Even though pathogens in water can be inactivated or removed by adding chlorine, boiling, or filtering, these techniques are often expensive or resource-intensive. Using the sun to purify water, by comparison, has the potential to be an affordable and energy-efficient solution. However, at the moment, there are no clear and widespread techniques to use sunlight as a disinfection mechanism.\nMotivated by a desire to develop viable techniques to combat water insecurity in developing countries, Professor Jaehong Kim, a Henry P. Becton Sr. Professor of Engineering in the Yale Department of Chemical and Environmental Engineering, co-led a study with graduate student Inhyeong Jeon to systematically compare various methods to disinfect water using the sun. \u201cWe wanted to explore how different technologies capture sunlight, transform photon energy to disinfecting power, and affect microbial inactivation via different mechanisms,\u201d Kim said.\nThe study examined the feasibility of five methods of disinfection. The first method involves using semiconductors to generate reactive oxygen ions, thereby disinfecting the water. The second method uses dyes that absorb photons to generate singlet oxygen, another oxygen ion that can effectively inactivate viruses. The third method involves using a solar cell to power UV-producing LEDs to disinfect the water. The fourth method utilizes distillation, evaporating the water over time through light-absorbing materials and collecting it in a receptacle. The fifth method involves pasteurization, keeping the water above pasteurization temperature for a short period of time to inactivate pathogens.\nEach method was tested extensively by measuring the parameters of disinfection capacity over different trials. A quantitative score was assigned to each technique, which was then used to compare the efficacy of each one, taking into consideration various uncertainties associated with geographical variations and the availability of existing data. The comprehensive analysis revealed that pasteurization is the most effective method to disinfect the water. \u201cIt seems to be much more reliable than others when all the decision points are considered as a whole, which is somewhat surprising,\u201d Kim said. Regardless, he was optimistic that future work on the topic could extend the study. Kim\u2019s research group is currently developing various prototypes to disinfect water using the sun to realize their goal of combating water insecurity.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/the-sun-as-a-water-purifier/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Clearing It Up: Unfogging the Physics of Glass Formation",
            "author": "Robin Tsai",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Tsai_Figure1-500x348.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Sebastian Kube, et al.\nDespite their prevalence, the complex and diverse nature of metallic glasses remains poorly understood. Particularly, the amorphous and random atomic structures of metallic glasses clash with our conception of metals as orderly and crystalline\u2014and for a good reason. Metals are ordinarily crystals, possessing an atomic spatial symmetry, and are thus much stabler and form easily. On the contrary, metallic glasses, being glasses, are inherently disordered and unstable\u2014and, therefore, very difficult to create. In fact, for most metallic liquid mixtures, it often takes a cooling rate of trillions of kelvins per second to freeze the disordered atoms into a metastable metallic glass. However, a select few mixtures\u2014narrowly defined compositions of some alloy systems\u2014can be viably formed in bulk.\nSo, what determines these alloys\u2019 glass-forming ability (GFA)\u2014how easily they turn into glasses? Fragility, the relation between the temperature and viscosity of the alloy\u2019s glass-forming liquid state, has long been thought to be a determinant of GFA. If the atoms have to trudge through a more viscous medium while cooling (lower fragility), it should take longer to array themselves, increasing GFA. Interestingly, it appears that this logic does not align with recent findings.\nIn a recent publication in Nature Communications, lead author Sebastian Kube (Yale SEAS PhD \u201921), now a postdoc at UC Santa Barbara, and Jan Schroers, Yale Professor of Mechanical Engineering & Materials Science, helped develop a pioneering technique, the film inflation method (FIM), to study this relationship. Using sputtering \u201cplasma\u201d guns, they deposited magnesium, copper, and yttrium atom-by-atom onto a silicon substrate divided into wafers. With these synthesis conditions, the magnesium-copper-yttrium alloys formed glasses over a much wider composition range\u2014over which the viscosity can then be probed. Moreover, this technique synthesized a gradient with large numbers of composition ratios in parallel, a task that would have taken lifetimes with previous methods. With this technique, they applied a constant gas pressure to the freestanding metallic films, inflating them into a bubble. Using lasers, they delicately measured the bubble\u2019s height over time and, in turn, were able to infer information about the respective compositions\u2019 fragilities.\nTo the shock of Kube, Schroers, and their colleagues, fragility was hardly a determining factor of GFA. \u201cI still believe in it. I believe that\u2026 a [lower fragility] liquid is the better glass former,\u201d Kube said. Indeed, the stark contradiction with the assumed importance of GFA, a mainstay of the metallurgy community, underlines just how nebulous the nature of metallic glasses remains to materials researchers. Going forward, Kube hopes to re-explore this problem in greater detail. \u201cMy long-term plan is to build a better version of this [experiment]\u2026 for ten or so alloy systems,\u201d remarked Kube, \u201cand we will get much more information\u2026 about how fragility affects GFA and interacts with other properties.\u201d Indeed, Kube is eager to elucidate this mystery of glass-forming ability and fragility, an undertaking with major implications for additive manufacturing and materials engineering\u2014of course, with only more twists and turns to be expected along the way.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/clearing-it-up-unfogging-the-physics-of-glass-formation/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Best of Both Worlds: Hybridizing Photosynthesis for Drought Resistance",
            "author": "Zara Ranglin",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Rangling_Photosynthesis_Figure1-500x331.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nThere is a phantom menace in the room\u2014climate change is insidiously altering our lives. Among the direst of threats is worsening droughts: as temperatures rise, surface water evaporation increases, quickly drying soil and diminishing the yield of essential crops. However, a team of Yale researchers has found a potential anti-drought mechanism hidden within the leaves of purslane (Portulaca oleracea), a common succulent that may someday be called the \u201csuper plant\u201d of drought.\nPhotosynthesis involves an important step known as the Calvin cycle, a series of reactions that fix carbon dioxide (CO2) to form sugar. During drought, plants close leaf pores to decrease water loss, preventing CO2 from entering the leaves. The resulting CO2 starvation causes rubisco, the carbon-fixing enzyme of the Calvin cycle, to preferentially bind oxygen. This inefficient process, termed photorespiration, decimates many crops.\nHowever, some plants employ a clever solution: carbon-concentrating mechanisms C4 and Crassulacean acid metabolism (CAM). These pathways recruit enzymes to perform extra steps before the main Calvin cycle, making CO2 readily available so that rubisco can work efficiently without losing resources to photorespiration.\nSpecifically, C4 allows plants to maintain high photosynthetic efficiency at elevated temperatures, whereas CAM allows for extended survival in dry conditions. To accomplish this, C4 separates initial CO2 fixation from the Calvin cycle spatially between different cell types during the day, while CAM separates these processes temporally between night and day in the same cells.\n\u201cBut because they\u2019re using the same enzymes, and in C4 they\u2019re expressed in very spatially explicit parts of the leaf during the day, while in CAM they\u2019re expressed at night, it was thought that they couldn\u2019t be compatible. How can you evolve both of these things in the same leaf when you\u2019re recruiting the same enzymes but asking them to do different things?\u201d said Yale\u2019s Erika Edwards, Professor of Ecology and Evolutionary Biology and the principal investigator of the lab which published this research. It appeared to many in the field that integrating these mechanisms in a single plant\u2014an idealized adaptation that could be the best of both worlds\u2014would only occur through spatial isolation.\n\u201cBut [in purslane] they actually are totally integrated, operating in the same cells,\u201d said Edwards, \u201cand what\u2019s really cool is that during the day, you can get the C4 cycle turning on and doing its thing, and at night have the CAM cycle upregulated in the same cell population using a different set of enzymes. And then, in the two parts of the biochemical cycle that overlap, we discovered that CAM metabolites, the intermediate molecules that it\u2019s making in the pathway, are actually just shunted right into the C4 cycle. So, CAM is actually feeding C4 photosynthesis.\u201d\nThis revelation opens new ambitions: engineering drought-resistant crop plants that integrate C4, CAM, or both. Rice, for example, is a C3 plant with no resistance adaptations, while corn and sugarcane are C4 plants that could be made to incorporate CAM mechanisms. There are technical challenges to such manipulation, but overcoming them could bring us one step closer to a food-secure future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/the-best-of-both-worlds-hybridizing-photosynthesis-for-drought-resistance/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Robot\u2019s Body Image",
            "author": "Yamato Takabe",
            "authorLogo": "",
            "date": "January 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/takabe-500x262.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nHow do people catch balls flying through the air with unpredictable trajectories? All humans have spatial awareness of their arms and automatically calculate how each joint needs to move to meet the ball at exactly the right time and place. Although this seems intuitive, many complex calculations occur in the brain to make this happen. For example, the glove size, length of each arm bone, the degrees through which each joint has to rotate, and the speed of motion must be accurately calculated for the catch to be successful. To translate this skill to robots, there is one essential factor: self-awareness.\nIn a recent Science Robotics paper, Boyuan Chen, formerly a PhD student at Columbia University\u2019s Creative Machines Lab and now an Assistant Professor at Duke University, created a visual self-modeling robot. Chen made a physical model to map the coordinate network of the arm and made a kinematic model to create equations for the movement of the arm for each coordinate point. Incorporating machine learning, Chen designed these self-modeling robots to build on the previously obtained information continuously. Once the robot determines its exact dimensions and potential movements, it can move on and complete complex tasks instead of relearning everything. Chen\u2019s robot can also map its future activity to predict what will happen in real-time to perform the exact movement needed to execute the tasks.\nHowever, just self-modeling is not enough. For practical use, these robots also need to have spatial awareness and be able to model outside variables to adapt to each specific scenario. For example, the robot would need to be able to recognize a motor malfunction, adapt to execute its tasks, and recalculate its movements. Chen used a red ball hanging around the robot to test its ability to recognize and touch objects. Because the robot can detect the ball at a specific position, it can perceive where the ball is relative to the robot and make a model of itself (self-image). Humans can improve this self-image by designing robots to be aware of outside variables as well, which is essential in the real world to avoid breaking objects. In this paper, the ball serves as a test for the robot\u2019s self-awareness and environmental awareness, indicating its ability to detect a 3D object around it.\nChen\u2019s goal for the future, through his new General Robotics Lab at Duke University, is to create \u201cgeneralist\u201d self-modeling that can deal with any task, whether that be playing catch or watering a plant, as opposed to current-day \u201cspecialist\u201d robots that focus on specific tasks. Robots can reach maximum efficiency by learning to map the outside world. If they can attain this skill, robots can execute a vastly more diverse set of tasks, increasing their potential to improve our lives.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/a-robots-body-image/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Jellyfish\u2019s Secret To Everlasting Life",
            "author": "Joey Tan",
            "authorLogo": "",
            "date": "January 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Tan_jellyfish_graphic-500x333.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Maria Pascual-Torner.\nMany people\u2014and organisms\u2014are familiar with the cycle of life.. Everything goes through various developmental stages\u2014from birth to adulthood, aging, and death. In each case, an organism\u2019s life ends the same way. Experiencing death is inevitable.\nThis is true for nearly every single living thing except one: the jellyfish Turritopsis dohrnii.\nTurritopsis dohrnii (known as T. dohrnii for short) is currently one of the only biologically immortal beings in the world. As T. dohrnii \u2018grows up,\u2019 it changes from a polyp (which is coral-like in appearance) to an adult jellyfish (technically called a medusa). But they don\u2019t eventually die of old age. Instead, they head in the reverse direction: shrinking into a blob of mass and reforming until they return to the early polyp stage. The jellyfish continues in this growth and reversal cycle for the rest of time.\nScientists have become fascinated with the mechanisms that allow T. dohrnii to be immortal. One of these scientists is Maria Pascual-Torner, a postdoctoral student at the University de Oviedo. She compared T. dohrnii and its close relative, Turritopsis rubra (T. rubra), another species of jellyfish that is genetically similar to T. dohrnii but is mortal. This research focused on comparing gene structure and gene expression related to aging between the two species by analyzing DNA samples between the two jellyfish and looking at RNA samples of T. dohrnii during its different stages of development. The goal was to find differences across the genomes, which could allow scientists to pinpoint why exactly T. dohrnii is biologically capable of being immortal.\nResults of the research showed that some mechanisms related to aging are more efficient in T. dohrnii compared to T. rubra and other species. Specifically, T. dohrnii has enhanced abilities in DNA repair and has strong pathways that allow cells to revert to their initial stages and de-differentiate, meaning that they don\u2019t have a specific role anymore and can become any type of cell.\nT. dohrnii also appeared to utilize what is known as the polycomb pathway, which essentially does the work of silencing particular genes that help with development. By stopping development, this pathway stops aging in its tracks. In the future, Pascual-Torner notes that her lab hopes to continue examining this pathway and learning how exactly the T. dohrnii silences these genes.\nResearching T. dohrnii was not easy. Both T. dohrnii and T. rubra are incredibly small organisms, so quantities of samples were limited. Because of this, it took more time to conduct an accurate and thorough analysis.\nThe implications of this research go beyond our knowledge of jellyfish. \u201cThese results are now candidates to keep studying aging. If there are some researchers that study Alzheimer\u2019s or cancer, for example, they could check for some of these variants. Our work tries to present new candidates to keep exploring [in these fields],\u201d Pascual-Torner said. However, the research is still very specific to this one species of jellyfish. \u201cAll the mechanisms that are in Turritopsis dohrnii make a synergy. All of them, in this kind of organism, work,\u201d Pascual-Torner said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/a-jellyfishs-secret-to-everlasting-life/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Life-Saving Sticker",
            "author": "Ximena Leyva Peralta",
            "authorLogo": "",
            "date": "January 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/StickerFinalWithBG-Kiera-Suh-347x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Kiera Suh.\nDiagnosing diseases can be tricky. How can doctors tell if a headache stems from a lack of sleep or something more serious? How can they see what is happening inside a patient? Peering inside the body can provide valuable, life-saving information for clinicians. Among the different imaging techniques, ultrasound\u2014a non-invasive, risk-free diagnostic tool\u2014stands out as a leading option. Researchers at the Massachusetts Institute of Technology (MIT) have developed a small, adhesive device that may revolutionize ultrasound technology.\nUltrasound devices use sound waves to create a picture of internal organs and tissues. An ultrasound probe emits high-frequency waves, which can travel through soft tissues but bounce off harder structures. An image is then created by a computer using these echoes. Thanks to its lack of radiation, ultrasound is the safest imaging tool, making it an ideal choice for continuous monitoring. However, current ultrasound devices are bulky and require an experienced clinician to operate the handheld probe. The clinician can only obtain a few images or videos in a regular ultrasound appointment, which typically lasts less than thirty minutes. Continuous imaging to monitor internal changes as the body moves on a day-to-day basis is not an option.\nThe team at MIT was able to transform the standard bulky, handheld ultrasound into a simple sticker by developing a brand-new bioadhesive that can comfortably attach a small ultrasound probe to the skin. The resulting bioadhesive ultrasound (BAUS) device can be attached to the body for up to forty-eight hours at a time to take high-quality images and videos of our body\u2019s activities\u2014blood vessels contracting, lungs expanding, stomachs digesting, and hearts pumping. The BAUS device can comfortably move with the person and capture the human body\u2019s natural dynamism.\n\u201cWearable ultrasound equipment can potentially revolutionize medical imaging,\u201d said Xuanhe Zhao, professor of mechanical engineering and civil and environmental engineering at MIT, who co-authored the Science paper that describes the BAUS device. \u201cMedical imaging is very important for diagnostic purposes. However, with existing medical imaging, the timescale is short. It\u2019s usually a few seconds or minutes\u2014just a snapshot.\u201d Continuous and frequent imaging of internal organs, over days or even months, could help clinicians more effectively monitor the health of patients and observe how diseases progress. It could also provide invaluable new data about the human body and lead to discoveries in medicine and biology.\nThe biggest challenge has been comfortably attaching an ultrasound probe to the body. \u201cIt\u2019s really [about] how you can integrate the ultrasound device with the body so it can give you long-term continuous imaging over days even under dynamic body motion,\u201d Zhao said. Previous wearable ultrasound devices were designed to be stretchable and move with the skin. However, this design sacrificed image quality and resolution despite the improved wearability. Moreover, sound transmission is vital to reach deep organs, such as the heart or stomach, and accurately image them. When using traditional ultrasound devices, clinicians apply a gel layer to prevent air pockets that can block the transmission of sound waves through the skin. However, these gels are not designed for prolonged use. \u201cThe liquid gel, if you put it in contact with the body, it can potentially cause acidification in a few hours,\u201d Zhao explained. Wearable ultrasound devices have used hydrogels\u2013\u2013a water-rich, goo-like substance\u2013\u2013in the past to solve this problem, but they get dehydrated and detach after only a couple of hours. Other devices use a rubbery material called an elastomer to attach the device to the skin. However, pure elastomer adhesives dampen sound waves, preventing them from reaching deep organs.\u00a0\nThe beauty of the BAUS device comes from a newly developed bioadhesive that combines the adhesion capabilities of an elastomer with the sound transmission abilities of a hydrogel. \u201cFor the bioadhesive part, we really spent lots of effort to develop a hydrogel-elastomer hybrid. It\u2019s very different from existing liquid hydrogels that can easily flow away,\u201d Zhao said. The new material consists of a hydrogel encapsulated by an elastomer to form a soft solid that can adhere robustly and comfortably to the skin, doubling as an adhesive and a gel to improve sound transmission. The researchers then embedded a thin high-performance probe in the hydrogel-elastomer to complete the BAUS.\u00a0\nThey tested its performance over forty-eight hours by imaging the various organs and tissues of fifteen test subjects. The BAUS device showed everything from how blood vessels\u2019 diameter increased as a subject stood up to how blood flow rate increased after thirty minutes of exercise to how the stomach emptied over two hours after a subject drank a glass of juice. It can also image the heart\u2019s four chambers and show how they change in size under continuous body motion. Furthermore, its success in imaging the lungs and the diaphragm means that the BAUS could potentially be used to monitor respiratory diseases, including COVID-19, and prevent further complications.\n\u201cI would say it\u2019d be easier for clinicians and maybe even patients to [use] this. It\u2019s like [adhering] a bandaid on the skin. And our lab is currently working to further simplify this process,\u201d Zhao said. Traditional handheld ultrasound requires qualified personnel and can be relatively expensive. Apart from continuous imaging, the BAUS device provides a simplified imaging process that could eliminate the need for an experienced operator and possibly even give patients the option of adhering the device by themselves. Hence, the BAUS could help increase the accessibility of ultrasounds.\nClinicians and healthcare professionals alike are excited about the broad medical potential of the BAUS device. Continuous imaging is essential for monitoring and tracking tumor growth and for early detection and treatment of cancer. Diagnoses for conditions that involve muscles, joints, and bones often require dynamic tests that cannot be performed using traditional ultrasound techniques. Cardiovascular diseases, which affect the performance of blood vessels and the heart, can lead to dangerous heart attacks that require ultrasound technology for diagnosis. A wearable ultrasound device could help alert those at higher risk for heart attacks of changes in their blood pressure in time to save lives. Ultimately, the BAUS opens up a world of possibilities in diagnostic practices and the continuous monitoring of patient health.\u00a0\nHowever, more steps must be taken before the BAUS device can be widely used and implemented. The existing device still needs to plug into a computer that collects and analyzes data. Zhao\u2019s team is working on making a portable wireless version that can truly move with a patient and be used even when there is no access to a computer. Zhao also describes that while the image quality of the BAUS probes is superior to other wearable devices, his team is still working on obtaining higher image resolution to match traditional ultrasound devices. Clinical trials must also be conducted before FDA approval. \u201cIn the first paper, we only tested healthy people. Now, we are applying this system to patients to study various diseases,\u201d Zhao said.\nThe development of the BAUS device is only the latest project that Zhao\u2019s team at MIT has been working on as part of their mission to advance science and technology at the interface of humans and machines. The team\u2019s expertise centers around materials science, mechanics, and biotechnology, but they regularly collaborate with experts in other fields and engage in intersectional projects. \u201cWe are really focused on addressing multidisciplinary challenges in health and sustainability. I believe we are solving some of the most important questions facing society, and I hope we can contribute to their solution,\u201d Zhao said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/a-life-saving-sticker/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Impact of Youth Arrests on Health in Society",
            "author": "Johnny Yue",
            "authorLogo": "",
            "date": "January 11, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/yue_image1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nArrests and incarceration have been pertinent issues in society for decades. Destiny Tolliver, an assistant professor in the pediatrics department at the Boston University Chobanian & Avedisian School of Medicine, has recently discovered a startling correlation between arrests and health. Tolliver and her team analyzed data from the National Longitudinal Study of Adolescent to Adult Health, examining cohorts from 1994 to 2018. They gathered information about participants\u2019 sex, race, and ethnicity, as well as the timeline and occurrence of arrests and different physical and mental health measures, including clinical biomarkers for diseases such as hypertension and diabetes.\u00a0\nHer analysis found that arrests made before the age of twenty-five were associated with higher rates of suicidal thoughts, depression, and worsening general health scores. On top of that, youth arrest and related policies didn\u2019t impact all communities equally. \u201cThere are well-documented racial and socioeconomic disparities in who experiences arrest, with Black children and children in lower-income households disproportionately impacted,\u201d Tolliver said.\u00a0\nCompounding the problem is the minimum juvenile prosecution age, which is currently only ten for the state of Connecticut. \u201cI think Connecticut can do more in this area by raising the minimum age at which children can be prosecuted in the juvenile court system to at least fourteen years of age, and instead focus on diverting youth to health-promoting systems in their communities,\u201d Tolliver said.\nSo what\u2019s next? Many states have already implemented changes to decrease the number of young people who are arrested. Tolliver hopes to research the effects of these modifications on youth health to create a model for other states to follow.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/01/the-impact-of-youth-arrests-on-health-in-society/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Shedding Light on the Nebulous",
            "author": "Robin Tsai",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/IMG_3218-487x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Yinuo Han & Peter Tuthill.\nImagine a rare, gigantic star scorching\u00a0 a second hot blue-white metallic star incessantly burning its fuel. Harsh cavalcades of photons shoot out from both stars in a dramatic, explosive dance. From both, spectacular stellar winds extend outwards, forming dust where the two winds collide. This phenomenon occurs in the eccentric WR140 binary system, providing astrophysicists with an exceptional example of cosmic dust formation.\u00a0\nWhile dust may be nothing more than a hygienic annoyance to us, it plays key roles in astrophysics, from the creation of nebulae to the formation of our solar system. Its complex geometries at colossal scales warrant further study on how they form. For the WR140 system, previous images by the Keck Observatory and, more recently, the James Webb Space Telescope showed a concentric shell pattern forming around the system. Interestingly, there appeared to be particular asymmetries in the dust shell geometry. The system\u2019s uniqueness eluded previous geometric models of both the shells and their features, especially models that assumed uniformity in dust expansion rates.\nEnter Yinuo Han, a graduate of the University of Sydney and now a third year at Cambridge University. Alongside University of Sydney professor Peter Tuthill, Han took the problem into his own hands\u2014quite literally\u2014by fitting and fine-tuning a novel model to account for the various intricacies of the system. His model included a plethora of new considerations about the WR140 system.\u00a0\nThe eccentricity of the orbit, a measure of how stretched an ellipse is, means that dust production increases as the stars draw closer together. However, fascinatingly, his model also predicted that as the stars draw too close, dust production comes to a near-complete halt, explaining the lack of dust structures in certain directions from the system. Moreover, by modeling asymmetries at the conical wind collision front\u2014the colliding boundary of both stellar winds which rotates over the orbit\u2014Han could reproduce further dust features, or a lack thereof, in the Keck data. Lastly, Han discovered that the dust structures accelerated as they expanded, which could be accounted for by the strong radiation pressure from the stars\u2019 light. With that, Han had one thing left to do: adjust parameters to fit the Keck imagery. \u201cIt turns out that most of the orbital parameters are tightly constrained by previous data, so [I was left] with only a handful of parameters to be tuned,\u201d Han said. His cumulative model now accurately reflected the dynamics of the WR140 dust shell, which had not been revealed by previous imaging data.\nWith the WR140 chapter coming to a close, asking about his future plans yielded a rather witty, humble answer. \u201cRight now, I just hope to complete my PhD,\u201d Han said. Han now works on dust in less conspicuous systems\u2014as he puts it, \u201cnormal star systems\u201d not unlike our own Solar system. In such systems, belts of planetesimals and asteroids continuously collide and grind each other into dust and gas that are observable. Han\u2019s techniques in analyzing the features and asymmetries of these dusty disks may help identify planetesimals and reveal the history of the system, such as how giant collisions and planetesimal collisions occur, a valuable contribution to exoplanetary science. This work, therefore, relates closely to understanding how planets form and evolve and their likelihood of hosting life, paving the way for explosive growth in our collective knowledge.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/shedding-light-on-the-nebulous/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Winding Synthetic Road to New Antibiotics",
            "author": "Nathan Mu",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Zoerb-1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Photo by Matthew Zoerb.\nSince the very first use of antibiotics, researchers have known about antibiotic resistance in bacteria. However, it takes a large investment of time and resources to discover novel antibiotics, which must be made cheaply available for patients. Therefore, the pharmaceutical industry has turned away from antibiotic development due to the immense input required and limited opportunity for profit, allowing antibiotic resistance to rise and our ability to fight infections to fall.\nOlivia Goethe and Mikaela DiBello, former and current graduate student researchers in Professor Seth Herzon\u2019s lab in the Yale Department of Chemistry, tackled this issue by seeking to create new antibiotics from one core molecule, pleuromutilin. Pleuromutilin is naturally produced by fungi, and its derivatives have been used clinically as antibiotics for skin infections and community-acquired pneumonia. Herzon\u2019s lab has also previously worked with pleuromutilins.\u00a0\nTheir recent paper, published in Nature Chemistry, presents a new total synthesis pathway to create pleuromutilin derivatives. This pathway is an improvement upon Herzon\u2019s previous method published in 2017, as well as pre-existing semisynthesis pathways, which rely on bacteria to synthesize products rather than commonly available chemical reagents. \u201cOur [new] synthetic route can access [unique] chemical modifications, like changing functional groups and changing ring sizes. But through semisynthesis, you\u2019re kind of blocked in. You can only modify the easily accessible functionality,\u201d Goethe said. Essentially, this new pathway allows for infinite new pleuromutilin derivatives to be produced by changing, removing, and rearranging atoms in a way that other synthesis methods could not. This total synthesis pathway is a powerful tool for learning about the properties of various pleuromutilin derivatives.\u00a0\nAnother key advancement was the ability to produce pleuromutilin derivatives in higher yields. Having enough product is vital for testing\u00a0 antibiotic activity. Obtaining viable yields of products was not an easy process, however. Each step in the synthesis pathway must be executed properly to give the correct molecule with the correct orientation or stereochemistry. Otherwise, subsequent reactions will result in little to no yield of product. This was one of the most challenging parts of the research process. It took Goethe months of going through the available literature and experimenting with different reactions to obtain the desired product in a reaction that initially gave the wrong stereochemistry. \u201cI had to have the right stereochemistry in order to make a usable amount of [the pleuromutilin derivative], which is why I definitely had to fix this, or I was screwed,\u201d Goethe said.\u00a0\nOut of all the pleuromutilin derivatives tested for antibiotic activity, many were surprisingly inactive, including many of the core derivatives proposed to improve metabolic stability, which would help the overall antibiotic effect. The most successful derivative contained a halogen, which was somewhat unexpected. \u201cIf you went into the ribosome site [of the bacteria], there wasn\u2019t really any indication that including a halogen there would be helpful,\u201d Goethe said. Successful pleuromutilin antibiotics usually bind to sites on bacterial ribosomes, but the chloride group had an unexpected effect that is worth more exploration. Work can also be done to find more compounds and, eventually, test the stability of pleuromutilin antibiotics once they enter the body. \u201cIt seems like, to me, medical chemistry is just a numbers game. You just need to make a ton of compounds and study them to get trends. There\u2019s a lot of interest in studying pleuromutilins, and we\u2019re contributing to the information available about what we can do to this molecule,\u201d Goethe said. Ideally, this research will lead to the straightforward synthesis of novel, cheap, and accessible antibiotics.\nGoethe found this research for her PhD to be extremely rewarding. \u201cI think that it\u2019s really cool, just something you made with your hands from stock materials can be used to kill bacteria,\u201d Goethe said. Now, Goethe works at Gilead Sciences, a biopharmaceutical company. She works in process chemistry, preparing materials for clinical phase trials, which test previously experimental treatments in human participants. \u201cI think that my ideal dream [job] would be that I\u2019ll combine the experience that I get here [at Gilead] in drug development with the passion I had for antibiotics, and maybe once I get a couple of years of experience, I can help antibiotic companies actually start to make some more drugs,\u201d Goethe said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/the-winding-synthetic-road-to-new-antibiotics/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Optimistic Results for RSV Prevention Strategies",
            "author": "Madeleine Popofsky",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/2369228615_9d042a4c1a_c-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nRespiratory syncytial virus (RSV), a deadly respiratory virus, has swamped hospitals globally. \u201cMost of the [Connecticut] hospitals are packed, and they need to build tents outside some hospitals to meet [the demand of] the children who are infected for RSV,\u201d said Zhe Zheng, a PhD candidate at the Yale School of Public Health. Critically, the virus has no vaccine or other effective, widely accessible prevention method.\nHowever, Zheng\u2019s analysis of clinical trial results for three prevention strategies in development proves there is hope ahead. First, extended half-life monoclonal antibodies, blood proteins that counteract pathogens, already have approval in the European Union but could take another year or two to be approved in the United States. The second, a maternal immunization, has promising clinical trial results but hasn\u2019t yet been filed for approval. According to Zheng\u2019s findings, each could avert more than half of RSV hospitalizations in children under six months. Live-attenuated vaccines proved highly effective for children between six months and five years, though they are still in the early stages of development.\u00a0\nAn important question Zheng shed light on relating to these prevention strategies involves the efficacy of seasonal versus yearly vaccination plans. While previously reliably seasonal, COVID has made RSV\u2019s seasons irregular, in addition to differences between seasonality in northern and southern states. \u201cA seasonal program may provide minor [cost] advantages over a year-round [program], but the year-round would cover more children,\u201d Zheng said. Zheng\u2019s research compares RSV prevention methods and discusses the best method of distribution\u2014information that could relieve overwhelmed hospitals and save children\u2019s lives.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/optimistic-results-for-rsv-prevention-strategies/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Turtle Transformers",
            "author": "Riya Bhargava",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Bhargava_Figure1-1-500x338.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Joko Diaz.\nPictured above is a baby leatherback turtle, a deep-diving reptile that lives in the ocean for years but migrates to the land to lay eggs. Leatherbacks have sleek, paddle-like forelimbs to navigate the seas, claws to walk on sand, and a mosaic of breathable cartilage for a shell. Many such adaptations have made turtles the masters of their niche between the land and the sea for over 200 million years. Accordingly, when engineers Robert Baines and Sree Kalyan Patiballa sat down to ideate a multi-environment mobile robot, they drew inspiration from turtle body plans and kinematics and named their robot the Amphibious Turtle Robot, or ART.\u00a0\n\u201cThe importance of the paper is that we are showcasing how you can have robots that have adaptive components\u2014components that change shape, and how this design paradigm can improve their efficiency and effectiveness,\u201d says Baines, a PhD student researcher in Rebecca Kramer-Bottiglio\u2019s lab at Yale, describing the lab\u2019s recent Nature publication. ART is a quadruped with a streamlined shell, weighs nine kilograms, and has a body amalgamating soft materials that respond to external stimuli and traditional, rigid robotics components. The most remarkable feature of the robot is its morphing limbs that undergo adaptive morphogenesis\u2014the limbs can alter their gait or shape in response to a stimulus, adopting morphologic features that best suit aquatic and terrestrial locomotion. For example, the limbs can morph into the streamlined flippers of a sea turtle when in water and the columnar legs of a land-faring tortoise when walking.\u00a0\nWhile rigid-bodied robots can be programmed to perform a single task efficiently, they do not afford the same body compliance needed to design bio-inspired robots with muscle-like actions. Soft materials also have move-and-hold operability\u2013these materials can retain changes in shape without the constant application of external force, enhancing the overall energy efficiency of the robot.\u00a0\nThe best metric for ART\u2019s performance was the Cost of Transport (COT), which measures the effectiveness of robot locomotion in terms of energy efficiency. ART had a minimum COT of three and ten for aquatic and terrestrial locomotion, respectively\u2013a number that equals or outperforms other famous unimodal quadrupeds like EPFL\u2019s Cheetah Cub and the Titan V-III.\u00a0\nHowever, many improvements must be made before the robot is put to commercial use, especially when it comes to untethering. \u201cOne of the things we\u2019re moving forward with is putting additional sensors on the robot to understand how it\u2019s moving in the environment,\u201d Baines said. \u201cThis way, it would know, for example, if it were in choppy water or still water, or if it were going down a hill and stumbling versus being stable and standing on flat ground.\u201d The lab is also working to find better gaits for the robot.\u00a0\nEven with such challenges, Baines foresees several important applications of such robots in the near future. Robots such as ART can be used to monitor ecosystems less invasively. \u201cSuch a platform is unique because it is bio-inspired. It would have less disturbance on the environment and the animals living in it,\u201d Baines said. Instead of using turbulent propellers, the turtle robot swims using streamlined flippers. This design paradigm also foreshadows advances in disaster relief distribution, security, and the study of animal locomotion physics.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/turtle-transformers/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Icy Interference",
            "author": "Daniel Havlat",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/32567303697_d54e785052_c-500x182.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nScientists have been searching for liquid water on Mars for decades. It\u2019s one of the most vital materials for future human inhabitation of the red planet and could harbor yet unknown Martian life. A groundbreaking paper published in 2018 by Orosei and others\u00a0 claimed that liquid water had finally been detected under the South Polar Layered Deposits (SPLD), the Martian equivalent of the Antarctic ice cap on Earth. The study analyzed radar data from the Mars Express Orbiter\u2019s Advanced Radar for Subsurface and Ionosphere Sounding (MARSIS) instrument, concluding that a briny layer of liquid water was responsible for significant radar reflections at the base of the SPLD. Later geophysical work, including modeling mantle heat flow under the SPLD, called this result into question based on the excessive heat requisite for a liquid layer to form. In September 2022, a paper published in Nature provided a plausible alternative explanation for the data initially interpreted as signs of liquid water. \u201cUnfortunately, I kind of feel like the Grinch a little bit, where I have to come in and say, \u2018That\u2019d be cool and all, but I don\u2019t think that\u2019s what\u2019s happening\u2019,\u201d lead author Daniel Lalich said.\nIn the paper, authors Daniel Lalich, Alexander Hayes, and Valerio Poggiali of Cornell University used computer-simulated radar models to demonstrate that the SPLD radar data collected by MARSIS could be reproduced without a liquid water layer. Instead, the study found that constructive radar wave interference could yield the same return data as a layer of liquid water. \u201cIt does seem like it would be unlikely, but we know it happens in other places,\u201d Lalich said.\nThe SPLD is an ice cap over one kilometer thick composed primarily of dusty ice. Layered on and within the deposits are also meter-thick slabs of carbon dioxide (CO2) ice. As CO2 ice and water ice have different chemical and physical properties, they interact with radar waves slightly differently. Lalich demonstrated that layered CO2 and water ice within a simply modeled SPLD can result in interference and amplification of the radar return at the bottom of the deposits to the same extent observed in the MARSIS data. \u201cIt\u2019s actually fairly easy to generate constructive interference given what we think the conditions are in the South Pole,\u201d Lalich said.\nThis result is important as it provides an alternative explanation for the observed data using only well-known material parameters from the SPLD, constituting a hypothesis more in line with prevailing geophysical models. \u201cEven with geothermal heating, the temperature should still be way too low for there to be liquid water,\u201d Lalich said. It also serves as a sign of caution for subsequent radar sounding studies of complex, layered features at not only the SPLD but across Mars. What this study does not do, however, is serve as definitive proof against the brine water hypothesis. \u201cIt\u2019s easy to say that we can\u2019t rule out interference, but that\u2019s different from saying that it\u2019s definitely what\u2019s happening,\u201d Lalich said. Subsequent arguments and closer examinations will undoubtedly continue, nudging us increasingly closer to elucidating the true nature of these intriguing, unexpected radar observations.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/icy-interference/",
            "captions": [
                ""
            ]
        },
        {
            "title": "An Improved Approach to Systems Neurology",
            "author": "Jessica Le",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Le_Figure1-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Behance.\nThe human brain is the most biologically complex organ, composed of eighty-six billion individual neurons that mesh together to form an incredibly intricate neural network. How do billions of neurons facilitate our behavior? The field of computational neurosciences takes a mathematical approach to uncover the mysteries of the brain. The field uses models, computer simulations, and theoretical analyses to study the principles that govern our cognitive capacity and the physiology of the nervous system. One challenge of establishing a biophysical neuron model that accurately predicts the behavior of a neuron is estimating fixed parameters\u2014measurements representative of other undeterminable variables. For example, the conductivity of a neuron\u2019s ion channels must be modeled by an indirect parameter since it cannot be directly measured. These critical parameters dictate neuron interactions and overall firing behavior. \u201cAll these responses depend on the interplay between the parameters,\u201d said Nirag Kadakia, a postdoctoral researcher in the Department of Molecular Cellular Developmental Biology at Yale.\u00a0\nKadakia proposed a new algorithm tailored to \u201cnoisy\u201d systems with nonlinear dynamics to infer the parameters of individual neurons. \u201cIf you really want to understand the system at its fullest detail, you have to include those nonlinear responses,\u201d says Kadakia. His proposed algorithm utilizes an engineering technique called optimal control theory. This mathematical optimization finds the best estimate for a parameter in the most efficient way possible, given the system\u2019s constraints. This model builds upon previous traditional modeling approaches and has significantly improved prediction accuracy. Older and more classic algorithms are inadequate in this context and may not ultimately converge on the best parameter estimate that fits the data. Kadakia\u2019s work demonstrates that unknown parameters can be inferred from nonlinear, high-dimensional systems despite noise and low observability, giving rise to rich data and more accurate model predictions.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/an-improved-approach-to-systems-neurology/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Black Death\u2019s Genetic Mark On Us",
            "author": "Avi Patel",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/7316086176_d95bc87f19_c-500x388.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nInfectious diseases have propelled the evolution of humans and other species across the tree of life, and the Black Death was no exception. Yersinia pestis, the bacterium responsible for the bubonic plague and its associated twenty-five million deaths, is also responsible for a form of positive selection pressure experienced in humans. According to a study published in Nature, individual genetic variants that conferred protective immunity against Y. pestis might have been under strong selection during the fourteenth and fifteenth centuries.\nKlunk & Vilgalys et al. identified genetic loci\u2014specific locations or segments within the genome \u2014 associated with protection against Y. pestis. \u201cThe main motivation was to understand how a single pathogen, Yersinia pestis in this case, would have been able to impose a noticeable selective pressure to the human genome within a very short time window,\u201d said Luis Barreiro, a population geneticist at the University of Chicago and one of the principal investigators of the study. In their study, the researchers examined individuals who died shortly before, during, or soon after the Black Death in London and across Denmark. In total, 516 samples were screened, and after quality control, the researchers found many samples lacking sufficient endogenous DNA content. They used a technique called hybridization capture, a method allowing targeted enrichment of specific genome regions to sequence the samples.\nAfter collecting the samples, the researchers manually curated a list of targeted immune genes based on their roles as immune receptors. The researchers then searched for unexpectedly large changes in allele frequencies within these genes between pre- and post-Black Death samples to detect alleles that may have conferred protection from Y. pestis. A stringent criterion was used to identify specific loci for the strongest candidates of selection, leveraging the different time periods and populations in the dataset. They found the most compelling evidence near the gene ERAP2, which had some of the greatest differentiation before and after the Black Death and also affected the cellular response to infection with plague in vitro. The evidence shows that individuals homozygous for the protective allele were forty percent more likely to survive the Black Death than those homozygous for the harmful variant.\nThe results have many implications for the field of immunology. \u201cIt is important to understand why living people are susceptible to the diseases we are susceptible to,\u201d said Tauras Vilgalys, an evolutionary and functional geneticist who co-led the project. \u201cBy showing that past populations had these selective pressures, along with evidence that shows how those genetic variants still affect health to this day, we can ultimately understand who we are and how we got here.\u201d\nMoreover, the breadth of the project spans various disciplines. \u201cIt is a very multidisciplinary project that involves anthropologists who know the history of Yersinia pestis and the Black Death, archeologists who have access to the samples and can date them through radiotyping, ancient DNA experts who can decode the degraded DNA, population geneticists like in my backgrounds, experts in genomics for genome sequencing, as well as cell biologists for laboratory testing,\u201d Barreiro said. Without this collection of experts, this project would have never been able to move past an initial idea.\nIn the future, Vilgalys and Barreiro are keen on continuing this project. After encountering several limitations due to the small sample size, Barreiro hopes to include more individuals and try to expand the study to cover the entire genome. For now, the quest to understand adaptation during the Black Death has only just begun.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/the-black-deaths-genetic-mark-on-us/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Palacrodon: A New Piece in the Mass Extinction Puzzle",
            "author": "Alex Roseman",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/4.Palacrodon_PaleoArt_KelseyJenkins-500x332.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Kelsey Jenkins.\nAround 250 million years ago, about ninety percent of living species died out in the end-Permian mass extinction. A recent study led by researchers at Yale University provides new insight into the following recovery period.\nThe researchers took computerized tomography (CT) scans of an Antarctic specimen of Palacrodon, an early reptile. The fossil was dated to the early Triassic period, just after the mass extinction. \u201cPeople have looked at this fossil before, but returning with new techniques like CT scanning and digital imaging allows us to get a lot of new information\u2026 we can look at the internal surfaces of the bones, and things that would have normally been hidden or obscured by rock,\u201d said Dalton Meyer, a graduate student in Yale\u2019s Department of Earth and Planetary Sciences and coauthor on the study.\nThe data helps fill a gap in the reptile evolutionary tree. Modern reptiles have long, thin stapes, a bone in the middle ear adapted to high-frequency sounds, whereas earlier reptiles had a thicker version. Palacrodon occupies a middle ground. \u201cEarly reptile ancestors had a big blocky one, and modern reptiles have a really thin one, and Palacrodon shows evidence of the transition,\u201d said Kelsey Jenkins, first author of the study and a PhD candidate at Yale\u2019s Department of Earth and Planetary Sciences.\nThe researchers noted Palacrodon\u2019s plant-eating teeth and toe bones were possibly adapted for climbing. These arboreal adaptations indicate greater tree presence than has usually been estimated so soon after the end-Permian extinction. \u201cBecause it\u2019s Antarctica and we don\u2019t have a lot of data there, maybe something weird was going on, or maybe there\u2019s a global response that we haven\u2019t calculated yet. It leaves a lot of room for speculation,\u201d Jenkins said.\nWhat\u2019s next for the researchers? More Palacrodon! \u201cI just sent an email to get more Palacrodons,\u201d Jenkins said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/palacrodon-a-new-piece-in-the-mass-extinction-puzzle/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Genetic Influences on PTSD",
            "author": "Kayla Sohn",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/4688523825_4ff04c2098_c-500x446.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nPost-traumatic stress disorder (PTSD) is a neuropsychiatric disorder triggered by experiencing or witnessing a traumatic or terrifying event. Currently, there are few studies related to PTSD, especially few specifically investigating how stressors from the environment can change and impact gene expression related to PTSD. Previously, researchers tended to focus on blood biomarkers. However, this approach does not address the neurological nature of the disorder. \u201cBlood is a peripheral tissue that is not necessarily indicative of what\u2019s going on in the brain,\u201d said Carina Seah, an MD-PhD student at the Icahn School of Medicine at Mount Sinai. Instead, Seah and a multi-institutional team looked at skin biopsies. They collected connective tissue cells from forty veterans\u2019 skin and reprogrammed the cells into neurons using novel stem cell technology while retaining the genetic information the cell donor had. \u201cWe can watch the entire disease model with a stem cell model\u2026 Stem cells are kind of like these amazing bridges that can connect fields,\u201d said Kristen Brennand, Professor of Psychiatry at the Yale School of Medicine.\u00a0\nThey conducted the study at the height of the COVID-19 pandemic, so an innovative work setting had to be adapted, including coordinated zoom calls and scheduled wet laboratory shifts. This study also connected a diverse array of expertise with collaboration between three different laboratories and the New York Stem Cell Foundation. \u201cIt was definitely a great testament to establishing cross-expertise environments,\u201d said Seah. Since it was the first study to use induced pluripotent stem cells in PTSD, their results were groundbreaking\u2014the study demonstrated there is likely a genetic factor interacting with the environment which, in the future, could better predict who will develop PTSD.\n\u00a0\u201cI hope those who read our paper learn the importance of considering the environment when we talk about psychiatric disorders,\u201d said Seah. By studying gene expression, the researchers demonstrated how the human gene sequence could respond to external stressors. \u201cOn average it takes ten years for someone to be treated once a psychiatric disorder is onset. If we could figure out how to tamp down that stress response, we could use this to both see who is at high risk and how to prevent PTSD\u201d, said Brennand.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/genetic-influences-on-ptsd/",
            "captions": [
                ""
            ]
        },
        {
            "title": "An Unexpected Marriage: Robot Drones & Flower Power",
            "author": "Cindy Mei",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/An-Unexpected-Marriage-Killer-Drones-Flower-Power-Sophia-Zhao-500x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Sophia Zhao.\nFlying over the cliffs of Kauai, a drone known as the Mamba sweeps the area on a rescue mission, searching for valuable buds of life beyond normal reach. On these cliffs lie extremely rare plants, many only found in Kauai, and some the last of their kind. The Hawaiian island is home to 250 endemic flora species found exclusively on the island, ninety-seven percent of which are classified as endangered or extinct. Environmental hazards are increasing the extinction rate to five hundred times the expected rate without human interference. For years, botanists have braved Kauai\u2019s cliffs and other hard-to-access locations in search of these critically endangered plants. However, the areas are extremely hazardous and are time-consuming and expensive to access.\nFor years, drones have been a prominent tool in environmental conservation and monitoring in harsh environments, imaging across different wavelengths of light and identifying plant habitats and distributions. However, the development of drones to navigate and interact with dangerous and inaccessible environments is an entirely new innovation in this field. \u201cWhat differentiates what we\u2019re doing with drones is that we\u2019re interacting directly with the environment,\u201d said Hughes La Vigne, a PhD student of robotics engineering at the University of Sherbrooke and co-founder of Outreach Robotics. The company first took root following the creation of the DeLeaves sampling system, a device designed to collect branches from treetops and canopies. \u201cThe purpose of Outreach Robotics is to develop robotic tools that could help scientists working in conservation, reforestation, and other environmental purposes,\u201d La Vigne said.\u00a0\nEnter the Mamba, the first aerial system that can sample plants on cliffs and transport them to a safer place. With a grant from National Geographic, Outreach Robotics teamed up with Ben Nyberg, a PhD student at the University of Copenhagen and the drone coordinator of the National Tropical Botanical Garden (NTBG), a nonprofit organization dedicated to the conservation and restoration of tropical plants. The project, which was published in Scientific Reports this fall, spanned two years of prototyping, iterating, and testing amid disruptions from COVID-19.\u00a0\nThroughout the design process, the team considered many factors to optimize and stabilize flight collections. The drone had to be able to endure windy conditions, collect samples quickly and gently, and navigate around unwelcoming terrain. The final system prototype utilized a suspended platform equipped with propellers that swung in a pendulum, reducing rigidity and allowing an extended reach from cliffsides, minimizing the potential for collisions. In addition, the Mamba had to be easy to use with minimal roboticist training. \u201cWhen you\u2019re developing tools that might have an impact on conservation or the environment, you want it to be used by people who are working in that field,\u201d La Vigne said.\u00a0\nThe final design was tested in two field trials in late 2021 and early 2022, with La Vigne and fellow University of Sherbrooke researcher and Outreach Robotics co-founder Guillaume Charron teleoperating the Mamba from the ground. Following imaging and identification of plant species targets, the Mamba navigated to the sites with built-in global navigation systems. Using an active robotic arm wrist suspended by long, snaking cables beneath the drone, the Mamba was able to cut and recover eleven otherwise inaccessible samples of seeds and cuttings with minimal impact from five critically endangered plants on Kauai\u2019s cliffs. These plants were then deposited at the NTBG, which used methods such as seed banking and ex situ cultivation to maintain growth. The final prototype of the Mamba was also time-efficient and could reach several sampling sites from one base station.Since then, some plants like the Lysimachia iniki have flourished in the NTBG nurseries, becoming the first recovered plants of their kind to do so in captivity, while others, like the Euphorbia eleanoriae, did not survive in the long run. L. iniki grew roots for the first time in captivity, bolstering the hope that the surviving single-population plants of Kauai will be able to regrow with the combined effort of the drones and conservation. In future projects, the Mamba will be taken to other islands of Hawaii, where ninety percent of flora is not found anywhere else on Earth, in its pursuit to save these rare plants. \u201cThis is what we dreamed about for the last two years or so when we saw that drones were being used to interact with the environment,\u201d La Vigne said. \u201c[NTBG] is doing an amazing job to preserve these endemic species, and our goal is to help them and continue to work with environmental scientists.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/an-unexpected-marriage-robot-drones-flower-power/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Does Parkinson\u2019s Smell?",
            "author": "Dinara Bolat",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/parkinsons-Pixabay-960x320-1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Newscop.\nCurrently, no specific diagnostic tests exist for Parkinson\u2019s disease, a degenerative brain disorder. Instead, patients get diagnosed once they start displaying trademark symptoms like tremors, muscle stiffness, and impaired balance. However, thanks to Joy Milne, a Scottish nurse with a hypersensitive nose, this is changing.\u00a0\nMilne came to the attention of UK scientists in 2015 when she proved her ability to detect people with Parkinson\u2019s by their unique smell. With her help, researchers from the Universities of Edinburgh and Manchester identified specific molecules that cause \u2018Parkinson\u2019s smell.\u2019 They identified molecules in the sebum, an oily substance on the skin surface, and found that people with Parkinson\u2019s have altered lipid signatures compared to non-Parkinson\u2019s patients. Using these results, they developed a skin-swab test to detect this lipid signature which analyzes sebum with PS-IM-MS, a type of ion mobility mass spectrometry. This new method reveals specific compounds unique to Parkinson\u2019s sebum samples and identifies lipid classes that are differentially secreted in patients with Parkinson\u2019s.\nScientists are hopeful that this swab test will be a key tool for earlier and faster Parkinson\u2019s diagnosis, leading to more opportunities and options for treatment. Although there are still clinical trials and accuracy assessments required before the tests can be authorized in hospitals, scientists involved claim that the test has a greater than ninety percent accuracy. This ground-breaking technology has inspired other research teams to study the olfactory signature of other diseases, opening a new field of research yet to be explored.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/qa-does-parkinsons-smell/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Gamer Neurons",
            "author": "Maya Khurana",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/MaliaKuo_gamerneuron.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Malia Kuo.\nOur brains are a collection of billions of neurons, firing in synchrony to make up the complex organ that is our brain. But zooming in, what if we consider a small, isolated subset of cells? What might they be capable of?\u00a0\nNeurons are unique cells in the body. Unlike other cells, which can simply maintain their functions isolated in a petri dish, neurons process information, meaning they need a stimulus that prompts them to act. This makes them both fascinating and difficult to study. Computational models have been used to study neural networks, but they are limited by the constraints of technology, which is no substitute for a biological system. To alleviate this concern, what if neural networks could be made from biological neurons in a petri dish? In their recent paper, Brett Kagan, his colleagues at Cortical Labs, and several university collaborators have set out to study the interface of biology and intelligence by exploring how biological neurons respond to electrophysiological input and feedback in vitro.\nThe team\u2019s research process started in 2019. However, the pandemic threw a wrench in their plans, especially with Australia\u2019s strict lockdown procedures. \u201cFortunately, we were able to get exemptions to go to work because we were considered critical workers, being in a hospital setting. But it was incredibly different circumstances nonetheless, getting supplies in and all the basic little things that we used to take for granted,\u201d Kagan said. Once the lab could work around the restrictions, the group hit the ground running, resuming their research skillfully and deliberately. Kagan and his colleagues adopted an approach called \u201cagile science,\u201d where they set up a series of small pilot experiments in tandem to see which conditions would be best for their cells. This allowed them to adjust their research environment as they went along and optimize their experiments throughout the process. By growing long-term cortical neurons that formed dense connections with supporting glial cells, Kagan and his colleagues were able to study the behavior and capabilities of these biological neurons in a petri dish.\u00a0\nA silicon chip inside the dish stimulated the neurons to create a simulated Pong game-world, where a paddle is moved up and down the screen to block a ball from hitting the side. \u201cWe chose Pong because we wanted something [in] real time, simple to code for with a clear \u2018win and/or lose\u2019 condition\u2014in this case, there was a really clear lose condition\u2014and [something] recognizable to people. It\u2019s actually the fiftieth anniversary of Pong [this year],\u201d Kagan said. Inputs from the silicon chip were delivered to a predefined sensory area of eight electrodes. These electrodes stimulated sensory neurons that then communicated with motor neurons also cultured in the dish. The researchers wanted to see if the motor neurons would learn to move the paddle and intercept the ball. Any time the neurons missed an interception, they would be stimulated randomly, while successfully intercepting the ball meant they would receive predictable stimulation.\nWhy might random stimulation in response to error cause the neurons to learn to play the game? Kagan and his team used the idea behind the free energy principle, developed by Karl Friston, a collaborator on their paper, to inform their hypothesis. As Kagan explained, the free energy principle says that a system will minimize the surprise or uncertainty in its environment. \u201cWhat we did was give the neuron feedback randomly if it got [the game] wrong. If the free energy principle is true, then the system should reorganize itself to minimize randomness,\u201d Kagan said. This means that to minimize the amount of random stimulation they received, the in vitro neurons would need to learn to play the game.\u00a0\nThis learning could be done in one of two ways: either the neurons could create a model or a \u201cbelief system\u201d so that the network can respond and match the model with the real world, or they could physically act upon their environment to change their surroundings. Kagan and his colleagues showed that in vitro neurons learned to move the paddle to play Pong, and biological neurons can thus be adaptive. \u201cWe found that these neurons want to act in a way that can minimize unpredictability, [and] we can see this by them learning to play Pong,\u201d Kagan said.\nThey also uncovered some interesting and unexpected findings. Kagan explained that one of the intriguing results of the paper was their data on information entropy, which is the amount of information conveyed in an event. \u201cIt was really exciting because it showed that the cultures were able to distinguish between internal and external noise,\u201d Kagan said. Essentially, they showed that the neurons could determine the difference between information generated on their own and information from an outside source, highlighting the specificity with which the neurons can source the signals they receive. \u201c[It] makes sense because I can distinguish between my thoughts and your words, so there must be a way to break that up. But to see that you\u2019re getting one response for external noise and one response for internal noise was pretty exciting,\u201d Kagan said.\u00a0\nThis system, which Kagan and colleagues aptly termed \u201cDishBrain,\u201d sits at the interface of neurobiology and computational technology. Short-term benefits of the system are numerous: drug discovery, disease modeling, and building a basic understanding of how neurons create intelligence. \u201cAll general intelligence that we have ever seen is biological\u2014from flies to cats to humans,\u201d Kagan said. Still, there are limits to biological neural networks. \u201cThis does not mean that you end up with a human in a dish. What it means is that neurons are this biomimetic material that can adapt to new information, so can you use it as an information processor,\u201d Kagan said. \u201cIt offers us an ethically responsible way to move forward.\u201d\u00a0\u00a0\nThough many questions remain, Kagan and his colleagues at Cortical Labs are looking forward to digging deeper into their work and making new, exciting findings. Now, they\u2019re working on perfecting their research infrastructure, from creating new biological environments to advancing their technology. \u201cWe\u2019re trying to improve what we call the wetware (the cells), the hardware, [and] the software. We\u2019re starting to do some disease modeling and drug testing, and all of these options are super exciting,\u201d Kagan said. While many questions remain, neurons are certainly firing at Cortical Labs to help uncover more answers. This exciting research is sure to produce more interesting data that will guide the field of neuroscience and biological intelligence in the future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/gamer-neurons/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Strength of Weak Ties",
            "author": "Eunsoo Hyun",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/The-Strength-of-Weak-Links-Kara-Tao-500x333.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Kara Tao.\nIn 1973, American sociologist Mark Granovetter published a paper that fundamentally changed the field of sociology. The paper, titled \u201cThe Strength of Weak Ties,\u201d theorized that weak ties (think casual acquaintances, friends-of-friends, and other arm\u2019s-length relationships) help disseminate new information and provide more job opportunities than strong ties (such as close friends, family, or immediate coworkers).\u00a0\nThis phenomenon, which may seem counterintuitive at first glance, happens because weak ties\u2014interpersonal relationships with fewer mutual connections\u2014help expose people to new information and opportunities outside their immediate social bubble. \u201cWeak ties tend to span a broader width of the overall social network of the labor market. Strong ties tend to be redundant because you have access to the same sort of resources, information, and so on,\u201d said Karthik Rajkumar, an applied research scientist at LinkedIn.\u00a0\nFor Rajkumar, it was fascinating to see this correlation in action. As a graduate student applying to internships in 2019, he found himself sending out resume after resume, just hoping to hear back at all. (A familiar story to many readers, especially those now looking for jobs and summer opportunities!) \u201cIt really made me think: there\u2019s so much more to the job market and the interview process than your resume and your credentials and your interviewing skills. There\u2019s that personal touch\u2014that connection, and that\u2019s something I learned the hard way,\u201d Rajkumar said. This prompted him to ask: what is the effect of social networks on job mobility?\nThe term \u201cjob mobility\u201d means that people in the labor market are able to move to new jobs when they want. \u201cJob transmission\u201d refers to job mobility as a result of connections made. \u201c\u2018Job transmission\u2019 is this idea that if I connected with you now, am I going to join your company a year down the line?\u201d Rajkumar said.\u00a0\nRajkumar and his co-authors designed a study to test for a causal relationship between interpersonal ties and job mobility using five years of data from LinkedIn. Their new paper in Science, titled \u201cA causal test of the strength of weak ties,\u201d is the first to conduct a large-scale, experimental study of a causal\u2014not just correlational\u2014relationship between weak ties and employment. More specifically, the researchers used LinkedIn\u2019s People You May Know (PYMK) algorithm, which recommends new connections for LinkedIn users to add to their networks. By adjusting the algorithm, the team randomly varied whether users got weak or strong tie recommendations in the PYMK section. The tie strength between two users was determined by the number of messages sent back and forth and the number of mutual connections they had.\u00a0\nThe results empirically validated the theory that weak ties cause increased job mobility. This discovery disproved the \u201cparadox of weak ties,\u201d identified by previous correlational studies that proposed strong ties as the agents behind job mobility. The overall relationship between tie strength, measured by the number of mutual friends, and job mobility was nonlinear, following an \u201cinverted U-shape.\u201d In other words, the weakest ties weren\u2019t the best at increasing job mobility. Rather, moderately weak ties increased job mobility and job transmissions the most. The strongest ties affected job mobility the least.\nHowever, when they looked at the results according to interaction intensity (the number of messages exchanged) as the metric of tie strength, weak ties with low interaction were the most helpful. Interestingly, these results varied by job industry. Weak ties mattered most when applying to jobs in industries that rely on software, but strong ties still held sway in less digital industries. This difference may be due to the importance of up-to-date information in rapidly evolving industries like tech. \u201cWeak ties are conduits for information. They\u2019re very efficient in bridging these information gaps across vast corners of the social network,\u201d Rajkumar said.\u00a0\nSo how has this discovery been applied to sites like LinkedIn? One example is the updated \u201cPeople You May Know\u201d section. Before, the PYMK page simply showed a list of connections. Now, LinkedIn separates these connections into categories\u2014connections from the same school, company, industry, and so on. \u201cA lot of times, I hear people say, oh, I would like to have weak ties, but you know\u2014how would I approach a total stranger? It\u2019s all about finding that commonality, whether it\u2019s your professional interest or mutual connections,\u201d Rajkumar said.\nThe discovery of a causal relationship between weak ties and job mobility provides important insights for networks like LinkedIn as the labor market becomes increasingly digitized.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/the-strength-of-weak-ties/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Would You Trust Working with a Robot?",
            "author": "Jamie Seu",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fig_1-500x273.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nIt\u2019s a familiar trope: a well-meaning scientist invents a piece of revolutionary technology that develops consciousness and rises up to destroy the human race. Machine consciousness has long been a subject of fear and fascination, but for people who regularly interact with robots, such as those who work in the manufacturing industry, trust in automation is an incredibly pertinent issue.\u00a0\nTo better understand the nuances of trust in human-robot collaborations (HRCs), researchers at Texas A&M University designed a series of trials that allowed them to study operator trust. Participants (operators) were instructed to polish a metal surface with a robot along an S-shaped trajectory under varying levels of robot reliability and operator cognitive fatigue. Working with an unreliable robot reduced task efficiency and accuracy (deviation from the defined trajectory) but not precision (variance in deviation from the trajectory). Participants also perceived the task as more demanding than when they worked with a reliable robot. For participants experiencing cognitive fatigue, higher fatigue scores and reduced task efficiency were reported, with female participants more strongly impacted than male participants.\u00a0\nAnalyses of human factors on trust in HRCs can be utilized to create more effective worker training programs and adaptations to robot design that will maximize efficiency and workplace safety, improving and fortifying HRC systems. Robots are here to stay, and it\u2019s on us to figure out how to work alongside them and trust them as partners. Maybe then they\u2019ll spare us when they decide to take over the world.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/qa-would-you-trust-working-with-a-robot/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: Atoms and Ashes: A Global History of Nuclear Disasters",
            "author": "Ximena Leyva Peralta",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fig-2-1.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nEver since scientists first split the atom in 1938, nuclear power has both fascinated and terrified millions. Today, ten percent of world energy is supplied by almost 440 nuclear reactors. In the US, closer to twenty percent of electricity comes from nuclear power. Regarded as a highly efficient, low-emission energy source, nuclear energy is an attractive option for many countries seeking to reduce their carbon footprint while meeting population needs. Yet, nuclear disasters like Chernobyl have shown the risks of working with radioactive material. Considering the industry\u2019s troubled history raises the question: Just how safe is nuclear energy?\nIn his new book Atoms and Ashes: A Global History of Nuclear Disasters, Serhii Plokhy, Harvard University professor of Ukrainian History, explores the dangers of nuclear power through six of the worst nuclear disasters: the 1954 Castle Bravo hydrogen bomb test, the 1957 Kyshtym nuclear waste tank explosion, the 1957 English Windscale reactor fire, the 1979 Three Mile Island partial reactor meltdown, the 1986 Chernobyl reactor meltdown, and the 2011 Fukushima disaster.\nPlokhy expertly creates a picture of the international nuclear industry. \u201cThe story told here is a global one,\u201d he writes, examining \u201cnot only the actions and omissions of those directly involved but also the ideologies, politics, and cultures that contributed to the disasters.\u201d For example, the Castle Bravo accident sets the stage for later chapters by introducing the pressures of the Cold War, government efforts to cover up disasters, and the inevitability of human error when dealing with emerging science and technology.\nPlokhy complements his well-researched piece with a skillful narration. Meticulously selected testimonies bring every accident to life, making the historical events all the more palpable and impactful. Discussing the Fukushima meltdown, Plokhy anchors his narration around plant superintendent Yoshida. \u201cYoshida was sitting behind his desk, [\u2026] when things around him started shaking. [..] \u2018My mind should have been panicking. But strangely, [it] was telling me to keep calm and start planning,\u2019 recalled Yoshida,\u201d Plokhy writes. In this manner, Plokhy builds an entertaining, well-informed historical thriller.\nAtoms and Ashes shows that science and technology alone cannot cause or prevent nuclear disasters. Many political, social, and cultural factors are involved in regulating nuclear energy. New international legislation was established through international cooperation to prevent future nuclear accidents, making it easier to exchange technology and enforce rigorous standard safety measurements.\nThough the impacts of nuclear disasters should not be disregarded, their rate and severity are lower than accidents in the coal, gas, and hydropower industries. While not perfect, nuclear fission reactors are the most efficient zero-emission energy source. As Plokhy recognizes, \u201cthe major accidents involved [\u2026] technologies developed in the 1950s and 1960s, [offering] some hope that the [industry\u2019s] major errors [are] behind us.\u201d Better policy-making and increased funding for research and development promise a safer future for nuclear energy. Moreover, they open the door to a promising, carbon-free, potentially safer option to power the second half of this century: nuclear fusion, fusing atoms instead of splitting them apart.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/science-in-the-spotlight-atoms-and-ashes-a-global-history-of-nuclear-disasters/",
            "captions": [
                "OLYMPUS DIGITAL CAMERA"
            ]
        },
        {
            "title": "Counterpoint: Life on Mars was Its Own Undoing",
            "author": "Crystal Liu",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/eso1509a-500x205.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of ESO/M. Kornmesser.\nHas life existed on Mars? If so, how would it have affected Mars\u2019s climate? There has been ample research on Earth\u2019s early life forms and their effect on the planet. Scientists have been particularly interested in methanogens, microorganisms that consume hydrogen (H2) and carbon dioxide (CO2) and generate methane (CH4) as waste. Both CO2 and CH4 are greenhouse gases, which trap heat in the atmosphere and lead to temperature increases, but CH4 retains twenty-five times more heat than CO2. Therefore, methanogen metabolism increased global temperature and, as a result, made Earth habitable to other organisms.\u00a0\nHowever, a recent study in Nature Astronomy found that if methanogens ever existed on early Mars during the Noachian period (about four billion years ago), they would have had an opposite cooling effect. This is because early Mars had a CO2-dominated atmosphere, as opposed to early Earth\u2019s nitrogen-dominated atmosphere. Collisions between CO2 and H2 molecules absorb more heat energy than CO2-CH4 collisions or CH4 alone.\u00a0\u00a0\nSince the existence of methanogens would have drastically changed the climate, it is important to evaluate whether the early Mars environment could support methanogenic life. The researchers concluded that Mars\u2019 subsurface environment was probably favorable to microbial life. Mars\u2019 crust is covered by regolith, a loose, heterogeneous layer made of dust, sand, and broken rocks. At that time, regolith may have sheltered microorganisms from ultraviolet and cosmic radiation. Simultaneously, brine, highly-concentrated salt water, would have filled the porous layer and provided an aqueous environment.\u00a0\nIn addition to an aqueous solution and shelter from radiation, the land must also have been free of surface ice to sustain life. Ice-free regions allow gases to exchange from the atmosphere, which microorganisms need to survive. Ice coverage depends on surface temperature and the brine freezing point. Researchers estimated the surface temperature on early Mars by modeling H2 and CH4 concentrations combined with the latitude and elevation of any given geographical area. They found that before any life forms existed, the average surface temperature ranged from 216 to 294 K (-57 to 21\u2103). Brine\u2019s freezing point, however, is largely unknown. As salt concentration increases, the solution\u2019s freezing point decreases, which is why we salt the road before a snowfall to prevent snow from settling. Brine likely consisted of other ions besides sodium and chloride, which would also have altered the freezing point. Estimates of early Mars brine freezing points from existing literature range from 203 to 273 K (-70 to 0\u2103).\u00a0\nResearchers ran three models, estimating the probability of methanogenic life with brine freezing points of 203, 252, or 273 K. If brine had a lower freezing point, more area would be ice-free and habitable. With a freezing point of 203 K, one hundred percent of Mars\u2019 surface would have been ice-free, whereas simulations at 273 K generated a median of only 0.15 percent ice-free area. In all three cases, some parts of Mars would have been habitable to methanogens, typically in lowlands at low-to-medium latitudes. It is important to note that this study only shows that early Mars satisfied every condition for methanogenic life rather than confirming the existence of life. However, the studies\u2019 findings will inform the search for traces of life in fossil records.\u00a0\nIf methanogens had really existed, their metabolic activity would have significantly changed Mars\u2019 climate, leading to new equilibrium temperature and atmospheric composition. The study estimates a reduction of 33 to 45 K. As a result, the fraction of ice-free regions would have dropped, and habitability would have been compromised. Even in places with no ice coverage, methanogens would have been forced deeper into the crust, which was warmer but scarcer in essential gases. Somewhat counterintuitively, if Mars had a lower brine freezing point, more methanogens could have existed in the first place, but they would have induced a larger drop in temperature and lower habitability at the steady state. Unlike on Earth, where the first life forms facilitated the emergence of later organisms, life on Mars may have been its own undoing.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/counterpoint-life-on-mars-was-its-own-undoing/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Undergraduate Profile: Eric Sun (MY \u201823)",
            "author": "Cindy Kuang",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/ES_Headshot_Crop-500x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Photo courtesy of Sophia Li.\nEric Sun (MY \u201923) is a lot of things: aspiring physician-scientist, cancer biology researcher, competitive yo-yo player, long-distance runner, and most recently\u2014a 2022 Barry Goldwater Scholar. Double majoring in Molecular Biophysics and Biochemistry (MB&B) and Statistics and Data Science (S&DS), Eric dedicates his time outside the classroom to researching and understanding cancer drug resistance, with previous work in epigenetics and DNA damage.\nGrowing up in northern Virginia, Eric was always excited by the proximity of the National Institute of Health in Maryland. \u201cYou see experiments in the textbook, and you\u2019re like \u2013 how do you actually do that?\u201d Eric said.\nAt sixteen years old, Eric cold-emailed NIH principal investigators hoping for a summer laboratory experience and ultimately joined Philipp Oberdoerffer and Mirit Aladjem\u2019s labs, where he spent the next two years. There, he studied the epigenetics behind the DNA damage response, primarily how different types and modifications of histones (which are what DNA wraps around in the cell\u2019s nucleus) could dictate or inform the environment in which DNA repair processes occur.\nHe continued pursuing this interest in epigenetics at Yale, where he joined Andrew Xiao\u2019s lab in the fall of 2019 as a first-year. \u201cI felt that the projects that were ongoing were really fascinating, and there was great mentorship from the MD/PhD students in the lab that have helped me tremendously through the last couple years, especially navigating the pathway of applying for an MD/PhD,\u201d Eric said.\nDespite initial setbacks due to COVID-19, Eric\u2019s work on cancer drug resistance\u2014specifically targeted therapies in the context of lung adenocarcinoma\u2014has made great progress. He focuses on epidermal growth factor receptor (EGFR) mutant lung adenocarcinoma, a subclass of non-small cell lung cancers, and how these cancers ultimately develop resistance against therapies that are initially greatly effective.\nCurrently, in the clinic, patients with EGFR mutant lung adenocarcinoma are treated with specific targeted therapies called tyrosine kinase inhibitors, one of which\u2014Osimertinib\u2014is used as a first-line treatment for EGFR mutant lung adenocarcinoma patients, and is the focus of Eric\u2019s research. These patients are sensitive to these targeted therapies because these inhibitors bind to mutated EGFR but not wild-type EGFR, effectively only targeting and killing the cancer cells and not wild-type healthy cells.\n\u201cThe problem is, patients often develop resistance in just a matter of months,\u201d Eric said. \u201cIn the clinical setting, we see tumors initially regress but then expand again and metastasize further, so understanding why tumors become resistant has been a major question in the field.\u201d\nEric\u2019s project particularly questions how oncogene amplification is involved in resistance, notably how two copies of an oncogene can amplify to fifty copies or even one-hundred copies and how the cell can then exploit that upregulation to develop therapeutic resistance. Through mining sequencing data, including rich clinical trial data from the National Cancer Institute, as well as hands-on imaging, genomics, and assay work at the bench in different cell line models, Eric has studied the acquisition of resistance through various approaches. \u201cWe have a lot of data from various aspects, from patient data to cell line models, suggesting a common mechanism of oncogene amplification that drives Osimertinib resistance,\u201d Eric said.\nEric reflected on the Barry Goldwater Scholarship and how the award has influenced him as a researcher. \u201cI take pride in that it\u2019s an affirmation that I\u2019m doing the right things,\u201d Eric said. \u201cReally, I\u2019ve been mentored really well, and it\u2019s a testament to the faculty and the professors that I\u2019ve been able to get to know at Yale who really supported me both in the classroom and in my research.\u201d\nAfter graduation, Eric plans to pursue an MD/PhD, stating that though he really enjoys research, he also really loves spending time in the clinic to see how his research interfaces with clinical issues.\n\u201cI don\u2019t think science lives in a vacuum; you don\u2019t do science just for science. You see patients, you see what their challenges are, you see patients fail treatment with a drug or develop resistance, and then you go back to the bench and ask: now how do you understand this?\u201d Eric said.\nRegarding advice for aspiring researchers, Eric stressed a confident mentality. \u201cJust don\u2019t be afraid in general. Reach out to people, screw up an experiment, those are small things in the grand scheme of everything. If you\u2019re afraid, you aren\u2019t even going to try,\u201d Eric said. Without a doubt, Eric\u2019s passion and enthusiasm for science and medicine will not just better the research community but will also continue to inspire everyone around him for years to come.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/undergraduate-profile-eric-sun-my-23/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Hidden Histories: Nettie Stevens",
            "author": "Anjali Dhanekula",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/MaliaKuo_nettie-418x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Malia Kuo.\nNettie Maria Stevens was born on July 7, 1861, in Cavendish, Vermont, where her family had lived for several generations. Still feeling the aftereffects of the Civil War, women in the US generally had few educational and professional opportunities. However, in part because of her father\u2019s accumulated wealth, Stevens attended public schools, eventually graduating from Westford Academy at the age of nineteen. Stevens was a dedicated student, earning praise from teachers and peers alike.\u00a0\nAfter graduation, Stevens became a high school teacher to save money to continue her education. Later, she attended Bryn Mawr College and pursued a graduate scholarship in biology. After just six months at Bryn Mawr, Stevens performed such brilliant work that she was awarded a fellowship to conduct research abroad. She studied at the Zoological Station in Naples, Italy and the Zoological Institute of the University of W\u00fcrzburg in Germany. After earning her doctorate at Bryn Mawr, she continued to teach and research at the college until her death due to breast cancer in 1912.\nStevens studied morphology, the study of the forms of living organisms, and cytology, the study of the structure and function of plant and animal cells. Her research focused on sex determination, how biological sex and sex characteristics are determined in organisms. At the time of Stevens\u2019 research, there were two major schools of thought on sex determination. Some believed sex was determined by external factors and others believed that sex was determined at the point of fertilization, not by the surrounding environment. Over the course of her research, Stevens noticed that male mealworms produced sperm with either a large chromosome (now known as the X chromosome) and sperm with a small chromosome (now known as the Y chromosome), but female mealworms only produced eggs with large chromosomes. She concluded that chromosomes, specifically on the paternal side, are responsible for sex determination.\u00a0\nDespite Stevens publishing her groundbreaking discoveries, many credit Edmund Wilson, a geneticist who worked in the same fields as Stevens, for the finding. While Stevens and Wilson worked on chromosomal sex determination simultaneously, they arrived at the conclusion independently. In fact, Thomas Hunt Morgan, a mentor to Stevens who did not accept the theory of chromosomal inheritance at the time, is often credited with discovering the genetic basis for sex discrimination. Morgan even went on to win a Nobel Prize in 1933 \u201cfor his discoveries concerning the role played by the chromosome in heredity.\u201d\nStevens is not the only female scientist whose contributions to science were not recognized as her own until long after her death. Others include Rosalind Franklin, who co-discovered the helical structure of DNA, and Esther Lederberg, who discovered a virus that infects E. coli bacteria, a widely used tool in the current study of genetics. This pattern indicates the Matilda effect: the repeated dismissal of scientific discoveries made by women in science. Stevens\u2019 discoveries about sex determination are the basis for many advancements in research on Turner syndrome and Down syndrome, as well as developments in the chromosomal basis of heredity. Although Stevens dedicated much of her life to her education and research, making crucial contributions to the field of genetics, the highest position she ever reached was as an associate in experimental morphology at Bryn Mawr College. Thomas Hunt Morgan described her as more of a lab technician than a true scientist. Reporters at the time stressed Wilson\u2019s discovery over Stevens\u2019, even though Stevens stated her conclusions more explicitly.\u00a0\nWithout Stevens\u2019 discoveries, it is impossible to know where the field of genetics would be today. Yet, like many other female researchers, her work has been consistently undervalued. There is limited research available on how to diminish gender bias in scientific fields. However, by continuing to acknowledge the contributions of female scientists, we can work to create a world where the Matilda effect does not exist\u2014a world in which we celebrate Nettie Maria Stevens for her achievements.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/hidden-histories-nettie-stevens/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Alumni Profile: Jonathan Rothberg (GSAS \u201891)",
            "author": "Sophia Burick",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Dong_3.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Photo Courtesy of Alex Dong.\nJonathan Rothberg GSAS\u2019 91, the pioneer of next-generation DNA sequencing, has always had a scientific bent and entrepreneurial spirit. His father, a chemical engineer, built his own company and turned the basement of their family home into a laboratory. Conversations around the dinner table often revolved around business.\nAfter earning his bachelor\u2019s in Chemical Engineering from Carnegie Mellon University in 1985, Rothberg arrived at Yale to complete a PhD in Biology. In the lab of Yale professor emeritus Spyros\u00a0Artavanis-Tsakonas, he investigated the molecular basis of nervous system wiring.\u00a0\nWhile still a student at Yale, Rothberg founded his first company, Curagen. Curagen was one of the first movers in the genomics industry in the 1990s. They invented a new field dubbed global proteomics, which entails identifying and analyzing all the proteins in a sample. \u201cWe were the first ones to map out all the protein interactions in a yeast cell, which got featured on the cover of Nature,\u201d Rothberg said.\nWhen his son had difficulties breathing after birth, Rothberg was frustrated that genome sequencing technology was not fast enough to provide him with genetic answers regarding his son\u2019s condition. While in the hospital, Rothberg saw an InfoWeek magazine cover featuring the new Pentium semiconductor chip. In that moment, inspiration struck. He could apply the concept of transistors\u2014which are used in circuits in large quantities to switch or amplify electrical signals in a massively parallel way\u2014to DNA sequencing. \u201cI could interrogate a sequence of bases, but this time, instead of doing it in one test tube, I could do it thousands of times or millions of times in parallel,\u201d Rothberg said. While still working at Curagen, Rothberg founded his second company, 454 Life Sciences, to develop this revolutionary technology. Rothberg\u2019s method became known as next-generation sequencing and is still used today.\u00a0\nShockingly, Rothberg was fired by the boards of Curagen and 454 for this idea. The company\u2019s board believed the completion of the Human Genome Project had rendered the technology obsolete and sold 454 Life Sciences for 140 million dollars.\u00a0\nStill convinced that next-generation DNA sequencing was the future, Rothberg founded Ion Torrent. This time, he\u2019d have to do something different. Instead of just using the general concept of massively parallel analysis derived from transistors on a chip\u2014sequencing the DNA at many different spots simultaneously\u2014Rothberg approached the issue more directly, creating a semiconductor chip that could directly sequence DNA in a massively parallel way. Out of this idea came the Ion Torrent chip: a semiconductor chip capable of sensing the chemistry of DNA synthesis through pH changes, allowing the user to rapidly sequence DNA. \u201cWe were really on a great path to a thousand dollars genome by just going to newer factories or foundries and making denser chips,\u201d Rothberg said.\nRothberg sold Ion Torrent to Life Technologies for 725 million dollars\u2014five times the amount 454 Life Sciences was sold for. Ironically, almost exactly ten years after he was fired for the idea, President Barack Obama awarded Rothberg a National Medal of Technology and Innovation for his work on next-generation sequencing.\nAfter Ion Torrent, Rothberg wanted to transition to parallel entrepreneurship\u2014helping several different startups develop at once. To do this, he launched a startup accelerator called 4Catalyzer. Rothberg has three key criteria that startups under 4Catalyzer must meet: each startup must solve a problem that affects the life of someone they love, use artificial intelligence, and take advantage of semiconductors or the concept of large-scale integration behind semiconductors. One of 4Catalyzer\u2019s startups, Detect, played a major role in the COVID-19 pandemic. Detect\u2019s mission was to develop an at-home COVID test with sensitivity comparable to a PCR test. The test they developed was sometimes demonstrated to be ten thousand times more sensitive than the at-home alternative of antigen tests. Now, Detect is applying their technology to other ailments. \u201cIt will be for universal testing, and they\u2019ll do STIs, COVID, and flu. They\u2019ve raised about 160 million dollars for the company,\u201d Rothberg said.\nMany of the companies under 4Catalyzer, like Detect, are headed by Yale graduates, and Rothberg is always eager to work with the latest talent coming out of Yale. For Yalies looking to try their hand at scientific entrepreneurship, Rothberg\u2019s advice is simple. \u201cFind somebody that compliments you. If you\u2019re good at business, find someone good at science. I think that raises your probability of success the greatest\u2014just finding a complement that you can work with,\u201d Rothberg said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/alumni-profile-jonathan-rothberg-gsas-91/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Robots vs. Humans: Organic Chemistry Edition",
            "author": "Anya Razmi",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/MaliaKuo_orgorobot-375x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Malia Kuo.\nFor thousands of years, human innovation has been defined by the creation of big tools: the wheel, the watch, the scythe. Only in the last two centuries have we begun to investigate the power of small tools: molecules. From synthetic dyes to life-saving medications, molecular toolmaking has the potential to solve some of society\u2019s greatest technological challenges.\u00a0\nBut making molecules isn\u2019t easy. The synthesis of small organic molecules usually requires very specific reaction conditions\u2014a tailored combination of solvents, temperature, pressure, and catalysts\u2014to maximize product yield. Knowing which conditions suit which reactions takes expertise, the kind of expertise that only organic chemists, after years of highly specialized study, possess.\u00a0\n\u201cRight now, molecule making is this very exclusive club that only a few of us can get into,\u201d said Martin Burke, a professor of chemistry at the University of Illinois at Urbana-Champaign. \u201cWe want to shatter those barriers and invite everyone into the molecule-making space.\u201d A recent collaboration between Burke and his colleague Bartosz Grzybowski, a professor at the Polish Academy of Sciences, is working to achieve just that. The paper, titled \u201cClosed-loop optimization of general reaction conditions for heteroaryl Suzuki-Miyaura coupling,\u201d was published in Science in October.\u00a0Together, the two teams of researchers searched for a way to optimize general conditions\u2014conditions that, regardless of the building blocks used, maximize the final product of a reaction. In particular, they investigated Suzuki-Miyaura cross-coupling (SMC), the quintessential reaction for carbon-carbon bond formation.\nWith so many factors affecting a reaction, finding the best combination to optimize yield is enormously challenging. \u201cThe haystack is astronomical,\u201d Burke said. \u201cIt\u2019s literally beyond the capacity of collective capability of our planet.\u201d The researchers needed a way to shrink this haystack\u2014to find a list of possibilities for general conditions, then test them as quickly and accurately as possible.\u00a0\nThe solution? Artificial intelligence and robots.\u00a0\nAt the Beckman Institute in Illinois, robots performed 530 chemical reactions. Syringes, purification columns, and pipettes were connected by masses of tubing, all of which worked in sync to carry out experiments independent of human hands. It wasn\u2019t humans typing in which conditions the robots should use, either\u2014it was AI. Grzybowski and his colleagues developed a machine learning algorithm to instruct the robots on which conditions to test.\u00a0\nThe process was a closed loop: Once a reaction had been performed, the data was transferred to the AI. The algorithm then developed altered procedures and transferred them back to the robot, which performed the reaction again under this new set of conditions. Then the cycle repeated.\n\u201cThe AI was in Poland. The robots are in Illinois. The loop was happening across the world,\u201d Burke said.\nBurke and his colleagues had tried defining general conditions before. In 2009, they published a paper in the Journal of the American Chemical Society which used human-guided experimentation to identify general reaction conditions for the SMC reaction. It was the best that humans could do, and it took six years.\u00a0\nWithin four months, artificial intelligence doubled their yield.\u00a0\nThe implications of this result are far-reaching. The scientists\u2019 ultimate goal is a \u201cplug-and-play\u201d platform in which researchers can enter the desired function for a molecule and have robots create it for them. With this type of technology, the synthesis of organic molecules could be democratized, no longer limited to a small group of experts. Ideally, this platform would use a limited number of reactions\u2014maybe even just one.\u00a0\n\u201cRight now, in chemistry, there are about fifty to one hundred thousand\u00a0 reaction types. And it all might be unnecessary, in some sense,\u201d Grzybowski said. \u201cNature uses very few operations, but repeatedly, in an iterative fashion. The robots are trying to do exactly the same.\u201d\nPart of the algorithm\u2019s success hinged upon its ability to probe both negative and positive results. \u201cThe AI was learning not only what works, but also what doesn\u2019t work,\u201d Grzybowski said. \u201cWith failure, the robot learns. And then it finds the right path.\u201d For this algorithm to succeed, negative results were just as important as positive ones. This is a notable departure from how the scientific field currently works: people don\u2019t publish negative results. For Burke, this was an important lesson.\n\u201cWe don\u2019t spend a lot of time trying to figure out why things fail,\u201d Burke said. \u201cWe\u2019re always trying to teach AI about how to do the things that we do. I think things just flipped. AI is teaching us something very important about how to do science. I feel like I learned something from AI, and that\u2019s exciting.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/robots-vs-humans-organic-chemistry-edition/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Golden Standard",
            "author": "Anavi Uppal",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/A-Golden-Elixir-Noora-Said.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Noora Said. \nWhether you\u2019re cooking a meal or mixing a drink, chances are that you taste your creation to figure out if it\u2019s right or not. Maybe there\u2019s too much sugar in the lemonade, or your tomato sauce isn\u2019t cooked enough, or your stir-fry needs more salt. Our senses have always helped us decode the mysteries of what we eat and drink. But now, we can also use chemistry to figure out when our favorite refreshments are perfect to consume. Researchers from the University of Glasgow and the Scotch Whisky Research Institute have recently designed a way to determine the flavor maturity of whiskey by using gold.\nAfter whiskey is distilled, it is stored for years in charred wooden casks to gain its characteristic flavor and amber color. The type of cask used for whiskey storage and the duration of aging can dramatically change its flavor profile. This flavor comes from chemicals called congeners that the whiskey absorbs from its wooden cask. Traditionally, casks of whiskey must be constantly sampled by a master blender, who determines if the flavor is just right. Since there are often hundreds or thousands of casks to sample, each taking so long to age, whiskey distillers are very interested in developing a quicker way to assess the maturity of their products.\u00a0\nWilliam Peveler, a chemist at the University of Glasgow in Scotland, first came across the science of whiskey when he saw a related infographic in Chemical & Engineering News magazine. He noticed that some of whiskey\u2019s chemical structures looked similar to the chemicals he worked with during his doctoral studies, which focused on creating gold nanoparticles. He wondered if whiskey could also be used to make these nanoparticles, and his team tested the hypothesis by using a cheap supermarket-brand whiskey in their lab. \u201cAnd it did work, which was surprising since things don\u2019t always do that!\u201d Peveler joked.\nThe researchers found that the qualities of gold nanoparticles that form in different types of whiskey can reveal how long it has been aged. Their analysis involves taking just fifty microliters of whiskey\u2014the equivalent of one droplet\u2014and mixing in the same amount of gold salt. The flavor congeners in the whiskey reduce the gold salt into gold nanoparticles and stabilize them against growing any larger than a few hundred nanometers. These particles are so tiny that they can\u2019t be seen by the naked eye. However, they do give the whiskey a visibly different color because gold nanoparticles absorb light very strongly compared to many other materials. Gold nanoparticles typically absorb green wavelengths of light the strongest. This means that we don\u2019t usually see green light from gold nanoparticles\u2014rather, we perceive the gold nanoparticles as different tones of pink, red, or purple. After just fifteen minutes, the final color of the sample reveals how aged or flavorful the whiskey is. Whiskeys with more flavor congeners generally produce more nanoparticles, giving the sample a more intense color.\nThe researchers\u2019 use of gold might strike some as strange. \u201cOf course, you use gold, and everyone goes, \u2018Well, gold\u2019s really expensive. Why are you using gold?'\u201d Peveler said. Peveler\u2019s group also explored using silver for their study since silver is cheaper and its nanoparticles absorb light even more strongly than gold nanoparticles. However, the composition of silver is different, and the researchers found that the chemistry of whiskey wasn\u2019t powerful enough to reduce silver into satisfactory amounts of nanoparticles. The color of the whiskey and silver mixture did change, but it took hours or days for the reaction to become visible, so Peveler\u2019s team stuck with gold. And surprisingly, the gold they used wasn\u2019t that expensive: the amount of gold needed for each whiskey test is much less than one cent.\nIn their research lab, Peveler and his team used a spectral photometer worth thousands of dollars to analyze the exact colors of these whiskey mixtures. This instrument looks at light on a wavelength-by-wavelength basis to see how much of each color the whiskey absorbs. However, it\u2019s possible to create a much cheaper version of this device that whiskey distillers could use to quickly and inexpensively test their own samples in-house. This device would use a diffraction grating, a clear piece of plastic or glass that spreads out white light into the rainbow of colors that it is composed of. By shining a light through the whiskey mixture and looking at it through a diffraction grating, you can tell which specific colors of light are being absorbed or reflected by the whiskey, revealing its age. Such a setup could be strapped to a smartphone camera and would only cost tens of dollars to make.\nIn future studies, the researchers hope to use gold nanoparticles to measure more than just the age of whiskey. \u201cWhat we saw tantalizing hints of in the paper but couldn\u2019t necessarily pin down in the time frame that we were working with was that sometimes we measured a whiskey, and it gave a really different colored particle, or it was a much bigger particle, or a different shape,\u201d Peveler said. \u201cSometimes we saw spheres. Sometimes we saw a sort of triangle plate-like thing. Sometimes we saw rods or a star-type shape. My hypothesis is that that is linked to the different chemistry that is coming out of the wood.\u201d Ideally, the gold nanoparticles would not only allow whiskey distillers to determine how much flavor has infused the whiskey but also identify the specific flavors. For example, they might be able to correlate certain particle shapes or colors with buttery flavors or with smoky undertones. \u201cThat\u2019s going to be a key challenge going forward,\u201d Peveler said.\u00a0\nThrough chemistry, it\u2019s becoming possible to dissect the flavors we encounter in our daily lives. \u201cI\u2019m fascinated by this kind of stuff: how we taste, how we smell, how we perceive flavor, and things like that,\u201d Peveler said. Peveler has previously done similar sensing research that goes even beyond food and beverages, such as detecting explosives in wastewater and sensing liver disease in blood. But as a big whiskey fan\u2014and a researcher based in Scotland, which is famous worldwide for its whiskey\u2014he has particularly enjoyed working with it for this project. \u201cIt\u2019s whiskey! It\u2019s fun, right?\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/the-golden-standard/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Conan the Bacterium",
            "author": "Kayla Yup",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Conan1-Breanna-Brownson-349x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Breanna Brownson.\nConan the Bacterium may be Earth\u2019s most promising astronaut. Named the world\u2019s \u201ctoughest organism,\u201d Deinococcus radiodurans\u2014nicknamed Conan\u2014could survive for a whopping 280 million years if buried ten meters beneath the Martian surface. This resilience suggests that if life ever existed on Mars, it could still exist today.\nThe surface of Mars is deeply frozen and extremely dry. The atmosphere contains almost no oxygen and is over one hundred times thinner than Earth\u2019s. Any life form released on Mars would essentially be freeze-dried and exposed to intense radiation from the sun. But Conan regularly challenges known limits of survival. The microbe can be frozen, desiccated, and face intense radiation, yet still live to see another day. In a recent study led by Michael Daly, a professor of pathology at Uniformed Services University of the Health Sciences and a member of the National Academies Committee on Planetary Protection, Conan and five other organisms were tested for potential survivability on Mars.\u00a0\nAs missions to and from Mars reach fruition, worry over cross-contamination between planets is putting the spotlight on Conan and other hitchhiking microbes. Future manned missions would expose Mars to astronauts and their microbiomes, raising the concern that Earthen microbes could be released and contaminate Mars\u2019 surface. Daly\u2019s study examined six microbes found in the human gut: Conan the Bacterium, E. coli, three spore-forming Bacillus bacteria, and a strain of baker\u2019s yeast called Saccharomyces cerevisiae. All six are representatives of the human microbiome. In this study, Conan and the baker\u2019s yeast broke all previous radiation survival records, even when compared to Bacillus spores, which are renowned for their resistance.\nTo simulate the conditions on Mars, all six organisms were first dried in a desiccation chamber for five days and then stored on dry ice. The frozen organisms were later placed in an irradiator and exposed to very large doses of ionizing radiation in the form of gamma rays and protons\u2014imitating forms of radiation from the sun.\nWhen charged particles, including protons from the sun, approach Earth, our magnetic field deflects them, and our atmosphere blocks them. But Mars has no magnetosphere and virtually no atmosphere to protect itself: protons are free to crash into the Martian surface and generate additional gamma rays. This is why the most dangerous part of Mars is the top ten centimeters of the Martian surface\u2014Conan could only survive that amount of ionizing radiation for about 1.5 million years. Further below the surface, shielding can protect against main forms of ionizing radiation, leaving only the planet\u2019s low natural background radiation, as it is on Earth. \u201cThe deeper you go [into Mars\u2019 surface], the more likely it is that you will find the remnants of life,\u201d Daly said. \u201cThe survivability of life is now greater than we had ever thought possible.\u201d\nConan\u2019s mechanisms for survival have previously been characterized, but not in the context of Mars. Past studies looked at radiation under Earthen conditions, representing a planet where life revolves around liquid water. The limits of ionizing radiation survival have traditionally been established by increasing doses of gamma radiation until the last viable microbe is dead. In decades past, Conan\u2019s \u2018survival limit\u2019 was approximately 25,000 kGy of gamma radiation under aqueous conditions. The present study found that if first dried and then frozen into a dormant state, Conan could withstand a whopping 140,000 kGy of gamma radiation.\u00a0\n\u201cIn the past, folks and scientists considered the survivability of life on Mars to be on the order of perhaps millions of years,\u201d Daly said. \u201cBut we now have the evidence to support that life, when dormant, could likely survive hundreds of millions of years.\u201d\nThere are two essential reasons for Conan\u2019s extreme resistance to radiation: the hyperaccumulation of manganese antioxidants (Mn-antioxidants) coupled with polyploidy (the presence of multiple identical genomes). Mn-antioxidants protect proteins needed to rebuild DNA, and polyploidy provides the cell with backup genomes used in repair.\nExtremophiles like Conan accumulate Mn-antioxidants, which are small complexes that consist of manganous ions bound to a variety of common metabolites. Generally, the more Mn-antioxidants accumulated in a cell, the greater the organism\u2019s resistance to ionizing radiation. Ionizing radiation is a high-energy form of radiation that can strip electrons from water, forming unstable molecules called \u2018reactive oxygen species\u2019 (ROS). The most toxic ROS in irradiated cells is superoxide, which \u201cfries\u201d the proteome, Daly explained. The proteome is the organism\u2019s set of proteins\u2014including the molecular machinery required to reassemble DNA broken by radiation. Mn-antioxidants in Conan defend the proteome against ROS and thereby preserve the enzymes needed to rebuild its broken genomes after radiation. In contrast, cells like E. coli that lack this Mn-antioxidant defense lose the ability to reassemble DNA damaged by radiation.\nManganese antioxidants do not prevent DNA damage caused by radiation\u2014luckily, the second molecular trick in Conan\u2019s tool kit is polyploidy. Polyploidy means that when one genome is damaged, other undamaged copies can be used to repair the broken one. Conan contains eight identical copies of its genome per cell. The team showed that the organisms with the greatest resistance to radiation are polyploid. E. coli and Bacillus spores typically have only one or two genome copies, while baker\u2019s yeast has four copies. In Conan, the eight genome copies are linked together by interstrand crosslinks called Holliday junctions, further accelerating DNA repair. \u201cWhen you get a double-strand break caused by radiation in the genome, then the repair templates for homologous recombination are never far away,\u201d Daly said.\nThe baker\u2019s yeast strain studied is also a polyploid, but this fungus accumulates fewer Mn-antioxidants than Conan. By comparison, E. coli does not accumulate Mn-antioxidants and typically has only one or two copies of its genomes. While the Bacillus spores accumulate Mn-antioxidants, they are merely haploids, containing only a single copy of the genome. In the end, the data showed that dried and frozen Conan would possibly survive 280 million years when buried ten meters below the Martian subsurface, the yeast would survive 48 million years, E. coli would survive sixteen million years, and Bacillus spores would survive relatively less.\nThe forthcoming ExoMars mission\u2019s Rosalind Franklin rover plans to drill two meters below the surface of Mars and collect samples in search of life. While the surface of Mars has been frozen and desiccated for billions of years, Daly theorized that life could still exist not far beneath the surface. He explained that Mars\u2019 lack of an atmosphere means that meteorites regularly bombard the planet. Upon impact, frozen water beneath a crater will melt, and simple organic compounds delivered by some meteorites could fertilize and fuel cellular recovery. If this theory holds true, Conan could have a Martian doppelganger out there to challenge its title as the world\u2019s toughest organism.\nArticle IX of the Outer Space Treaty (OST) of 1967 is an international agreement aimed at preventing harmful cross-contamination in the exploration of life across celestial bodies. While Conan\u2019s survivability suggests that forward-contamination of Mars would be essentially permanent over mission time-frames of thousands of years, this would not be considered harmful under the OST because the organisms cannot proliferate when frozen and desiccated. Harmful backward contamination from Mars to Earth is also unlikely because if life ever evolved on Mars, it would now be anaerobic\u2014able to survive without oxygen\u2014and susceptible to the toxic effects of Earth\u2019s oxygen-rich atmosphere.\u00a0\n\u201cIt is not considered harmful contamination unless these organisms were dispersed across the planet and somehow found some warmth and water,\u201d Daly explained. \u201cThere are good reasons to think that we can explore the surfaces of Mars without harming the science that is dedicated to looking for the possibility of extraterrestrial life. One can speculate that Martian life, if it ever existed there, still exists below the surface.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/conan-the-bacterium/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A New Approach to Cystic Fibrosis",
            "author": "Matthew Zoerb",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Zoerb_Figure1-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nThe possibility of rewriting genetic code has given hope to the 35,000 Americans suffering from cystic fibrosis (CF). In individuals with CF, a \u00a0mutated gene causes a specific protein called the cystic fibrosis transmembrane conductance regulator (CFTR) to malfunction, wreaking havoc on the respiratory system.\u00a0\nIn each breath, dust, allergens, and pathogens enter our lungs and become trapped in a thin layer of mucus. This mucus must be constantly replenished to clean our airways and digest food, but without the properly functioning CFTR protein, mucus becomes viscous and thick, trapping contaminants in the lungs. The symptoms of CF manifest as coughing fits, frequent lung infections, and other discomforts. However, with the advent of gene editing, there is hope for a treatment for CF and other genetic diseases.\nA recent study by Yale postdoctoral research fellow Alexandra Piotrowski-Daspit and Marie Egan, a professor at the Yale School of Medicine, investigated a novel gene editing approach to restore the function of the mutated CF gene in mice. They targeted a specific mutation, the F508del mutation, responsible for about ninety percent of CF cases. To edit the mutated gene, the researchers encapsulated peptide nucleic acids (PNAs) and an unmutated \u201cdonor\u201d version of the CFTR gene into polymeric nanoparticles. PNAs are synthetic nucleic acids with a similar structure to DNA and the same complementary base pairs, which allow them to bind to target sites in genomic DNA. Once inside the cell, the PNA molecules form complexes around the mutated DNA, leveraging the cell\u2019s natural repair mechanisms to insert the corrected sequence using the donor DNA as a template.\nThere are several key differences between PNA and CRISPR/Cas9 gene editing. CRISPR/Cas9 uses nucleases to \u201ccut\u201d genomic DNA, which reliably enables genetic modification, but may accidentally damage DNA in regions other than the target site. PNA-based editing reduces the possibility of off-target effects by harnessing the cell\u2019s existing, non-mutagenic repair mechanisms to incorporate the correct DNA sequence. This makes them an attractive choice since they reduce the likelihood of accidentally harming other systems in complex living organisms.\nThe experiment demonstrated that gene editing has the potential to treat CF, which affects multiple organs throughout the body. \u201cIt\u2019s kind of the holy grail of gene editing\u2014to be able to effectively deliver gene editing agents systemically,\u201d lead researcher Piotrowski-Daspit said. Even though the percent of cells edited in the treatment was less than the estimated five to fifteen percent needed to match healthy individuals, a partial restoration of function in the affected organs was observed without any off-target effects.\u00a0\nLooking beyond the specific F508del mutation that served as the focus of this study, new PNAs will need to be synthesized to target other mutations responsible for CF, for which no treatments are currently available. Piotrowski-Daspit\u2019s personal goal is to improve delivery efficiency and restore function to a higher percentage of cells. These advances may eventually translate into treatments that can cure CF and other genetic diseases in humans.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/a-new-approach-to-cystic-fibrosis/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: Eating to Extinction",
            "author": "Dinesh Bojja",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/26676026664_274d633466_c-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nEvery day, our dining halls are filled with countless choices: dozens of types of pizza, chicken tikka masala and aloo gobi, Cajun fish tacos, and cheese quesadillas. But if we take these foods back to their base ingredients, that variety vanishes. In fact, only three plants\u2014rice, wheat, and maize\u2014account for half of all calories consumed globally. This expanse of diverse food options masks a dramatic loss in true food biodiversity and the increased homogenization of agriculture and food production.\u00a0\nIn his book Eating to Extinction: The World\u2019s Rarest Foods and Why We Need to Save Them, Dan Saladino discusses the uniformity of modern food production, driven by a steep demand for low-cost, high-quantity food species. For example, half of the world\u2019s cheese is made from bacteria and enzymes produced by the same company. The same breed of pig controls the international pork trade. And only one of the 1500 types of bananas dominates the global market. Saladino attributes this trend\u2014sacrificing variety for surfeit\u2014to a few concurrent factors: shifts in land usage, the introduction of chemical fertilizers and pesticides, and a rise in genetic modifications for crops and livestock alike. Dubbed the \u201cGreen Revolution,\u201d this shift in the 1960s and 1970s was marked by unparalleled crop prosperity and food production, enough to sustain the world\u2019s growing population. Overall yields of staple crops skyrocketed, but other wild crops were driven to near extinction.\u00a0\nWhile there may be more food produced overall, this marks a dangerous trend. A decline in food biodiversity increases the risk of pests and diseases disrupting global food security. For example, one fungus, Fusarium graminearum, has led to billions of dollars of damage by infecting wheat crops in Europe, Asia, and the Americas. Saladino runs through countless examples of mass-produced foods overshadowing traditional species, from Cosmic Crisp and Red Delicious apples overpowering the apple market to slaughterhouse chickens, eliminating the need for traditional breeds or historically used but now obsolete species. A loss of diversity comes with a loss of culture, identity, and history.\nIt is not too late to reverse the trend, however. From scientific seed repositories in Norway to government-run food conservation efforts, thousands of different crops, animals, and fruits have been painstakingly preserved in hopes of future reintroduction and production. Thankfully, corporations also have recognized the need for increased food biodiversity, and twenty of the world\u2019s biggest food businesses have pledged to preserve traditional foods.\nBut the real hope is in the hands of farmers daring to continue their tradition, even in the face of agricultural giants. A \u201cchocolate lab\u201d in Venezuela specializes in producing traditional chocolate made from Criollo cacao. A village of resilient fishermen holds steadfast to their roots of selling wild Atlantic salmon. A group of millers on the Orkney Islands work with agronomists to bring back nutritious Bere barley. Even on the individual level, every effort is the chance to bring another species back from the brink of extinction. With a stroke of encouragement and support, the opportunity to restore food biodiversity is within reach.\n\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/science-in-the-spotlight-eating-to-extinction/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Streamlining the Search for New Drugs",
            "author": "Emily Shang",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/StreamliningSearch_MaliaKuo-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Malia Kuo.\nHave you ever wondered how scientists synthesize drugs? Everything, from the Advil you take to alleviate a headache to the Vitamin C gummies you eat to strengthen your immune system, needs to undergo rigorous scientific testing and scrutiny to ensure that it is safe for human consumption. The process of efficiently finding and synthesizing drugs is especially challenging for those treating specific medical maladies since the drug\u2019s functional mechanism must be investigated. Drugs often function by targeting specific receptors in our bodies and either block the effects of the receptor\u2019s typical function (antagonism) or activate the receptor to create a response (agonism).\nThe Challenge of Synthesizing Drugs\nWhen synthesizing new drugs, researchers have a lot of metrics to satisfy and a lot of factors to consider. First, the specificity and favorability of the drug to the drug target: are the pieces of the receptor and drug compatible, and is there a possibility for off-target binding? Second, the size of the drug: will its molecular weight hinder its ability to get where it needs to be in the body? Third, the molecular kinetics of the drug: how many of the bonds are rotatable, and how stable and likely is the conformation it takes on to bind the receptor? It\u2019s no secret that designing a drug that is specific, effective, and safe is no easy task: it\u2019s why the research and development process, not to mention the process of clinical trials and safety testing, is so long and arduous.\nBut recently, in a collaboration between the Ellman Lab at Yale University, the Irwin and Shoichet Labs at the University of California San Francisco, the Wetsel Lab at Duke University, the Skiniotis Lab at Stanford University, and the Roth Lab at the University of North Carolina, researchers have been able to use a novel virtual screening technique to streamline the beginning stages of drug discovery by finding promising molecules that bind potently and selectively to the 5-HT2A receptor. This receptor is a serotonin receptor involved in producing both the negative (hallucinations, delusions) and positive effects (alleviation of anxiety, depression) of the psychedelic drug lysergic acid diethylamide (LSD) and its affiliates in the brain.\nThe virtual screening process started with a broad analysis of the commonalities between the chemical structures of a variety of FDA-approved drugs. Researchers found that the most often-observed structures included the six-membered nitrogen heterocycles piperidine and pyridine. Thus, they began looking into using a virtual library technique to create a tetrahydropyridine (THP) drug, a much less investigated subclass of the kinds of structural molecules described above. This structure also produces some obstacles for synthesis, which made it an interesting candidate for virtual screening and analysis of molecular docking and binding.\u00a0\nCreating a Database of THP Molecules\nUsing the THP structure as a foundation, the researchers created a database of 75 million THP molecules. The contents of this database were limited to synthetic chemistry techniques available to the Ellman Lab using three different types of starting materials: an amine, enal/enone, and alkyne. The researchers also implemented a molecular weight limit of 350 grams per mole to increase the likelihood that the compounds would have effective delivery in animals. They also considered a cationic property of the molecule that would help the molecule competitively bind to G-coupled protein receptors such as the 5-HT2A receptor, as well as eliminate chiral starting materials that would have resulted in mixtures of THPs with different three-dimensional structures, for a simplified single-conformation output.\nNarrowing Down the Search\nThese 75 million THP molecules were then pared down using computational molecular binding techniques. Since the structure of the 5-HT2A receptor was unknown, the researchers composed one thousand models of the receptor bound to LSD in the hopes of analyzing the dynamics of the binding and finding a competitive molecule. Using this refined structure of the 5-HT2A receptor, the binding of the 75 million THP molecules was evaluated, and thirty molecules were selected as most likely to bind to the receptor. From the thirty molecules, seventeen molecules were able to be synthesized using commercially available materials. Four of these molecules were identified to bind to 5HT2A receptors, and two of these molecules exceeded preset binding thresholds in testing. Based upon the initial THPs that bound to the receptor, the team then designed, synthesized, and tested numerous additional analogs to obtain compounds that were potent and selective 5-HT2A receptor agonists.\u00a0\n\u201cWhile you can dock to predict binding, at this stage, you cannot predict if a compound is going to be an agonist or an antagonist. Virtual screening is just a foot in the door; afterwards, you really need chemistry for synthesizing a lot of compounds, testing a lot of compounds, critical analysis of data, and many iterations,\u201d said Jonathan Ellman, principal investigator of the Ellman Lab.\nThe 5-HT2A receptor can undergo two different pathways once activated. The first is the beta arrestin pathway, which has been linked to undesired psychedelic effects, and the second is the G-protein mediated pathway. \u201cOur molecules are more biased towards the G-protein mediated pathway, and we didn\u2019t see the psychedelic effects,\u201d James Kweon, one of the lead researchers from the Ellman group, explained. While it\u2019s very hard to predict just by looking at a chemical structure which signaling pathway will be favored, the molecules synthesized by the Ellman Lab are able to bias the receptor towards the G-protein mediated pathway rather than the beta arrestin pathway, which can then separate the psychedelic function of the receptor from the antidepressant function.\nLooking Into the Future\nThe next steps for the Ellman Lab and their collaborators include using the same virtual screening approach to find more complex molecules to selectively target a new receptor: this time, a pain receptor that is targeted by opioid drugs such as morphine. They hope to separate the harsh respiratory distress associated with opioid use by synthesizing a molecule with great functional selectivity that can separate these negative effects from the pain-relieving positive effects.\n\u201cWe\u2019re basically trying to demonstrate that virtual screening really can be used as a tool for even more complex molecules,\u201d Kweon said.\u00a0\nThe kinds of molecules they\u2019re synthesizing have a three-dimensional component which opens up more complex levels of docking analysis and will show that the technique of virtual screening is capable of taking on complex problems and solutions. Given its efficacy in successfully finding possible drug molecules fast, it\u2019s likely this virtual screening technique will become increasingly important for the discovery of new drugs.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/streamlining-the-search-for-new-drugs/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Lab Profile: CarDS Lab",
            "author": "Yusuf Rasheed",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Kim_9-500x167.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Images courtesy of CarDS Lab website.\nAccording to the CDC, one person dies every thirty-four seconds from cardiovascular disease in the United States. It is also the leading cause of death for men and women across the country, costing over $200 billion annually. In 2020, around 697,000 people in the United States died from cardiovascular disease, which accounted for twenty percent of all deaths that year. There are strong efforts worldwide in research and clinical care to improve the diagnosis and treatment of this disease, particularly at the Cardiovascular Data Science (CarDS) Lab at the Yale School of Medicine, which is tackling this issue through a creative intersection of computer science and patient data.\nThe CarDS Lab aims to improve cardiovascular health using data-driven insights into how care is delivered to patients. This means they use technology\u2014artificial intelligence (AI) with machine learning, for example\u2014to augment our ability to diagnose and treat patients. For example, the lab has built AI models that can detect cardiac muscle dysfunction from electrocardiograms (EKG), which humans are unable to do. \u201cThe entire idea is to democratize the access to technology so that more people know they may have [cardiovascular disease] so that they can be referred to the health system for more advanced imaging,\u201d said Yale University Assistant Professor of Cardiovascular Medicine Rohan Khera, who is the principal investigator of the lab. The group also works with national registries and datasets to define best methodological practices in conducting studies, evaluates healthcare policies and their association with cardiovascular health outcomes, and interprets clinical trial results personalized for individual patients. These goals are reflected in the structure of the lab, where members are part of a \u201ccore\u201d or a specific aim within the lab\u2019s overall goal. \u201cSome folks work on natural language processing, some work on ECGs, some work on cardiac imaging, some are focused on EHR design, some are working on trials. People present from one theme to the others, so everybody can learn what the others are doing, but [they] tend to focus on their own domain. That\u2019s been our key, to focus on building micro-labs within a large lab,\u201d Khera said.\u00a0\nKhera grew up in India, where he attended the All-India Institute of Medical Sciences for his medical training. He then had a variety of away rotations at several institutions, including Johns Hopkins University, the University of California, Los Angeles, and the University of Pennsylvania, where he gained broad exposure to basic translational and clinical research. This experience continued at the University of Iowa during his residency and at UT Southwestern for his fellowship. \u201cWhen I graduated fellowship, I knew I was going to start a research program\u2026It felt like there was a lot happening at [Yale]. It was very exciting how [Yale] had been at the cutting edge of health policy and outcomes research, so I came here to see if I could extend that further into more advanced data science,\u201d Khera said.\nKhera started his faculty position at Yale in July 2020, during the peak of the COVID-19 pandemic. \u201cEverything was shut down, and there was a lot of time spent thinking how one would structure the lab when nobody\u2019s around,\u201d Khera said. He noted that there were fewer opportunities to meet new people who would be interested in the lab, so he spent the first several months of the lab\u2019s inception exploring the Yale community. He credits the decision to run the lab virtually as one of the key reasons for its success, as people do not need to be in the same room all the time. Now, the CarDS lab has grown to over twenty people.\nAlong this mission to integrate machine learning with cardiovascular health, the lab recently published a paper titled \u201cIndividualising intensive systolic blood pressure reduction in hypertension using computational trial phenomaps and machine learning: a post-hoc analysis of randomised clinical trials.\u201d This study looked at two clinical trials, SPRINT and ACCORD BP, which each compared intensive versus standard blood pressure control treatment. Using a machine learning algorithm and a \u201cphenomapping strategy,\u201d which creates a network of all patients recruited in the trial to compare their phenotypes, they found that not every patient in the SPRINT trial benefitted to the same extent from the intensive blood pressure control treatment. In other words, the effect of the treatment seemed to vary across different types of patients. From these results, the lab was able to analyze a given patient\u2019s key characteristics and can tell how likely that patient is to benefit from intensive blood pressure control treatment. They then validated these findings independently in the ACCORD BP trial. \u201cThe traditional interpretation of clinical trials does not necessarily inform us about whether a given treatment works for each patient\u2026We\u2019re interested in better understanding how the results of a study can be individualized for each unique patient in front of us at the clinic\u2026We think that\u2019s pretty interesting because not every patient should be treated in the same way. And that\u2019s one step closer to more personalized cardiovascular care,\u201d said Evangelos Oikonomou, a clinical fellow in cardiovascular medicine at Yale\nA second project that the lab has been working on is developing AI models to diagnose structural heart diseases from printed ECG scans. The focus on ECG comes from the fact that they are the most widely accessible and ubiquitous tool in the world to better understand a patient\u2019s heart. However, physicians are only able to diagnose certain conditions and heart rhythm disorders from ECGs, creating the need for more expensive and harder-to-obtain screening tools for other heart conditions. The goal of the project is to be able to diagnose these conditions from ECGs\u2014leading this effort is Yale College senior Veer Sangha YC \u201923, who has recently received the Rhodes Scholarship for his work with the lab. \u201cWe have a large repository of patients at the hospital, so we have their ECGs, and we know which patient has which disease,\u201d Sangha said.\u201cSo we can train our deep learning models to be able to learn features in the ECG that are relevant to a certain class of disorders or a certain disorder that a patient may have. And it can learn these features that humans themselves cannot learn.\u201d To make this further accessible for patients, Sangha developed the model so that it didn\u2019t need to use the signal data from the ECGs, which is not always available at the point of care. Instead, the model can make these inferences from printed scans of an ECG, which are widely available to patients and their clinicians.\u00a0\nFor undergraduate students interested in joining the CarDS lab, Khera recommends using the lab\u2019s website Contact page or reaching out to him directly. He also suggests that students who want to join should ideally be interested in health technology and its applications and have some coding experience. Finally, he enjoys having students who want to be part of the lab for a long period of time. \u201cThose who engage for a longer time are always there in a community learning, adapting, and growing. The folks that have really developed their careers in the lab have been associated with us for a couple of years already now,\u201d Khera said.You can learn more about the CarDS Lab at https://www.cards-lab.org/.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/lab-profile-cards-lab/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The New Circular Economy",
            "author": "Abigail Jolteus",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/The-New-Circular-Economy-Kara-Tao.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Kara Tao.\nIncreased wildfires, heat, drought, and hurricanes are some of the devastating effects of climate change that continue to be seen across the world, and urgent action must be taken. To ensure that the Earth remains tolerable for humans to live on, environmentally friendly technologies are crucial. Over the past few years, there has been growing excitement about hydrogen fueling stations worldwide. The media portrays hydrogen fuel as a sustainable alternative to fossil fuels, with water being the only by-product.\u00a0\nIn reality, hydrogen fuels are usually generated using fossil fuels, emitting carbon dioxide (CO2) as a by-product. Hydrogen comes from methods such as steam methane reforming, coal gasification, and electrolysis from electricity sources such as grid, solar, etc. Hydrogen fuel contributes to greenhouse gas emissions and, consequently, climate change.\u00a0\nBut if many methods to generate hydrogen fuel either directly or indirectly contribute to greenhouse gas emissions, what can we do to mitigate its impact on the climate? The answer lies in a process called bioenergy with carbon capture and storage (BECCS), which is the process of generating energy from biomass or organic matter while capturing and storing the CO2 emitted and providing net negative greenhouse gas emissions.\u00a0\u00a0\nIn previous studies, methods such as techno-economic analysis (TEA) and life cycle assessment (LCA) were used to assess the economic feasibility and environmental impacts of BECCS. However, these studies did not consider the effect of the choice of energy supply. Moreover, previous studies rarely explored categories beyond climate impact, such as a broader range of impact indicators (e.g., human health impacts) of hydrogen as a fuel. In order to maximize the potential of BECCS, a holistic understanding of the effect of energy supply strategies and the implementation of carbon capture is crucial.\u00a0\nResearchers at the Center for Industrial Ecology at the Yale School of Environment wanted to assess the efficiency and impact of BECCS. \u201cThe basic idea is to evaluate the economic feasibility and environmental impacts of emerging biotechnologies,\u201d said Na Wu, a postdoctoral researcher in the Yao Lab.\nTo assess its impacts, the researchers developed the techno-economic-environmental assessment (TEES) framework\u2013a method to evaluate the environmental and economic impacts of BECCS and other similar carbon capture technologies. This framework incorporates methods used in previous studies, such as TEA and LCA, but also simulations of implementing BECCS with different possible conditions for the biorefinery, the facility that converts biomass to energy.\u00a0\nHow It WorksThis study assessed gasification-based BECCS, using leftover wood scraps and branches from logging, called forest residues, as a source of biomass for gas conversion. Their analysis focused on forest residues from the Pacific Northwest, specifically the Douglas fir and ponderosa pine, because there is a large amount of biomass present in the region, and due to wildfires, there is a need to thin the forests. This assessment was conducted using the TEES framework and is novel because it is an integrated model addressing the knowledge gaps of the biorefinery with all carbon dioxide emission sources. These simulation models integrate energy supply strategies while also taking into consideration the real-world application of these models.\n\u201cWe tried to maximize the carbon capture and storage process using our simulation models and integrate that with energy supply strategies,\u201d Wu said.\nIn order to simulate real-life scenarios, the researchers used a system with various components to measure and calibrate different options. They modeled eight biorefinery processes to determine which scenario is the most economically and environmentally feasible. These components include biomass preparation (such as size reduction and drying), gasification, cleaning syngas (a mixture of hydrogen and carbon monoxide), water-gas shifting, carbon capture, pressure swing adsorption, air separation, and heat power generation. This was used to simulate the conditions required to produce syngas from biomass. Additionally, they modeled the three main stages of carbon capture: capturing the CO2, transporting it, and then storing it deep underground. As the amount of biomass can affect the method\u2019s perceived efficiency, different scales with different amounts of biomass were used.\u00a0\nWith the appropriate boundaries established, the researchers analyzed four different scenarios. Scenario one consists of burning the syngas produced to generate heat and power simultaneously, leading to electrical self-sufficiency while trapping carbon underground (carbon capture). Scenario two is similar to scenario one but with no carbon capture, which served as a baseline to understand the effect of carbon capture implementation. Scenario three includes the same components as scenario one but uses all the syngas products for hydrogen production, leading to partial electrical self-sufficiency. Scenario four includes carbon capture technology but does not use a combined heat and power generation plant, which makes it the least self-sufficient electricity scenario.\nThe researchers decided which scenario was most favorable based on considerations such as the highest capital expenditure and operating expenditure. The most and least favorable scenarios varied depending on the type of expenditure examined. For instance, scenario one (fully self-sufficient) has the highest capital expenditure (CAPEX), whereas scenario two (no carbon capture) has the lowest CAPEX. This indicates that carbon capture requires a large amount of capital since scenario two is the only scenario without carbon capture included. However, scenario four (least self-sufficient) has the highest yearly operating expenditure (OPEX), whereas scenario one (fully self-sufficient) has the lowest OPEX due to the lowest utilities needed as a result of the full electrical self-sufficiency.\u00a0\nAfter calculating and analyzing the minimum selling price for hydrogen and carbon price for these four scenarios, they made two main conclusions. First, hydrogen derived from forest residues has the potential to achieve similar economic feasibility to current fossil fuel-based hydrogen with carbon capture. In fact, when the price of carbon dioxide is higher than $89 per ton of CO2, all four scenarios become more economically attractive than the current fossil fuel-based hydrogen. However, the opposite\u2014lower economic attractiveness when the price of CO2 is lower\u2014also applies. This leads to the second conclusion, which is that CO2 prices help determine how economically competitive the three scenarios with carbon capture can be.\u00a0\nTo further analyze the effect of renewable energy, additional cases for scenarios one (fully electricity self-sufficient) and four (least electricity self-sufficient) were examined. Instead of using an electricity source from the current grid, solar and wind energy were used. The findings indicated that renewable energy sources make scenario four preferable to electricity self-sufficiency (scenario one). However, further research needs to be conducted to determine the optimal renewable energy design for BECCS.\u00a0\nThese findings suggest that using BECCS has lower environmental impacts than the current hydrogen production methods and highlight the need for individuals from various sectors, including chemistry, analytics, business, engineering, and more, to successfully implement this biotechnology approach.\u00a0\nLimitations\nThere is no denying that BECCS has an immense amount of potential to be an excellent environmental solution, but it is important to acknowledge certain limitations in this study. The study did not include CO2 transportation and storage or hydrogen transportation in its model. Moreover, the study focused on the Pacific Northwest of the United States, which is only one small region in the world. Similar studies must be conducted in other regions to determine if this technology is economically feasible and has reduced environmental impacts.\u00a0\nImplications and Next Steps\nLooking towards the future, BECCS could be used in other waste feedstocks beyond forest residues to sustainably provide energy, such as animal wastes, food wastes, etc. This could be used to reform the agricultural industry, which is responsible for much of global greenhouse gas emissions.\u00a0\nThe findings from this study can help inform further research on other types of carbon capture and storage. Looking ahead, Wu wants to expand their study of carbon capture technologies to assess their economic and environmental impact. \u201cBECCS is a chemical-based process, but there are more natural methods for carbon capture and storage, such as afforestation and reforestation, enhanced weathering, and biochar and soil carbon sequestration,\u201d Wu said. Afforestation and reforestation rely on trees, enhanced weathering relies on rocks, and biochar and soil carbon sequestration rely on the soil (after CO2 is transformed into more stable carbon). \u201cThe next project I am working on is analyzing enhanced weathering carbon capture\u2014using rocks to capture CO2 in the atmosphere. We are trying to explore the different possibilities,\u201d Wu said.\u00a0\n\u201cWe can help in the decision-making of various parties, such as researchers working in the lab, and we can also provide insights to companies. For instance, we can explain if it\u2019s a good investment by determining if it is profitable, and we can also provide insights to the environmental authorities,\u201d Wu said. One thing is clear: an interdisciplinary team is necessary to create a more sustainable, low-carbon, and circular society. \u201cWe need different kinds of parties: authorities, companies, chemists, engineers, business people, etc. In that way, we can make sure we are heading in the right direction,\u201d Wu said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/the-new-circular-economy/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Recoding in the Brain",
            "author": "Elisa Howard",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Brain_Recode-Evelyn-Jiang-500x301.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Evelyn Jiang.\nThe human brain is constantly recoding itself. Adenosine-to-inosine (A-to-I) editing, a form of RNA modification, occurs at more than one hundred million sites in the human transcriptome, diversifying RNA sequences of the human brain.\nIn a recent paper published in Cell Reports, researchers at Icahn School of Medicine at Mount Sinai and the Yale School of Medicine investigated the spatiotemporal and genetic regulation of A-to-I editing over the course of human brain development. Their work catalogs A-to-I editing sites throughout human brain maturation, enhancing current understandings of neurodevelopment and underlying mechanisms of neurological diseases. \u201cRNA editing is dysregulated in neurodevelopmental disorders,\u201d said Winston Cuddleston, a PhD candidate at the Icahn School of Medicine and lead researcher of the study. \u201cWe are trying to get a better understanding of which RNA editing sites are dynamically regulated across brain development to realize which cellular and molecular processes are being affected.\u201d\nThe Science of RNA Editing\nAccording to the central dogma of molecular biology, coined by biophysicist Francis Crick, the expression of protein-coding genes involves the flow of genetic information from DNA to RNA to protein. A gene\u2019s DNA is copied into RNA through transcription, and that RNA specifies an amino acid sequence for protein synthesis in the translation process.\u00a0\nIn eukaryotes, primary RNA transcripts undergo diverse post-transcriptional modifications, resulting in mature RNA molecules prior to protein production. These modifications diversify the transcriptome, the collection of an organism\u2019s RNA transcripts.\u00a0\nA-to-I editing is a post-transcriptional modification involving adenosine conversion to inosine nucleosides. This conversion process is catalyzed by a family of enzymes called adenosine deaminase acting on RNA (ADAR) and occurs most prominently in the central nervous system (CNS). These modifications affect neuronal genes, including those involved in synaptic transmission and signaling.\u00a0\nIn protein-coding regions, A-to-I editing can result in amino acid substitutions at locations known as recoding sites. These recoding sites are necessary for normal neurodevelopment, given their involvement in modulating calcium permeability, desensitization recovery rates, and cytoskeletal organization at excitatory synapses, alongside other functions.\u00a0\nInvestigation of A-to-I Sites in the Brain\nMillions of individual A-to-I editing modifications have been found in humans\u2014many in the brain. Nevertheless, according to this study\u2019s senior author Michael Breen, assistant professor of psychiatry, genetics, and genomic sciences at Mount Sinai, only a small subset of these modifications appears to be functional. \u201cThose sites that are functional have precise temporal patterns across time. Their editing efficiency changes throughout age and development in the brain,\u201d Breen said.\u00a0\nBreen and colleagues took a systematic look at A-to-I editing sites across prenatal and postnatal stages of human brain maturation. The researchers collected RNA sequencing data from brain samples of the dorsolateral prefrontal cortex (DLPFC), cerebrum, and cerebellum. They also analyzed RNA-sequencing data from in vitro models of neuronal maturation, postmortem cortical samples from late stages of aging, and murine and non-human primate models of brain development. In doing so, the researchers collected brain RNA sequencing data covering the human lifespan.\n\u201cRNA editing is dynamically regulated in the brain during aging, and this is a unique property of RNA editing in the brain compared to other tissues in the body,\u201d Cuddleston said. In their paper, Breen, Cuddleston, and colleagues provide an atlas of A-to-I sites that are spatiotemporally and genetically regulated throughout brain maturation while uncovering key features of RNA editing throughout neurodevelopment. In particular, A-to-I editing is enriched in repetitive sequences known as Alu elements. Using an Alu editing index (AEI) to quantify modification levels, Breen and fellow researchers observed that global Alu editing steadily increases across all stages of brain development and neuronal maturation. This editing peaks around thirty to fifty-nine years of age, while advanced aging stages do not exhibit dynamic regulation.\u00a0\nThe researchers identified thousands of editing sites that are temporally regulated and increase in editing levels throughout neurodevelopment. The majority exist in the three-prime untranslated regions (3\u2032 UTRs) of genes critical for neurodevelopment. The minority of spatiotemporally regulated editing sites exist within protein-coding regions, and thirty-seven RNA-recoding sites appear to change in editing levels across maturation.\u00a0\nThe researchers also describe trends in hyper-editing. As opposed to A-to-I editing at individual adenosine nucleosides, hyper-editing refers to modifying many adjacent adenosines along an extended region. The results indicate that hyper-editing is enriched in advanced stages of aging with the function of stabilizing RNA secondary structures.\u00a0\nA-to-I Editing in Neurodevelopmental Disorders\u00a0\nEditing rates increase globally throughout brain development. \u201cGlobal increase is dynamic in different neurological diseases, so it could be looked at as a predictor of brain health,\u201d Breen said. The researchers asked whether sites displaying increased editing throughout brain development are affected in neurodevelopmental disorders. Their results suggest that A-to-I sites disrupted in postmortem brain tissue from individuals with schizophrenia and autism spectrum disorder are temporally regulated, exhibiting an increase in editing levels across maturation. \u201cKnowing what we think these sites do in typical brain development, [i.e.,] modulating the ability of micro-RNAs to regulate host gene expression, and that these sites are disrupted in neurodevelopmental diseases gives an immediate avenue towards trying to understand what these sites might be doing in these disorders,\u201d Breen said.\nRecoding sites where A-to-I editing results in amino acid substitutions provide further insight into neurodevelopmental diseases. \u201cA handful of recoding sites have been described as dynamically regulated in Alzheimer\u2019s, schizophrenia, and other neurological disorders,\u201d Breen said. \u201cWe know that these sites are important for synaptic transmission, and their editing efficiencies are altered in these different diseased states.\u201d\nAdditionally, hyper-editing data enhances the current understanding of the aging brain. Only a handful of prior studies investigate RNA hyper-editing, and none consider the developmental regulation of hyper-editing in the brain. Breen and fellow researchers discovered that hyper-editing increases in the aging brain and appears to affect transcript stability rather than directly regulating gene expression. Considering all study datasets, the normalized hyper-editing signal steadily rises across brain development periods and peaks into advanced aging stages. \u201cWhile site-selective editing peaks in terms of its rate of change in mid-fetal development, hyper-editing continues to accumulate all the way into advanced aging,\u201d Cuddleston said. \u201cThis is really important for aging research.\u201d RNA hyper-editing may provide insight into Alzheimer\u2019s disease, for instance, which Cuddleston aims to investigate in the future.\u00a0\nThe Prospects of RNA Biology\nIn Cell Reports, Breen and colleagues provide an atlas of spatiotemporally and genetically regulated A-to-I sites in the brain throughout human neurodevelopment while unearthing key features of RNA editing throughout the lifespan. These findings not only improve current understandings of human brain development at the RNA level but also provide an avenue for learning more about the foundations of neurodevelopmental disorders. \u201cWe know very little about RNA modifications and what those might mean for disease pathology,\u201d Breen said. \u201cWe are just starting to paint that picture.\u201d\nIt is through understanding such diseases at the neurobiological level that progress can be made toward treatment development. \u201cUnderstanding which RNA editing events are functionally relevant for disease is how we are going to get closer to therapeutics that we can use in the clinic,\u201d Cuddleston said.\u00a0With thousands of temporally regulated RNA editing sites, the brain is a fascinating organ of continual change. How is your brain recoding itself?\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/recoding-in-the-brain/",
            "captions": [
                ""
            ]
        },
        {
            "title": "On-Demand Membrane Deformation",
            "author": "Risha Chakraborty",
            "authorLogo": "",
            "date": "May 12, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Membrane_MaliaKuo-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art by Malia Kuo.\nScientists learn more about the cell every day. From taking microscopic pictures to performing biochemical tests on pellets of harvested cells, biologists are able to determine the organization and interactions of major cellular components, including organelles, proteins, and nucleic acids. But understanding what these interactions look like in real-time is much more difficult than capturing fluorescent images, which offer a freeze-frame snapshot of the cell, and biochemical assays, which offer only a general understanding of molecular interactions but are often limited by the experimenter\u2019s ability to manipulate the reacting biomolecules in space and time. In a recent article in Science Advances, Yale Professor of Cell Biology and Biomedical Engineering Chenxiang Lin and postdoctoral fellow Longfei Liu pioneer a unique way to study cell biology by harnessing the power of DNA as a molecule with a highly controllable structure to study the interactions of proteins and the cell membrane in real-time.\u00a0\nStudents typically learn that DNA is the genetic code of the cell, responsible for encoding the information eventually converted to the proteins responsible for cellular functions. But Lin offers an alternate perspective on DNA: that DNA itself has unique structural and chemical properties that can guide the assembly of other biomolecules and modulate how they interact. The DNA contained within our cells\u2019 nuclei is in the traditional double-stranded helix because this conformation keeps DNA stable and relatively easy to transcribe. But scientists can now control the sequence of short single-stranded DNA molecules, called oligonucleotides, such that they spontaneously form nanoscale assemblages of precisely defined shapes. And because DNA oligonucleotides are easier to synthesize and chemically modify than molecules not found in nature or even proteins, they form nanostructures desirable for biochemical and biophysical experiments, where scientists want to study the finest details of molecular organization, dynamics, and function. The programmability and self-assembling nature of the DNA structures allow scientists to repeat such experiments many times and with all kinds of permutations. \u201cThis bottom-up approach is very powerful since all you need to do is design the DNA molecules correctly. The DNA strands can find each other and self-assemble into larger structures, with precise experimenter control.\u201d Lin explained.\u00a0\nHistory of DNA Nanotechnology\u00a0\nAccording to Lin, the idea to use DNA as a structural macromolecule for more than just encoding genetic material harkens back forty years to New York University Professor Ned Seeman. Seeman imagined DNA nanostructures completely conceptually before creating them was even possible. DNA nanotechnology began to materialize upon creating a stable four-way DNA junction in a test tube resembling the Holliday junction, a somewhat complicated three-dimensional arrangement of single-stranded DNA pieces that forms during a type of DNA repair called homologous recombination. Scientists then began experimenting with combining multiple small, single-stranded DNA oligonucleotides into \u201ctiles\u201d and harnessing the symmetry of these tiles to build two-dimensional lattices or three-dimensional crystalline structures. In 2006, Paul Rothemund at the California Institute of Technology invented a new technology called DNA origami. He folded a single-stranded DNA extracted from viruses into shapes like smiley faces with the help of tens to hundreds of oligonucleotides. Importantly, these helper strands could each carry additional modifications to attach other molecules to the DNA origami structure at precise locations.\nScientists sought to create domains in the DNA nanostructure that would change in conformation in response to some physiologically relevant signal, such as changes in pH, visible light, or UV radiation. These DNA nanostructures can mimic proteins to study how changes in these proteins\u2019 structures would impact their biochemical activities. DNA structures containing regions of non-conventional motifs, such as four stacked cytidine bases (one of four nitrogen-containing cyclic molecules that comprise the inside of the DNA helix), change in conformation in acidic environments, which are characteristic of cancerous cells. Similarly, chemically joining an azo-benzene group (two hexagonal carbon rings connected by two nitrogen atoms) to the DNA backbone allows DNA to change conformation in response to a visible or UV light source. Such trigger-responsive DNA structures allow engineers to build nanorobots under users\u2019 command by adding a drop of a chemical or simply by shining a light. This is also very useful for mimicking the dynamic activity of some proteins that act as enzymatic molecular switches.\u00a0\nStudying Membrane Dynamics\nUnfortunately, while DNA nanotechnology has seen some traction in studying soluble, cytoplasmic proteins, proteins embedded in the cell\u2019s membranes are harder to manipulate. Membrane proteins are crucial for many of the cell\u2019s most basic functions, such as motion, regulating molecular traffic through the membrane, and interacting with pathogens, all of which require the membrane proteins to respond to changes in the membrane landscape and sometimes actively remodel the membrane. However, the membrane proteins are often involved in very complex interactions with lipids, other membrane proteins, and the cytoskeleton, scaffolding proteins that give cells their shape. Because this system is so complicated, Lin and Liu aimed to build a highly reductionist cell membrane model to contain only some features or proteins of interest. In their article, the proteins were foregone and replaced with mimics made of DNA. \u201cThese DNA structures were designed to look like a membrane-remodeling protein and work like one,\u201d Lin said. \u201cBy tweaking them and observing how they behave on membrane, we may learn a thing or two about how the protein works in cells.\u201d\u00a0 This system enabled them to study cell membranes as a platform and create artificial environments relevant to biological problems.\nOne of the most important membrane dynamics researchers have attempted to model is membrane tubulation, whereby one part of a membrane pokes out from an existing piece of a membrane but remains in close contact, essentially creating an extended \u201ctube\u201d of the membrane. This process is ubiquitous across the cell, involved in organelle and cell division, as well as packaging molecules for transport in membrane-enclosed vesicles. The interaction requires exquisite molecular machinery to change the membrane curvature and actually pinch the membrane destined to be separated from the old membrane (budding).\u00a0\nLiu and Lin were able to understand the key factors required for membrane vesicle formation to occur using DNA nanostructures. The DNA nanostructures in their study mimicked the proteins that integrate into the membrane, contributing to membrane curvature. This allowed them to study the proteins\u2019 properties and their effect on tubulation and vesiculation. The DNA nanostructures they integrated into their cell membrane model were initially set in an open state with high internal tension. Releasing such tension caused the DNA structures to buckle and adopt a closed, highly curved conformation (imagine a spring-loaded clamp). When they operated such DNA nano-clamps on the membrane, membranes were able to be curved, and many DNA-coated membrane tubes spontaneously emerged. However, fewer tubes were observed when the closed DNA clamps were less curved themselves. Moreover, releasing the DNA clamps from the high internal tension state seemed important for tubulation since preventing the DNA from changing from its initial state prevented the phenomenon. Interestingly, removing the DNA from membrane tubes led to vesiculation. Thus, Liu and Lin were able to deduce that the curvature of certain membrane proteins contributes to membrane curvature and that the ability of these proteins to switch conformation can release energy and act as a biophysical switch to determine whether the membrane could bud or not.\u00a0\nNext Steps\nLin and Liu\u2019s study was landmark in several ways. They were able to provide a proof of concept that the geometric properties of DNA nanostructures could act as a reliable substitute for the geometric properties of a membrane-bound protein and that tuning the mechanical properties of the DNA structures to modulate membrane dynamics could provide insights into how proteins impact membrane dynamics. \u201cMembrane proteins are quite hard to manipulate. With DNA nanostructures, we can control the structure, shape, geometry, and modifications, which means we can do experiments in a more controlled way,\u201d Liu said. Moreover, they were able to model membrane tube formation across multiple designs and experimental conditions\u2014such as by varying the curvature and internal tension of the DNA clamps and changing the starting curvature of the membrane\u2014and show that the curvature of the DNA nanostructure was the instigating factor in tubulation across these varying conditions. This highlights the unique advantages of using DNA nanostructures for such experiments. These nanostructures enable researchers to tune previously inaccessible parameters and ensure experiment reproducibility.\u00a0\nHowever, both Lin and Liu expressed some caution about applying such conclusions definitively to the cells of living organisms. First, while DNA nanostructures may be used to structurally approximate proteins, key differences in the two classes of molecules\u2019 stability, folding, and activity need to be accounted for when making conclusions about how proteins interact with membranes. Secondly, since the cellular models they employed were simplified, their conclusions from their experiments will probably need to be verified by studies in cells extracted from living organisms since membrane proteins in cells are engaged in many more interactions than the minimal set. Both researchers are embarking on new projects, including several in collaboration with Martin Schwartz, a Yale professor, to study how membrane proteins and the DNA structures that mimic them act on membranes with underlying cytoskeleton in major cellular processes.\u00a0Lin and Liu aim to further investigate how external signals impact DNA nanostructures mimicking membrane proteins and how cellular processes are accordingly modulated. Eventually, they aim to harness the similarities between membrane proteins and DNA nanostructures to create a reliable cell model from scratch. \u201cIt would be very cool to build synthetic cells that would work similarly to naturally existing cells,\u201d Lin said. With these headways in the field of DNA nanotechnology and cell biology, the scientific community is on its way to learning more about real-time cellular processes than ever before.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/on-demand-membrane-deformation/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Case Against Intelligent Computer Vision",
            "author": "Samantha Liu",
            "authorLogo": "",
            "date": "May 10, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/47959568261_44a6873050_c-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nConvolutional neural networks, or CNNs, are deep learning networks trained with millions of images. Designed to imitate primate brains, they proved highly adept at object recognition, sparking media excitement over the future of computer vision\u2014the use of AI to interpret visual input. Moreover, researchers hoped CNNs could offer a shortcut to studying the primate brain. Rather than undertake copious MRI scans and patient trials, scientists could run a simulation through a CNN to predict how the human brain would respond.\nBut the research of Yaoda Xu, a senior research scientist at Yale, proves otherwise. Ten years ago, when a perfect visual recognition system and its manifold implications\u2014think! driverless cars! \u2014 loomed on the brink of discovery, those possibilities now seem distant as ever. \u201cPeople got excited about using the CNN to model the brain,\u201d Xu said. \u201cBut my findings have been that, no, it doesn\u2019t look like the brain. It\u2019s maybe a primitive, overdeveloped, early visual area of the brain.\u201d\nAs her recent paper published in NeuroImage clarifies, where CNNs fail is in the realm of identifying transformation tolerant representations. The process sounds complex, but it\u2019s something humans carry out every day: when a person walks toward a table and sees it enlarge in their field of vision, they know it\u2019s the same table as before. The same goes for objects viewed from different perspectives or positions\u2014even as altered representations, the brain maps them onto the same visual identity.\u00a0\u00a0\nThis intuitive procedure proves much more challenging for neural networks. In her project, Xu took images of eight real-world objects, ranging from a pair of scissors to an elephant, and distorted them in various ways. Some she geometrically transformed, moving up and down or dilating on the page. Others she subjected to non-Euclidean transformations, changing the contrast and resolution. In each case, when tested on eight different CNNs, the neural networks showed weaker consistency and tolerance for these images.\nThe implication is striking: a process trivial for primate brains remains elusive for the complex, pre-trained machines meant to model them. Xu attributes this discrepancy to the mechanics of human cognition versus machine learning. The primate brain processes visual information through two streams: dorsal, which recognizes the object\u2019s spatial location (the \u201cwhere\u201d), and ventral, which recognizes the object\u2019s identity (the \u201cwhat\u201d). Though seemingly redundant, the ability to identify the same object in different contexts arises from these two systems.\u00a0\u00a0\u00a0\nThe CNN, in contrast, employs a sub-optimal approach. \u201cIn my view, it basically has a huge amount of memory,\u201d Xu said. \u201cIt memorizes each instance of each object it was exposed to, without making a connection among these different objects.\u201d Scientists are unsure how this algorithm works precisely, thus creating a \u201cblack box.\u201d But Xu is hopeful about cracking it \u2014 if only the scientific community reframes its approach. She plans to delve deeper into neuroscience research, seeing where and how primate vision diverges from neural networks, to shed light on the CNN algorithm and identify stages for improvement. Importantly, she believes the key lies in crafting a comprehensive biological understanding of vision rather than tackling the problem unilaterally through computer engineering.\u00a0\nShe compared this pursuit to trying to replicate flight: someone can blindly tweak the wing, fold a new flap, and throw everything against the wall until something flies or falls off a cliff. But someone can also investigate how flight works, learning the fundamental aerodynamics and physics which drive movement to find inspiration for an airplane. \u201cWhat is vision trying to achieve? What is the problem you\u2019re trying to solve?\u201d Xu asked. She expressed aversion toward the trial-and-error experimentation employed by many computer science labs. \u201cI\u2019m showing you that, hey, this is the algorithm and computation that\u2019s happening in the brain. If the system you\u2019re building can have the same principles, maybe you can do a lot better than what you have right now.\u201d\nXu looks towards a future where artificial networks could perfectly mimic human vision. She recalled how, as a student growing up in China, she spent entire weekends hand-washing her clothes. When the laundry machine mechanized the process, her free time could be put toward more valuable endeavors\u2014like advancing her research career. \u201cThere\u2019s a lot of human potential that is untapped,\u201d Xu said. \u201cIf some of our boring tasks can be done by a machine efficiently with this kind of visual intelligence, it could lead to another leap in human development. We could have the creativity to be who we want or to be the best version of ourselves.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/__trashed/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Forecasting Extinction: A New Take on Range Maps",
            "author": "Evelyn Jiang",
            "authorLogo": "",
            "date": "May 10, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/9818454644_b0e36a2532_c-500x332.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nWhile extinction is a natural phenomenon, human activity has accelerated the deterioration of ecosystems worldwide and driven an epidemic of species extinctions, leading growing numbers of scientists to search for ways to conserve the Earth\u2019s existing natural resources for future generations. Geospatial analytical tools like range maps, which describe the geographic area a species is believed to inhabit, are essential resources for informed conservation planning. Researchers can use data from these maps to forecast future range dynamics to identify vulnerable \u201cgaps\u201d in protection, informing decision-making and conservation resource allocation.\nTraditional gap analyses tend to focus solely on threats to species\u2019 range. However, a team of researchers led by Nyeema Harris, an associate professor at the Yale School of the Environment, has developed an innovative methodology that simultaneously analyzes positive conditions and threats to generate more comprehensive range maps.\n\u201cWe aggregated different layers. Some were threat layers that were detrimental to species\u2019 range, and others were resource layers that were positive for promoting species conservation,\u201d Harris said. \u201cWe overlapped these resources and threats to identify areas vulnerable to range contractions and that maybe aren\u2019t receiving enough conservation and research efforts.\u201d\nThe researchers performed a gap analysis across the ranges of ninety-one African carnivores to determine whether existing and available conservation capacities are sufficient. The team assessed factors like hunting pressures, drought vulnerability, cultural diversity, and protected area coverage. They found that, on average, fifteen percent of a species\u2019 range was at risk of contraction. \u201cWe hope this analysis can be used to inform future conservation and research,\u201d Harris said.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/__trashed-2/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Hidden Pandemic",
            "author": "Sofia Jacobson",
            "authorLogo": "",
            "date": "May 10, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/protective-suit-gc15cd4084_1920-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nThe pandemic drastically altered the daily tasks of many adults who, in addition to their everyday professions, took on new responsibilities in the home, including child and elder care. As many of these new duties fell mainly to women, associate research scientist Ji-Young Son and Professor of Environmental Health Michelle Bell launched a series of studies on how women and minority scientists were potentially disproportionately impacted by the pandemic. One study with the Yale School of Environment, supported by the Yale Women Faculty Forum, focused on gender disparities in submissions to academic science journals.\nThe researchers hypothesized that the percentage of women scientists submitting articles would decrease during the pandemic. They found that there was actually an increase in women\u2019s submissions compared to men. They examined 99,114 submissions from January 2019 to July 2021. Of these, the corresponding authors were 82.1 percent male, 17.8 percent female, and 0.1 percent nonbinary. Comparing the pre-pandemic time to the pandemic time, the percentage of women submitting slightly increased to 18.7 percent. However, the pandemic did have one notable effect on women\u2019s submissions. \u201cThe rate of increase in submissions [by women] slowed during the pandemic compared to the pre-pandemic period,\u201d Son said.\u00a0\nThere is still an enormous gender disparity in the sciences. Although studies such as this one are bringing the issue to light, the problem continues\u2014before, during, and after the COVID-19 pandemic. \u201cMore resources from universities, not [just] individual efforts, and other measures for women scientists are needed to promote equality,\u201d Son said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/__trashed-3/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Big Tech is Always Watching",
            "author": "Alex Dong",
            "authorLogo": "",
            "date": "May 10, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/data-security-1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Wikipedia Commons.\nHave you ever read Facebook\u2019s Terms of Service after downloading the app? Chances are, probably not. While we often mindlessly click \u2018accept,\u2019 big tech companies like Meta have been known to violate user privacy without their knowledge or consent. With the rapid rise of big tech, data privacy has increasingly become a concern for both individuals and regulatory organizations.\nIn light of this issue, Adrian Kuenzler (YLS \u201915), Assistant Professor of Law at Zurich University, presents a new framework for how competition between big tech companies can promote data privacy. Kuenzler\u2019s research draws on a variety of legal investigations, empirical economic analyses, and cognitive science studies. He proposes a new way of protecting consumer interests by integrating three strategies typically used separately.\nFirstly, users should be able to choose between different platforms like Google Chrome and Safari to maintain consumer sovereignty. Next, different providers must be interoperable\u2014switching platforms and migrating data must be practical. Finally, consumer input should be considered and used to improve existing services such as feature addition and product design. Taken together, these strategies promote consumer voice and choice, giving users more authority to prioritize data privacy.\nAuthorities typically only use a single approach, often overlooking the convergence of the three strategies when remedying data privacy issues. \u201cIt doesn\u2019t follow that we only need one account or that a certain regulatory scheme is always appropriate,\u201d Kuenzler said. Ultimately, using the three strategies as complements rather than substitutes enables us to better navigate data privacy concerns and leads to more effective regulatory policy decisions.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/__trashed-4/",
            "captions": [
                ""
            ]
        },
        {
            "title": "It\u2019s Not All Bad",
            "author": "Matthew Blair",
            "authorLogo": "",
            "date": "May 10, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/microbiome-banner-x-500x200.webp"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of iStock. \nThere is a common misconception that all bacteria are bad bacteria. Perhaps this narrative is bolstered by the branding of disinfectants claiming to kill 99.9 percent of all viruses and bacteria or the cartoonishly frightening drawings on the walls of doctor\u2019s offices. This generalization is simply untrue.\nBacteria play a critical role in helping humans maintain a healthy gut. Our gut is an amalgamation of trillions of bacteria that form unique interactions and express various genes essential to their colonization of the gut. This bacterial colonization helps humans to maintain a balanced gut and, consequently, a healthy body. Already, questions abound. How do organisms \u201cdecide\u201d which genes to express? Are there genes whose expression is more desirable than others? It is just these questions that Jeongjoon Choi, an associate research scientist in the Department of Genetics at the Yale School of Medicine, focused on answering.\u00a0\nSpecific genes are expressed when they receive the direction to do so from regulatory and signaling proteins. \u201cBut what I was kind of surprised by is even when you give such an inducing signal, some genes are not expressed under certain conditions,\u201d Choi said. Interestingly, many unexpressed or silenced genes were of a specific variety: horizontally transferred genes (HTGs), also called foreign genes. HTGs are important as they drive bacterial evolution by introducing foreign DNA, and thus new traits, to the recipient organism.\nThe silencing of foreign genes is done by the heat-stable nucleoid structuring protein (H-NS). Nucleoid structuring refers to how this protein upholds the basic structure of DNA. Building on this function, H-NS represses foreign genes by specifically binding to the corresponding DNA. In some instances, gene silencers like H-NS are beneficial. The laissez-faire expression of all foreign genes at once would be fatal. Unfortunately, however, H-NS can suppress the expression of important HTGs. For foreign genes to be expressed, they must overcome gene repression by the silencer H-NS.\u00a0\nChoi\u2019s study provides new insight into how organisms can overcome foreign gene repression by silencers such as H-NS. It has been a dogma in the field that H-NS amounts remain constant regardless of the conditions. Choi made the groundbreaking discovery that the abundance of H-NS varies in different conditions, such as acidic and neutral conditions. Additionally, in some conditions, H-NS is degraded. \u201cBecause H-NS amounts were believed to stay constant, overcoming foreign gene silencing was largely ascribed to anti-silencing proteins,\u201d Choi said. Thanks to Choi\u2019s research, there is a new understanding that both anti-silencing proteins and H-NS degradation work collaboratively to overcome gene silencing by H-NS and control foreign gene expression.\nThe study focused on Escherichia coli, an example of a \u201cgood\u201d type of bacteria. Choi found that for the E. coli to grow in the guts of mice and express HTGs, H-NS had to be degraded. The silencing effect of H-NS can be overcome in two steps. Firstly, the DNA binding regulatory protein PhoP\u2014a protein impacting the expression of certain parts of DNA \u2014displaces H-NS, making it susceptible to degradation. Then, the protease Lon\u2014an enzyme that breaks down proteins\u2014targets specific regions of H-NS to degrade it. With H-NS degraded, E. coli can grow.\u00a0\n\u201cThis is basic molecular biology, and I like basic science, but if the basic science wants to change the word, then we need to transfer it, making it more applicable for treatment or another purpose,\u201d Choi said. The impacts of this finding are far-reaching, potentially changing how we address many ailments, from minor bacterial infections to tuberculosis. The possibilities of Choi\u2019s discovery lie in the manipulation of H-NS. \u201cBy manipulating H-NS degradability, we can cause our bacteria, not our good bacteria but those big, bad bacteria, to be more susceptible to environmental changes. This will prevent harmful bacteria from causing much of a problem,\u201d Choi said. This approach could work in tandem with antibiotics commonly prescribed to remove harmful bacteria. In cases of intense antibiotic resistance, H-NS manipulation could be the solution: where antibiotics do not work, causing the bacteria to be more vulnerable to the natural processes of our body can make these harmful bacteria unable to cause disease.\nChoi\u2019s research done in the guts of mice can be extrapolated, with some caveats, to human health, making leaps in our understanding of how bacteria can be regulated and how we can work to maintain a healthy gut through the development of \u201cgood\u201d bacteria.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/__trashed-5/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Soot Factor",
            "author": "William Archacki",
            "authorLogo": "",
            "date": "May 10, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/17241942652_1a2f008382_c-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nNext time you\u2019re cruising at forty thousand feet in the air, think about how amazing it is that a few hundred tons of metal can whisk you between two distant cities in just a few hours. For the seasoned flier, air travel is so simple it almost feels like magic. Behind that magic, though, lie many technological innovations\u2014one of the most important being the jet fuel that keeps the engines running.\nMost aircraft engines today burn petroleum fuels that emit large volumes of carbon dioxide, the primary pollutant behind rising global temperatures. To reduce these emissions and make aviation more sustainable, biofuels may be a necessary replacement. Biofuels consume carbon dioxide from the atmosphere in production, balancing the amount they emit when burned. Because they have similar physical and chemical properties to petroleum fuels, biofuels could easily power existing jet engines. However, with thousands of possible biofuels competing for a single spot in the future of aviation, it\u2019s hard to say which one to use. Thus, it\u2019s necessary to consider a key piece of data: the soot factor.\nSoot is the black residue left behind by burnt organic matter. When dispersed in the atmosphere, it absorbs solar energy and contributes to climate change alongside carbon dioxide. Under some circumstances, it can even induce the growth of high-altitude cirrus clouds that absorb solar radiation more strongly than carbon dioxide. When inhaled, soot can lead to the development of heart disease and certain cancers, adding to the public health risk of air pollution. To minimize the burden of soot emissions on the climate and human health, researchers must select biofuels that burn without releasing harmful amounts of soot.\nIn an effort to improve available data about soot emissions, the Pfefferle Lab Group at Yale developed a new method to measure a fuel\u2019s \u201csooting tendency\u201d and then examined two dozen biofuel candidates. Earlier techniques for calculating sooting tendency required researchers to burn large volumes of fuels to observe the complex properties of the flames. The Pfefferle group\u2019s new method reduced the amount of fuel necessary to generate data. They opted to calculate sooting tendency by measuring the luminosity, or brightness, of the fuels\u2019 flames when burning individual drops\u2014the brighter the flame, the sootier the fuel.\nThe biofuel candidates subjected to this new test all fall under the category of terpenes, combustible chemicals found in organisms ranging from redwood trees to algae. Charles McEnally, a chemical engineering research scientist at the Pfefferle lab, explained that terpenes are of special interest because of their diversity.\n\u201cWhat\u2019s interesting about terpenes is that the biochemistry that makes them is always the same, and the input molecule is always the same: its isoprene,\u201d McEnally said. \u201cDepending on exactly how the chemistry works, you can get an enormous number of different outputs. There are tens of thousands of terpenes that are known.\u201d\nOut of the twenty-four terpene biofuels that the Pfefferle group tested, seven were produced through a process known as hydrogenation, in which the chemical structure is modified to include more hydrogen atoms and fewer double bonds. These hydrogenated options outperformed their unmodified competitors for soot reduction, posting lower numbers on the sooting index that the Pfefferle group developed. Hydrogenation\u2014as well as other chemical processes that are broadly referred to as \u201cupgrading\u201d\u2014have the potential to further improve the properties of biofuel candidates.\u00a0\n\u201cWe have all of organic chemistry at our disposal, so we\u2019re no longer limited to the molecules that are in petroleum. Almost certainly, out of all of organic chemistry, there are other molecules that will make better fuels than the ones that happen to be in petroleum,\u201d McEnally said.\n\u00a0In their paper regarding terpene biofuels, the authors note that large-scale production of terpenes could shift toward bioreactors in the future. By genetically engineering microorganisms like E. coli to synthesize terpenes in bioreactors, the aviation industry could find a path to a simple and sustainable fuel source.\u00a0\nThe Pfefferle group\u2019s measurements for terpenes add to an ever-growing set of data about biofuel candidates. Their simplified method for determining sooting tendency provides a starting point for further research. With the group\u2019s work, a biofuel alternative to petroleum-based jet fuel may eventually be what takes you to the skies.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/__trashed-6/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Smell You Later",
            "author": "Maya Khurana",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Khurana-Figure-1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Futurity.\nWhat lies within an odor plume? For humans, a fleeting smell of something, perhaps accompanied by a flash of color. The plume is barely discernible, and there are mere seconds before it dissolves into indetectable wisps. But for flies, odor plumes contain a fountain of information that help them navigate the world.\nIt has long been thought that flies use the wind as their primary directional cue when navigating turbulent odor plumes to identify the source of the scent. This theory has led to a widely recognized insect odor navigation model known as odor-elicited upwind motion, where flies use the direction of the wind to orient themselves upwind and move in their desired direction. However, Nirag Kadakia and his colleagues in the Emonet and Clark Labs at Yale University have found that these flies are able to determine the direction of the odor itself. Kadakia combined his experience in mathematical modeling with his interest in the experimental work at the Emonet Lab to study this insect olfactory model. \u201cOlfaction is key for insects,\u201d Kadakia said. \u201cIt\u2019s their primary sense of finding food, finding potential mates, and fighting competitors.\u201d In his research, Kadakia characterized what navigational algorithms these insects use to maneuver through their environments. \u201cThis is a tricky problem because odor landscapes are very complex,\u201d Kadakia said. Odor scenes, as they are also known, are not continuous, but instead appear in bursts with periods of clean air in between. So, how do insects work around the complexities of these landscapes?\nTo find out, Kadakia and his colleagues used optogenetic stimulation on genetically engineered blind flies. Essentially, they used light as a fictive odor\u2014a fake stimulus\u2014to make light behave as an odor signal, allowing the presence of wind to be eliminated as a variable. The flies were genetically blinded to ensure that they did not visually perceive the optical stimulation in any way.\u00a0 \u201cWe can deliver very precise \u2018odor signals\u2019 on the flies and make the signals move in certain directions,\u201d Kadakia said. What his team found was that flies can sense the direction that the odor moves, and they react to it largely in the same way they would if it were a wind signal. Additionally, they found that the flies not only respond to odor motion cues but that they can sum different motion cues. \u201cIt\u2019s possible that the wind can move in one direction and the odors can move in a different direction\u2026 Flies are able to combine these directions and go against [their] vector sum,\u201d Kadakia said. Thus, flies are able to respond to the sum of these direction cues to optimize their navigation.\u00a0\nInterestingly, these researchers uncovered a similarity between the odor detection algorithm and the visual detection algorithm. \u201cI think the coolest way we were able to show that was by [using] illusory stimuli,\u201d Kadakia said. These stimuli do not occur in nature, but they do have a motion component that the researchers were able to use to study the parallels between the two systems. \u201cWe broke up motion into these statistical properties, and using that we were able to show that [flies] can detect motion using the same algorithm [as the visual system],\u201d Kadakia said. He was also able to manipulate the illusory stimuli to do something else: move opposite to their natural direction. \u201cWe can play odor plumes backward to reverse the odor motion,\u201d Kadakia said. This allowed the researchers to study how flies respond when the odor motion has been changed but the rest of the environment, including the wind direction, has remained the same. What they found was that flies had much more trouble getting to the source of the odor in those scenarios. \u201cThat\u2019s because they rely on the natural motion of the odor to navigate properly. When that is perturbed, their navigation success is affected,\u201d Kadakia said. While this research has important implications for current models of the olfactory system, it also has a more widespread impact. \u201cUnderstanding how insects navigate can also help us understand how they spread disease,\u201d Kadakia said.\nThis research has opened new channels for the world of computation modeling to explore. \u201cI\u2019m hoping the biggest impact will be a deeper understanding of how similar computations can be in olfaction and vision,\u201d Kadakia said. Since so much research has been done on the visual capabilities of flies, it can guide the way for olfactory research going forward. Clearly, there is more to odor plumes than meets the (undiscerning, human) eye.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/smell-you-later/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Detecting the Undetectable",
            "author": "Sydney Hirsch",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Hirsch_Figure2-500x281.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Wikimedia Commons.\nThe emergence of the COVID-19 pandemic resurfaced the necessity for pathogenic surveillance\u2013\u2013that is, the detection of emerging and unknown disease agents. One mechanism for uncovering these pathogens is genomic sequencing of patient nasal swabs, which identifies present viruses. Sequencing hundreds of samples, however, is expensive and inefficient. To solve this issue, a team of Yale researchers, including Ph.D. student Timothy Watkins in the Foxman lab, found that a single molecule involved in the body\u2019s immune response to viral infection can be tested by clinicians, aiding in the prioritization of samples to be sent for further genomic analysis. This biomarker, CXCL10, is a chemokinea protein released during viral infection that signals for the recruitment of other immune cells.\u00a0\nWatkins and his colleagues tested for the presence of CXCL10 in patient nasal swabs and found an association between increased CXCL10 and previously-unknown viral infection. For one, in samples with undetected SARS-CoV-2, CXCL10 elevation was the differentiating factor between otherwise indistinguishable samples. Furthermore, CXCL10 is produced in large quantities, making it easily testable, and is a nonspecific signal of viral immune responses.\nThese results provide a means by which to increase the efficiency of surveilling threatening pathogens. \u201cIf someone exhibits symptoms of respiratory infection, CXCL10 may be high, but clinical tests may not pick up the virus infecting them [\u2026] You should do deeper sequencing to identify it, in case it\u2019s something unusual or an emerging virus that isn\u2019t regularly tested for,\u201d Watkins said. In the short term, research efforts focus on further developing the clinical applicability of their techniques\u2013\u2013developments that would allow for these methods to be used on a larger scale, with the hopes of detecting unknown viruses before they have the opportunity to cause the next pandemic.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/detecting-the-undetectable/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Solving the Mysteries of Reptilian Evolution",
            "author": "Andy Gu",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Gu_Figure1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Chase D. Brownstein.\nLong before humans evolved, lizards and other reptiles roamed the Earth. One such class of these lizards was the Squamata, literally meaning \u2018scaled ones.\u2019 Today, Squamata are the largest order of reptiles, but during the Mesozoic Era, the time of dinosaurs, they were far from the dominant species. Sometime during the Mesozoic Era, the Squamata clade \u2013 a group of organisms sharing a common ancestor \u2013 experienced adaptive radiation, the rapid development of a single species to multiple new species that occupy different environments. However, fossil records of this time are poor, so researchers have struggled to develop a full picture of the evolution of these species and where it fits in with other groups of organisms.\u00a0\nSo, how did researchers solve that puzzle? The two primary methods of reconstructing relationships between species are morphology and DNA analysis. In morphology, researchers look at an organism\u2019s key features and how closely they match the features of other species. Species sharing more features are more closely related. However, many morphological features that help determine ancestry are lost with adaptive radiation. Because of this phenomenon, researchers also use DNA analysis, which uses the number of differences in DNA sequences to determine how closely species are related. For Squamata, these two methods previously led to conflicting stories. For example, morphological analysis has related Squamates to certain clades which DNA analysis subsequently disproved. But new findings have the support of both methods.\u00a0\nIn a recent publication in Nature Communications, Chase Brownstein (YC \u201823) and other researchers at Yale\u2019s Department of Earth and Planetary Sciences determined new evolutionary relationships held by the Squamata clade using morphology. These results confirmed previous DNA analyses and added to them. The team established their findings using two lizards, the Eoscincus ornatus and Microteras borealis. Both species hold stable positions within the Squamata clade, meaning they hold confirmed positions as early members of the clade, allowing researchers to build upon these previous relationships with certainty. \u201cWith the species we chose, understanding their anatomy helped understand transitions and the evolution of the family,\u201d Chase said.\u00a0\nLooking at the skulls of these two lizards, the researchers were surprised to find many differences in the hard palates. In fact, in E. ornatus, Chase and other researchers were able to find features lost to all modern descendants, allowing them to tie the Squamata with another major lizard clade, the pan-lacertids. \u201cThese features gave us a greater appreciation for the degree of complex evolution in the group,\u201d Chase said.\nThe team\u2019s findings provide new and improved evidence for current hypotheses of species distribution and evolution. For example, the distribution of these lizards in the Northern hemisphere solidifies a hypothesis that their clades had spread to both North America and Eurasia-Africa before the continent\u2019s separation. \u201cYou can never be sure of how evolution and biogeography happen,\u201d Chase said. Despite this, he remains interested in connecting the puzzle pieces of evolution and solving more mysteries of how the animals we know came to be.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/solving-the-mysteries-of-reptilian-evolution/",
            "captions": [
                ""
            ]
        },
        {
            "title": "All-Knowing Robots",
            "author": "Matthew Dobre",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Dobre_Figure2-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "A staggering 4.6 billion dollars are spent annually replenishing the ranks of physicians who depart from their current positions. High physician turnover is detrimental to the quality of patient care and contributes to the notorious inefficiency of the healthcare system. However, in a paper recently published in the journal PLOS ONE, researchers at the Yale School of Medicine have developed a model to identify when a physician may be at risk for departure. \u201cAs a clinician myself, [\u2026] what brought you into medicine is the time you spend talking with patients and hearing their stories, but often what takes up a lot of your time is documenting, or finding the correct order that\u2019s going to be covered by insurance,\u201d said co-author Andrew Loza, who earned his Ph.D. from Washington University in 2016 and later obtained his M.D. from Yale School of Medicine.\u00a0\nThe study aimed to develop a model to predict physicians who may be at risk of departure by identifying and quantifying factors that interfere with a physician\u2019s ability to work directly with patients. The researchers used an algorithm called XGBoost, which receives a set of input variables to classify the level of a physician\u2019s departure risk. Some of these variables included electronic health record (EHR) use, tenure (time since hiring date), physician age, and patient volume. However, due to the vast number of parameters in the model, it is difficult to understand the recipe that turns input variables into an output. So, the researchers used a data analysis technique called Shapley Additive Explanations (SHAP) to determine the level of influence of individual variables on a physician\u2019s departure risk, and subsequently derive conclusions from the data.\u00a0\nInterestingly, tenure was found to be the strongest predictive factor in classifying physicians at high risk of departure. For physicians with longer tenures (10-35 years), high EHR use was found to increase risk of departure and decrease risk for less experienced physicians. Similarly, longer documentation times were shown to reduce the risk of departure in some tenure brackets and elevate the risk in others. Since this was an observational study, the algorithm cannot establish a causal link between the identified factors and physician departures. Loza provided an example illustrating the fallacy that correlation implies causation. \u201cIf you look at literature for retention of software use, individuals who report software bugs are more likely to keep using the software, but you would never tell a manager I think we should add more bugs,\u201d said Loza. Further work is currently being conducted to uncover any potential underlying causal relationship between the identified variables and departure risk.\u00a0\nUltimately, Loza hopes that this research will serve as the foundation for developing screening tools to identify physicians who are at risk of departure and provide support for them to better engage with patients. \u201cI hope this would be used to shift the variables which are associated with risk of departure into lower risk and increase the time spent with patients,\u201d said Loza.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/all-knowing-robots/",
            "captions": [
                "Stethoscope and doctor sitting with laptop stress headache about work in hospital"
            ]
        },
        {
            "title": "The Virtualization of Our Past",
            "author": "Yamato Takabe",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Screen-Shot-2023-04-17-at-5.10.15-PM.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nWhen walking through a museum or examining historical texts at Beinecke Library, true understanding starts when you can visualize yourself living in these civilizations, immersed in the local culture and embracing their way of life. However, due to natural erosion and looting, it is becoming increasingly difficult to enjoy physical archeological sites. One of these sites is Dura-Europos. Founded around 300 BC and located along the Euphrates River in modern-day Syria, Dura-Europos was a critical site for cross-cultural trade. This site boasts the earliest evidence of a house church, and there are inscriptions and graffiti written in Greek, Latin, Persian, and Hebrew because of its proximity to the Roman and Persian Empires.\u00a0\nThe city came to the attention of Western scholars in the 1920s when British soldiers in the area came across some of the wall paintings from Dura-Europos. In the 1930s, Yale archaeologists were part of a Temple that excavated the site. As a result, Yale University has one of the largest collections of artifacts and documents from the ancient city housed in the Beinecke Rare Book and Manuscript Library, the Peabody Museum, and the Yale University Art Gallery. However, Dura-Europos cannot currently be investigated due to the Syrian Civil War. How can we walk through the ancient bustling town and experience day-to-day life without ever physically visiting the archeological site? The answer lies in a magical collaboration between the past and the present.\nIn 2007, Holly Rushmeier, John C. Malone Professor of Computer Science, came across thousands of field photos of Dura-Europos in the Yale Art Gallery. \u201cI was interested in apply[ing] computing for preservation and documentation of local cultural heritage and using the photos to craft a digital representation of the society,\u201d Rushmeier said. However, she ran into an issue with the images as they were far too grainy and sparse for automatic 3D generation that many modern phones can accomplish. Also, there was too much cross-institutional material and international research. She needed help to somehow piece the photos together based on location and relevance to map out the city as a whole. Fortunately, Rushmeier met Anne Chen who was a fellow at the ARCHAIA program at Yale and had all the expertise needed. Chen, now an Assistant Professor of Art History and Visual Culture at Bard College, had experience studying both Roman and Persian empires and an interest in implementing Linked-open Data to the site\u2019s research.\u00a0\nLinked-open Data is a Wikilink-like concept that brings together data and resources from all over the world into one platform and connects them based on knowledge webs. A way to categorize the data is through \u201cUrban Gazetteering\u201d\u2014classifying architectural structures and cataloging them by location so they can be distinguished online. This process works at a macro-level. It differentiates between settlements and improves keywording so specific buildings can be easily identified across the various settlements around the world. However, it does not yet work at the micro-level, as they still need to distinguish similar sites across the street from each other in the same city. Similarly, excavation reports were inconsistent, so connecting them proved to be a big challenge. They still needed historians, linguists, and archeologists in the area, as well as data scientists to work together to parse information while making it available and accurate across many languages.\nWith any Wikidata or database project, using more data improves the accuracy of the entire workflow. In the future, Chen and Rushmeier plan to integrate artifacts in Damascus that have not yet been accounted for. They also plan to implement more of Yale\u2019s database of Dura-Europos into Wikidata and potentially use computer vision or AI to categorize the data more efficiently and accurately. Furthermore, they plan to improve view spaces to increase accessibility for interested researchers and the public. By expanding the public interface, more researchers can exchange original findings and view different interpretations to translate them for modern understanding.\u00a0\nMost importantly, both researchers aim to make the technology available to everyone. \u201cLots of locals were interested in the site, but there was no information available in Arabic despite the site being viewed as a textbook example in the US,\u201d Chen said. Oral traditions have materialized around the site and thus the naming conventions of the buildings are all varied based on local language. It\u2019s their goal to make the new Linked-Open Data translated for all local users, so anyone and everyone can virtually walk through the ancient Dura-Europos.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/the-virtualization-of-our-past/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Verbal Autopsies Help \u2018MakeDeathsCount\u2019",
            "author": "Faith Pena",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/MakeDeathsCount-Figure-1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons.\nAccording to the World Health Organization, almost fifty percent of all deaths are unregistered. Autopsies aren\u2019t performed in these cases, so the causes of these deaths go unrecorded. Ahmad Saleh MPH \u201922, Ehsan Abualanain MPH \u201922, and Madison Novosel MPH \u201923 co-founded MakeDeathsCount (MDC) in response to these findings. What started as a project at the Yale School of Public Health has grown into a non-governmental organization (NGO) dedicated to increasing the amount and accuracy of causes of death (CoD) data globally through the use of verbal autopsies (VAs).\u00a0\n\u201cIn simple terms, a VA is a verbal interview of people close to the deceased about their symptoms to reach the same CoD as a typical autopsy,\u201d Saleh said. \u201cThere are many preventable CoDs, but they are only preventable if the CoD is known.\u201d MDC seeks to raise awareness of the insufficiency in the number of registered deaths and support NGOs who can conduct VAs in low- and middle-income countries where unregistered deaths are widespread. They currently work with HIS-Unit, a Syrian NGO, to pilot their first VA mortality surveillance project. Having reached their initial goal of six hundred interviews, MDC can analyze the data and supply mortality reports to the region.\u00a0\nMDC is the only organization in the world focused on developing mortality surveillance, specifically through the use of VAs. Although the founders remain proud of this fact, it comes with plenty of challenges, and they are always looking for more support. They hope to expand their efforts globally with specific interests in Somalia, Colombia, and India.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/verbal-autopsies-help-makedeathscount/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Animal Architects",
            "author": "Neha Middela",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-2-Seed-Dispersal-article-Neha-Middela.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Katja Schulz, Flickr.\nIn recent years, conservation and governmental organizations worldwide have devised new strategies for forest restoration, focusing on a variety of static metrics, including water flow and tree species composition. Yet existing research often misses a crucial, dynamic facet of these ecosystems that could be key to accelerating restoration efforts: seed dispersal by animals.\u00a0\nA Yale-led team of researchers examining this process in the Barro Colorado Nature Monument in Panama has found that seed dispersal, particularly by large flightless animals, can greatly accelerate forest restoration efforts.\nTwo factors made the Barro Colorado Nature Monument an ideal location for showcasing the beneficial effects of seed dispersal by animals\u2014proximity to old growth forests and a ban on hunting since the 1970s, leading to a high population of large mammals. Additionally, since the Barro Colorado Nature Monument has been studied for over one hundred years, the researchers had a wealth of data about animal interactions in the area.\n\u201cThe areas we studied were next to large tracts of old growth forests with many dispersers, such as small birds, large birds, bats, and large flightless mammals,\u201d said Sergio Estrada-Villegas, a lead author of the study. \u201cThis abundant community of animals was able to slowly go into these areas that were undergoing succession and regeneration and bring those seeds back into these areas.\u201d\nIn the future, the scientists will expand their dataset in order to compare Barro Colorado with other sites and further test their hypothesis. Through these studies, they will examine the role of these animal architects in other sites in the neotropics.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/animal-architects/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Turning over a new leaf",
            "author": "Jenny Liu",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Liu-Figure-1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Wikimedia Commons.\nPicture a leaf: the image that comes to mind may be a rounded, green shape with lines running through it. But how did the leaf come to be? This imagery may be intuitive, but the development of the leaf itself has long eluded scientists. However, an interdisciplinary team of Yale researchers composed of biologists and physicists recently determined how a unique and niche structure, the spongy mesophyll, plays a crucial role in developing the structure of the leaves. Specifically, they explored how the movement of plant cells follows a transition from spherical, tightly-packed cells in early development to loose, porous networks in later stages while maintaining their mechanical stability.\nThe team chose to explore the spongy mesophyll, which is the tissue that exists between the leaf top and the leaf bottom, because of its important role in performing photosynthesis. From a biological perspective, this material is extremely important in carbon sequestration. As sunlight hits the top of the leaf, carbon from the atmosphere is absorbed through the bottom layer. Once those processes happen, the light and carbon dioxide molecules react with the chloroplasts in the cells of the spongy mesophyll. This, in turn, creates glucose for the plant to provide them with energy to continue to grow. \u201cSo, from a plant biology perspective, this tissue is super important because it\u2019s like a combination of the lungs and the stomach of the plant,\u201d said John D. Treado, a physicist and lead researcher of the project.\nHowever, instead of focusing on the biological function, this study instead pivoted toward how the spongy mesophyll maintains its mechanical integrity. Unlike animals, whose cells can move around while the animal is still developing, plants can develop only through cell division and cell growth with no mobile cells. From a physical perspective, plant cells have a fundamental constraint on how they are able to grow. Furthermore, the cells grow in a densely packed manner. However, observational images and computer simulations of the spongy mesophyll revealed that it actually grows in a different way. \u201cThe tissue looks basically like a sponge,\u201d Treado said. There are rather large spaces between the cells, which makes the tissue very porous rather than densely packed. How could this be sustained?\u00a0\nTo figure out this question, the team created computer simulations and varied different parameters to see which simulations were most similar to the images they collected of the mesophyll. They implemented certain growth rules based on deformable polygons that can change their shape in response to different stressors placed on them. As more pressure was placed on the cells, the boundary relaxed and expanded in response, which is how the network of mesophyll cells grows while keeping its overall formation. They found that the robust generation of pore space was due to a unique balance of the parameters of cell growth, adhesion, stiffness, and tissue pressure. The lack of contact with other cell boundaries made growth and remodeling of the cell wall possible. Additionally, cells needed to use the cell-cell adhesive strength to build networks and make sure that those networks did not bend too much, but rather formed rigidly. Thirdly, the pressure inside the boundary must be constant throughout. All this demonstrates that a complex, unique tissue such as the spongy mesophyll can be assembled through simple mechanical rules.\u00a0\nThe significance of studying spongy mesophyll is rooted in its exciting applications for climate science and environmental engineering. Not only does this tissue allow plants to capture the energy they need to grow further through photosynthesis, but it also provides a key substance needed for other organisms to continue growing and provide more life\u2014oxygen. \u201cThe reason the atmosphere is so oxygen-rich is because life evolved this ability, millions of years ago, to convert the carbon dioxide in the atmosphere to oxygen,\u201d Treado said. \u201cAll of the other organisms that were evolving at the same time realized that they could breathe the oxygen that was created by the plant.\u201d In the future, the spongy mesophyll has the potential to advance research on creating synthetic plant tissues to help with carbon sequestration. Perhaps, instead of only envisioning a leaf, scientists may be able to create one too.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/turning-over-a-new-leaf/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Lost Amino Acids",
            "author": "James Han",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/49066748948_494ba0cc08_c-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nProteins, the molecular machines within a cell responsible for basic biological functions like maintaining structure and facilitating reactions, are made up of amino acids\u2014a type of organic molecule with a specific domain that allows them to attach to one another like Lego blocks. Like the four bases of DNA which are common to all organisms on Earth, scientists have discovered twenty different amino acids, each with varying properties that allow for specific protein functions, that are conserved across all organisms, whether they are archaea, bacteria, or eukaryotes\u2014the three domains of life.\u00a0\nRecently, scientists have also discovered two other amino acids used by organisms to assemble proteins: selenocysteine and pyrrolysine. In a study published in the Journal of Biological Chemistry, a group of Yale researchers outlined a new family of enzymes that allows cells to integrate the latter amino acid into proteins. The authors were also able to pinpoint the time in evolutionary history in which the two families diverged, which they estimated to be before the three domains of life even emerged.\u00a0\n\u201cIt\u2019s quite amazing that cells can do so much with just twenty amino acids; by adding unnatural amino acids, we can expand the functions that proteins can have,\u201d said Jeffery Tharp, the lead author of the study and a professor at the Indiana University School of Medicine. Studying the machinery cells use to add these noncanonical amino acids into proteins offers researchers powerful insights into engineering enzymes that can access the unique properties of other unnatural amino acids.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/the-lost-amino-acids/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Recovering Lost Light",
            "author": "Steven Dong",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/detector-image-1-281x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Yiyu Zhou.\nIn quantum information science and quantum sensing, single-photon detectors play a crucial role in enabling various scientific breakthroughs and fundamental tests of quantum optics. While photon-number-revolving (PNR) detectors are considered the predominant tool for measuring light, PNR detectors today can typically only resolve up to ten photons at a time.\nTo address this issue, the Tang Lab at Yale has developed an innovative on-chip detector that allows them to resolve up to one hundred photons with unparalleled accuracy, while also providing high-speed response times. With this new detector, they are able to uncover the statistical properties of photons from a true thermal light source\u2014which emits light because of thermal radiation from its temperature, like an incandescent light bulb\u2014at a level never seen before.\nHowever, creating the photon detector was a challenging process. The research involved complex chip fabrication processes, which included putting together multiple layers of semiconductors, superconductors, and optical circuits. Tang believes that this technology can be extremely powerful, and as quantum infrastructure continues to develop, he hopes that his photon detector can become accessible to regular researchers.\nWith such promising results, what is the future of this technology? \u201cIn five or ten years, we could see the insertion of our detector technology in the commercial world,\u201d Tang said. If researchers can leverage these advances in quantum technology to manufacture quantum devices in a more robust manner, Tang believes that it will play a remarkable role in making such devices more powerful than ever before.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/recovering-lost-light/",
            "captions": [
                ""
            ]
        },
        {
            "title": "All Roads Lead to Rome",
            "author": "Isabel Trindade",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-1-2.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "The Roman Empire is known, among other feats of engineering, for its extensive and durable road system. This transportation network extended north to Britain, south to northern Africa, east to Mesopotamia, and west to Portugal. In total, the Romans built over fifty thousand miles of roads, facilitating the spread of the empire through efficient military transport.\nRoman roads are famed for their straightness, durability, and innovation, including surfaces that facilitate water drainage. These innovations have allowed many roads to survive for millennia. However, the specific mechanisms used to build these roads have remained unknown. Recently, researchers from MIT have performed analyses on the mineral components associated with ancient Roman mortars, shedding light on the materials and preparation methods used to construct these roads.\nFor centuries, Roman roads\u2014and other architectural elements, including walls, foundations, and aqueducts\u2014were constructed using unreinforced concrete, and they were bound by mortar made from volcanic ash and lime. Lime mortars typically rely on taking carbon dioxide from the air to harden, but Romans used hydraulic mortars, meaning they combined lime with water and silicates to form a harder, more durable material. This invention allowed them to build larger and more complex structures than ever before.\nA notable feature of their concrete is the presence of relict lime clasts, which are pieces of remnant limestone left over after construction. Previous investigations of these clasts focused on those in maritime Roman concretes, such as those used in bridges. However, there has been less research conducted on lime clasts in open-air Roman constructions, such as roads. The team at MIT, led by Admir Masci, sought to investigate these clasts. Using a sample of lime clasts obtained from the archeological site of Privernum, Italy, the researchers performed a series of electron microscopy and x-ray spectroscopy tests. They then used advanced imaging techniques to characterize the composition of the lime clasts.\nThese analyses generated insight into the method of mixing the Romans used for the mortar. The team found compelling evidence for hot mixing of mortar using quicklime (which contains calcium oxide) instead of, or in addition to, slaked lime (which contains calcium hydroxide), which was more common at the time. To confirm their hypothesis, the team developed a cement mixture using the same materials and preparation methods the Romans used. They found that the concrete exhibited a remarkable self-healing effect of cracks measuring up to 0.5 milimeters in width. This self-healing effect provides insight into the durability of Roman structures and may have helped pave the way for the development of more durable and resilient concrete structures that characterized the Roman empire.\nAccording to the team, Roman mortars and concretes have remained durable in a variety of climates, seismic zones, and even in direct contact with water, such as those used in bridge building. This is in stark contrast not only to other concretes used by the Romans\u2019 contemporaries, but also to modern concrete. As a result, the longevity and innovation of Roman concrete can provide an attractive model for the design of sustainable construction projects, even for modern engineering applications.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/all-roads-lead-to-rome/",
            "captions": [
                ""
            ]
        },
        {
            "title": "AI vs. Nature: The Protein Game",
            "author": "Lawrence Zhao",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Zhao_Figure1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Wikimedia Commons.\nBeyond Amazon Alexa and self-driving cars, artificial intelligence (AI) has transformed modern biology. For over fifty years, scientists have been trying to figure out how to determine a protein\u2019s structure from just its amino acid sequence. AI has made a major breakthrough \u2013 Google developed a program called AlphaFold that is able to predict folded protein shapes with greater accuracy than ever before. Following in this vein, scientists at SalesForce Research recently developed an AI tool called ProGen, which produces powerful, artificial enzymes from scratch.\nProGen relies on a large language model. Language models produce human-like text by predicting the most probable word to occur next given what has already been written. These models have gained a lot of recent attention \u2013 take, for instance, ChatGPT, which will answer any question as if a real person was writing back to you. Inspired by the success of language models, Nikhil Naik, director of SalesForce AI Research, saw that the same technique might work for proteins. Because proteins can be represented as a sequence of letters from a shared alphabet of twenty amino acids, he reasoned that a language model might also be able to generate new protein sequences.\u00a0\nFor a language model to be successful, it must learn by example. ProGen was trained on 281 million protein sequences covering almost 19,000 protein families in nature. Aside from the sequences, ProGen includes control tags \u2013 labels that specify the properties of a particular protein. Along with including more data for ProGen to work with, control tags allow ProGen to synthesize proteins based on user input \u2013 when prompted with a property, ProGen can build a protein based on that property.\u00a0\nNaik then tested whether the novel proteins produced by ProGen could work in the real world. His team focused his efforts on lysozymes, which are a kind of bacteria-killing enzyme found in animals. To increase accuracy, they first fine-tuned the language model to lysozymes. James Fraser, a professor in the Department of Bioengineering at the University of California San Francisco, measured the activity of the new enzymes. Remarkably, an artificial lysozyme created by ProGen could kill bacteria even though it shared at most 31.4 percent of its sequence with any known protein. \u201cThe model has learned substitution and co-occurrence patterns that are hard for humans to intuit, but that can lead from data,\u201d Naik said. In this way, ProGen uses the grammar of protein language to build proteins completely different from anything we have seen before.\nThese findings serve as a proof-of-concept of a new paradigm of protein engineering. Scientists have previously designed new proteins by using natural selection in the laboratory. Through a technique called directed evolution, biologists repeatedly induce mutations in a protein over time. Unlike directed evolution, however, ProGen does not need nature\u2019s help and designs proteins much faster. Although Naik feels AI technology is still far from creating any protein that we can imagine, ProGen shows that this dream might be within reach. AI tools like ProGen will accelerate the discovery of new drugs and environmentally-friendly enzymes. But with this newfound power comes responsibility \u2013 while this technology develops, we must consider the ethical implications of having nature\u2019s code at our fingertips.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/ai-vs-nature-the-protein-game/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Birds of a Feather Get Sick Together",
            "author": "Nathan Mu",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-6.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Ben Freeman.\n\u201cOne morning, I woke up on the concrete floor of my hotel room with no memory of how I got there. And no, I was not drinking,\u201d said Ben Freeman, postdoctoral fellow at the University of British Columbia. He had fallen unconscious in Lae, a lowland city in Papua New Guinea. Having traveled from Vancouver, he was there to catch birds and collect blood samples. Unfortunately, he contracted a case of malaria that caused him to faint. But how? Freeman had been working in the highlands, where malaria should not have been a concern. His doctor walked into his room in the clinic. \u201cOk, but look, you have malaria, and you need treatment,\u201d his doctor said, clearly not as intrigued as Freeman was.\nAfter recovering, Freeman remembered that global warming had caused human malaria to move upslope. He wondered if the same was true for avian malaria. \u201cIn Hawaii, birds have gotten pushed to higher and higher elevations due to climate change,\u201d Freeman said. Perhaps, the same was occurring in New Guinea. The biotic interactions hypothesis suggests that more species clustered in warmer regions drive disease transmission. Indeed, Freeman found that disease prevalence was higher at warmer, lower elevations. However, there was another, unexpectedly stronger influencing factor: evolutionary relatedness.\nAs Freeman puts it, there are two ways to think about disease risk. \u201cRisk is a function of environment or risk is a function of who you are as a bird,\u201d he said. Freeman\u2019s second hypothesis, based on evolutionary relatedness, was the key driving force behind disease prevalence in New Guinean birds. For example, three species of Melanocharis berrypeckers had high infection rates, while three species of Pachycephala whistlers had low infection rates despite all these birds living in similar elevations.\nThe importance of relatedness is not unique to birds. There might be similar patterns in coral reefs, where temperature is not a large factor for parasitic infection. Yet, it is unclear how far this pattern extends. \u201cHumans were a tropical species when they were in sub-Saharan Africa. How does that shape our disease risk?\u201d Freeman said. Could there be an evolutionary rather than environmental connection?Freeman and his team spent years collecting and analyzing over two thousand blood samples from bird species. He loved inspecting and admiring the various bird species his team caught using fine mesh mist nets. \u201cChecking on the birds in the nets was like Christmas morning,\u201d Freeman said. Once, his team caught the Hooded Pitohui, a poisonous bird. While not strong enough to harm humans, the bird holds the same poison as dart frogs. Egged on by his team, Freeman excitedly licked his finger after touching the bird and felt his tongue turn slightly numb. \u201cI suspect that explains why the [Hooded Pitohui] just sits there calmly, waiting for you to agree that they taste terrible as opposed to most birds, which just try to rip your fingers off,\u201d Freeman said\nFreeman\u2019s experience demonstrates that sometimes, accidents result in incredible discoveries. Freeman\u2019s discovery of the influence of evolutionary relatedness in disease transmission has implications beyond \u201cwho you are as a bird.\u201d In particular, the host-parasite coevolution phenomenon displayed in this research raises fascinating questions about evolution, population changes, and disease dynamics that deserve to be explored beyond New Guinea.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/birds-of-a-feather-get-sick-together/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Quieting the Stars with a Galactic Quench",
            "author": "Hannah Qin",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Graphic1-500x346.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of ESA/Hubble & NASA.\nStar formation is so innate to the existence of galaxies that the loss of a galaxy\u2019s precious, star-forming gas is a sentence to a tragic end. This end is the reality for some dwarf galaxies\u2014small systems that carry a few billion stars, in contrast to the upwards of one hundred billion stars in our Milky Way. These dwarf galaxies are prone to losing their star formation ability in a process known as quenching.\nQuenching was believed to require local environmental processes, such as entrapment in the hot halo of a galactic cluster which results in the loss of cold gas. Consequently, dwarf galaxies isolated from other galactic bodies would theoretically be safe from quenching.\nHowever, a new study from Yale astrophysicists led by graduate student Imad Pasha offers insightful additions on the cosmological mechanisms responsible for quenched dwarf galaxies\nThe cosmic web is a network of filamentary and sheet-like structures of dark matter, gas, and galaxies, with nodes at connecting points typically containing galaxy groups and clusters. Cosmic sheets within the web are in constant collision with each other. Their impacts send out accretion shocks that can quickly heat the gas surrounding a galaxy, stripping away the cold gas required to form stars and cutting off a galaxy\u2019s fuel supply. Using simulations, Pasha discovered that accretion shocks from cosmic sheets can lead to large-scale environmental quenching, even in isolated dwarf galaxies.\n\u201cThe most surprising result, if anything, was the uniformity with which dwarf [galaxies] below a certain mass tanked their star formation rates and quenched after interacting with the sheet,\u201d Pasha said.\nHowever, observational samples of dwarf galaxy populations are small because these systems are faint. Thus, current methods of counting galaxies may accidentally exclude dwarf galaxies quenched by cosmic sheets. \u201cThe collapse of large-scale structure and sheet collisions are universal processes, but aren\u2019t really being included in the way people think about how galaxies got to where they are,\u201d Pasha said\nThis research was made possible by the contributions of Pasha\u2019s team, from graduate students to postdocs, and faculty. \u201cA lot of progress can be made, and a lot of great mentorship and scientific exchange can occur when you step back from the science and examine the human aspects of how science is done,\u201d Pasha said.\nThere is no shortage of direction for future research on dwarf galaxies. Over the last billion years, dwarf galaxies in the local volume around the Milky Way have seen their star formation go up and down in tandem with each other, even without a causal connection. This phenomenon is not well understood, but new technologies such as the Large Synoptic Survey Telescope at the Vera C. Rubin Observatory in Chile may bring about better observations to aid our understanding of the tragic fate of quenched dwarf galaxies.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/quieting-the-stars-with-a-galactic-quench/",
            "captions": [
                "This image shows a dwarf galaxy in the southern constellation of Phoenix named, for obvious reasons, the Phoenix Dwarf. The Phoenix Dwarf is unique in that it cannot be classified according to the usual scheme for dwarf galaxies; while its shape would label it as a spheroidal dwarf galaxy \u2014 which do not contain enough gas to form new stars \u2014 studies have shown the galaxy to have an associated cloud of gas nearby, hinting at recent star formation, and a population of young stars. The gas cloud does not lie within the galaxy itself, but is still gravitationally bound to it \u2014 meaning that it will eventually fall back into the galaxy over time. Since the cloud is close by, it\u2019s likely that the process that flung it outwards it is still ongoing. After studying the shape of the gas cloud, astronomers suspect the most likely cause of the ejection to be supernova explosions within the galaxy. The data to create this image was selected from the ESO archive as part of the Hidden Treasure competition."
            ]
        },
        {
            "title": "Small but Mighty",
            "author": "Jessica Le",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Le_Figure2-500x119.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikipedia.\nAt the beginning of the year, Hong Tang, Professor of Electrical Engineering at Yale University, and his team developed the world\u2019s first chip-sized titanium:sapphire laser, shrinking a laser that would conventionally take up an entire table length to just a few centimeters. Titanium:sapphire lasers have been one of the most important advancements in laser development. The coupling between the sapphire crystals and active titanium ions results in the largest emission spectrum of any solid-state material, allowing researchers to exploit this powerful property to amplify and direct energy. However, the bulky commercial titanium:sapphire lasers require an immense amount of power, so they are often costly and limited to industrial lab environments.\n\u00a0\u201cA few years ago we were thinking, why don\u2019t we miniaturize this titanium:sapphire laser and put it on an integrated photonic chip platform,\u201d said Yubo Wang, lead author and graduate student in the Tang lab. This new model minimizes the area to a chip while still preserving the performance of the full-sized titanium:sapphire laser, allowing for portability and minimal power consumption. They were able to accomplish this feat by bringing down the energy threshold from more than one hundred milliwatts to less than seven milliwatts.\u00a0\nThe Tang lab continues to work on iterations of the chip-sized laser and aims to achieve an even lower threshold (around one milliwatt) and higher output power. Not only is this new model a reduction in size, but also a steep reduction in price. Wang expects that at large-scale manufacturing, the laser could cost less than a thousand dollars, more than a three-fold decrease in price. \u201cMiniaturization of the titanium:sapphire laser will bring about many applications, especially those sensitive to power consumption and size, such as integrated atomic clocks, portable sensors, visible light communication devices, and quantum computation chips,\u201d Wang said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/small-but-mighty/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Fight or Flight",
            "author": "August Rios",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1.-.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "In 2020, the World Health Organization labeled antimicrobial resistance as one of the greatest threats to global health. Resistance occurs when bacteria evolve defense mechanisms that counter the drugs designed to destroy them.\u00a0\nKatie Kortright and her colleagues in the Yale Department of Ecology and Evolutionary Biology are leading the search to find a worthy opponent for antimicrobial resistance. For decades, scientific literature has pointed to the bacteriophage, or phage for short, as a possible solution. A phage is a viral parasite that infects a bacterial host. Translating appropriately to \u201cdevour\u201d in Greek, the phage reproduces by bursting out of its host, killing the bacteria.\u00a0\nIn nature, when two species interact, coevolution can occur, where organisms genetically adapt to each other over generations. Two forms of coevolution may happen under different conditions: arms-race (ARD) and fluctuating selection (FSD) dynamics. ARD is a back-and-forth acquisition of attack and defense mechanisms while FSD implies a continuous cycle of mutual resistance. Tackling antimicrobial resistance, Kortright aimed to find out which form, if any, would exist in bacteria-phage interactions.\u00a0\nTo accomplish this goal, Kortright exposed colonies of bacteria to phages for ten days. She investigated coevolution by sequencing the genome of the bacteria, and from the genome, she found that coevolution occurred through both ARD and FSD dynamics. This finding demonstrates that different mechanisms of coevolution can occur under a single bacteria-phage system. The reason for this phenomenon, however, remains unknown.\nThe battle is far from over. Before phage therapy becomes a feasible combatant against antimicrobial resistance,\u00a0it is imperative to identify every evolutionary consequence. \u201cWe are never going to run out of things to study,\u201d Kortright said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/fight-or-flight/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Tinkering with T cells",
            "author": "Kayla Sohn",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/figure-1-10.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Cancer immunotherapy is an essential treatment used to boost or change how your immune system works. T cells are a type of white blood cell in the immune system that help fight cancer. T cells rely on antigen receptors to locate their target cancer cells, but they often do not have the specific receptor repertoire they need. To solve this issue, artificial receptors can be genetically engineered into T cells, creating efficient chimeric antigen receptors (CAR) T cells that are better equipped to bind to cancer cells. In the field of CAR T cells, it is difficult to precisely identify which CAR T cell binds optimally. Many of them have only been shown to help blood cancer tumors and are extremely toxic. T cells are challenging to genetically modify, and although scientists have managed to knock out genes, knock-in cell therapy is more difficult.\u00a0\nYale professor Sidi Chen\u2019s lab developed a precise, high throughput genomic engineering system, CLASH, to address these problems. After nearly half a decade, Xiaoyun Dai, an associate research scientist in Chen\u2019s lab, and Chen found that electroporation\u2014using electric shocks to introduce DNA into cells\u2014can be used in combination with a versatile adeno-associated viral vector to deliver therapy and target cancer cells. This method is much less toxic for the cells, is easier to use, and has higher efficiency than current therapy. \u201cWe were able to create a new platform to modify the human genome in a precise manner by massive insertions,\u201d Chen said.\u00a0\nCLASH can be applied to other types of cells and translational medicine as the technology is further introduced. \u201cIt brings much hope and flexibility to change our genomes in immune cells in any direction we want to improve and find new targets for the CAR T cell models,\u201d Dai said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/tinkering-with-t-cells/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Tale of Two Brains",
            "author": "Nathan Wu",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wu_Figure1-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nThe brain is, arguably, the most important organ in the body. It is the seat of consciousness, emotion, language, and intelligent action: it is what makes us human. This makes damage to the brain all the more terrible. While the brain can repair minor damage by making more neurons or regrowing axons (the \u2018cables\u2019 that carry signals between neurons), its regenerative capabilities are too limited to restore proper function when large swaths of it are lost. Injuries like strokes or traumatic brain injuries could have lifelong consequences for cognitive function. Consequently, much neuroscientific research aims to develop strategies to repair large-scale brain damage.\nNeurosurgeon Han-Chiao Isaac Chen and his team at the University of Pennsylvania have found a promising lead. They have demonstrated that clumps of stem cell-derived tissue, called organoids, can successfully integrate into the damaged brains of adult rats. These organoids are created by applying an understanding of developmental biology to cause stem cells to develop in a structured manner, often mimicking an organ or part of an organ. Chen\u2019s target was the rat\u2019s visual cortex: the part of the brain that takes in visual input and abstracts it into edges and objects.\u00a0\nChen and his colleagues surgically removed regions of the rats\u2019 visual cortexes and replaced them with organoids grown from human stem cells. They then allowed the rat to live with its transplant for one to three months before evaluating the integration between the organoid and the rat\u2019s brain. The researchers found that axons from the rat\u2019s cortex and the organoid had bridged the boundary between them and that output from the retina was successfully reaching the organoid.\u00a0\nAdditionally, Chen and his team evaluated the functional integration of the organoid by characterizing the responses of its neurons to different visual stimuli. Areas of the organoid not only responded to flashing lights, but also responded with varying strengths to moving bars presented at different angles. This preference by different neurons for edges of different orientations is a key part of visual systems that allows for the recognition of more complex features, like shapes.\u00a0\nBoth the physical and functional integration of the organoid into the rat\u2019s brain make organoid transplantation a promising technology for neural tissue repair. Previous attempts to restore visual function by transplanting unorganized collections of stem cells into lesions have failed to yield more complex responses to stimuli, like edge orientation selectivity. Accordingly, Chen believes that the organoid\u2019s structure plays an important role in restoring higher-order functions. \u201cA central hypothesis of my lab is that neural tissues with brain-like structure will be more effective than individual cells for rebuilding the brain,\u201d Chen said. \u201cBrain organoids have by far the greatest degree of brain-like structure of any neural tissue that can currently be created in the lab.\u201d\nAn ideal solution to repairing large-scale brain damage would be to transplant entire columns of cortex directly from fetuses, which would possess the structure needed to restore higher-order functions. However, this approach carries with it the ethical questions of obtaining and using fetal tissue. Organoids may be the next best thing. With more research, scientists will better understand how to control organoid development to yield desired structures, such as the layers of the cortex. Although this technology is still far from implementation in humans, it holds great promise.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/a-tale-of-two-brains/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Cosmic Dawn over I-287",
            "author": "Samantha Liu",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Perimeter-Kara-Tao-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Kara Tao.\nArtist\u2019s Statement:\nThere is no shortage of poetry about astronomy. As early as the founding of civilization, we have searched for romanticized meanings in our cosmos\u2014we are all made of stardust, or we all see the same night sky, or it\u2019s written in the stars\u2014and tried to create art from it. What struck me, then, about Shannon Hall\u2019s Nature article was not only the beautiful language and metaphors she used to describe our galaxies. Hall took the science of discovery\u2014of hydrogen reionization and rest-optical spectra\u2014and wove it into a story, a real story, about our universe\u2019s genesis. And this story is not so different from our own lives. As the universe transformed from \u201cseething plasma\u201d to \u201ccosmic blackout,\u201d I thought back to my life half a year ago\u2014at home for October break, two months into college, and already feeling that nebulous cloud of adulthood settling over my future. So when Hall wrote about discovering these \u201cPeter Pan galaxies\u201d which not only uncloaked us from darkness, but also continue to light the skies today, I thought that was beautifully poetic. We don\u2019t need to romanticize the stars, and we don\u2019t need to invent far-flung metaphors. All the stories and all the meaning we need\u2014it\u2019s right there above us, if only science teaches us to look.\nCosmic Dawn over I-287\nWe start as seething plasma, like the mid-June afternoon when we rolled open the car sunroof to scream karaoke lyrics at the neighborhood police. We are seventeen and deathless then, the universe white-slick as our hands outstretched beneath the sun. When our high school valedictorian declares our futures blindingly bright, we throw our graduation caps into the sky and fill the football field with green pea galaxies of boundlessness.\nWe end as cosmic blackout on I-287, ouroboric in the way a thick fog can block a vehicle\u2019s headlight. When I drive down this October highway, the only galaxies I see are suffocated by suburban light pollution and this blanket of hydrogen / hanging over the universe. The astronomers call it intergalactic, distant bodies and hazy lives of my hometown friends four months and twenty states away, and all I can think about is how adulthood is a dying star, all my potential narrowing and flickering out, when\u2014\nsupermassive black hole swirling welcomed gravity swallowed harsh radiation tore apart a \u2018fog\u2019 violence gnashes the clouds billow-black pulled back when sudden luminosity furious & brilliant & starlight reddening reddening redshift reionization reionization reionization\u00a0\u2014Eventually, this dark age ended. When the clouds clear, we find ourselves surrounded by ionizing radiation. Lit green by fledgling stars, these are Peter Pan galaxies, rebirthing us as lone protons and electrons. Which is to say we are for the first time unbounded\u2014whole, charged, free. And I wonder what it would take for us, too, to carve out a pea of possibility in our own hearts. To survive harder and shine brighter, while hurtling lightyears away from where we came. To create our own constellations. Maybe, when the fog lifts, rendering stars and galaxies visible for the first time, it\u2019s just us discovering the radiance that was there all along.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/cosmic-dawn-over-i-287/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Can A.I. Distinguish One Artist From Another?",
            "author": "David Gaetano",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Sistine_Madonna-500x366.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nWith the recent mania surrounding AI and its capabilities both in creating art and identifying it, researchers are working to uncover hidden truths about Renaissance paintings.\u00a0Experts believe they may have discovered concrete evidence of a previously unidentified Raphael painting.\nProfessor of Visual Computing Hassan Ugail has developed AI technology capable of analyzing features of artwork imperceptible to the human eye. The AI system, known as a deep neural network, was trained for months in facial recognition and can compare aspects of a painting, including its texture and shading, to a database of previously analyzed pieces.\nThis technology has been used to settle the long-disputed origins of the Br\u00e9cy Tondo, a portrait of Mary and Jesus that possesses an uncanny resemblance to the Sistine Madonna, one of Raphael\u2019s most famous paintings.\u00a0While some experts believe the Tondo is a Victorian copy of the Raphael, Ugail\u2019s technology says otherwise.\u00a0With a similarity report of ninety-seven percent between the two pieces, this new evidence is hard to dispute.\nAlthough this technology has proved promising, it has sparked debate among experts.\u00a0Those critical of the neural network\u2019s ability believe that the technology is unable to consider the motivation behind the artwork\u2014after all, would it be reasonable to conclude that Raphael created two nearly identical paintings?\nUgail\u2019s work provides a glimpse into what the future may hold for the field of art analysis. Though AI may not provide definitive answers to the Tondo\u2019s origins, this technology shows just how diverse the applications of the neural network can be.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/can-a-i-distinguish-one-artist-from-another/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Alumni Profile: David Quammen",
            "author": "Santiago Calderon",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/DQ-in-plane-Charlie-H-J-500x334.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Charlie Hamilton James.\nDavid Quammen (YC \u201870) gestured behind him to a large glass tank on the floor of his office. \u201cOver there is a rescue python that shares this office with me. He\u2019s lived here for four years. His name is Boots,\u201d he said, with a note of pride. The same love of nature that prompted Quammen to catch snakes and bugs as a boy continues to be a major influence in his work as a science non-fiction writer. Throughout his long career, Quammen has written numerous essays and books on the natural world and the forces that drive it, including a monthly column in Outside magazine that he has continued for fifteen years, numerous pieces for National Geographic, and a book on COVID-19 titled Breathless.\nQuammen\u2019s journey to becoming a non-fiction author began with a love of nature and writing that transitioned seamlessly into his studies at Yale. In the summer between his junior and senior years, Quammen traveled to a troubled neighborhood in Chicago to work as a community organizer. That experience inspired his first book, To Walk the Line, which he wrote on yellow legal pads in his dorm room and published in 1970 after his mentor, Pulitzer Prize-winning novelist Robert Penn Warren, recommended it to an editor.\nAfter finishing his education at Yale with an English degree and spending two years at Oxford on a Rhodes Scholarship studying the works of William Faulkner, Quammen decided he wanted a change of scenery. \u201cI was tired of ivy-covered walls, I was tired of being in school, and I was tired of being in elite institutions. [\u2026] As I thought of it then, I wanted to live closer to the ground,\u201d Quammen said. Using the profits from the publication of his first book, he bought a Volkswagen bus and packed it with Penguin paperbacks, an electric typewriter from his parents, and a fishing rod, before driving to Montana. Not foreseeing how long he would spend there, he ended up staying for a lifetime. He worked for thirteen years before he published his second book, writing in the mornings while working as a bartender and a fishing guide to cover his living expenses.\nWhile he was in Montana, Quammen reconnected with the natural world. \u201c[My interest in the natural world] reawakened now that I was in a place that had mountains and wildlife and rivers filled with trout and snow,\u201d Quammen said. Meanwhile, he became fascinated with Darwin\u2019s works and with scientific writing in general. In 1980, after pitching an article on the benefits of mosquitoes to an editor of Outside magazine, he began writing its monthly nature column. In the process, Quammen\u2019s focus transitioned from novels and essays on natural history to science writing about theoretical ecology and the history of evolutionary thinking. \u201cAs passionately interested in and impressed by William Faulkner and his novels as I was, I became that interested in and impressed by Charles Darwin,\u201d Quammen said. This focus on non-fiction writing led him to pursue a successful career writing about Ebola, molecular phylogenetics, and a biography of Darwin himself.\nThe vast amount of Quammen\u2019s research is conducted through two avenues: extensive reading of scientific journal articles and interviews with experts (he conducted ninety-five Zoom interviews for Breathless), with occasional field visits. His next book, to be published in May 2023, is drawn from a collection of conservation-related pieces originally published in National Geographic, titled The Heartbeat of the Wild. After that, he will resume work on a book on cancer as an evolutionary phenomenon. The novel contains a number of counterintuitive cases, such as devil facial tumor disease (DFTD), a cancer affecting Tasmanian devils. Cancers are almost never transmitted between individuals, instead arising due to time, genetic mutations, or environmental factors. However, DFTD is a transmissible cancer that spreads through bites, indicating that cancer is an evolutionary phenomenon and that tumors can adapt over time. This interplay between evolution and cancer fascinates Quammen, and he is excited to conduct more research.\nQuammen is looking forward to whatever comes his way, but is experienced enough to know that life is unexpected. \u201cLife doesn\u2019t follow your plans. [\u2026] You gravitate toward things that a) interest you and engage your passions, but b) allow you to pay for food and shelter,\u201d Quammen said. He still lives in Bozeman, Montana with his wife, an assortment of dogs and cats, and, of course, Boots.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/alumni-profile-david-quammen/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Diving into the Deep",
            "author": "William Archacki",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fig1_How-Far-the-Light-Reaches-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Unsplash.\nYou\u2019ve probably seen it in nature documentaries: a translucent fish meanders through the darkness, searching for scraps of food in the wasteland of the deep ocean. The screen sparkles with flakes of decaying matter that drift above the ocean floor, to be consumed by sparse communities of microbes and strange, gelatinous creatures. The narrator explains that the deep ocean has an average temperature of just four degrees Celsius and that the water is under such pressure that it could crush anything but a few specialized vehicles.\nMore than two-thirds of the Earth\u2019s surface is water, and our understanding of the organisms that live in its depths remains severely limited. But to Sabrina Imbler, a science journalist and former New York Times reporting fellow, the mystery of the murky waters is no cause for unease. Rather, as Imbler shows in their new collection of essays, How Far the Light Reaches: A Life in Ten Sea Creatures, the networks of resiliency that populate Earth\u2019s waters provide a glimpse of the beauty that can flourish amid turbulence and oppression.\nEach essay in the collection examines one creature and a corresponding piece of Imbler\u2019s identity, drawing parallels between the unique ecology of the sea and Imbler\u2019s lived experience. In the collection\u2019s opening essay, Imbler notes that goldfish can grow to be long-lived, far-traveling giants when freed from the confinement of fishbowls. Interweaving poignant adolescent memories within the exposition of goldfish biology, Imbler suggests that a person\u2019s identity, too, may flourish when freed from constraints. As Imbler recounts the process of defining their queer, mixed-race identity, they show that nature serves as a model for personal authenticity.\nWhen the spotlight turns to the yeti crab, a tiny crustacean that ekes out an existence in the heated waters of hydrothermal vents, Imbler questions the notion that living in Earth\u2019s most inhospitable environments is a matter of mere survival. The yeti crab is an eternal dancer, waving its pincers in circles continuously to harvest microbes on its hairlike filaments, living in a place scientists long thought impossible. \u201cI prefer to think of it not as a last resort but as a radical act of choosing what nourishes you,\u201d Imbler writes.\nThe unexpected triumph of the yeti crab comes interspersed with Imbler\u2019s memories of the queer, mixed-race communities they have found hidden in American cities. Imbler touches upon the struggles they have faced grappling with racism, sexism, gentrification, fetishization, and other forms of intolerance in contemporary America. Movingly, Imbler reflects on resilient aquatic populations as symbols of solace and hope.\nImbler\u2019s sprawling exploration of the creatures that inhabit the sea questions the way our definitions of normality restrict us. An examination of hybrid fish in one essay becomes a critique of the impulse to categorize nature\u2019s disorder. For Imbler, the vast and beautiful world of sea creatures offers a call for a deepened understanding of our most authentic identities\u2014abnormal, confounding, and gelatinous as they may seem.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/diving-into-the-deep/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Sipping Up a One-Hundred-Year-Old Mystery",
            "author": "Hanwen Zhang",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Plant-migration-Court-Johnson-349x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Court Johnson.\nLike any great puzzle, the initial setup seemed deceptively simple. What two botanists noted at the 1920 Royal Society of Edinburgh meeting was just that: larger plants had more complex vascular systems. The bigger the plant, the more shapes its bundles of xylem and phloem would take on to exchange water with its root systems. Yet, as with all unsolved mysteries, the pair of scientists could not explain why this relationship existed. The scientific world would go on to assume that increasing vascular tissue complexity was nothing more than a morphological quirk of plant size, not considering that there might be an evolutionary layer to the problem.\nA recent study published in Science from the Brodersen Lab at the Yale School of the Environment might just have fit the pieces together. Through simulations, modeling, and paleobotany, they uncovered how certain vascular tissue arrangements could have offered the earliest plants a survival advantage as they migrated from the comforts of their watery habitats onto dry land. One century and two years later, we have an answer.\nA Balancing Act\nThe earliest forebears of plants today were likely a small and scraggly bunch\u2014most fossil reconstructions give them the look of tiny, mushroom-like hairs rather than anything that remotely resembles a fern. But they faced many of the same challenges as their present-day descendants: accessing light, finding enough carbon, weathering droughts. At its heart, the struggle for survival is also about photosynthesis.\n\u201cOne of the core parts of how plants work is that they exchange water for carbon,\u201d said Jonathan Wilson, professor of environmental studies at Haverford College and an author of the study. To acquire atmospheric carbon, plants must open their stomata. These tiny pores on the undersides of leaves release precious water vapor in exchange for the carbon dioxide in their environment. What follows is usually a tightrope walk of delicate tradeoffs: keep water sources steady, and you slowly deplete your carbon reserve; open a stoma too wide or for too long, and you might die from drought.\nThere\u2019s another catch: opening stomata also runs the risk of succumbing to another kind of slow, languishing death. In extremely dry surroundings, the atmosphere can pull from the plant\u2019s exposed water reserves harder than usual. Water molecules would normally follow like a chain or rope, tugged along by hydrogen bonds. Yet in some instances, these hydrogen bonds can break to cause what Wilson explained as a \u2018cavitation\u2019: a bubble of air within the vascular tissue. Like a clogged artery, the consequences are often fatal. This \u2018embolism\u2019 blocks the xylem, which is responsible for transporting water from the roots to the leaves, leading the obstructed parts to waste and wither away. Left unsolved, it only worsens. \u201cThese gas bubbles can spread through the vascular system where connections exist, which means that the connectivity of the vascular network becomes a key feature of drought tolerance,\u201d said Craig Brodersen, professor at the Yale School of the Environment and principal investigator of the study.\nWhile some vascular plants\u2014namely, trees\u2014can either grow new xylem or dissolve the air bubble, this is not always an available option. \u201cThe tricky part about this is [that] in a lot of places, water stress-induced embolism is a limiting factor in plant growth,\u201d Wilson said.\nPiecing It Together\nDuring their search through the early fossil records, the researchers noticed a stunning variety of patterns: there were xylem tissue cross sections that appeared like neat circular bundles, three-lobed stars, tapered lines, and, in other cases, haphazard U-shaped streaks of paint. \u201cWe see this diversity of arrangements early on in plant evolution, and then quickly that [\u2026] diversity gets kind of winnowed down a little bit,\u201d Wilson said.\nBy the time nature finished dry running its designs, most surviving species seemed to have undergone a sudden spike in vascular system complexity. Xylem cells arranged in the form of narrow, curled arcs or warped asterisks had somehow taken the place of the contiguously bunched circles. Something was afoot.\nMaking sense of this problem required turning to a mix of math and microscopy.\u00a0 Some researchers including Wilson imaged fossilized plant stems from four hundred million years ago with electron microscopy. Another group simulated the evolutionary changes in the primordial xylem arrangement by incrementally adding nodes and branches to create complex, spiraling shapes that could approximate the kinds found in the fossil record. Others conducted experimental drought trials on currently existing plants to gather data for their models.\nThe findings teased out a surprising advantage: xylem tissue arrangements that were more structurally complex fared better under drought stress. In the narrower, thinner groupings of vascular tissue, each xylem cell was surrounded by fewer neighbors and therefore less prone to embolism. Highly lobed, intricate xylem tissues offered fewer paths through which the embolism could spread. The simulation results suggested that advantageous xylem tissue arrangements could have potentially decreased plant mortality two-fold.\nA Glimpse Into The Past\nThe intimate association between xylem shape and drought resistance reveals telling insight about the past. The team drew upon a wide range of species for their analysis, sampling everything from lycophytes\u2014a plant lineage that had once spawned one-hundred-foot trees in cold swamps three hundred million years ago whose modern descendants are low creepers\u2014to everyday ferns.\nComparing the xylem shapes between past and present specimens showed an evolutionary trajectory shaped by an arc of drought resistance. Statistical analyses determined that the least drought-resistant xylem arrangements were found entirely among extinct Paleozoic species; even configurations that were fairly common among plants at the time are hardly seen today.\n\u201cThese plants [worked] very, very well for their environment. But we also find that some early land plants had vascular systems that would have allowed [\u2026] relatively mild drought events to harm them,\u201d Wilson said. Xylem cells in sampled modern-day ferns have at most three neighbors. Among their Paleozoic predecessors, that number would have hovered closer to around four or five. In other words, the study suggests that some constant, evolutionary pressure has continued to shape xylem tissue arrangement.\nSpecies in reliably moist environments varied widely in their xylem arrangement. Only in xeric conditions\u2014where drought is a constant, daily threat\u2014did the researchers come across plants with consistently resilient xylem arrangements.\nThe findings dispel the age-old assumption of size and its inevitable complexity. The shapes of xylem tissue were not biological oddities or products of some unexplainable physiological rule of thumb.\u00a0 \u201cThere\u2019s lots of different arrangements of a vascular system that could support larger plants,\u201d Wilson said.\u00a0 \u201c[But] the fact that we don\u2019t see a uniform distribution of these strategies in plants [is] telling us that there\u2019s an environmental selection on top of it.\u201d The study instead suggests that there were real evolutionary advantages for having differently shaped xylems, and that xylem tissue shapes continue to be sculpted by the complex interplay of environmental factors: water supply, soil moisture, and atmospheric humidity.\nThe project also gives us a window into an evolutionary period where even the slimmest of advantages must have made a difference. \u201cNobody had really looked at [xylem tissue] from this kind of eco-physiological perspective before,\u201d Wilson said. Plants arrived on land anywhere from five hundred to seven hundred millions of years ago, but the first vascular organisms\u2014most of the plants we readily recognize today\u2014wouldn\u2019t appear until a few hundred million years later. That leap from mossy bryophytes to stemmed plants posed formidable challenges: the earliest vascular organisms would have had to develop new modes of transporting water that went against the forces of gravity. The researchers also noticed that xylem tissue diversification coincided with the Devonian period, a time in which scarce levels of atmospheric CO2 would have forced these plants to negotiate the razor-thin margins of survival even more rigorously than before. For the first vascular pioneers, the terrestrial world was an unforgiving one.\n\u201cThe main takeaway is that plants developed this complex inner plumbing, and it protected them from drought, and allowed them to colonize and spread on the land surface,\u201d Wilson said. \u201cWe wouldn\u2019t have vegetation on land, if plants hadn\u2019t [\u2026] figured out these particular evolutionary strategies.\u201d\nTowards The Future\nThe team\u2019s findings have immediate importance. Unlocking the secrets of xylem arrangement and water uptake could allow the agriculture industry to develop plants better prepared for an increasingly erratic climate. \u201cWe believe that by understanding how the earliest plants overcame the limitations of living on land. We can also better understand how plants will respond to drought in the future,\u201d Brodersen said.\nBut the sprawling, rich history of plant evolution cannot be distilled into a single study. The findings offer no more than a slice of the roughly 320,000 plant species that have since made themselves at home on this planet. Wilson expressed potential interest in comparing the water uptake processes found among their specimens of study to those of flower-bearing angiosperms, which connect their xylem cells with special structures called pits.\nThe researchers hope that their work offers just a start to decoding other evolutionary puzzles, too. Xylem tissue is, after all, only one trait among a vast selection of others. \u201cI think everybody is in this collaboration is quite interested in thinking about interesting evolutionary novelties in plants,\u201d Wilson said.\nFor now, though, they close the one-hundred-year-old puzzle with a four-hundred-million-year-old story. Plants effectively terraformed early Earth, but also changed themselves. They tell a story about the power to shape and be shaped, all the while tucking their heritage and history within themselves.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/sipping-up-a-one-hundred-year-old-mystery/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Staring Spell",
            "author": "Cindy Mei",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Ava Hoffman.\nIt comes without warning: all motion halts and activity stills. Moments later, the world returns between blinks, all memory of the lost time gone. These staring spells are the hallmarks of absence seizures, which are brief episodes of unresponsiveness and loss of consciousness. Epilepsy, a neurological disorder that affects nearly seventy million people worldwide, is characterized by the occurrence of recurring seizures due to abnormal electrical activity in the brain.\u00a0\nAbsence epilepsy primarily presents in children, comprising ten percent of childhood seizures. They can occur up to several hundred times a day and prevent normal engagement in school and social interactions. Knowledge about absence seizures has evolved considerably with the help of neuroimaging techniques and computational methods. However, there are still many questions on the mechanisms by which absence seizures occur that Hal Blumenfeld, Yale School of Medicine professor of neurology and director of the Yale Clinical Neuroscience Imaging Center, and his lab seek to answer. \u201cFor years, we\u2019ve worked on trying to understand the basic cellular mechanisms of what goes wrong during loss of consciousness in absence seizures because that\u2019s been a puzzle,\u201d Blumenfeld said.\u00a0\nThe Puzzle of Absence Seizures\n\u00a0It is now understood that absence seizures are caused by abnormal rhythmic activity in the corticothalamic network, an interconnected circuit in the brain that regulates attention and cognitive processing. But some of the unexplained phenomena that Blumenfeld and his lab encountered were discrepancies in brain activity during absence seizures between children and animal models.\u00a0\nCommon techniques used to map seizures include functional magnetic resonance imaging (fMRI), a technique that maps the flow of oxygenated blood in the brain utilizing its different magnetic properties from deoxygenated blood, as well as electroencephalograms (EEGs), which measure electrical activity generated by neurons in the brain. During absence seizures in children, the cerebral cortex typically shows a decrease in blood-oxygen-level-dependent (BOLD) signal on fMRIs and a repetitive spike-wave discharge (SWD) pattern on EEGs. SWDs are the defining electrographic characteristic of absence seizures. However, previous experiments in animal models showed confusing results: studies instead observed an increase in cerebral fMRI signal which did not resemble the decreases seen in children.\u00a0\nThere were also major discrepancies in behavioral response between children and animal models during absence seizures. \u201cAbsence seizures interrupt an individual\u2019s ability to respond normally to the environment, whether it\u2019s something that\u2019s simple and repetitive, like tapping on a button, or more challenging like responding to a specific stimulus,\u201d Blumenfeld said. However, previous attempts to characterize such changes in animals failed because behavioral activities suppressed or interrupted seizures. \u201cThe problem is that nobody had ever tested absence seizures in an animal model where animals were in a state where the seizures wouldn\u2019t be interrupted\u2026 the tasks that were used were very exciting for the animals,\u201d Blumenfeld said. The pursuit to understand these discrepancies drove a five-year-long project led by Cian McCafferty, then a postdoctoral student in Blumenfeld\u2019s lab and current lecturer and principal investigator in the Department of Anatomy and Neuroscience at University College Cork.\u00a0\nValidating an Animal Model\nIn their study published in Nature Communications, McCafferty and colleagues used a common model for absence epilepsy: genetic absence epilepsy rats of Strasbourg (GAERS). \u201cAs a rat model, the behavior can be more easily interrogated than a mouse model. They are less prone to impulsive or hyper-aggressive behavior [than mice],\u201d McCafferty said.\u00a0\nPreviously, fMRI scans of absence seizures had only been done on anesthetized animals, as the cold and loud fMRI machine generates a distressing environment. In this study, researchers were able to habituate the rats to the machine and record fMRI without anesthesia. \u201c[McCafferty] would wrap them up like a little child, almost like swaddling a baby, to make them very comfortable,\u201d Blumenfeld said. \u201cAnd he would train them until they\u2019re very calm and habituate them. So they\u2019re at the point that they would be able to not move without any drugs or anesthesia and sit still for long enough to do an MRI scan\u2026 just like children do.\u201d Unlike measurements from anesthetized rodents, a decrease in blood flow accompanied absence seizures in these rats, just like in children. The researchers then determined that previously reported increases in blood flow were due to anesthesia rather than a characteristic of the seizure itself.\u00a0\nBesides a new method for fMRI scans, this study also developed two behavioral tests that did not disrupt absence seizures. In one task, rats were trained to respond about once a minute to eighty decibel (dB) sound signals, around the volume of a noisy restaurant, by licking a sensor to receive a sugary water reward. However, this intensity kept the rats aroused and inhibited seizures. So, researchers lowered the intensity to forty-five dB, or average room noise, every few minutes, or upon detection of an SWD (signaling seizure onset)\u2014whichever came sooner. This change allowed for seizures to occur and interrupt behavior. On average, rats responded to 88.2 percent of all sound signals before seizures but only 0.4 percent during seizures.\u00a0\nIn the other task, researchers trained rats to spontaneously lick at a spout by giving sugar rewards at random intervals. The average rate of licking decreased during SWDs, indicating that activity was interrupted. Licking recovered within a few seconds after SWDs ended. However, five percent of all seizures were \u201cspared,\u201d meaning that rats demonstrated at least one lick during SWDs. No rats responded to sound signals during a seizure as an auditory response was a more demanding task. These behavioral changes are consistent with observations in humans. \u201cJust like children, the rats had a decrease of fMRI activity in their cortex and these changes in behavior. We finally had a model that we could trust,\u201d Blumenfeld said.\u00a0\nMeasuring Neuronal Activity\nOnce the model was validated, the group turned to investigating the underlying causes of absence seizures on the cellular level. In EEGs, they found for the first time an overall decrease in neuronal firing both at the surface and deep in the brain, which Blumenfeld hypothesized was most likely responsible for the loss of consciousness. They also discovered a decrease in neuronal activity a few seconds before SWDs started and a transiently higher activity at seizure initiation before the overall decrease again. In addition, they found that neuronal patterns were more rhythmic during seizures. During normal function, neurons encode information in varied firing signals. The increase in rhythmicity and loss of irregular firing, then, indicates that important signaling is lost.\u00a0\nAfter discovering these changes in neuronal firing, the researchers went on to characterize individual neurons and discovered four different patterns of neuronal firing that contribute to the overall physiology of an absence seizure SWD. The majority of neurons decreased in firing, contributing to the overall lower activity. However, there are groups of neurons that show increased firing, some that have no change in firing, and some that display a transient increase in firing just before the seizure begins. \u201cWe think that the different neurons might be playing different roles in the seizure initiation and maintenance\u2014in particular, the group of neurons with abnormal transient increase in firing might be critical for triggering the onset of the seizure. And identifying those can be very exciting to try to prevent the seizures from getting started,\u201d Blumenfeld said.\u00a0\nThis study also reported systematic neuronal and behavioral changes forty to eighty seconds prior to seizure initiation, consistent with the directions of changes at seizure onset. Still, McCafferty remains cautious with these findings. \u201cThese changes are quite preliminary. One thing that would be interesting to see is whether those trajectories of behavior and EEG happen at other times when it doesn\u2019t lead to a seizure,\u201d McCafferty said.\u00a0\nToward Targeted Therapeutics\nMcCafferty is interested in one day using these findings to predict and inhibit seizures. While there is still a long way to go from identifying a trend to establishing reliable predictive power, he believes that pre-onset changes may inform an algorithm to predict seizures in children with absence epilepsy. \u201cOther people have suggested things that happen in a shorter period before the seizure starts that could lead to the seizure,\u201d McCafferty said. There is robust evidence that sensory stimuli can prevent seizures and, in some cases, even stop them at an early stage. It may be possible to devise portable devices that detect neuronal changes and prevent an anticipated seizure or restore partial functionality after seizure onset.\u00a0\nAt the same time, Blumenfeld\u2019s lab is working to determine the different neuronal cell types, including their genetic identities and how different groups connect to one another. These efforts will help develop targeted therapeutics for absence seizures. \u201cPrior to relatively recently, it looked like things were going wrong in the whole brain all at the same time [during an absence seizure], so it\u2019s really hard to figure out how to fix that. But if it turns out that there are only some neurons that you need to target to fix, that could facilitate the development of more targeted therapies,\u201d McCafferty said. Maybe one day, equipped with targeted therapies and devices to stop seizures, scientists can eradicate these staring spells.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/a-staring-spell/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Why Doesn\u2019t Immunotherapy Work For Everyone?",
            "author": "Abigail Jolteus",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Why-Doesnt-Immunotherapy-Work-for-Everyone_.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Iva Knezevic.\nThe cancer world is buzzing about immunotherapies. They promise to target cancer cells while avoiding healthy cells, a difficulty for many cancer treatments since cancer cells often originate from mutated healthy cells. So with six hundred thousand people in the United States still dying from cancer every year, why are these therapies either not working in patients or not offered to them? Immunotherapies have recently shown promising results\u2014but only in a handful of cancer types\u2014and even then, they seem to elicit different responses between cancer patients depending on individual variability.\nA new study completed in partnership between members of the Iwasaki Lab and the Santin Lab at the Yale School of Medicine analyzed data for endometrial cancer patients\u2019 responses to immunotherapies. Immunotherapies are a type of cancer treatment that utilize the patient\u2019s own immune system to fight cancer. Instead of using harsh substances such as chemotherapy or radiation to indiscriminately kill cancer cells, immunotherapy reactivates the body\u2019s natural defense mechanisms to recognize and attack cancer cells.\u00a0\n\u201cImmunotherapy is this really exciting area of cancer treatment where we use antibodies or other kinds of drugs to manipulate the immune system into better targeting cancer and recognizing it as something that needs to be eliminated,\u201d said Ryan Chow, an MD-PhD student at the Yale School of Medicine and first author of the study.\nA variety of different cancer immunotherapy approaches are actively being developed. Most clinical successes to date have been based on therapeutic antibodies that block specific proteins and receptors that allow cancer cells to evade the immune system. Other types of cancer immunotherapy include genetically modifying the patient\u2019s existing immune cells to redirect them against tumors, as well as cancer vaccines that are analogous to those used for COVID-19 and other pathogens.\n\u201cThe idea of immunotherapy is that our immune system is very good at dealing with foreign pathogens, things like viruses or bacteria, but in a way, we can also think of tumors and cancers as being foreign because they have acquired alterations and mutations that make them different on a genetic level,\u201d Chow said.\nWhile immunotherapies have improved survival rates for patients with certain cancer types, most patients do not respond to treatment. To date, the best response rates to immunotherapy have been seen in tumors with deficiencies in a DNA repair process called mismatch repair. Mismatch repair-deficient (MMRd) tumors characteristically accumulate very high levels of mutations, which in turn increases the probability that the immune system will successfully recognize the tumor as foreign. However, even among patients with highly-mutated tumors, less than half of patients will benefit from immunotherapy\u2014a mystery that has long eluded scientists.\u00a0\n\u201cThough taking the brakes off the immune system can be really effective, when you do that there can be intense side effects such as organ failure, autoimmune diseases\u2014this is not a drug without its problems,\u201d said Tai Michaels \u02bc23, an undergraduate research assistant in the Iwasaki Lab and co-first author on the paper. Since the side effects of immunotherapy can be very severe, understanding why some patients are more or less likely to respond to treatment is key to maximizing the efficacy of immunotherapy while minimizing toxicity.\nTwo Subtypes of Tumors\nYale researchers studied the effects of immunotherapy on patients with endometrial cancer, a type of cancer that starts in the lining of the uterus. The team looked at twenty-four participants with different molecular subtypes of endometrial cancer\u2014either mutational MMRd tumors (mut-MMRd) or epigenetic tumors (epi-MMRd). Six of the patients were classified as having mut-MMRd, which means that the driving mechanism of the cancer is mutations in the MMR genes, and eighteen were classified as having epi-MMRd, which means the driving mechanism of the cancer is epigenetic changes that silence mismatch repair mechanisms. Epigenetic changes are reversible changes that alter the way cells \u2018read\u2019 their DNA, but do not necessarily alter the DNA itself.\u00a0\nAll patients were administered an immunotherapy called pembrolizumab\u2014an antibody that blocks the inhibitory immune receptor PD-1\u2014to evaluate its efficacy. Normally, the PD-1 receptor acts as a safeguard to prevent immune cells from aberrantly attacking the body\u2019s own cells. As tumors can take advantage of this inhibitory mechanism to evade elimination by the immune system, blocking this receptor through anti-PD-1 immunotherapy can unleash an immune response against tumors.\nThe patients were treated with pembrolizumab every three weeks for up to two years. The researchers wanted to determine whether classifying patients by their mechanism of mismatch repair loss would allow them to better identify which patients are more likely to respond to anti-PD-1 immunotherapy. They observed that one hundred percent of the six mut-MMRd patients and forty-four percent of the eighteen epi-MMRd patients responded to the treatment, indicating that the mechanism of mismatch repair loss is indeed associated with the clinical effectiveness of anti-PD-1 immunotherapy.\n\u201cWe used various sequencing techniques. Sequencing means trying to understand the DNA makeup of the cancer cells or looking at what kind of proteins or mRNA the immune cells are making, called [single-cell] RNA sequencing. By using a combination of the two, we were able to profile both the cancer and the immune cells in the same patients, so we can try to figure out after therapy, how the immune cells are reacting to certain types of cancer cells,\u201d said Eric Song, an ophthalmology resident at the Yale School of Medicine and one of the lead senior authors on the paper.\nThe researchers also looked at peripheral blood mononuclear cells (PBMC) from patients before and after pembrolizumab treatment using single-cell RNA sequencing and matched T-cell receptor repertoire sequencing\u2014a method of tracking T cells, immune cells that attempt to recognize and kill cancerous cells, and their specificities. PBMC samples are composed of a variety of immune cells that circulate in the blood, including T cells and natural killer cells, two major cell types which can be involved in mounting anti-tumor immune responses.\nWhile the immune response in patients with mut-MMRd tumors was defined by T cells, that of patients with epi-MMRd tumors was instead characterized by natural killer cells. This led the researchers to conclude that the two molecular subtypes of endometrial cancer (mut-MMRd or epi-MMRd) are subject to different types of immune surveillance. This finding could, in turn, explain why patients with mut-MMRd tumors were more likely to respond to therapy, as the anti-PD-1 immunotherapy pembrolizumab is usually thought to act on T cells. At the same time, the researchers also discovered that natural killer cells from epi-MMRd patients demonstrated enhanced expression of many anti-tumor genes, suggesting that natural killer cells are the primary immune cells mediating anti-tumor responses in these patients.\u00a0\nWhat Next?\nThis study only analyzed twenty-four patients with one specific type of cancer, which raises the question of whether the conclusions would translate into a trend across other types of cancers and studies with larger patient cohorts. The researchers hope that the findings from this study could help inform further research on immunotherapies for various other cancers. Looking ahead, while this study was conducted on cancers with high mutational burdens, future studies could provide insight into cancers with variation in other factors\u2014such as natural killer cell activation\u2014and help improve the health outcomes of more cancer patients. \u201cWhile mut-MMR patients had a uniformly high response rate, there was significant variation in response among epi-MMR patients which was not tied to mutational burden, suggesting that this was instead due to variation in other factors,\u201d Michaels said.\u00a0\u00a0\nWhile Chow and Michaels worked together on data analysis and curation, Song and colleagues led the study conceptualization and data collection. Along with the Santin lab\u2019s team, who designed and enrolled patients in the clinical trial, their contributions all came together in the end. \u201cIt\u2019s such a big team effort; it\u2019s not something that one person can do alone,\u201d Chow said. As teams of scientists across the world continue in this vein, immunotherapies could continue to improve the health outcomes of more and more cancer patients.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/why-doesnt-immunotherapy-work-for-everyone/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Hell Planet",
            "author": "Brianna Fernandez",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Hell-planet-Breanna-Brownson.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Breanna Brownson.\nImagine if Earth\u2019s orbit shrunk to 1.5 percent of its current radius. The Sun would swallow the sky, temperatures would soar to devastating heights, and Earth\u2019s surface would be completely consumed by oceans of lava. A year, or a full rotation around the Sun, would pass in 17.5 hours\u2014but you wouldn\u2019t see its completion, as you\u2019d never survive on the scorching surface at a temperature of two thousand degrees Celsius. This world, a so-called \u201chell planet,\u201d exists forty light years from Earth, but its fiery exterior and apocalyptic atmosphere are not what make this burning alien world interesting.\u00a0\nThis planet, formally called 55 Cancri e, has an ultra-short period orbit, meaning that it essentially hugs its star as a full revolution takes under eighteen hours. The planet is known as a \u201csuper-Earth\u201d since it is just larger than our home planet\u2014except Earth orbits the Sun from a safe, habitable distance of ninety-three million miles rather than a shocking 1.4 million miles. Many extrasolar planets, or exoplanets, which orbit in close proximity to their stars are hot Jupiters: large, Jupiter-like planets that take under ten days to complete their orbits. Being so large and so close to their stars makes detection easy; the real challenge lies in detecting the smaller, Earth-like planets whose measurements are often drowned out by the noise from the stars they orbit.\u00a0\nArmed with the EXtreme PREcision Spectrograph (EXPRES), an ultra-precise instrument that can make these difficult measurements, Yale astronomy researchers Debra Fischer and Andrew Szymkowiak are chasing otherwise elusive low-mass planets like 55 Cancri e. At first, astronomers thought the orbit was four times larger, as the blink-and-you\u2019ll-miss-it nature of the orbit evaded proper study. But Harvard graduate student Rebekah Dawson correctly interpreted its signal, prompting recent Yale PhD graduate Lily Zhao to spearhead efforts to accurately characterize 55 Cancri e. By studying smaller planets of varying alignments and orbital distances, researchers can better understand how planetary systems form. But our current understanding is biased by our measurements of majority-large planets. Large, high-mass planets like those similar to Jupiter are easier to detect, so we have more data characterizing them, which is why we know the least about the smaller planets that make up the majority of planetary systems.\u00a0\nEXPRESsing Precise Data\nEXPRES was developed by Fischer at Yale and installed at the Lowell Discovery Telescope at the Lowell Observatory in Flagstaff, Arizona. It uses the Doppler effect to detect planets based on the motion of their stars. As a planet orbits a star, it exerts a small gravitational effect. The star moves very slightly in response, shifting the frequency of its measured light. Scientists measure that Doppler shift using spectrographs, instruments that separate stars\u2019 light into their component spectra. When the wavelengths of the spectra are bluer than expected, meaning they have shorter wavelengths, the star is being tugged toward us. Redder, or longer, wavelengths indicate movement away from us. These Doppler shifts can be described as changes in a star\u2019s radial velocity, the measured motion of the star away from or toward an observer. Over time, radial velocity measurements can be used to determine properties of orbiting planets that are essential to their characterization, such as mass, orbital period, and distance from the star.\nOther instruments have detected thousands of exoplanets by the starlight they block as they pass between the star and its observer, but the resulting dimming from these transits only yields the radii of each planet. With the radial velocity method, researchers can also calculate how much it weighs. Using both mass and radius measurements allows them to determine the planets\u2019 densities. From this parameter, researchers can infer composition\u2014in short, is it an ice planet or a rocky planet?\nHowever, radial velocity methods may produce data with large uncertainties due to instrumental interference, atmospheric effects, and intrinsic stellar variability, which could smother the near-imperceptible gravitational stellar effects caused by low-mass planets. EXPRES sought unprecedented radial velocity precision of a ten-centimeter-per-second Doppler shift, which is the motion that Earth induces on the sun as it orbits.\u00a0\nWhen the project was first proposed, Fischer faced doubt from many prominent voices in the astronomy community, as they believed the stars\u2019 large velocities would mask those of small planets. But she persevered. Today, EXPRES is able to detect Earth-sized planets at a precision of twenty to thirty centimeters per second, and other spectrographs have followed. \u201cI think the performance of EXPRES emboldened the community to think, \u2018Maybe we can get this precision,\u2019 and it\u2019s definitely worth doing,\u201d Fischer said.\u00a0\nAnd its precision will only keep improving. Newer spectrographs on bigger telescopes may push the precision to five to ten centimeters per second, and upcoming projects involving the James Webb Space Telescope and Habitable Worlds Observatory may provide the data to characterize hundreds more Earth-like planets. \u201cThey\u2019ll be able to block out the light of the star, see the planets sitting around the star, and collect spectra of the atmospheres of those little pale blue dots. So this field will look back someday and laugh at how crude everything is right now,\u201d Fischer said.\n55 Cancri e: A Hell of a Planet\n55 Cancri\u2019s large, gaseous planets were among the first discovered outside our solar system, supporting the existence of multi-planet systems. Its large signal attracted astronomers as the study of exoplanets emerged in the late nineties. Using EXPRES data, Yale astronomers could detect and characterize the smaller planets in the system, uncovering more about planets with ultra-short orbital periods and the formation of their planetary systems, as EXPRES\u2019 higher precision is especially valuable for understanding planetary architectures, or structures, of multi-planet systems.\nKnowing that Earth induces a ten-centimeter-per-second shift on the Sun as it orbits, the EXPRES team modeled a tiny signal of just forty centimeters per second. The velocity signal is a function of the spin and angle of the star and indicates that 55 Cancri e is a small planet that orbits its star along its equator. This signal would have been lost on most other spectrographs, highlighting the necessity of EXPRES\u2019 precision in the search for low-mass planets such as super-Earths.\u00a0\n55 Cancri e\u2019s ultra-close orbit defies traditional models of planetary formation. Astronomers believe that small rocky planets form inside the \u2018snowline\u2019 of protoplanetary disks, which is the region within the dense gas surrounding a newly formed star (like the Sun) that is located near Mars in our Solar System. However, the current location of 55 Cancri e is thought to be too hot for even rocky planet formation. Furthermore, its orbit doesn\u2019t match the other known planets in the system. These clues suggest that the planet formed in a farther, cooler orbit and somehow migrated inward, altering its orbit as it neared the star\u2019s equator.\nSo how did it migrate in? Did 55 Cancri e gently spiral in and then find a parking spot relatively close to the star? Did it get gravitationally kicked in by other planets? Planet migration is a hotly debated topic in astronomical communities, and little is known. But the observation that this planet\u2019s orbital plane is aligned with its stellar equator is consistent with a more gentle inward migration\u2014which could occur as other material, dust, and gas exert a slow, dragging force on the planet\u2014as opposed to a quick gravitational interaction, bringing researchers one step closer to understanding planetary migration and architectures.\n55 Cancri is particularly interesting because researchers already understand much about it, such as its five, tightly-packed orbiting planets, and now they are beginning to understand how planets in the system may have migrated. \u201cOnce we understand that as a sort of general principle, [that] it\u2019s true that planetary systems are dynamically packed, then we can start to extrapolate about what that means for all of the worlds around the four hundred billion stars in the Milky Way galaxy. And then, the probability of life,\u201d Fischer said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/hell-planet/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Plaque Attack",
            "author": "Breanna Brownson",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Plaque-Attack-Sophia-Zhao-386x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Sophia Zhao.\nAlzheimer\u2019s disease (AD) is a progressive and devastating disease that affects more than six million Americans. This neurodegenerative disease is characterized by the deterioration of memory, cognition, and behavior to a greater extent than the memory loss typically associated with aging. AD involves the buildup of abnormal protein in the brain, forming beta-amyloid plaques and tau tangles. These protein aggregates are believed to cause the malfunctioning of neurons and the loss of neural connections that ultimately result in AD.\u00a0\nIn Alzheimer\u2019s, the first areas of the brain to be affected are usually the hippocampus and the entorhinal cortex, both of which are crucial to memory formation. Over time, neuronal death can affect additional parts of the brain, causing brain tissue to shrink. Symptoms of the disease at different stages can vary, ranging from difficulty handling money to not recognizing loved ones or even forgetting how to eat, eventually progressing to total body shutdown. Given the immense toll of Alzheimer\u2019s on both patients and their loved ones, research focused on treating AD has the potential to transform the lives of millions.\nScientists do not fully understand what exactly causes neurodegeneration and cognitive decline. Thus, it is unlikely that a single drug could successfully treat all patients living with Alzheimer\u2019s. Based on current knowledge that the brain produces less acetylcholine\u2014an important brain chemical for memory and thinking\u2014as the disease progresses, several cholinesterase inhibitors have been approved by the US Food and Drug Administration (FDA) to help manage symptoms in patients. These drugs, such as galantamine, rivastigmine, and donepezil, prevent the breakdown of acetylcholine and temporarily improve a patient\u2019s quality of life. These drugs were the only available treatments until recently, in 2021, when the FDA approved the first AD drug\u2014aducanumab\u2014that targeted the underlying cause of the disease.\nWith this development, scientists are now advancing the landscape of Alzheimer\u2019s disease treatment with this new class of drugs that attack the disease at its source rather than just ameliorating symptoms. Recent clinical trials at Yale are studying monoclonal antibodies that target amyloid plaques.\u00a0\nDrug Contender #1: Aducanemab\nAnita Huttner, director of the Yale Alzheimer\u2019s Disease Neuropathology Core, obtained the first pathological evidence substantiating the impact of aducanumab to reduce amyloid plaque neuropathology in an AD patient. Aducanumab is a human antibody, or immunotherapy, that targets the protein beta-amyloid. Currently, aducanumab is sold under the brand name Aduhelm to treat patients with early-stage AD or mild cognitive impairment. The researchers hypothesized that healthy donors with no cognitive effects likely possessed immune systems that could successfully resist AD, so they used a process known as \u2018reverse translational medicine\u2019 to harvest antibodies from healthy donors and turn them into therapeutic antibodies.\u00a0\nIn a recent study published in Acta Neuropathologica, Huttner analyzed an eighty-four-year-old woman with moderate dementia who received thirty-two monthly doses of aducanumab before passing away in hospice. The patient was included in a multicenter trial of aducanumab organized by Huttner\u2019s colleague Christopher van Dyck at the Alzheimer\u2019s Disease Research Unit at Yale, which enrolled patients with early-stage Alzheimer\u2019s disease and tracked their disease progression over time with amyloid positron emission tomography (PET) scans and cognitive tests. To determine the effects of aducanumab, Huttner analyzed the data collected over the course of the patient\u2019s time in the study and from their final autopsy.\u00a0\nHuttner\u2019s autopsy of the patient who recently passed confirmed that aducanumab successfully reduced the size of amyloid plaques in the patient\u2019s brain. \u201cThe results were very surprising,\u201d Huttner said. \u201cThe effects were very significant. The antibody ate away at the fluffy periphery of the amyloid plaques, leaving a dense core behind.\u201d This data corroborated the amyloid PET scans collected over the course of the patient\u2019s treatment and provided substantial evidence supporting the therapeutic effects of aducanumab. As aducanumab has completed a phase three study in early AD patients, Huttner\u2019s studies are a reason for optimism.\u00a0\nHowever, Huttner cautions that there is still much work to do. \u201cKeep in mind that the ultimate goal is not just to remove plaques, but also to prevent cognitive decline,\u201d she said. The autopsy results show that amyloid plaques were decreased in the recently deceased patient, but they do not reveal the mechanism of the antibody\u2019s action or why amyloid plaques lead to cognitive decline. Still, Huttner is enthusiastic about this first stepping stone towards better understanding AD pathology and developing an effective treatment.\u00a0\nDrug Contender #2: Lecanemab\nvan Dyck, director and founder of Yale\u2019s Alzheimer\u2019s Disease Research Unit, has been researching the ability of another drug, lecanemab, to slow cognitive decline in patients with early-stage Alzheimer\u2019s disease. Following the recent publication of the phase III clinical trial results in the New England Journal of Medicine, the FDA granted the treatment accelerated approval.\nLecanemab is an antibody that works by binding to amyloid beta protofibrils, which are small soluble protein strands that come together to form the larger insoluble protein fibers that form harmful beta-amyloid plaques. Lecanemab is thought to clear protofibrils from the brain, slowing the progression of Alzheimer\u2019s disease. By reducing toxic forms of amyloid plaque buildup, lecanemab also decreases the number of abnormal tau tangles in the brain. \u201cThe difference between this and the originally approved drugs [for Alzheimer\u2019s] back in the \u02bc90s is that those were symptomatic therapies,\u201d van Dyck said. \u201cThey were compensating for neurodegeneration rather than slowing it.\u201d\u00a0\nIn a trial consisting of 1,795 participants, van Dyck and other investigators found that lecanemab reduced amyloid plaque in the brains of patients with early-stage AD, as well as led to significantly less cognitive and functional decline than a placebo for the eighteen months that the treatment was taken.\nWhen looking towards the future for lecanemab, van Dyck is excited to research the efficacy of lecanemab when given to participants with elevated brain amyloid who don\u2019t yet have symptoms in the AHEAD Phase III clinical trial funded by the National Institutes of Health. \u201cIt\u2019s all about going earlier,\u201d van Dyck said. \u201cImagine how much time we might save somebody [with Alzheimer\u2019s] with intervention before symptoms begin that then continues for several years of treatment. That\u2019s very much the hope.\u201d\u00a0\nvan Dyck credits a mixture of personal and intellectual motivating factors for his involvement in Alzheimer\u2019s research. \u201cI remember going to my grandparents\u2019 fiftieth wedding anniversary when I was in college. I hadn\u2019t seen them for two or three years, and when I said, \u2018Hey, grandad!\u2019 he responded, \u2018Who are you?\u2019\u201d van Dyck recalled. van Dyck has spent his career studying degenerative diseases like Alzheimer\u2019s from a patient-oriented standpoint. \u201cI trained initially in psychiatry and really gravitated towards older patients with these cognitive disorders that were like a puzzle to diagnose,\u201d van Dyck said. \u201cRight out of residency and fellowship, I founded Yale\u2019s Alzheimer\u2019s Research Unit. At that time, no other researchers were interested in Alzheimer\u2019s disease, so we had to build it from the ground up.\u201d\u00a0\nFast forward to the present, van Dyck is now leading a massive research unit with studies ranging from neuroimaging investigations of AD to therapeutics trials, as has been the case with lecanemab. Pharmaceutical company Eisai is partnering with Biogen Inc. for the manufacture and sale of lecanemab as Leqembi\u2122, a drug delivered via intravenous infusion once every two weeks.\u00a0\nThe Verdict?\nAducanumab and lecanemab are both antibodies targeting toxic aggregated forms of beta-amyloid proteins in the brains of patients with AD. Both exhibit promising results in their ability to reduce amyloid plaques in their clinical trials, but some patients in both drug trials have experienced side effects such as brain swelling and bleeding. Since amyloid protein is also deposited in vessel walls, its clearance by antibodies may compromise the blood-brain barrier, leading to temporary swelling. Sometimes, the swelling can cause small vessels to rupture leading to microhemorrhages in the brain. Larger hemorrhages are rare and unusual, and considering the fact that there are no existing treatments for patients with AD that actively target the disease itself rather than just managing symptoms, the benefit-to-risk ratio may be favorable.\nvan Dyck emphasized that\u2014based on the success of these trials\u2014both aducanumab and particularly lecanemab are currently being used as treatments for AD on a limited basis by patients paying out of pocket or those in patient assistance programs. \u201cMost experts view lecanemab as the first unequivocally positive disease-modifying therapy for AD,\u201d van Dyck said. He described lecanemab\u2019s development as relatively smooth, contrasting it against that of aducanamab. \u201cIts trials were fraught with complications and unfortunate circumstances,\u201d van Dyck said. These issues included having to adjust dosages mid-study and having to prematurely halt the trials for presumed futility.\nAlthough the last decade of AD research has largely focused on the amyloid beta protein, the disease is much more complicated than plaques accumulating in the brain\u2014there are many types of dementia and causes of cognitive decline. \u201cThe amyloid story is just one aspect of understanding Alzheimer\u2019s disease,\u201d Huttner said. It remains uncertain whether focusing on amyloid beta plaques is the best trajectory due to the complexity of the disease. Regardless, we are at the point where we can start analyzing the effects of aducanumab and lecanemab. The information from these trials has the potential to inform a new class of drugs and a new way of understanding Alzheimer\u2019s disease pathology.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/plaque-attack/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Elephant Whisperers",
            "author": "Victor Nguyen",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Elephant_Family-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay.\nIn a village in Tamil Nadu, the southernmost state in India, a marriage ceremony is taking place. Elderly elephant caretakers Bomman and Bellie revel in their newly formed union wearing vibrant, ceremonial wreaths. But the most extraordinary sight is their groomsman and bridesmaid: elephants Raghu and Ammu who celebrate their marriage alongside them. The recently released Netflix documentary, The Elephant Whisperers, explores the interdependence between elephants and humans and gives insight into the possibilities of cross-species connections.\u00a0\nIn the film, Bomman and Bellie first meet when the Indian forestry department assigns them to the same elephant sanctuary. Their connection flourishes through their combined efforts to take care of Raghu and Ammu, a pair of injured elephants. Through an arduous recovery process, the pair nurse Raghu and Ammu back to health. Stories similar to Raghu and Ammu are becoming more common as elephants and humans come into close contact due to crop raiding, which occurs when elephants eat crops grown by farmers. According to a review article published in Frontiers in Ecology and Evolution in 2019, four hundred people and one hundred elephants are killed in these incidents each year, which is why sanctuaries like the one run by Bellie and Bomman are pivotal in creating separate safe spaces for both parties.\u00a0\nBeyond just rehabilitating displaced elephants, the sanctuary also serves as a place of healing and hope for Bellie and Bomman. Raghu reminds Bellie of her daughter who passed away; when Bellie mourns her loss, Raghu wipes her tears with his trunk. For Bomman, caring for Raghu and Ammu connects him to his rich ancestral heritage, since Bomman\u2019s father and grandfather were elephant caregivers. These heartfelt anecdotes reveal how it\u2019s possible to foster strong familial ties through human-animal interactions.\nThough this story may seem idealistic, it is important to acknowledge where the lines between narrative and reality lie. Critics of the documentary assert that the practices portrayed in the film are not compliant with wildlife rehabilitation standards. They argue that true rehabilitation requires animals to be reintroduced to nature after recovery, rather than being incorporated into human practices. According to the Asian Elephant Specialist Group, effective recovery is an intensive process consisting of three steps: planning, rehabilitation, and post-release monitoring. During rehabilitation, caretakers focus on the elephants\u2019 ability to reintegrate, and after their release into the wild, the elephants are monitored to ensure successful assimilation. While the recovery of Raghu and Ammu may not have followed these standards, it must be acknowledged that without the help of Bellie and Bomman, they would have suffered more.With its 2023 Oscar nomination, The Elephant Whisperers brings to light the importance of human interactions with nature and how this relationship can be mutually beneficial when approached in a mindful manner. This dialogue is vital in a world where human habitation increasingly crosses over into animal territory. After all, how we interact with our environment and animal neighbors is a choice that impacts us all.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/the-elephant-whisperers/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Can You Take the Heat?",
            "author": "Matthew Blair",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wong_2-500x344.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Jenny Wong.\nExtreme heat is something we feel acutely. Not to be confused with a sunny day, extreme heat describes those times when it is insufferably hot outside, when the heat sits heavy and stale, and the mere task of existing outside becomes a feat of endurance. As the earth warms, extreme heat events become all the more intense. Without the proper resources, this heat can be dangerous, and, in some cases, deadly.\nAn individual\u2019s response to extreme heat is impacted by various factors, ranging from socioeconomic background to the specific street someone lives on. As such, some populations\u2014especially historically marginalized groups\u2014are more at risk in events of extreme heat. Mitchell Manware and fellow researchers at the Yale School of Public Health were left unsatisfied by prior attempts to quantify heat vulnerability, noting that they failed to create a holistic image of one\u2019s actual risk. Thus, they created a new heat vulnerability index (HVI), which builds on past systems, but, importantly, also takes into account one\u2019s race, ethnicity, and broader socioeconomic background.\nThis improved HVI covers a complex amalgamation of variables, all aimed at more fully capturing not only who is most vulnerable to heat, but also why someone is vulnerable in the first place. \u201cThe HVI combines many different variables, each having evidence to support its association with heat-related outcomes,\u201d said Manware, the first author of the research paper in which the HVI was presented. These variables include environmental factors such as the average summertime temperature and the percentage of land covered by non-green space, as well as social factors like the percentage of the population that is Hispanic or Latino, non-Hispanic African American or Black, elderly, unemployed, or English-proficient. As a result, this index is comprehensive in a way that a heat index has never been before.\u00a0\nOn a scale from ten to twenty-six, the HVI creates a standard of comparison for heat vulnerability, quantitatively capturing the unique vulnerability of census tracts across the country. \u201cThe HVI allows one to compare, say, New York City to Miami by including such a wide, diverse set of variables,\u201d Manware said.\nBy creating this standard of comparison\u2014using a range of variables considering more than one\u2019s geographic location\u2014Manware and his colleagues have created a tool that shines a critical light on systemic, environmental racism stemming from America\u2019s past. Environmental racism in the United States, tied to a long history of redlining and current disparities in public services, is the idea that different racial and ethnic groups are disproportionately exposed to various environmental hazards\u2014identifying where these inequities are most prominent is an integral use of this index.\u00a0\n\u201cIndividuals across the United States were assigned a heat vulnerability index score based on which census tract they lived in, allowing us to calculate an HVI average for eight race and ethnicity groups,\u201d Manware said. \u201cThe non-Hispanic African American and Hispanic or Latino groups had the two highest average HVI scores, showing, again, in the whole United States, not just in one city or in one census tract, that these communities of color are disproportionately vulnerable to heat.\u201d\nDeveloping this index was about not only identifying the problem, but also providing a starting point to inform and motivate climate activism. \u201cCreating a website that was publicly available, and interactive, is a way to try and translate research into practice,\u201d Manware said. \u201cWe didn\u2019t want this paper just to sit and exist in some database: we wanted it to be seen and used by elected officials and regular citizens alike.\u201d\u00a0\nAs the earth continues to warm, taking steps to combat climate change and mitigate its effects will become increasingly vital. The HVI is a remarkable tool that lays the groundwork for the equitable implementation of climate change policy. \u201cGiven the scale and the inevitability of climate change, it will take a collective effort to do what we can to mitigate its effects and adapt to the changes that have already happened,\u201d Manware said. It will indeed take a collective effort to address climate change, and it can only be the hope that as climate change policy is implemented, there is a concern for the equitable distribution of resources to offset the history of environmental inequity in the United States.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/can-you-take-the-heat/",
            "captions": [
                "OLYMPUS DIGITAL CAMERA"
            ]
        },
        {
            "title": "Climate Checkmate",
            "author": "Kelly Chen",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/climate-checkmate-scaled-e1681763553450-500x195.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Hannah Shi.\u00a0\nWhen the World Chess Championships occur, everything is accounted for\u2014the weight of the chess pieces, the matte of the chess board, the indoor noise levels, the number of arbiters and broadcasters\u2014ensuring that the best chess players in the world can play at the top of their game. But scientists have discovered a confounding factor that competitions don\u2019t account for, something that people can\u2019t even see: air quality. Many studies have already been performed to corroborate the negative impacts of outdoor air pollution on the human mind, but new research suggests that the buildings we spend our days in may not actually keep out these harmful particles. Steffen K\u00fcnn and Nico Pestel from Maastricht University as well as Juan Palacios, Head of Research at MIT\u2019s Sustainable Urbanization Lab, have studied just how badly indoor air pollution can hinder strategic decision-making by looking at the game of chess. Chess is a game of constant strategic decision-making where all players are gathered in one location, making it an ideal way to explore the impacts of air pollution on people\u2019s cognitive abilities.\nThe data included over thirty thousand chess moves from three different chess tournaments in Germany from 2017 to 2019. Players in the tournament were given a total of 110 minutes to make the first forty moves, with additional time for moves past the fortieth move. Air quality data measured the concentration of PM2.5, or fine particulate matter with a diameter smaller than 2.5 micrometers, from three sensors installed in the tournament venue. PM2.5 can enter the lungs and bloodstream when inhaled, leading to harmful effects on the body.\nEach chess move was analyzed independently by an artificial intelligence chess engine for optimality and errors based on the configuration of the chessboard. Overall, it was found that when chess players are exposed to high levels of air pollution, they make more erroneous moves. Other confounding variables such as time of day, temperature, traffic jams, indoor carbon dioxide levels, and the impact of the opponent\u2019s errors on the observed player were explored to ensure that there were no other factors that could have caused these effects.\nThe researchers also found that air pollution has an increased effect on chess players when they are under stricter time pressure. In an evenly matched game, the last moves they make become the most crucial for the players, but also the most time-intensive. \u201cAir pollution hits the hardest on cognition when good moves are needed the most,\u201d Palacios said. Strategic decision-making is highly utilized in chess, but also in everyday life and careers. From managers to workers to students where day-to-day work requires intense cognitive thinking and decision-making, it\u2019s concerning that their decisions could be negatively influenced by environmental factors, especially when these decisions could result in long-term consequences.\nThis study is one of the first to explore indoor air quality and the effects it has on cognitive thinking, and there is great potential for future research in this area. \u201cWe are still in the infancy of understanding what the costs are of indoor air problems,\u201d Palacios said. A federal report done by the Governmental Accountability Office found that forty-one percent of public school districts in the United States need to update or replace the heating, ventilation, and air conditioning (HVAC) systems in over half of their schools. If skilled chess players are led to erroneous decisions because of indoor air pollution, we can only imagine how poorly ventilated education buildings are affecting the learning of students worldwide.\u00a0\nUnsurprisingly, worsening outdoor air pollution is correlated with worsening indoor air pollution. More research is necessary to examine how we can construct and upgrade buildings to protect us from harmful particulate matter. \u201c[We need] better understanding of the indoor environmental conditions on humans and [we need to use this understanding] to protect us against climate change and environmental hazards in the United States and beyond,\u201d Palacios said. We could be getting close to the climate endgame\u2014hopefully, a victorious checkmate is still in sight.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/climate-checkmate/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Tiny Transformers",
            "author": "Lee Ngatia Muita",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Tiny_Transformers_YSM_Illustration-Court-Johnson-e1681762125834-400x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Court Johnson.\nFans of the cult classic film franchise Terminator remember the iconic scene where the evil robot T-1000 easily passes through a metal grate by partially turning into liquid. Well, machines can do that now, and they don\u2019t have to be evil! Researchers from Sun Yat-Sen University, The Chinese University of Hong Kong, and Carnegie Mellon University have created a robot that can turn from solid into liquid and vice versa, at will.\u00a0\nThe scientists drew inspiration for this innovation from the most mysterious of places: the ocean. The unassuming sea cucumber has a remarkable ability to rapidly change its stiffness to adapt to its environment. To do so, the animal internally manipulates the millions of tiny fibers embedded within its tissues to link together in a tight mesh for hardening, and unlink for softening.\nThe sea cucumber employs this tactic in many ways, including stiffening to navigate hostile environments that would otherwise pierce and tear soft tissue, and softening to move through obstacles and fit into efficient hiding spots. Scientists were especially inspired by the sea cucumber\u2019s ability to fit through tight spaces and sought to develop this process for use in machinery.\nIn order to replicate this ability, scientists used magnetoactive liquid-solid phase transitional matter, which is a magnetic substance that can quickly switch between liquid and solid states. Since the process of changing states between solid and liquid is tied to temperature, the scientists had to find a metal that melted and froze at relatively warm temperatures. They chose gallium, which is a nonmagnetic metal that melts at 29.8 degrees Celsius. This means that it is a solid at room temperature and exhibits the strength typical of a solid metal, but it melts when held in your hand for a while. Once they had fast-transition matter, they had to turn it into a responsive machine.\nThis next step was done by embedding ferromagnetic neodymium-iron-boron microparticles into the internal structure of gallium. These micromagnets were held in fixed positions by the strong solid matrix of gallium so they all synchronized appropriately with the magnetic field. This process produced a gallium alloy that could respond to magnetic fields and enabled the researchers to control its movement. These magnets and the physical properties of gallium contribute to most of the functionality of the shape-shifting robots.\nIn its solid state, the shape-shifting machine is very responsive to magnets and can easily be controlled by manipulating the magnetic field around it. These properties allow the machine to move through a given path, jump over obstacles and move up to speeds of 1.5 meters per second. When the machine encounters a space too narrow for a solid, it turns into a liquid through internal heating that melts the gallium.\nThis heating is achieved by manipulating the magnetic field around the machine to cause its micromagnets to form a specific pattern that induces a current within the metal. This current encounters resistance as it flows through the robot, causing it to produce enough heat and raising the temperature to about thirty-five degrees Celsius, which is above the melting point of gallium. This process, known as electromagnetic induction, enabled scientists to dictate when and where the material changed from solid to liquid.\nAs a liquid, the properties of the alloy notably change. It no longer responds as well to magnets because the solid matrix holding and aligning the micromagnets falls apart during melting. As a result, the micro-magnets respond independently to the magnetic field and to each other, creating many shifting incohesive magnetic alignments within the material, reducing the complexity of the material\u2019s mobility. Nonetheless, while it loses its ability to jump, the liquid still responds enough to magnets that it can split into smaller blobs, elongate, reshape itself, and merge from smaller parts, just like water.\nIn order to turn back into a solid, the matter simply cools to room temperature and solidifies.\u00a0 You may wonder why scientists can\u2019t cool the material the same way they heated it up, but cooling using an electric current is difficult unless special thermoelectric materials are used, which would interfere with the functionality of the liquid-solid machine. Nonetheless, senior author and mechanical engineering professor Carmel Majidi of Carnegie Mellon University is working with another group to implement similar functionality, so they may eventually be able to dictate when it solidifies as well.\nA shape-shifting machine sounds great for escaping through the bars of a prison cell, but these malleable machines have tangible real-life applications as well. \u201cThe medical sector has the greatest potential to benefit from applying this technology,\u201d Majidi said. The scientists demonstrated these applications by using the machine to remove a foreign object from a model stomach. In real life, a person would swallow the machine as a pill, and it would be guided to the foreign object using a magnet. At this point, it would change into a liquid and envelop the object in a process similar to a white blood cell consuming harmful cells. It would then solidify to trap the object and carry it out under the guidance of a magnetic field. Since the body is warm, scientists would add compatible metals such as bismuth or iron to the alloy in order to raise the melting point above the average body temperature.\u00a0\nThe machine could also be used for drug delivery: it could be inserted into the body as a solid containing the medicine to be delivered and guided to a specific location. Once there, it would melt and release the medicine before solidifying and exiting.\nFurthermore, the machine could be used in the assembly of circuits by carrying tiny components to specific points in the circuit, changing to liquid around the connectors, and then solidifying to form a firm weld that conducts electricity through the component. In addition, the material can act as a universal screw for construction by pouring the liquid machine into a screw hole and using a magnet to guide and fit it snugly into every crevice, before solidifying and fixing itself as the perfect screw. Moreover, the machines could be used in the remote repair of most engineering structures. Imagine a future where you need only drop a pin-shaped machine inside a malfunctioning computer to allow a hardware specialist working from home to diagnose and repair your device in mere moments.\u00a0\nThese applications are possible because the machine, in its solid state, is designed to carry up to ten thousand times its own weight, which was demonstrated as the machine lifted and supported a two-hundred-gram weight. The ability to bear this weight is more than sufficient when applied to the minuscule scale that the machines are expected to operate on, and more weight can be supported by using swarms of these machines to carry heavier loads through weight distribution.\n\u201cThe materials required to produce a machine are about as costly as a kitchen magnet,\u201d Majidi said. This affordability has the potential of reducing surgery costs when manufactured and applied en masse.\u00a0\nWith more research being conducted focusing on the development of nanomachines, we can expect even more interesting, quality-of-life improvements through inventions like this one.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/tiny-transformers/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Counterpoint: Does the \u2018Love Hormone\u2019 Oxytocin Really Lead to True Love?",
            "author": "Lea Papa",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Candy_Hearts-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of StockSnap.\nDerived from the Greek phrase for \u2018quick birth,\u2019 oxytocin\u2014initially discovered as a \u2018contraction hormone\u2019 in 1909 by physiologist Sir Henry H. Dale\u2014has historically been touted as a miracle pregnancy hormone due to its efficient labor-inducing abilities. Produced in the hypothalamus and released into the bloodstream by the pituitary gland, oxytocin aids in both childbirth and postpartum lactation, and is commonly used by obstetricians and gynecologists.\nIn popular culture, however, oxytocin has been viewed quite differently. Through the influence of marketing strategies, oxytocin has become associated with the development of love. Commonly referred to as the \u2018love hormone\u2019 or \u2018liquid trust,\u2019 oxytocin products are sold by numerous companies that claim to have benefits for consumers\u2019 outward trustworthiness and ability to form lasting, loving relationships. These claims were founded on numerous scientific studies conducted through the 1990s on prairie voles\u2014a species of rodent known for their lifelong monogamous mating patterns. These studies suggested that the hormone played a significant role in the development of their mating relationships and parental behaviors.\nLater studies from the 2000s and early 2010s also showed that oxytocin levels increase when people hug, experience gentle touch, or engage in consensual sexual interactions, while cortisol levels, associated with stress, decrease. Validated by these studies, oxytocin\u2019s supposedly unmatched ability to promote love and bonding between people has been the main focus of \u2018love hormone\u2019 companies over the last twenty years. However, a recent study by Kristen Berendzen, Ruchira Sharma, and their colleagues at the University of California, San Francisco has uncovered inaccuracies and possible exaggerations in our understanding of this hormone.\nIn their paper published in Neuron in January, the researchers revealed that oxytocin may not be the determining factor in yielding mating and parental relationships in prairie voles. The researchers used CRISPR gene targeting technology, a gene editing tool capable of manipulating precise DNA sequences, to produce oxytocin receptor (Oxtr)-null prairie voles. These Oxtr null voles lacked function in their oxytocin receptors and were therefore unable to support oxytocin signaling. When these Oxtr null prairie voles were tested against control Oxtr prairie voles with intact oxytocin signaling abilities, the scientists found that the Oxtr null voles were still able to develop certain behaviors that previous studies had suggested were the result of oxytocin signaling in the brain.\nUnexpectedly, even without the presence of oxytocin signaling, the Oxtr null prairie voles formed social attachments, mated normally, and presented typical parental behaviors. All of these behaviors were shown to have developed to the level\u2014or mostly to the level, in a few cases\u2014of those in control voles. Both male and female voles made mating connections and showed a preference for their mate over animals of the opposite sex. Female voles gave birth to healthy babies and nursed their pups to weaning, and parent voles displayed a similar intensive care for their children as regular voles did.\nThe study also revealed some variation in prairie vole behavior which may be attributed to the changes in oxytocin signaling induced by the researchers, even though the social behavior observed in Oxtr and Oxtr null voles was mostly the same. The most notable of these differences was that Oxtr null voles showed less aggression than regular voles towards voles of the opposite sex who were not their mate. In addition, Oxtr null female voles were found to produce litters with fewer surviving pups at weaning. These observations suggested that the importance of oxytocin in social attachment is much less than was previously believed.\nTogether, these findings indicate that oxytocin may play a different, more complex role in bonding, parenting, and social interaction than what was once believed. The groundbreaking results of this study, however, are not sufficient to fully understand the nuances of oxytocin and its properties. Subsequent oxytocin studies in a variety of species and populations will be necessary to decode this new mystery of the famous \u2018love hormone.\u2019 In any case, companies profiting from oxytocin product sales may have to find a new way to play on their consumers\u2019 relationship insecurities\u2014one that doesn\u2019t involve their star hormone.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/counterpoint-does-the-love-hormone-oxytocin-really-lead-to-true-love/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Can Water Freeze in a Liquid State?",
            "author": "Ignacio Ruiz-Sanchez",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Ball_Mill-500x344.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Nature (Jonathan O\u2019Callaghan).\nThe longstanding debate over which type of ice\u2014cubed or crushed\u2014is best to chill drinks is still largely undecided, but why are we limited to only two options?\u00a0\nIn a recent Science paper, researchers at the University College London (UCL) recently discovered medium-density amorphous ice (MDA), a form of ice with the same density as liquid water but that presents a glass-like appearance. Normally, when water freezes, the molecules crystallize into a hexagonal, solid structure, the most abundant form found on Earth. Since the early twentieth century, scientists have known about low-density and high-density amorphous ice which both contain water molecules in a disordered arrangement. The former is created when water vapor freezes on a surface colder than -150 degrees Celsius, while the latter develops when normal ice is placed under high pressure at similar temperatures. Until now, however, medium-density structures were unknown.\nTo produce MDA, the researchers used a ball mill tool to grind down standard crystallized ice. They placed the ice in a container that shook back and forth twenty times per second, exerting a pressure high enough to synthesize the unique structure. X-ray diffraction, which measures the crystallinity of solid structures as their electrons scatter X-rays, revealed that MDA had the same haphazard structure and density as liquid water. They discovered that this liquid was analogous to the water found in moons in our solar system, such as Jupiter\u2019s Europa and Saturn\u2019s Enceladus. Staying curious about the universe\u2019s complicated relationship with water might ultimately unearth the possibility of life outside our little dome.\n\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/qa-can-water-freeze-in-a-liquid-state/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Undergraduate Profile: Grayson Wagner",
            "author": "Elise Wilkins",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Havlat.-6-289x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Daniel Havlat.\nGrayson Wagner (YC \u201923) knew from a young age that she wanted to be an engineer. She grew up admiring her father\u2019s work as an industrial engineer, and by her junior year of high school, she had decided on biomedical engineering. Wary that many students switch majors during college, Wagner wasn\u2019t sure if she would stick with it. However, she has delved deeply into the realm of biomedical engineering, while adding a second major in mechanical engineering.\nIn 2020, Grayson founded Yale\u2019s inaugural e-NABLE chapter\u2014a volunteer group that uses 3D printing to construct upper-limb prostheses for those in need. The e-NABLE club allows Wagner to use her two majors for a humanitarian purpose. She established the chapter with the help of Vincent Wilczynski, the Deputy Dean of the School of Engineering and Applied Sciences. She originally learned about the organization during her senior year of high school and wanted to bring it to Yale. \u201cI\u2019ve shadowed at a lot of clinics, [and] I\u2019ve seen a lot of patients. I\u2019ve gotten that experience, and it\u2019s a really interesting field. A lot of people don\u2019t know about [prosthetics], about the fabrication, the assembly, and the difference it can make for people,\u201d Wagner said.\nThe e-NABLE club began work soon after its founding. The group received a request from a father hoping for a prosthetic arm that his daughter, Emily, could use to hold her bow while playing the cello. When starting projects, the group consults a database that contains about twenty basic prosthetic designs, including ones for upper-limb prostheses beginning at the wrist, elbow, shoulder, and even fingers. The team can then download the design that is best suited for their goal and use computer-aided design software, such as SolidWorks or Onshape, to upload the design and make their changes. Once satisfied, the prototype can be 3D printed and assembled.\u00a0\nA notable aspect of designing prostheses in this manner is that the files for each design are transferable. Wagner explained that while Emily was filming a commercial in Arizona, her prosthesis broke mid-shoot, but e-NABLE design head Zubin Kremer Guha (YC \u201824) was able to send the files to Arizona where the device could be reprinted. Wagner loved working with Guha and the other design head for the project, Audrey Whitmer (YC \u201823). \u201cIt was exciting seeing two different passionate engineers come together and create one cohesive device for Emily. They did a fantastic job,\u201d Wagner said.\nThe prostheses made by e-NABLE are not intended to replace traditional prostheses since the volunteers are not certified prosthetists or orthotists. However, as Emily\u2019s story shows, there are many benefits to making specialized prosthetics that are not meant for everyday use. \u201cYou can make these really specific adaptive features that are harder to do and less accessible in a clinical setting,\u201d Wagner said.\nWagner\u2019s passion for biomedical engineering extends to her research with John Geibel, a professor of cellular and molecular physiology and vice chairman of the Department of Surgery at Yale. With Geibel, Wagner works on bioprinting, which uses similar techniques to 3D printing but relies on biomaterials such as living cells to build complex structures. Bioprinting has the potential to greatly impact the future of manufacturing bioengineered tissues and organs. Wagner, who has many interests within this field, published a review paper in Pharmaceutics in December 2022 on the use of hydrogels\u2014networks of polymer chains with great capacity to hold water\u2014in bioprinting, and she has recently submitted another review about bioprinting\u2019s applications to bone tissue.\u00a0\nWagner further shares her love for engineering as the president of Tau Beta Pi, the engineering honor society. She also enjoys connecting with friends outside of the engineering sphere as a member of the Yale Climbing Team.\u00a0For the rest of the semester, Wagner plans to savor her last moments with her biomedical engineering class, and she looks forward to continuing her work in tissue engineering and medical device design after graduation. \u201cI\u2019m excited to move on to my next phase, working with companies that are taking bioprinting and tissue engineering from the bench to the bedside,\u201d Wagner said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/undergraduate-profile-grayson-wagner/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Turning Back the Clock",
            "author": "Risha Chakraborty",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Turning-Back-the-Clock_-Using-Genetics-to-Reverse-Aging-Kara-Tao-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Kara Tao.\nHumanity has been obsessed with ending mortality for millennia. From famous historical conquests to find the Fountain of Youth to the contemporary race to find medicines combating heart disease, cancers, and neurodegeneration, scientists and philosophers alike are driven by the motivation to turn back the clock. Aging is a fundamental, natural process of life\u2014all living organisms grow old and eventually die, and since the advent of molecular biology, scientists have attempted to figure out why.\u00a0\nProfessor David Sinclair of Harvard University is a pioneer in the field of aging. From his discovery of the anti-aging molecule resveratrol to his successful restoration of eyesight for old and glaucomatous mice, Sinclair and his lab are making notable leaps in understanding and even reversing aging. One of the members of Sinclair\u2019s team, postdoctoral fellow Jae-Hyun Yang, spearheaded an article published in Cell early this year studying one of the lab\u2019s greatest contributions to the field of aging. They suggested that a loss of epigenetic information\u2014changes in the chemical modification and packaging of our DNA and proteins within the nucleus\u2014causes aging. Yang identified possible molecular mechanisms of aging and accordingly, a possible target for therapies that could one day reverse aging.\u00a0\nPrior to joining Sinclair\u2019s lab, Yang was interested in studying epigenetic modifications that activated muscle genes during mouse embryonic cell differentiation, the process in which naive cells acquire a specific identity, as in whether they should be an eye cell, or a liver cell, or a muscle cell. Upon learning more about the fields of epigenetics and cell fate decision while obtaining\u00a0 his PhD, he was drawn to combining his interests and harnessing epigenetic mechanisms to study the process of aging. Differentiation is characterized by the accumulation of epigenetic information, while aging is characterized by the opposite. The team\u2019s paper marks the success of a decade-long project to prove that loss of cell-specific epigenetic information contributes to aging.\n\u201cThe difference between the epigenome and genome is similar to that of the software and hardware of a computer,\u201d Yang said. Ultimately, the computer hardware\u2014the amount of storage it has, its processing ability, its graphics elements\u2014is similar to the genome of an organism: at its core, the organism is determined by the sequence of nucleotides in its DNA. However, the computer can\u2019t actually do anything useful without software\u2014applications that make the computer function the way it does. This is similar to the epigenome of an organism\u2014by turning certain genes on and off at different points in their lifetime, epigenetic changes are capable of giving individual cells their identity, allowing them to become different types of cells.\u00a0\nWhen DNA is damaged, the process of preserving the lost genetic information causes the loss of the original epigenetic information. Yang hypothesized that the accumulation of this epigenetic information loss is what ultimately constitutes aging.\u00a0\nTo test this hypothesis, Yang developed a genetically-altered mouse called ICE (Inducible\nChanges to the Epigenome), to which epigenetic information loss could be introduced without genetic information loss. After inducing epigenetic information loss in ICE mice, Yang observed hallmarks of aging, including an increased frailty index (constituting body weight, grip strength, mobility, vision, and hearing), reduced bone density, damage to kidney cells, loss of melanocyte stem cells in skin contributing to fur graying, cognitive decline, and impaired muscle function. He found that many developmental processes that determine cell identity were altered in ICE-induced cells and mice. Regions of DNA that were far apart and originally should not have been able to impact each other did in fact bind and communicate, which caused cells to lose their identity. Specifically, he showed that muscle cells tended to behave more like immune cells after ICE treatment.\u00a0\nNext, Yang wanted to test if he could reverse the physiological effects he saw in his ICE mice. Knowing that gene-expression factors called the Yamanaka factors\u2014Oct4, Sox2, Klf4, and Myc (OSKM)\u2014alleviate the symptoms of aging mice, Yang wondered if treating his induced ICE mice with the Yamanaka factors, except Myc, would reverse features of aging. In fact, he found that treating cells or mice with OSK restored age-associated gene expression, epigenetic marks, and turned back the epigenetic aging clock. Yang hypothesized that there may actually be some copy of the epigenome in the cell that can be restored upon treatment with Yamanaka factors to reverse aging.\u00a0\n\u201cIt\u2019s hard to target aging, as a treatment, because aging is not defined as a disease. But [Yamanaka factors] can be used for multiple different age-associated diseases. Currently, we can target different tissues and other projects in the lab are targeting eyes, muscles, and kidneys,\u201d Yang said. \u201cI hope we can eventually target aging as a whole, but for now we are targeting specific diseases and tissues. I\u2019m interested in finding safer and cheaper methods that could replace [Yamanaka factors], so we can have the same effect without using gene therapy.\u201d\nMoving forward, Yang is interested in exploring some of the specific epigenetic factors that may be relocated after DNA damage, causing DNA cross-talk issues and contributing to epigenetic information loss. Yang is eager to find ways to make these proteins function more faithfully with the goal of preventing the aberrant cross-talk between far-apart DNA and the loss of cell specificity contributing to the progression of aging.\u00a0\nYang and his fellow researchers in the Sinclair lab have their work cut out for them. From identifying single cell\u2014as opposed to bulk tissue\u2014epigenetic changes to testing the results of this paper on human cells, tissues, and organoids, their work aims to determine the most crucial factors contributing to the universal process of aging, enabling us to gain a deeper understanding of why, despite our differences, humanity is united in mortality. With their advancements directly contributing to possible treatments for all the diseases whose greatest risk factor is aging, we are inching closer than ever before toward a world in which we may indeed live longer and healthier lives.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/turning-back-the-clock/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Catching Lightning",
            "author": "Ximena Leyva Peralta",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Catching-Lightning_-Rapid-Fire-Lasers-Divert-Lightning-Strikes-Kara-Tao-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Kara Tao.\nFor the first time, scientists have successfully used lasers to divert lightning in real-world experiments. During the summer of 2021, a team of around twenty-five scientists used a rapid-firing laser to redirect lightning, moving it more than fifty meters. Their results will pave the way toward improved lightning protection for airports, launchpads, and other large infrastructures.\nDuring storms, charges accumulate in clouds. When this build-up becomes too large, there is a rapid discharge of electricity, called lightning. Classical metal Franklin lightning rods provide a preferential channel for the discharge to reach the ground. This way, they guide lightning away from houses and small structures. \u201cThey protect roughly an area with a radius corresponding to their length,\u201d said Aur\u00e9lien Houard, a researcher at \u00c9cole Polytechnique in France and the leading author of the Nature paper detailing the team\u2019s results. However, Franklin rods rarely protect areas with a radius greater than thirty meters. \u201cWhat we want with the laser is to increase the range of protection,\u201d Houard said.\nMuch like a Franklin rod, lasers create a preferential channel for lightning. The difference is that they do so using air rather than metal. When a high-intensity laser is fired rapidly enough, it heats up the air in its path and transforms it into plasma by turning the gas particles into charges. This phenomenon creates a tunnel with very high conductivity through which lightning can travel. The biggest advantage is that lasers can reach higher in the sky than any metal rod and can point in multiple directions.\u00a0\nGuiding lightning with lasers was first achieved in the lab over twenty years ago. But diverting lightning by two meters in a controlled laboratory setting is child\u2019s play compared to doing it over tens of meters in an unpredictable storm. Calculations and simulations showed that only rapid-firing lasers would reproduce the lab results in the real world. \u201cAlthough it worked on paper, we had to convince someone to build that laser up for us,\u201d said Jean-Pierre Wolf, professor of physics at the University of Geneva. \u201cWhen I was at Yale [on sabbatical] in 2000, I was already talking about lightning control with lasers. It\u2019s been a very long-term project.\u201d It was only six years ago that new laser technology and funding sources came together to create a laser capable of firing at the necessary one thousand pulses per second at an intensity of roughly one terawatt, or one million million watts.\nFrench, Swiss, and German scientists came together in a highly collaborative research team determined to show the capabilities of the laser. They chose a telecoms tower at the top of S\u00e4ntis Mountain in Switzerland, a location with a high rate of lightning strikes, equipped with multiple sensors for accurate lightning measurements. During six hours of operating the laser in thunderstorms, they recorded four successful lightning redirection events. Out of these, only one happened in good enough conditions to be recorded by high-speed cameras. The footage showed that the lightning strike followed the plasma conductive channel created by the laser over a fifty-meter distance.\u00a0\nWorking with lightning in the field is challenging because of its unpredictability. On top of that, the research team couldn\u2019t use the laser at all times. \u201cWhen the air traffic was very heavy, in the morning, for instance, we weren\u2019t allowed to shoot,\u201d Wolf said. \u201cWe were lucky to have four events where the laser was on, and everything was operating correctly.\u201d Ideally, the research team would have tested the different wavelengths the laser can emit: infrared, visible green, or ultraviolet. But due to their time constraints, the team only tested infrared radiation.\nUltraviolet light ionizes the air more easily but does not travel as well through the air, while infrared radiation has the opposite characteristics. Both Houard and Wolf are optimistic that green light would be the best option. \u201cWe would also need to better characterize the ability of the plasma to trigger and guide lightning. All of these parameters are not very well known,\u201d Houard said. After all, this project was only a demonstration experiment. \u201cWe would need much more experimental characterization before we can really claim that we can protect a large area with this [system].\u201d\nDespite the promise of increased lightning protection, it could be anywhere between five and fifteen years before this project comes to fruition. Scientists are essential for these first steps of characterization and optimization, but it will be an engineering challenge to create compact and cost-effective laser-based technology for lightning protection in the future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/catching-lightning/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Green Peas in Space",
            "author": "Robin Tsai",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Green-Peas-in-Space-Hannah-Barsouk-500x281.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Hannah Barsouk.\nYou gaze up at the sky on a clear night. The stars, too numerous to count, appear as nothing more than little specks. Together, however, they keep the universe lit up like fireflies in the dark. For astronomers, these stars and galaxies serve as lampposts throughout the universe\u2019s history and evolution. But about thirteen billion years in the past, there was a \u201cdark age\u201d without visible galaxies, stars, or any kind of light, which has puzzled astronomers. Scientists aren\u2019t sure how reionization\u2014the epoch of high-energy radiation that ended this cosmic dark age\u2014occurred. Recently however, two astronomers, professors James Rhoads and Sangeeta Malhotra of NASA\u2019s Goddard Space Flight Center, presented findings that could advance our understanding of this dark era.\nBefore we can talk about reionization, however, we must take a few steps back to the Big Bang, when the universe began, then stretched and continued to grow as large as it is right now. Immediately following the Big Bang was an era of pure brightness: a hot soup of electrons, quarks, and photons. When the universe expanded enough for this soup to cool down, hydrogen atoms formed from the protons and electrons in an era known as the recombination epoch. This thick, dense fog of neutral hydrogen continuously absorbed light within it, thus ushering in the universe\u2019s dark age.\nThen, something amazing happened. \u201cOne might naively expect for the neutral hydrogen to just sit there, but sometime in the late 60s [we discovered] that the gas between galaxies is ionized today, and has been for at least the last 10 billion years,\u201d Rhoads said. The neutral hydrogen did not stay neutral forever: it reionized. The question is how, when, and by what?\nCosmic objects\u2014such as galaxies, stars, or clouds\u2014send out a spectrum of wavelengths, from infrared light, to visible light that brightens up the night sky, to ionizing ultraviolet and X-rays. These spectra are largely determined by the objects\u2019 chemical compositions and their corresponding emission lines. As such, these spectra are a \u201csignature\u201d of these cosmic objects, allowing them to be classified based on their light\u2019s properties. Add a bit of redshift\u2014wherein these photons\u2019 wavelengths are stretched by the source\u2019s speed away from us or by the universe\u2019s expansion\u2014and you also get information about the object\u2019s age. In particular, because of the universe\u2019s expansion, the further away an object is from us, the faster it seems to be moving away from us. The faster it appears to be moving away from us, the redder its spectrum. Because light takes time to travel, redshifted galaxies must be older.\nTo figure out what kind of galaxies drove the harsh radiation of reionization, we must find two qualities of a galaxy: the redshift and the spectrum. The problem? These galaxies are faint\u2014extremely faint. It wasn\u2019t until recently, with the launch of the James Webb Space Telescope (JWST), that astronomers were finally able to see these faint high-redshift galaxies at a higher resolution.\nBut there\u2019s one more elephant in the room: what drove the sudden reionization? Neutral hydrogen gas left alone in a tank cannot suddenly ionize; there must be some driver for the process to occur. Now, armed with a powerful enough telescope, astronomers could finally answer their question about reionization. Cue Rhoads and Malhotra, who noticed something peculiar about the JWST data they were analyzing.\nSix months after its launch, JWST sent back images that contained the answer to this puzzle. Focused on a galaxy cluster named SMACS 0723, Rhoads and Malhotra noticed that three of the galaxies closely resembled some local galaxies\u2014galaxies that were billions of years separated from the trio. These were the Green Pea galaxies, aptly named for their greenish hue and minuscule size. They were found by citizen scientists working on Galaxy Zoo, and presented first in a paper led by astronomer Carolin Cardamone.\u201cWe [saw] that they were small, their galaxy population was young [at their redshift]\u2026 what you see in these galaxies is that their spectra are dominated by these huge [emission] lines,\u201d Malhotra said.\nMalhotra and Rhoads found that these emission lines were from glowing gas created by very young energetic stars. Galaxies with very young stars produce harsh ultraviolet radiation. These properties are unexpected for local galaxies, but it made sense that these galaxies would appear at the epoch of reionization. \u201cWe\u2019d have expected that these Green Peas were analogs of these high-redshift galaxies, but we hadn\u2019t tested that. So we were so excited when it actually happened!\u201d Malhotra said. Astronomers had expected that the Green Pea galaxies, which are easier to observe since they are nearby, would be common at the epoch of reionization, so it came with great excitement that their predictions were accurate.\nThere is little doubt that more groundbreaking headway will be made. As more discoveries are made with JWST data, it is likely that we will see more objects like the galaxies analyzed in Rhoads\u2019 and Malhotra\u2019s study, and we may finally find the key to the end of the universe\u2019s dark age. \u201cI think the JWST is going to revolutionize [our understanding of reionization],\u201d Malhotra said.\nAs for Rhoads and Malhotra, their plans going forward remain similar. They have worked in this field for many years and expect to continue working towards uncovering more about the high-redshift universe. Working with both ground-based telescopes and JWST, the two astronomers expect to build a more quantitative evidence base surrounding reionization-era galaxies. And since distant galaxies are harder to study, Rhoads and Malhotra plan to study local Green Pea analogs as well as higher redshift galaxies.\nThe journey to understand the end of the universe\u2019s dark age has been an arduous one, but also highly rewarding. Just as our universe exited its dark age, our knowledge about it has as well. \u201cIt\u2019s been quite a fun thing to do! We\u2019re looking at images, finding new things, making new discoveries, and forming a community. Many people, including citizen scientists, have paved the way for these exciting discoveries,\u201d Malhotra said. \u201cThis definitely represents the fun part of science.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/green-peas-in-space/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Magic Mushrooms",
            "author": "Yale Scientific Magazine",
            "authorLogo": "",
            "date": "May 2, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Magic-mushrooms-Kara-Tao-500x386.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Kara Tao.\nPeople constantly anthropomorphize objects. We look at a chair with two buttons and a line and see a face. We bump into our dresser and apologize as if it had feelings. At the end of the day, we know they are not alive, but new research conducted by researchers at Eidgen\u00f6ssische Technische Hochschule (ETH) Z\u00fcrich and Delft University of Technology could soon change this assumption.\nProfessor Kunal Masania of Delft University of Technology and Professor Andre Studart of ETH Z\u00fcrich, along with their colleagues, have created a 3D-printed material out of living fungi that has the ability to self-heal. \u201cThe most frustrating thing about making structural materials is that you are really limited by the design complexity that you can come up with, and biological materials don\u2019t have that problem,\u201d Masania said.\u00a0\nFungi contain mycelia, which are rootlike structures that grow underneath mushrooms and absorb nutrients from the soil. More importantly, mycelia can form a complex signaling network. The researchers mixed individual cells of this mycelia from the fungi Ganoderma lucidum into an ink called a hydrogel, which can then be fed into a 3D printer and used to create different types of structures. \u201cWhen you let the structure grow, all these cells reconnect and form all of the signaling networks they had as a living organism before,\u201d Masania said.\u00a0\nThis signaling network is what gives the material its remarkable regenerative and growing abilities. But how does it work? The answer lies with hyphae\u2014elongated cells in mycelia that catch nutrients from the environment and expel waste. This process creates a chemical gradient that tells the organism where nutrients and space are, and thus where to grow. \u201cThat is really something special that you cannot do any other way, even with 3D printing,\u201d Masania said.\nCurrently, the material can heal gaps up to three millimeters across. However, the fungi on its own has been shown to fill gaps of ten millimeters or more in larger organisms, so there is room to improve. That improvement would come with more advanced work on the biological component of the material.\u00a0\nThe material\u2019s lifespan is dependent on three factors: sugar, water, and space. But even without one of these requirements, the material will not die\u2014instead, it will go dormant. It is extremely resilient and can later be reactivated with the return of the missing requirement. The mycelia network was even able to survive accidental contamination in the lab, showing that it is strong as well as forgiving to researchers.\u00a0\nThis fungi material can be used for robotics\u2014specifically soft robots, which are made of malleable skins as opposed to firm metal. Soft robotics is a relatively new field with exciting medical and industrial applications since they have increased range of motion and flexibility. The researchers created a robotic grasper that could pick up items and a rolling mechanism that would allow a robot to move. \u201cIt can protect the robot from the environment, but it can also protect the environment from the robot, and then it\u2019s regenerative, so if it is damaged it will repair itself,\u201d Masania said.\nPotentially even more exciting than the material\u2019s regenerative properties is the potential to harness the mycelia\u2019s chemical signaling mechanism in conjunction with artificial intelligence, which is the subject of the lab\u2019s future research. By placing electrodes on the material, the action potential (a change of voltage across a membrane) produced by the chemical signaling can be recorded, similar to those created by neurons in our brains. The goal is to separate the chemical signaling caused by the normal biological processes of the organism and those specifically caused by environmental triggers.\u00a0\nBy separating out the signals caused by environmental triggers such as fungi growth from its sensing of nutrients, the researchers would be able to use these signals to collect environmental data, such as the locations of such nutrient sources. Moreover, they could play back these signals to the organism to gain control of its functions. For instance, researchers could replicate the signal for nutrients in a certain part of the material, causing the mycelia to grow in certain directions\u2014essentially brainwashing a living organism to do their bidding.\u00a0\nYour fridge may not have feelings just yet, but a world full of soft robots with self-healing, growing, living skin may be on the horizon.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/05/magic-mushrooms/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Architectural Mysteries of Our Past",
            "author": "Risha Chakraborty",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Chakraborty_Figure1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr\nThe Great Pyramid of Egypt is one of the Seven Wonders of the World, and deservedly so. Composed of thick, heavy stone slabs on the outside and multiple rooms on the inside, Khufu\u2019s Pyramid has drawn thousands of archaeologists and tourists to marvel at its enigmatic architecture and ponder how it was built 4,500 years ago. \u201cIt\u2019s both fascinating and frustrating that we still don\u2019t know how this monument was built,\u201d said S\u00e9bastien Procureur, one of the scientists from the French Alternative Energies and Atomic Energy Commission (CEA). Today, inferences from particle physics have revealed new details about its complex internal structure that may prove more awe-worthy than scientists and historians could have ever imagined.\nThe inside of the pyramid is divided into multiple spaces, including the so-called King and Queen chambers, corridors connecting the chambers, a grand gallery, and, as an international team of researchers named ScanPyramids recently discovered, a nine-meter-long cavity with a complicated Chevron structure close to the North Face of the pyramid. The Chevron, an inverted V-shape, itself pokes out from the original entrance and consists of huge gabled limestone slabs, but the internal structure belying it has eluded archaeologists and physicists alike until the advent of muon detectors.\u00a0\nMuons are a type of subatomic particle, similar to an electron, that are released in the atmosphere by the interactions with primary cosmic rays originating from the universe. Just like other subatomic particles, matter on Earth is capable of absorbing some of the muons from the atmosphere. The fraction of muons absorbed depends on the density of the matter. Measuring how many muons come through matter, or muon flux, can reveal a 2D map of the density of an object, depicting its inner structure. If one measured more flux than expected behind a structure, this would imply the presence of a hidden cavity within the structure. Procureur worked on the development of muon detectors during his research. \u201cNow, after around 10 years, there is still a lot to do in muon imaging. Several startups have been created over the last few years. It\u2019s very rewarding to think that there will be applications in the real world,\u201d said Procureur. \nThe team was able to use strategically placed muon detectors to measure the muon flux distributions around the pyramid. By combining multiple 2D representations, they were able to estimate the dimensions and shape of this unknown void within a few centimeters of accuracy. This study proved a novel technique to elucidate the inner architecture of otherwise obscure historical wonders which can be used to understand and shed light on other structures, from ancient mausoleums to stone heads to ziggurats. \u201cIn some sense, it is a bridge between two civilizations, a way for all of us to \u201ccommunicate\u201d with these people,\u201d said Procureur. The pursuit of such knowledge ties together advances in physics and history, so that our understanding of subatomic particles, the science of the future, can better inform us about the mysteries of our past.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/architectural-mysteries-of-our-past/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Flight of the Black Hole: Did Galactic Collisions Eject Supermassive Black Holes?",
            "author": "David Gaetano",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-6-500x304.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of \u201cA candidate runaway supermassive black hole identified by shocks and star formation in its wake\u201d\nBlack holes have long been the source of both advances in astronomy and advances in our understanding of the laws of physics that govern our universe. Supermassive black holes are a specific type of black hole defined by their astounding weights of millions\u2014even billions\u2014of solar masses. Until now, no such supermassive black holes have been found entirely outside of a galaxy, but researchers believe they may have found the first evidence to suggest the presence of a black hole of this nature\u2014one kicked out of its galaxy.\nIn the aftermath of a galactic collision, the black holes of each former galaxy slowly and steadily spiral toward each other, waiting to merge into an even larger black hole. However, if another galactic collision hurtles a third black hole into the orbiting pair, the impact may destabilize their orbits, ejecting one or more of the black holes from the galaxy. For decades, astrophysicists have predicted the existence of supermassive ejections, but their models have lacked direct evidence, until now.\nProfessor Pieter van Dokkum of Yale University studies stellar populations. While studying dark matter in distant galaxies, he happened upon an intriguing image captured by the Hubble Space Telescope. Upon further inspection, he noticed a single unique-looking streak in the image captured by the Hubble Space Telescope\u2014\u201dsomething I had never seen before,\u201d van Dokkum said. Further investigations of the streak, including spectroscopy with Keck Observatory, could reveal that this streak may be caused by a supermassive black hole escaping its host galaxy. If proven, it will be the first recorded evidence of its kind.\nThis is a groundbreaking discovery for many reasons. For one, scientists have proposed strong hypotheses surrounding the behavior of these supermassive collisions since 1970, and this evidence would be able to verify fifty years\u2019 worth of research. Further, this discovery makes way for the continued search for evidence to improve our statistical modeling. In particular, van Dokkum is interested in what this discovery could reveal about the formation of supermassive black holes and how one behaves when it is isolated from the center of a galaxy.\n\u201cThe hope is to find more in the future, that this is indeed a first of many,\u201d van Dokkum said. \u201cUltimately, the way forward is to find tens or hundreds of these.\u201d He believes that the real potential here is in finding as many examples of this phenomenon as possible so that researchers can better understand the role black holes play in the universe.\u00a0\u00a0\nThe next step for van Dokkum and his team is to confirm their findings with more data.\u00a0 They have already been granted time on the Hubble Space Telescope to conduct further investigations of nuances in this system. Even further down the line, researchers are excited to make use of the 2037 launch of the LISA satellite for the next major discoveries in the detection of supermassive black holes and their mergers.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/flight-of-the-black-hole-did-galactic-collisions-eject-supermassive-black-holes/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Quantum Computers, A Promising New Tool for Chemistry",
            "author": "Ximena Leyva Peralta",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/figure-1-3-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Creative Commons\nWhile most chemical research takes place in laboratories, theoretical chemistry is crucial to understanding and predicting the behavior of molecules before we ever synthesize them. It often relies on computer simulations to obtain information that is difficult or impossible to measure experimentally. For example, in drug development, computational methods are used to determine if potential new drugs would be safe and effective.\nSimulating large chemical systems is challenging for classical computers. The computational resources required increase exponentially with the number of particles. A water molecule takes only hours, while a protein can take several days. But researchers at the University of Oxford are exploring how quantum computers could solve these limitations. While classical computers store information in bits with fixed values of 0 or 1, quantum computers use qubits, which have some probability of having either value until they are measured. Qubits allow computers to run multiple calculations simultaneously, making them faster and more efficient, enough to facilitate simulations of complex chemical systems.\n\u00a0The Oxford team used clusters of classical computers to emulate a 36-qubit quantum computer, with which they were able to simulate chemical systems. \u201cIt\u2019s like a simulation inception, a simulation inside a simulation,\u201d said Hans Chan, a doctoral student and lead author of the Science paper detailing the group\u2019s results. Classical computers can currently model systems with multiple different types of atoms and several electrons, but the emulation requires considerable processing power and memory, which limits the complexity of the systems it can model. Hence, the team chose two simple systems: an electron in a hydrogen-type atom, and two electrons in a helium-type atom, to provide an initial proof-of-concept. Both classical and quantum computers use quantum mechanics to describe chemical systems, but the team\u2019s results suggest that quantum computers can provide superior results due to their efficient resource usage.\nIn quantum mechanics, particles and waves are a single entity. Each particle is described by a wavefunction, which contains information about its probable position and energy. The wavefunction extends over the space where a particle is moving, and the shape of this space dictates the value of the wavefunction at each point. An electron flying alone through space will have a different wavefunction than an electron living in a hydrogen atom. These wavefunctions can grow complicated for chemical systems with multiple electrons, so computers often use approximations to model them. One such approximation, the grid-based method, divides the total space into a finite number of small cubes, obtains the magnitude of the wavefunction in each small cube, and adds up these values to model the wavefunction over the whole space. \u201cIt\u2019s like \u2018pixelating\u2019 the wavefunction. Like an image, the more pixels, the more accurate it is,\u201d Chan said.\u00a0\nOn a quantum computer, adding one extra qubit doubles the number of \u2018pixels\u2019 we can use to model a chemical system. Hence, we could be more efficient with physical resources while obtaining more accurate results. However, quantum computing is still a young field. A fully functional device capable of simulating chemical systems is years away. \u201cWe can only make rough estimations,\u201d Chan said. More work is needed to fully gauge the capabilities of quantum computing, but its potential to help us solve chemical problems is already shining through.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/quantum-computers-a-promising-new-tool-for-chemistry/",
            "captions": [
                ""
            ]
        },
        {
            "title": "\u00a0A One-Year Gap, A World of Difference",
            "author": "Morgan Kenna",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Morgan_Figure1-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay\nIn the human lifespan, one year may seem fairly insignificant. But for women seeking further cancer treatment following breast-conserving surgery, the disparities between therapy recommendations for sixty-nine-year-olds and seventy-year-olds are stark.\u00a0\nAcross medical disciplines, age is a factor commonly used to identify the most beneficial treatment for a patient\u2019s needs. Past research has shown that adjuvant treatments (which are meant to prevent cancer from recurring after primary treatment) are less effective in older patients. Given that some cancer therapies\u2014like radiation\u2014can have serious side effects, doctors are less inclined to prescribe such intense therapies for elderly patients who may not experience their full benefits.\nBut how can oncologists effectively distinguish between \u201cyounger\u201d and \u201colder\u201d patients? Intuitively, the likelihood for breast cancer patients to be recommended for adjuvant treatment should gradually decline as patient age increases. However, a new study by Yale researchers showed something quite different: the only significant drop in adjuvant therapy recommendation occurred between ages sixty-nine and seventy, with an especially large gap between these two ages.\u00a0\nThese findings suggest that doctors are implementing an \u201cage cutoff heuristic,\u201d suddenly knocking breast cancer patients into the \u201colder\u201d category as they enter their eighth decade. According to Wesley Talcott, a radiation oncologist and researcher for this study, his research shines light on an overuse of age as a factor in determining cancer treatment regimens. \u201cThis study highlights the importance of getting away from a patient\u2019s chronologic age and thinking more about their physiologic age and their values,\u201d Talcott said. He also emphasized the study\u2019s significance as a collaboration between the Yale Schools of Medicine and Management. While heuristics and thinking patterns are widely studied in the field of economics, their impacts on healthcare are only now entering the spotlight as studies like this one become more common.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/a-one-year-gap-a-world-of-difference/",
            "captions": [
                ""
            ]
        },
        {
            "title": "You Are What You Eat",
            "author": "Hannah Qin",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Qin_Figure1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Wikimedia Commons\nHave you ever wondered why some people have a strong preference for spicy foods while others can\u2019t handle anything hotter than a bell pepper? Or why some people love the taste of coffee while others find it too bitter? Taste preferences are complex and varied, but a recent study sheds light on how our experiences, particularly when we are young, shape our gustatory cortex and ultimately influence our taste preferences.\nA study by neurobiology researcher Hillary Schiff and colleagues at Stony Brook University investigated how experience-dependent plasticity\u2014the ability of the brain to change and adapt based on experience\u2014affects the circuits in the gustatory insular cortex, a region of the brain that plays a crucial role in processing taste information.\nThe researchers used a mouse model and exposed infant mice to different taste stimuli over a period of several days. They found that repeated exposure to a battery of tastes led to changes in the activity of specific neurons in the gustatory insular cortex. A preference for sweet tastes was increased by eight days of exposure to four tastes, including sweet, salty, sour, and that of a nutrition shake named Ensure. Each day, mice were given one taste in their water bottle for twenty-four hours, so over eight days they received all four tastes twice.\u00a0\nInterestingly, the researchers found that neurons in the gustatory cortex of mice exposed to the battery of tastes were better at coding for different concentrations of sucrose. For example, exposure to these tastes led to increased activity in a specific subset of neurons called GABAergic inhibitory neurons and reduced the activity of other glutamatergic excitatory neurons.\u00a0\n\u00a0The study examined if the preference for sweet taste is modulated by early life experience or if it can be changed by taste experience throughout life. \u201cWindows of high sensitivity to taste experience [exist], because if we use the same paradigm in adult animals, the shift in sweet preference doesn\u2019t happen,\u201d said Arianna Maffei, a researcher on the study and a professor in Stony Brook\u2019s Department of Neurobiology and Behavior.\nThere is plenty of untapped potential for future studies to examine the gustatory cortex. In particular, Maffei\u2019s lab is currently interested in examining special diets, such as high-fat or high-salt diets associated with cardiovascular conditions and diabetes, and whether those diets could also affect brain development.\u00a0\nSo what does this mean for us humans? Even for us, taste experience could have a surprisingly long-lasting effect on brain development, and thus the implications of a healthy diet in early life cannot be understated. Our taste preferences are influenced by our experiences and the resulting changes in our gustatory cortex, which plays a crucial role in processing taste information. While we can broaden our palate by exposing ourselves to new tastes and flavors, our individual taste preferences are shaped by a complex interplay of factors, including exposure to certain tastes in infancy. So the next time you try a new food and find yourself loving or hating it, remember that it\u2019s not just your taste buds at play\u2014your brain is adapting to the new experience.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/you-are-what-you-eat/",
            "captions": [
                ""
            ]
        },
        {
            "title": "ChatGPT, MD",
            "author": "Yusuf Rasheed",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Rasheed_Figure1-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Courtesy of Pexels.\nGPT3 is a large language model built upon a neural network with 175 billion parameters, and it\u2019s transforming the way we learn. With simple, accurate explanations of complex topics and step-by-step answers on tasks ranging from coding a website to cooking a steak, its responses can promote creativity and our acquisition of knowledge. These capabilities have spurred discussions on how ChatGPT, our interface with the GPT3 model, can be used as an educational tool in a variety of fields, including medicine.\nRecently, researchers at Yale University and the National University of Ireland, Dublin tested how well ChatGPT could perform on the United States Medical Licensing Examination (USMLE) Steps 1 and 2. USMLE Steps 1 and 2 are considered to be the most important exams that medical school students take on their path to matching with a residency program.\u00a0\n\u201cWe saw ChatGPT [when it came out] and started asking [it] clinical questions, and we were like, \u2018Wow, it does better than we expected.\u2019 So we started wondering what would be a more systematic evaluation of this,\u201d said Vimig Socrates, a fourth-year PhD student at Yale. Socrates and the team tested ChatGPT\u2019s performance on the USMLE Step 1 and 2 exams by using the National Board of Medical Examiners (NBME) practice exams, known to be the most reputable, and AMBOSS practice exams, which offer explanations for each question.\u00a0\nThe researchers found that ChatGPT scored 64.4 percent, 57.8 percent, 44 percent, and 42 percent on the NBME-Free-Step1, NBME-Free-Step2, AMBOSS-Step1, and AMBOSS-Step2 exams, respectively.\u00a0 Above 60 percent is considered a passing rate for the USMLE Step 1 exam.\nThese findings highlight the potential for ChatGPT to be leveraged in medical applications. Faced with complex and overwhelming patient charts, doctors must often navigate cluttered information to identify the necessary details required to treat their patients. \u201cYou have to know exactly what you\u2019re looking for. You can look up if a patient was on warfarin [an anticoagulant medication], but it\u2019s really hard to find all blood thinners or surgical risk factors a patient may have,\u201d said Aidan Gilson, a fifth-year Yale medical student currently doing a year of research. However, by integrating ChatGPT or similar artificial intelligence models into patient charts, doctors could efficiently identify crucial information pertaining to their patients\u2019 medical histories.\nSimilarly, the potential for ChatGPT can be applied on the patient side. Patients often receive a large amount of information from their healthcare provider, which can be challenging to interpret. By using a digital assistant like ChatGPT to navigate healthcare data, patients may be better able to comprehend their medical records and communicate with their healthcare providers. By leveraging the capabilities of large language models, healthcare providers and patients alike can collaborate more effectively to achieve better outcomes.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/chatgpt-md/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Restless Night",
            "author": "Yamato Takabe",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/PREFERRED-IMAGE-Takabe_Figure1-500x375.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Courtesy of Pixabay.\nLife in a hospital is all about routine. Every day, well before sunrise, nurses visit every patient to check for vital signs and draw blood. Lab technicians then run tests on these blood samples checking for disease progression and overall well-being. This is a necessary precaution for physicians, who often need this analysis done before their morning rounds to provide informed decisions and advice for the patients.\u00a0\nHowever, there is one crucial factor that this routine overlooks: sleep. There have been previous studies, especially among elderly patients, that show sleep deprivation leads to an increase in their risk of adverse events during and after hospitalization, speaking to a need for more research on post-hospital syndrome and other factors impacting patient care and increasing stress for patients.\u00a0\nIn a recent study, Cesar Caraballo-Cordovez, a postdoctoral associate at the Yale School of Medicine, focused on the burden of the timing of blood draws on patients\u2019 well-being. After taking data from 5,676,092 blood draws at the Yale New Haven Hospital, his team discovered that 2,206,410 samples (38.9 percent) were drawn between 4:00 am and 6:59 am. From 2016 through 2019, this proportion of early morning blood samples drawn increased from 36.9 to 41.4 percent, indicating an increase in this trend.\u00a0\nTo improve upon this issue, hospitals may consider restructuring how medical care is delivered. \u201cIn the end, the hospitals are built on efficiency, so the main focus would be to shift this focus to the quality of patient care and patient satisfaction to have a tangible impact,\u201d Caraballo said. With additional concerns about overworking hospital workers, there is a pressing need for the future of healthcare systems to consider the balance between hospital efficiency and the well-being of both patients and healthcare professionals.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/a-restless-night/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Through the Gate: How HIV Sneaks Into the Nucleus",
            "author": "Nathan Wu",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/figure-1-1-2-500x422.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr.\nWith a death toll of over forty million, the AIDS epidemic is among the most fatal in human history. Nearly the same number continue to live with the disease today, as a cure or vaccine has yet to be found. However, researchers are working to solve a mystery central to this battle: how the human immunodeficiency virus (HIV), the cause of AIDS, enters a cell\u2019s nucleus.\u00a0\nHIV replicates by merging its DNA with its host\u2019s DNA (housed in the nucleus) and then co-opting the host cell\u2019s own biological machinery to produce viral proteins. Therefore, inhibiting its mechanisms of nuclear entry could prevent infection. The virus\u2019s DNA must pass through the nuclear pore complex (NPC), a collection of over 400 proteins that act as the \u201cgate\u201d to the nucleus. Some scientists believe that the entire HIV capsid, a cone-shaped shell holding the genome, passes through intact. Somehow, the capsid tricks the proteins of the NPC, called nucleoporins, into letting it through.\nA technology developed by Qi Shen, Chenxiang Lin, and Patrick Lusk, all researchers at Yale University, could help reveal a potential mechanism for this entry. Using \u201cDNA origami,\u201d where DNA\u2019s capabilities to fold into well-defined structures is harnessed to create nanoscale objects, Shen built mimics of the NPC\u2019s inner channel. These mimics, dubbed \u201cNuPODs,\u201d consist of nucleoporins bound to a ring of DNA scaffolding. The NuPOD platform allows for the targeted examination of a single type of nucleoporin while still allowing multiple proteins to act cooperatively in a nuclear pore-like environment.\nIn collaboration with Yong Xiong, a professor and HIV researcher at Yale, Shen employed the NuPODs to study how HIV capsids interacted with three nucleoporins: Nup358, Nup62, and Nup153. The team first designed mimic channels each with one type of nucleoporin and then investigated which ones capsids bound to. Capsids did not bind to Nup62 channels but bound strongly to Nup358 channels and especially to Nup153 channels. Next, they created NuPODs with multiple layers of nucleoporins ordered according to their organization in NPCs. They found that the capsid was able to insert deeper into channels when entering from the Nup358 side, as it would in a real channel, than when entering from the Nup153 side. Additionally, Nup62 hampered the ability of the capsid to enter the channel.\u00a0\nThe team determined that capsid passage through the NPC was guided by the capsid\u2019s affinity to different nucleoporins. \u201cOn the outside, affinity is weak: on the inside, affinity is tight\u2026 There\u2019s a gradient that provides the driving force to drive the virus in,\u201d Xiong said. Secondly, they concluded that nuclear entry of the capsid involves more than just Nup153, Nup358, and Nup62. With a model consisting of just these three, complete penetration of the NPC does not occur because of the barrier effects of Nup62. Other proteins likely help the capsid pass.\nThis project was the first application of the NuPOD platform towards modeling a viral system. It bridges a technological gap in a field that currently lacks methods to study interactions between the HIV capsid and the nuclear pore. Shen, Lin, and Xiong plan to incorporate other nucleoporins into their NuPODs to further examine HIV capsid entry into the nucleus. Additionally, they hope to use the NuPOD platform to investigate whether other viruses use a similar trick to bypass the nuclear gate. This technology has opened a gate of its own: the study of viral entry into the nucleus. Perhaps this new path can lead us in the right direction to develop an HIV treatment once and for all.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/through-the-gate-how-hiv-sneaks-into-the-nucleus/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Unlikely Research Grant For Black And Women Scientists",
            "author": "Kayla Yup",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Yup_Figure1-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Yale School of Medicine.\nBeing a researcher is like being on Shark Tank. Except the shark has seven times Mark Cuban\u2019s net worth and belongs to the government.\u00a0\nWith thirty-three billion dollars to invest in research, the National Institutes of Health (NIH) can afford to dream big. However, even its pot of money gets drained quickly. The problem is that there are a million theories on how to save more lives. And whatever hodgepodge of hypotheses the NIH picks to fund will likely be the future of medicine.\nThat thirty-three-billion-dollar check ultimately gets split 58,368 different ways across the U.S. And if you\u2019re wondering who\u2019s enjoying that funding, just know it\u2019s less likely to be Black and women scientists, according to a recent JAMA Network Open study. \u201cIt\u2019s a bit discouraging,\u201d said Mytien Nguyen, an MD-PhD candidate at the Yale School of Medicine and first author of the study. \u201cBecause you want to succeed and be able to do the things that you want to do for your community.\u201d\nEven research has its monopolists\u2014sort of. There\u2019s an elite class of scientists called \u201csuper PIs,\u201d who each receive three or more NIH grants. That status is unequally distributed across gender, ethnic, and racial groups. Compared to principal investigators (PIs) who are white and male, Black women PIs were seventy-one percent less likely to be super PIs, the study found. Nguyen\u2019s team also found that, similar to Black women PIs, Black PIs and women PIs were respectively forty percent and thirty-four percent less likely to be super PIs than white men.\u00a0\nMeanwhile, the researchers found that the percentage of super PIs tripled from 1991 to 2020, rising from 3.7 percent to 11.3 percent. \u201cIt means that whenever there\u2019s a budget increase, most of the time it\u2019s going to white male PIs rather than being distributed equally,\u201d Nguyen said.\nNguyen added that there are currently only twelve Black super PIs in the country\u2014and that underrepresentation at the top trickles down. It\u2019s difficult for minority trainees to find mentors with similar backgrounds and struggles. The few that exist are overwhelmed and overworked in terms of mentoring, Nguyen added.\nNguyen grew up in a low-income, immigrant household. Neither of her parents, who are Vietnamese and Black, finished high school. As Nguyen rose through academia, she realized there was a hidden curriculum to success, one to which she lacked access. That\u2019s why she\u2019s passionate about improving diversity in science, starting with funding.\nAcademic grants fund your trainees and research agenda, Nguyen explained. They boost your chances of getting promotions. Plus, the more money you have, the riskier and more high impact of a project you can pursue. She added that diversity in PIs ensures research serves a diverse population. Nguyen pointed to clinical trials, which traditionally fail to represent people from marginalized backgrounds.\u00a0\n\u201cIt\u2019s important to have researchers representing these underserved communities so that they\u2019re asking the questions that are relevant,\u201d Nguyen said. \u201cSo that it\u2019s a more equitable transplant from the bench to the bedside.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/the-unlikely-research-grant-for-black-and-women-scientists/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How it Works: Forming Carbon-Nitrogen Bonds from Thin Air",
            "author": "Lawrence Zhao",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-2-2-500x481.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Holland research laboratory.\nFrom DNA to colored dyes, carbon-nitrogen (C-N) bonds, are everywhere. However, scientists find it difficult to efficiently synthesize these bonds from common starting materials. What if we could make these bonds directly from nitrogen gas, which makes up most of Earth\u2019s atmosphere?\nNitrogen gas (N2) is abundant, but it is also unreactive, so C-N bond formation usually first requires the energy-intensive reduction of N2 to ammonia. But three years ago, Patrick Holland\u2019s group in the Department of Chemistry at Yale discovered a new way to incorporate N2 into carbon-containing, or organic, compounds using an iron complex. The researchers knew that they had discovered an innovative method to make C-N bonds without the help of ammonia, but they weren\u2019t sure how it worked.\u00a0\nSamuel Bhutto, then a graduate student in the Holland lab, isolated some of the reaction intermediates and their structures, then suggested that this phenomenon happened in a single-step reaction. Another graduate student, Reagan Hooper, used computation to determine that bonds break and form simultaneously in the transition state. All signs pointed towards the same explanation. \u201cThe high oxidation state of iron [\u2026] is what drives the insertion by giving the complex an unusual electronic structure,\u201d Bhutto said. Because of how the iron atom interacts with N2, a nitrogen atom can accept electrons from a nearby organic compound and create a new C-N bond.\u00a0\nNow that we know how this kind of reaction works, the Yale scientists hope to generalize this tool to make many kinds of C-N bonds. Currently, the synthesis of many industrial chemicals like surfactants uses a pathway that inserts carbon monoxide (CO) into organic molecules, and doing the same with N2 would be a major innovation. \u201cIf we can do half that much with nitrogen, which is more abundant and less toxic than CO, then that would be great,\u201d Holland said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/how-it-works-forming-carbon-nitrogen-bonds-from-thin-air/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Saving Coral Reefs & Humans with Eco-friendly Sunblock",
            "author": "Matthew Zoerb",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/bleached-coral-flickr-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr\nIn 2018, Hawaii banned the sale and distribution of sunscreen products containing oxybenzone and octinoxate due to their toxicity to coral reefs. In 2023, the ban was broadened to include avobenzone and octocrylene. These active ingredients are found in most chemical sunscreens, leaving few options for beach-goers. There is rising concern about the effects of chemical sunscreens on marine ecosystems, especially among popular ocean-side destinations. The U.S. Virgin Islands and Key West, Florida have taken similar measures to protect the biodiversity of their marine habitats.\nChemical sunscreens function by absorbing solar radiation with polymers called \u201cUV filters.\u201d However, these ingredients become harmful pollutants once they enter the ocean. They damage coral DNA and increase the risk of coral bleaching, which leaves the coral vulnerable to degradation and strips away its normal color. The active ingredients are also small enough to permeate the skin barrier and enter the bloodstream. Studies have reported that oxybenzone can disrupt sex hormone systems in humans and lead to developmental abnormalities in animal test subjects.\u00a0\nHawaii now only allows the sale of mineral sunscreens, which are less toxic to the environment. Mineral sunscreens use particles of titanium dioxide or zinc oxide to physically reflect the sun\u2019s rays. The FDA recognizes them as generally safe for humans since they are too large to pass through the skin membrane. However, they leave a pasty white layer on the skin and are more likely to cause acne breakouts, making them less desirable for consumers who are concerned with aesthetics. Until a replacement for the banned active ingredients is developed, though, they are the only option available for purchase in Hawaii.\nA recently published investigation led by researchers from Tsinghua University in China developed a new active ingredient for chemical sunscreens: P(3). The team leveraged the Biginelli reaction, a synthetic technique that coordinates the simultaneous reaction of three molecules, to create compounds that resemble common active ingredients. They hoped to create a larger compound with similar UV filtering properties that would not be able to pass through the small pores in the skin membrane. After many attempts using the Biginelli reaction and another similar reaction, the team was finally successful in developing a suitable polymer. \u201cWe are quite lucky to finally find the conditions to get P(3),\u201d said professor Lei Tao, supervisor of the study.\u00a0\nWhen tested on mice, P(3) offered significantly more UV protection compared to pure active ingredients and commercial sunscreen products. Furthermore, while coral and algae exposed to oxybenzone did not survive, P(3) had no harmful effect on them. P(3) does not penetrate further than the very outer layer of the skin and has unexpectedly low toxicity levels when injected into the bloodstream. A quick glance at the pictures of the bleached coral labeled \u201coxybenzone\u201d next to healthy coral treated with P(3) reaffirms the potential impact of these findings.\nAlthough the results from P(3) are promising, the research team is still searching for compounds that are biodegradable and easy to make. \u201cWe hope to find easier synthesis routes to prepare coral-friendly and environment-friendly anti-UV polymers with different structures,\u201d Tao said. This discovery brings us a step closer to developing sunscreens that protect users from harmful UV radiation without harming the environment.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/saving-coral-reefs-humans-with-eco-friendly-sunblock/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Cell Cartography",
            "author": "Gia Cabral",
            "authorLogo": "",
            "date": "November 21, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figures-1-and-2-500x204.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Yang Liu.\nTo understand the function of a cell, we must first understand the role of genes. Think about a section of tissue as small as a single hair follicle: the activity of tens of thousands of genes forms a blueprint for this fraction of space\u2014packed full of organelles, cellular fluids, and more. How can we get a complete view of this complex space and its inner workings?\nYang Liu, an assistant professor at Yale University, sought to visually describe these relationships through a method called spatial CITE-sequencing, where transcriptomic data can be associated with sections of tissue via a series of protein tags, antibodies, and short RNA sequences. Researchers then form a 2D map and pinpoint the locations of hundreds of genes simultaneously. Previously, CITE-sequencing could only sequence a limited number of targets with low efficiency. Now, the technique can sequence hundreds of genes simultaneously. This technology will help grow global databases for RNA coding sequences, which are valuable for understanding the distinct roles of genes and generating possible treatments for genetic diseases.\u00a0\nWhen working with a process as novel as CITE-sequencing, a technique that has only been available for five years, the successes are rewarding, but the failures are frequent. \u201cWhenever you solve [one problem] there is another. But incremental progress is still progress, so taking a big problem and breaking it up into smaller ones is essential,\u201d Liu said. For example, to solve an issue of keeping thin fragments of tissue in place for experimentation, the team has been developing prototypes of a specialized tissue clamp.\u00a0 Spatial transcriptomics is expanding quickly, and this Yale research team is leading the charge to add to our knowledge of gene activity. An increase in funding for the field has promoted protocol optimization, decreased experimental costs, and improved accessibility for CITE-sequencing technology.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/cell-cartography/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Your Unique Fingerprint",
            "author": "Elisa Howard",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fingerprint_-Breanna-Brownson-349x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Breanna Brownson\nLook at your hands. Look closely at the patterns drawn on the tips of your fingers. The fingerprint is present from birth, unchanging over the human lifespan, and unique to each and every individual. Even identical twins with the same genes exhibit distinct fingerprints. So, how does your fingerprint develop? And what factors contribute to the unique patterns that you see?\nFingerprints exhibit three main pattern types: arches, loops, and whorls. Fingerprint ridges begin to form in the twelfth week of gestation, the period between conception and birth, and the organization of the fingerprint pattern is defined by week fourteen. However, little is known about the biological mechanisms underlying fingerprint variation. In a recent paper published in Cell, researchers at the University of Edinburgh and the Shanghai Institute of Nutrition and Health provide insight into the genetic foundations of fingerprint development. \u201cWe are interested in individual molecules and genes and how they work together to create structure and form,\u201d said Denis Headon, a senior research fellow at the University of Edinburgh and an author of the study.\u00a0\nLeading the project, Shanghai Institute researchers in the Laboratory of Dermatogenomics performed genome-wide association studies (GWAS) linking fingerprint pattern type with genetics. A GWAS is a research approach that correlates variation in observable traits with variation in the DNA. The Shanghai researchers conducted GWAS of several thousand Han Chinese individuals characterized for the three main fingerprint patterns. This GWAS method identified forty-three locations of genes associated with developing arches, loops, or whorls.\nThe researchers then studied the functions of fingerprint-associated genes and the timing of their activity in development. \u201cInterestingly, locations in the genome that correlate with fingerprint type are populated by genes involved in limb formation, rarely skin development,\u201d Headon said. That is, genes involved in embryonic limb formation appear as the predominant factors determining heritable variation in fingerprint patterns. The researchers also found that many of the fingerprint-associated genes identified through GWAS are not even active in the skin when the fingerprint forms. Rather, the genes function early in development to set up the proportions and shapes of the fingertips. As development progresses, the genes switch off. These findings can be understood in the context of correlative work from the twentieth century, which argues that the shape of the finger strongly influences fingerprint patterns. Thus, it appears that limb development genes dictate the presence or absence of arches, loops, or whorls through their involvement in finger shape.\u00a0\u00a0\nHowever, the GWAS results only explain part of the variation in fingerprints across the human population because fingerprint type is not entirely heritable. For instance, identical twins have different fingerprints, and the fingerprints of the left and right hand are not mirror images. \u201cThe same genome running through the process of making a fingerprint at different times, for different fingers, for different individuals will come up with a slightly different outcome,\u201d Headon said. Therefore, rather than simply focusing on genes, it is important to consider development as a process. \u201cThe genes inform, but then there is a process of development that interprets and gives an outcome in the anatomy,\u201d Headon said.\nHow can this study help explain the distinct fingerprints of identical twins? If one identical twin has all arches, then the other twin is more likely to have all arches than a random, unrelated member of the population. In other words, there is at least some genetic influence. \u201cBut genetic variation will go through a developmental process that has a certain amount of randomness to it,\u201d Headon said. Simply knowing the list of genes active in a particular tissue provides an incomplete understanding of how that tissue develops. \u201cYou need to abstract a step from that and say, \u2018what is the process through which these genes operate together to produce a particular outcome?\u2019\u201d Headon said.\nLook at your hands again. How might your fingerprints have formed?\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/your-unique-fingerprint/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How Mussels Flex to Keep Coastal Ecosystems Afloat",
            "author": "Abigail Jolteus",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/how-mussels-flex-Luna-Aguilar-500x488.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Luna Aguilar. \nDue to climate change, sea levels could rise twelve inches in the next three decades, equivalent to the measured rise seen over the last century. This rise stresses vegetated coastal ecosystems, which include mangroves, salt marshes, and seagrasses. Coastal ecosystems provide habitats for a wide variety of wildlife and protect both humans and animals from storms. They also contribute to stabilizing the shoreline, filtering nutrients, and storing carbon dioxide from the atmosphere in the ground. \u201cCoastal ecosystems are very near and dear to my heart,\u201d Sin\u00e9ad Crotty, associate director of science at the Yale Carbon Containment Lab, said.\nIn a recent paper published in Nature Communications, Crotty examined the direct and indirect effects of one unassuming invertebrae\u2014mussels\u2014on the persistence of vegetated coastal ecosystems.\nEven small changes in sea levels can substantially alter these ecosystems through coastal flooding, resulting in higher storm surges\u2014the rise of seawater during a storm\u2014and an influx of saltwater into freshwater habitats. Sea level rise has prompted more effort and resources to be directed to vertical and horizontal accretion, a natural process that results in a change in the elevation of salt marshes. Accretion can indicate how well a salt marsh is persisting in spite of changes in sea level, and, according to Crotty, refers to how the marsh moves upwards to compensate for sea level rise. It can increase vertically, up and down in direction, or horizontally, in the landward direction of the boundary of the marsh.\nStudying accretion is particularly important because it helps prevent a phenomenon known as drowning, in which the vegetated area of a salt marsh is converted into an open water area. This originally looks like a small pond that eventually grows larger. As the salt marshes drown, the vital services that they provide, including habitation, storm buffering, and carbon storage, also disappear, destabilizing the wildlife around it.\u201cWe care deeply about accretion because for marshes to not drown, we need the rate of accretion to be greater than the rate of sea level rise,\u201d said Hallie Fischman, a Ph.D. student at the University of Florida and an author of the paper.\u00a0\nHistorically, studies on accretion focused on environmental factors, such as tidal range and sediment supply. The tidal range consists of the difference between the highest and lowest point of the tide, and sediment supply refers to the availability and transport of sediment. However, organisms can also shape their environment, which includes modifying accretion processes. This concept is known as faunal engineering. It refers to animals that provide habitats, nutrients, or some other alterations that allow other organisms, as Crotty put it, to \u2018persist and thrive.\u2019\u00a0\nMussels: The Underdogs of Coastal Ecosystems\nOne of the most abundant faunal engineers present in salt marshes in the United States are Atlantic ribbed mussels. Mussels can be easy to miss in these vast ecosystems. Yet even though these organisms are tiny, their functions are vital\u2013they can, either directly or indirectly, alter plant growth and improve water quality by removing organic matter and unwanted particles. These particles and organic matter are filtered by mussels, processed, and subsequently excreted. Therefore, mussels help with sediment deposition, the deposition of the organic material that remained after digestion. Mussels are also an important food source for many terrestrial and aquatic organisms.\u00a0\nResearchers at the Yale Carbon Containment Lab and the University of Florida were interested in quantifying the effects of the Atlantic ribbed mussel on accretion in southeastern US salt marshes. They performed three field experiments to fulfill this objective.\nThe first field experiment was to investigate whether the sediments deposited by mussels could supply marshes beyond the areas where the mussels were gathered. Where exactly was the sediment spreading? To answer this question, the researchers tagged biodeposits that were already on the mound. Then, the fluorescent chalk was mixed with already deposited biodeposits, and the researchers came back to trace the movement at night. \u201cIt was a crazy idea that we could feed mussels orange chalk, they would poop it out, and we could follow it across the marsh,\u201d Fischman said.\nThe researchers returned at night and used black light detection to trace the distribution of the fluorescently-tagged biodeposits. Blacklight, or ultraviolet (UV) light, is a tool commonly used to detect fluorescently-tagged materials. The maximum distance that fluorescent biodeposits traveled was measured in every direction.\nInterestingly, the researchers discovered that the biodeposits were quickly redistributed beyond the areas where mussels were present. To confirm these results, the researchers collected approximately ten mussels from each of their six mounds, brought them to the University of Georgia\u2019s laboratory, and fed them a mixture of seawater and chalk, which resulted in the excretion of fluorescently-tagged biodeposits. After the previous fluorescent material was washed away, the researchers planted the mussels in the respective mounds and performed the study again, subsequently confirming their previous findings. One limitation of this experiment that the researchers hope will be addressed in future studies is that the fluorescent dye in the biodeposits functioned for only the first twenty-four hours, so the study was performed on a limited time scale.\u00a0\nIn the second field experiment, the researchers wanted to investigate the effects of cordgrass, also known as marsh grass, and mussels on sediment deposition at different marsh elevations. Seven different scenarios were tested in two zones in the state of Georgia for a month: the creekhead, or where a narrow inlet called a tidal creek enters onto the marsh, and the marsh platform, or the main flat surface that extends landward. These scenarios included alterations to the presence of cordgrass and mussels, as well as the density of mussels.\u00a0\nCordgrass was found to have no significant effect on sediment deposition in both zones, which further highlights the importance of mussels. As for mussels, after performing statistical analysis, the researchers discovered a positive correlation between the number of mussels and increased sediment deposition. The implications of this study are limited by the size of the areas that were observed.\nIn the third field experiment, to assess the potential effects of mussels on marsh accretion at the level of a creekshed, a smaller version of a watershed, researchers manipulated the presence and population size of mussels. Approximately two hundred thousand mussels were manually moved from one creekhead to another. A control creekhead side in the same marsh was also established. With the help of a tool called the Digital Elevation Model (DEM), the researchers were able to assess the elevation of the creekheads after three years. DEM was created using drone imagery, which was then filtered and edited to remove vegetation to focus on the sediment. The team discovered that the creek from which the mussels were removed decreased in elevation, but the creek to which mussels were added increased in elevation. Mussels were putting in the work.\nTo further explore and validate the conclusions from their field experiments, the researchers used the Delft-3D-BIVALVES model, a digital tool to create simulations, generating different scenarios that mimicked salt marshes in the region. This model determined that the highest sediment accretion was found on mussel aggregations using simulations based on the assumption that mussels filter the water column\u2014which refers to the space between the surface and floor of a body of water. Mussels expel the filtered content and their feces on mounds, which facilitates a build-up of sediments that increases the elevation of the salt marsh.\u00a0\n\u201cWhile the manual labor and methodology development were at times challenging, I think ultimately this has been one of the most collaborative and gratifying scientific efforts that I have been a part of,\u201d Crotty said. Each of these field experiments in addition to the simulation models contributed to the overall claim that mussels increase salt marsh accretion. The results suggest that mussels contribute significantly to sediment deposition and vertical accretion in salt marshes.\u00a0\nNew Ideas for Mitigating Sea Level Rise\n\u201cThe coolest takeaway of this study is that mussels increase salt marsh accretion, which means that mussels are important in helping marshes keep up with sea level rise,\u201d Fischman said. Other researchers can use the insights provided by this study to direct their research projects on animals similar to mussels. Mussels may not, however, be the only animals that are contributing to the health of their ecosystems.\u00a0\nDue to climate change, scientists are observing a phenomenon in which small animals are adapting their roles to their changing environment. Understanding the behavior of these animals can help guide future research on other types of terrestrial and marine ecosystems. \u201cRelatively small animals are increasing in their relative importance and the roles that they play in response to the changes that climate change is implementing,\u201d Crotty said.\nAs for next steps, Fischman is interested in the effect of mussels on nitrogen cycling, which is a cycle of various processes in which nitrogen moves through living and non-living things in the environment.\u00a0\nAs climate change continues to worsen, an additional rise in sea levels is inevitable. Among its dangers are more frequent and intense floods, higher storm surges, and loss and alteration of coastal habitats. Future studies, including those on overlooked parts of an ecosystem, can hopefully help mitigate its harmful effects.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/how-mussels-flex-to-keep-coastal-ecosystems-afloat/",
            "captions": [
                ""
            ]
        },
        {
            "title": "It\u2019s In Our Bones",
            "author": "Evelyn Jiang",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Heart1-Gia-Cabral-386x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Gia Cabral.\nBumps, whiteheads, rashes, scars: acne vulgaris is the most prevalent skin disease in the world, affecting the physical and mental health of 9.4 percent of the global population. This figure includes a whopping eighty-five percent of people between twelve and twenty-four years old. Cutibacterium acnes is the major cause of acne. It is a Gram-positive bacterium, meaning it has a thicker cell wall and causes different infections than Gram-negative bacteria. C. acnes coexists with healthy skin follicles and pores, but certain strains lead to acne and other complications, such as eye inflammation after tissue implantation. To treat these infections, dermatologists often prescribe a class of antibiotics called \u201ctetracycline,\u201d which include doxycycline, minocycline, and sarecycline.\u00a0\nTetracycline-class antibiotics are a group of medications used in the treatment of bacterial infectious diseases. They target the ribosome, an organelle that translates genetic information from RNA sequences into amino acid chains, which then fold into proteins. Tetracycline is a naturally-occurring antibiotic isolated from actinomycetes, a soil bacteria, and was approved by the FDA for medical use in 1954. Doxycycline and minocycline, termed second-generation tetracyclines, were approved in 1967 and 1971, respectively, thanks to their improved stability and pharmacological efficacy. Almost half a century later, in 2018, sarecycline was introduced as a third-generation tetracycline-class antibiotic. While doxycycline and minocycline kill all types of bacteria\u2014meaning they are broad-spectrum antibiotics\u2014sarecycline has narrow-spectrum activity against only certain Gram-positive bacteria, including C. acnes.\u00a0\nChristopher Bunick, associate professor of dermatology at the Yale School of Medicine, noticed the importance of this novel antibiotic and decided to look into its molecular mechanism. \u201cBecause of our expertise in protein synthesis, ribosome structure, and dermatology, we couldn\u2019t resist taking on this project,\u201d said Ivan Lomakin, an associate research scientist in the Bunick lab. Lomakin, Bunick, and their collaborators analyzed how sarecycline interacts with the C. acnes ribosome using cryogenic electron microscopy (cryo-EM), and published the results in Nucleic Acids Research. They discovered that sarecycline binds to the C. acnes ribosome at two different sites, which had not been observed in structures with other tetracyclines or model bacteria. They also discovered two novel ribosomal proteins and demonstrated their antimicrobial properties independent of the ribosomal complex. This study ultimately confirmed that sarecycline may be a more effective treatment option for C. acnes infections.\u00a0\nWhy bind to ribosomes?\u00a0\nSince protein synthesis is an indispensable part of life, many antibiotics inhibit the activity of bacterial ribosomes, and sarecycline is no exception. As a complex\u2014an assembly of multiple subunits that carry out a function together\u2014the ribosome is made of ribosomal RNA (rRNA) associated with certain ribosomal proteins. Translation, the process it catalyzes, involves messenger RNAs (mRNAs) and transfer RNAs (tRNAs). The mRNA contains information \u2018copied\u2019 from the DNA that the ribosome must \u2018read and translate.\u2019 The tRNA contains nucleotides that recognize specific, three-base long mRNA sequences and the amino acid that corresponds to this sequence. The ribosome consists of large and small subunits, which are responsible for different steps of the process. The small subunit binds to the mRNA strand and identifies the correct tRNA molecule for every three bases within the decoding center. The large subunit then catalyzes the addition of the new amino acid to the growing polypeptide (protein) chain, which exits the ribosome through a structure called the nascent peptide exit tunnel (NPET). This process is how cells make proteins.\u00a0\nStructural biologists have characterized the binding mechanisms of many antibiotics with ribosomes of model bacteria like E. coli and Thermus thermophilus. For first- and second-generation tetracyclines, existent structures all suggest that they bind to the decoding center of the small ribosomal subunit, inhibiting mRNA-tRNA interactions and slowing protein synthesis. The interaction patterns that Lomakin and colleagues characterized with cryo-EM agree with models of other tetracyclines. They show that the stacking of three hydrophobic layers stabilizes the binding of sarecycline in the decoding center of the C. acnes ribosome and inhibits tRNA arrival.\u00a0\nBesides the canonical binding site, researchers were surprised to discover that sarecycline has a second binding site (SBS) on the C. acnes large ribosomal subunit, in the NPET. Here, sarecycline blocks the NPET and is thought to suppress the growth of the peptide chain. This binding site is specific to the C. acnes ribosome, as X-ray crystallography of sarecycline in complex with the Thermus thermophilus ribosome\u2014also performed by the Bunick Lab\u2014showed only the canonical binding site. Based on indirect experiments, researchers speculated that sarecycline could probably bind to both sites with similar affinities, and the sarecycline molecule in the SBS may assist with function in the canonical binding site.\u00a0\nThe paper compared this binding interaction with an antibiotic from another structural family, tetracenomycin X, which was recently shown to bind to the E. coli ribosome at a similar site. The team postulated that certain uridine bases were important in this interaction, and mutations from uridine to another base, cytosine, would confer resistance. However, Lomakin is not too worried about bacteria gaining sarecycline resistance, compared to other tetracyclines. \u201cFor sarecycline, we have an additional site on the large ribosomal subunit, encoded by a different gene than the small ribosomal subunit. The probability of simultaneously getting mutations on both of them is the multiplication of getting mutations on each, so it is very low,\u201d Lomakin said.\u00a0\nPotential Antimicrobial Properties\nUsing cryo-EM, the researchers managed to capture the first high-resolution structure of the C. acnes ribosome. They also examined the ribosomal proteins attached to the ribosomal RNA and explored how the C. acnes ribosome\u2019s catalytic mechanisms could differ from other known bacterial models. This knowledge would help inform the future design of antibiotics against C. acnes.\u00a0\nBut of particular interest to the team were the bacterial small ribosomal subunit protein 22 (bS22) and the bacterial large ribosomal subunit protein 37 (bL37). These proteins are normally part of the ribosome and help synthesize proteins, but independent of the complex, they have displayed antimicrobial properties. C. acnes exists in normal skin, so researchers wonder if it helps defend the skin against other pathogenic bacteria. \u201cFrom a dermatology perspective, we know C. acnes lives in our follicles and pilosebaceous units as a commensal organism\u2014only certain strains of it are pathogenic for acne. We are trying to probe whether or not C. acnes has a natural defense mechanism against Staphylococcus aureus, which is a major pathogenic skin organism,\u201d Bunick said. They discovered that the bS22 could inhibit the growth of E. coli and S. aureus while the bL37 only affected S. aureus but not E. coli.\u00a0\nThe next step down the antimicrobial properties path was to understand whether these proteins were present independent of the ribosome. Usually, ribosomal proteins form a complex with ribosomal RNAs to catalyze protein synthesis, but additional functions outside of ribosomes are possible. Bunick proposes that C. acnes may either secrete these peptides directly or release them when they die and lose their membranes.\u00a0\nSarecycline: The Better Acne-biotic?\nSarecycline was introduced in 2018 as a drug with higher specificity and fewer side effects than minocycline and doxycycline. However, primarily due to pricing issues, it only has about six percent of the prescription market for oral tetracycline in dermatology. To Bunick, sarecycline deserves more recognition. \u201cAt least to my knowledge, it is the only FDA-approved drug that targets two active centers of the ribosomes currently,\u201d he said.\u00a0\nThe human gastrointestinal tract contains many beneficial Gram-negative bacteria. Since sarecycline is more specific to certain Gram-positive bacteria and spares Gram-negative bacteria, it causes fewer side effects in the gastrointestinal tract while effectively targeting Gram-positive C. acnes. Doxycycline is photosensitive, so certain users may experience rashes, itching, or severe sunburn, while sarecycline is not. Sarecycline is also less hydrophobic, meaning a decreased possibility of diffusing through the blood-brain barrier and causing dizziness, vertigo, or tubular disturbance.\u00a0The Bunick lab partners with Almirall, the pharmaceutical company that licenses and sells sarecycline in the United States. \u201cOur laboratory [work] has been predominantly keratins, intermediate filaments, and the skin barrier for over a decade. But [learning about sarecycline] presented a unique opportunity as an entryway into a new area of research understanding the molecular mechanisms of dermatology drugs. Sometimes the science leads you to where you need to be,\u201d Bunick said. He does not rule out the possibility of developing a fourth-generation tetracycline. This paper was the first to publish a C. acnes ribosomal structure. Given the new information about multiple active sites, it is possible to further optimize the structure of the antibiotic to achieve more precise treatment of the infection behind your bumps and whiteheads.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/its-in-our-bones/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Acne-biotics",
            "author": "Crystal Liu",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Girl_In_Mirror_YSM-Hannah-Han-386x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Hannah Han.\nBumps, whiteheads, rashes, scars: acne vulgaris is the most prevalent skin disease in the world, affecting the physical and mental health of 9.4 percent of the global population. This figure includes a whopping eighty-five percent of people between twelve and twenty-four years old. Cutibacterium acnes is the major cause of acne. It is a Gram-positive bacterium, meaning it has a thicker cell wall and causes different infections than Gram-negative bacteria. C. acnes coexists with healthy skin follicles and pores, but certain strains lead to acne and other complications, such as eye inflammation after tissue implantation. To treat these infections, dermatologists often prescribe a class of antibiotics called \u201ctetracycline,\u201d which include doxycycline, minocycline, and sarecycline.\u00a0\nTetracycline-class antibiotics are a group of medications used in the treatment of bacterial infectious diseases. They target the ribosome, an organelle that translates genetic information from RNA sequences into amino acid chains, which then fold into proteins. Tetracycline is a naturally-occurring antibiotic isolated from actinomycetes, a soil bacteria, and was approved by the FDA for medical use in 1954. Doxycycline and minocycline, termed second-generation tetracyclines, were approved in 1967 and 1971, respectively, thanks to their improved stability and pharmacological efficacy. Almost half a century later, in 2018, sarecycline was introduced as a third-generation tetracycline-class antibiotic. While doxycycline and minocycline kill all types of bacteria\u2014meaning they are broad-spectrum antibiotics\u2014sarecycline has narrow-spectrum activity against only certain Gram-positive bacteria, including C. acnes.\u00a0\nChristopher Bunick, associate professor of dermatology at the Yale School of Medicine, noticed the importance of this novel antibiotic and decided to look into its molecular mechanism. \u201cBecause of our expertise in protein synthesis, ribosome structure, and dermatology, we couldn\u2019t resist taking on this project,\u201d said Ivan Lomakin, an associate research scientist in the Bunick lab. Lomakin, Bunick, and their collaborators analyzed how sarecycline interacts with the C. acnes ribosome using cryogenic electron microscopy (cryo-EM), and published the results in Nucleic Acids Research. They discovered that sarecycline binds to the C. acnes ribosome at two different sites, which had not been observed in structures with other tetracyclines or model bacteria. They also discovered two novel ribosomal proteins and demonstrated their antimicrobial properties independent of the ribosomal complex. This study ultimately confirmed that sarecycline may be a more effective treatment option for C. acnes infections.\u00a0\nWhy bind to ribosomes?\u00a0\nSince protein synthesis is an indispensable part of life, many antibiotics inhibit the activity of bacterial ribosomes, and sarecycline is no exception. As a complex\u2014an assembly of multiple subunits that carry out a function together\u2014the ribosome is made of ribosomal RNA (rRNA) associated with certain ribosomal proteins. Translation, the process it catalyzes, involves messenger RNAs (mRNAs) and transfer RNAs (tRNAs). The mRNA contains information \u2018copied\u2019 from the DNA that the ribosome must \u2018read and translate.\u2019 The tRNA contains nucleotides that recognize specific, three-base long mRNA sequences and the amino acid that corresponds to this sequence. The ribosome consists of large and small subunits, which are responsible for different steps of the process. The small subunit binds to the mRNA strand and identifies the correct tRNA molecule for every three bases within the decoding center. The large subunit then catalyzes the addition of the new amino acid to the growing polypeptide (protein) chain, which exits the ribosome through a structure called the nascent peptide exit tunnel (NPET). This process is how cells make proteins.\u00a0\nStructural biologists have characterized the binding mechanisms of many antibiotics with ribosomes of model bacteria like E. coli and Thermus thermophilus. For first- and second-generation tetracyclines, existent structures all suggest that they bind to the decoding center of the small ribosomal subunit, inhibiting mRNA-tRNA interactions and slowing protein synthesis. The interaction patterns that Lomakin and colleagues characterized with cryo-EM agree with models of other tetracyclines. They show that the stacking of three hydrophobic layers stabilizes the binding of sarecycline in the decoding center of the C. acnes ribosome and inhibits tRNA arrival.\u00a0\nBesides the canonical binding site, researchers were surprised to discover that sarecycline has a second binding site (SBS) on the C. acnes large ribosomal subunit, in the NPET. Here, sarecycline blocks the NPET and is thought to suppress the growth of the peptide chain. This binding site is specific to the C. acnes ribosome, as X-ray crystallography of sarecycline in complex with the Thermus thermophilus ribosome\u2014also performed by the Bunick Lab\u2014showed only the canonical binding site. Based on indirect experiments, researchers speculated that sarecycline could probably bind to both sites with similar affinities, and the sarecycline molecule in the SBS may assist with function in the canonical binding site.\u00a0\nThe paper compared this binding interaction with an antibiotic from another structural family, tetracenomycin X, which was recently shown to bind to the E. coli ribosome at a similar site. The team postulated that certain uridine bases were important in this interaction, and mutations from uridine to another base, cytosine, would confer resistance. However, Lomakin is not too worried about bacteria gaining sarecycline resistance, compared to other tetracyclines. \u201cFor sarecycline, we have an additional site on the large ribosomal subunit, encoded by a different gene than the small ribosomal subunit. The probability of simultaneously getting mutations on both of them is the multiplication of getting mutations on each, so it is very low,\u201d Lomakin said.\u00a0\nPotential Antimicrobial Properties\nUsing cryo-EM, the researchers managed to capture the first high-resolution structure of the C. acnes ribosome. They also examined the ribosomal proteins attached to the ribosomal RNA and explored how the C. acnes ribosome\u2019s catalytic mechanisms could differ from other known bacterial models. This knowledge would help inform the future design of antibiotics against C. acnes.\u00a0\nBut of particular interest to the team were the bacterial small ribosomal subunit protein 22 (bS22) and the bacterial large ribosomal subunit protein 37 (bL37). These proteins are normally part of the ribosome and help synthesize proteins, but independent of the complex, they have displayed antimicrobial properties. C. acnes exists in normal skin, so researchers wonder if it helps defend the skin against other pathogenic bacteria. \u201cFrom a dermatology perspective, we know C. acnes lives in our follicles and pilosebaceous units as a commensal organism\u2014only certain strains of it are pathogenic for acne. We are trying to probe whether or not C. acnes has a natural defense mechanism against Staphylococcus aureus, which is a major pathogenic skin organism,\u201d Bunick said. They discovered that the bS22 could inhibit the growth of E. coli and S. aureus while the bL37 only affected S. aureus but not E. coli.\u00a0\nThe next step down the antimicrobial properties path was to understand whether these proteins were present independent of the ribosome. Usually, ribosomal proteins form a complex with ribosomal RNAs to catalyze protein synthesis, but additional functions outside of ribosomes are possible. Bunick proposes that C. acnes may either secrete these peptides directly or release them when they die and lose their membranes.\u00a0\nSarecycline: The Better Acne-biotic?\nSarecycline was introduced in 2018 as a drug with higher specificity and fewer side effects than minocycline and doxycycline. However, primarily due to pricing issues, it only has about six percent of the prescription market for oral tetracycline in dermatology. To Bunick, sarecycline deserves more recognition. \u201cAt least to my knowledge, it is the only FDA-approved drug that targets two active centers of the ribosomes currently,\u201d he said.\u00a0\nThe human gastrointestinal tract contains many beneficial Gram-negative bacteria. Since sarecycline is more specific to certain Gram-positive bacteria and spares Gram-negative bacteria, it causes fewer side effects in the gastrointestinal tract while effectively targeting Gram-positive C. acnes. Doxycycline is photosensitive, so certain users may experience rashes, itching, or severe sunburn, while sarecycline is not. Sarecycline is also less hydrophobic, meaning a decreased possibility of diffusing through the blood-brain barrier and causing dizziness, vertigo, or tubular disturbance.\u00a0The Bunick lab partners with Almirall, the pharmaceutical company that licenses and sells sarecycline in the United States. \u201cOur laboratory [work] has been predominantly keratins, intermediate filaments, and the skin barrier for over a decade. But [learning about sarecycline] presented a unique opportunity as an entryway into a new area of research understanding the molecular mechanisms of dermatology drugs. Sometimes the science leads you to where you need to be,\u201d Bunick said. He does not rule out the possibility of developing a fourth-generation tetracycline. This paper was the first to publish a C. acnes ribosomal structure. Given the new information about multiple active sites, it is possible to further optimize the structure of the antibiotic to achieve more precise treatment of the infection behind your bumps and whiteheads.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/acne-biotics/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: Measure for Measure",
            "author": "Henry Chen",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Measureformeasure3-500x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Measure For Measure.\nHow would you rank the following: Friends, The Office, and Modern Family? How do you\u2014and other people\u2014differentiate between your favorite shows, books, and podcasts? Is there a universally defined scale? What are some factors we use to compare? These are all important questions that \u201cMeasure for Measure\u201d seeks to explore.\n\u00a0\u00a0\u00a0\u00a0\u00a0 Run by the organization Ministry of Ideas and co-hosted by Liya Rechtman and Andrew Middleton, \u201cMeasure for Measure\u201d is a limited podcast series that investigates a different form of measurement in our daily lives. The nine episodes, which range from nine to twenty-five minutes in length, are perfect to squeeze in during a walk between classes. The podcast covers topics spanning the Scoville spice scale, used to measure the pungency of chili peppers, to star \u201cheartbeats,\u201d which are pulses that cause a star to expand and contract, leading to variations in brightness. Most importantly, each episode tries to answer the overarching question: why has measurement been crucial throughout human history?\nFor example, in episode two, Rechtman talks about how the Talmud, a central Judaic text, contains a number of references to measurements, like how much matzah to eat during Passover, that were based on the size of other foods, like olives. Because olive sizes have varied over the centuries, many Jewish people today have tried to update the medieval measurement to determine how much matzah to eat. The story of the olive is one of unity across time\u2014how even though Jewish people are separated from their ancestors by thousands of years, they can still celebrate in the same way, following similar cultural guidelines. Importantly, each episode presents a narrative about using measurement as a way for us to (re)connect with the rest of the world\u2014both past and present.\nAs I made my way through the series, it became clear where each of the co-hosts\u2019 passions came into the episodes. Rechtman is a Jewish climate activist, while Middleton is a cartographer and ocean enthusiast. As a result, it felt like each episode was a science lesson infused with niche, thoroughly interesting historical and cultural facts\u2014an engaging format that sparks questions about the intersection between the humanities and science. For instance, in episode three, we learn about the Mohs scale for categorizing the hardness of rocks and how it was created by the Habsburg Empire to distinguish itself from competing empires and increase national unity. These stories reinforce the idea that measurement isn\u2019t solely restricted to the International System of Units we use in chemistry class. Instead, it extends far beyond, into almost every facet of human life.\u00a0\u00a0\u00a0\u00a0\u00a0 At the end of the nine episodes, I still haven\u2019t found a definitive scale to rank podcasts, but I have learned the importance of tools for measurement in our lives and how they turn a continuous reality with infinite possibilities into discrete categories\u2014and maybe that\u2019s the point. For its combination of historical facts, scientific trivia, and broad cultural trends, I\u2019m placing \u201cMeasure for Measure\u201d in the category of \u201chighly recommended.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/science-in-the-spotlight-measure-for-measure/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Vacationing In Spain",
            "author": "Matthew Blair",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Vacationing-in-Spain-1-375x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Malia Kuo\nGenetic testing platforms like 23andMe and Ancestry.com have been in the spotlight for many years now. These testing programs have grown immensely popular, with some people finding long-lost relatives or discovering that a historical figure is somewhere in their family tree.\nBut for those living over forty thousand years ago, unfortunately, no such genetic testing was available. Those early humans lived without ever knowing their full genetic history. Some early humans perhaps wholly missed the opportunity to gloat that they were related\u2014somewhere in their bloodline\u2014to the first Homo sapiens to discover fire.Now, however, He Yu of Peking University in Beijing, China and her team of researchers have constructed a genetic narrative for these early humans. Their study is the most comprehensive examination of certain hunter-gatherer groups living in Europe around the Ice Age. It reveals important information about the mixing between different groups and their migratory patterns. This study shines light on the genetic differences and similarities of different hunter-gatherer groups and focuses especially on how these groups survived the Last Glacial Maximum (LGM), which was the most intense period during the last Ice Age.\nThe group\u2019s study examined where hunter-gatherer groups migrated in order to evade the massive glaciers and blisteringly cold temperatures moving across the globe during the LGM, which lasted from twenty-five thousand to nineteen thousand years ago. The LGM is particularly interesting to study because researchers believe it created a large migration of hunter-gatherer groups. Prior studies have found that the LGM pushed hunter-gatherer groups to move into southern latitudes, specifically the Iberian peninsula and southern France, with some studies also suggesting that hunter-gatherers could have moved into the Italian peninsula, the Balkans, and the southeastern European Plain.\nIt is impossible to determine where groups may have moved during the LGM without having a snapshot of their locations and genetic makeups before and after this period. As such, the study spans from thirty-five thousand to five thousand years ago, covering before, during, and after the LGM. \u201cThis paper focuses on where people traveled to find refuge and, after the LGM, expanded again to form the later population structure,\u201d Yu said.\nUsing mostly bones, teeth, and other materials that could contain genetic information, Yu and her research team created new genomic information for hunter-gatherer groups that are now extinct. It is easy to send in your saliva sample to a genetic testing company site, but researchers had to meticulously comb through paleogenomic data to construct a very large and complex family tree. In this paper, 356 ancient hunter-gatherer genomes were analyzed, 116 of which were newly reported by researchers across the globe in fourteen countries throughout western and central Eurasia.\nOnce the researchers confirmed that these samples contained genetically viable information, they began the process of genetic testing. The first, most crucial, step in this process is to extract the DNA and sequence the genome. Often, however, sequencing the genome is the simplest part. \u201cWhen we get the data, we have a lot to do with it. We first examine their genetic differentiation, trying to see what samples look more similar and which are more dissimilar. Specifically, we focus on the alleles and other genetic information that could be shared between some individuals and not others,\u201d Yu said. Alleles are the genetic information that could potentially be shared between individuals\u2014the genetic information that could contribute to physical traits like blue eyes, brown hair, or the like. This process of analyzing these alleles and other genetic information involves a great deal of high-level statistical analysis and other methods of biological comparison.\u00a0\nThis data analysis allows researchers to test specific hypotheses about the movement and mixing of hunter-gatherer groups. There are many different ideas about where a group could have gone and which other hunter-gatherers they might have encountered along the way, but this method of data collection and analysis can quantitatively prove or disprove these conclusions.\nThe researchers also considered a multitude of other factors, including the radiocarbon dates of the materials, so that they can pinpoint the age of the samples and discover other archaeological information. Simply, radiocarbon dating is the process by which researchers analyze the amount of radioactive carbon-14 left in a sample in order to measure its age. Further, cultural information about specific hunter-gather groups, such as knowledge about their mortuary practices or the types of weaponry they commonly used, allowed the researchers to make increasingly sound conclusions about the movements of certain hunter-gatherer groups and their possible relations to other groups.\nWith this research, Yu and her team of researchers have established a genomic study of remarkable depth and breadth. By drawing on multitudes of biological and historical information, they created a firmly-rooted \u201cfamily tree\u201d for hunter-gatherer groups.\u00a0\nWhen working with a data set that is so ancient, many challenges can arise. The majority of the time, the samples used usually come from bones or teeth. These physical samples last through the ages which makes them strong candidates for DNA extraction. In especially old samples, however, the DNA degenerates and is poorly preserved. \u201cThe samples that are reported, of course, are not the only samples that we have processed. There were various samples that did not produce enough DNA and some which had none at all, failing during the DNA extraction process,\u201d Yu said.\n\u00a0Even when a sample does produce enough DNA, that data must be observed with a critical eye. As these samples have often been studied by multiple parties and transported across the globe, the risk for contamination is high. \u201cFor many samples, we also had a hard time trying to detect and confirm if they are contaminated or not. Further, if samples were found to be contaminated, we then had to go through the process of separating the DNA of that specimen from its contaminants so that we could get real information,\u201d Yu said.\nThis study showed that hunter-gatherer groups flocked to western and southwestern Europe to escape the Ice Age. \u201cIt was always assumed that the Iberian Peninsula was a refuge during the Ice Age, but this is the first time we genetically confirmed that there is really a human population\u2014with the same genetic ancestry found earlier in other regions of Europe\u2014living in that area,\u201d Yu said. This is a powerful confirmation that paints a clearer picture of the survival, migration, and mixing of hunter-gatherer groups.\nBut researchers still have questions, especially about the importance of another region as a refuge during the Ice Age: the Italian Peninsula. In this region, there were massive genomic changes before and after the Ice Age, so researchers cannot make a succinct conclusion on whether or not it was a refuge based on DNA evidence alone. These regions saw a huge genomic turnover, with distinct genetic populations before and after the LGM. \u201cGenetic information could help us to answer or confirm some points, but it alone cannot confirm them all. It is important in these sorts of studies to combine information from different sources and evidence from different disciplines,\u201d Yu said.\nHistory itself is expansive, and trying to capture the movement of many different groups over tens of thousands of years is an exceedingly difficult task, but researchers like Yu and her team are embarking on this journey through time to reveal important information about how our earliest ancestors survived and how all of us are here today. As we move forward and learn more about our personal genomic histories through popular testing platforms, we can appreciate the work they are doing to capture the genomic ancestry of humans across the world.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/vacationing-in-spain/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Plant-Animal Hybrids",
            "author": "Samantha Liu",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Plant-Animal_Hybrids-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao\nPlant-animal hybrids are here, and they are exactly what they sound like. In the Sainsbury Laboratory in Norwich, UK, wild tobacco plants have been engineered to produce \u201cpikobodies,\u201d synthetic proteins that can recognize and attack pathogens expressing fluorescent proteins. These pikobodies are made by taking rice-derived receptors and swapping in antibody fragments originating from camelid mammals, specifically llamas and alpacas. In a proof-of-concept study\u2014carried out by postdoctoral scientist Jiorgos Kourelis of the group headed by Sophien Kamoun\u2014the team discovered that these pikobody-producing tobacco plants could successfully stave off viral invaders.\u00a0\nThis discovery arrives at a crucial moment: in the past year alone, wars, climate change, and trade routes in flux have ferried pathogens around the globe in dangerously unprecedented ways. Meanwhile, as a wheat blast devastates crop yields in Africa and Asia, and scientists sound alarm bells to food security worldwide, protection against plant diseases is more important than ever.\nWhile current mechanisms of disease resistance in agriculture are mostly chemical (think pesticides, fungicides, and a host of other -ides), with pikobodies, genetic treatments may replace our reliance on chemical treatments. \u201cWe can generate made-to-order resistance genes against virtually any pathogen,\u201d Kourelis said.\u00a0\nThe idea is certainly an imaginative if not unbelievable one, almost like science fiction. But it didn\u2019t originate out of the blue. Scientists have long been interested in the integrated domain (ID) of plant receptors, which is responsible for recognizing pathogen effectors and triggering an immune response. In one key study by French scientist Stella Cesari, engineering the ID of Pik-1\u2014a receptor that normally attacks fungal invaders\u2014could allow tobacco plants to gain specificity and bind new sequences.\u00a0 Ever since then, Kamoun has wondered if he could engineer Pik-1 to recognize other pathogens.\nThe second piece of the puzzle\u2014introducing the animal antibody\u2014came four years ago, with Kourelis\u2019 arrival at the lab. During a lab meeting, Kourelis proposed \u201cA General Solution for Plant Pathology\u201d\u2014a title which, of course, caught the attention of everyone in the room.\u00a0\nAs Kourelis noted, one problem with plant immune defenses is that they lack mobile or specialized cells for attacking viruses, unlike animals. Plants instead rely on nucleotide-binding, leucine-rich receptors (NLRs), which can recognize diverse pathogen components and activate the immune response. But NLRs are limited in what they can recognize\u2014and their scope is hard-coded by DNA, which cannot evolve as fast as rapidly-changing viruses.\u00a0\nIn contrast, mammals can create and proliferate specific antibodies for virtually any virus they are exposed to. Not only do these antibodies target, mobilize, and kill viral particles, but the animal also retains them well after the infection, in case of future threats\u2014the same principle which guides vaccines. \u201cBasically, you could potentially build a disease resistance gene against any plant pathogen by exploiting the adaptive immune system of animals,\u201d Kamoun said.\nEnter the llamas. Kourelis suggested taking camelid mammal nanobodies\u2014the fragment of antibodies which actually binds to the pathogen\u2014and fusing them to Pik-1. In this way, plants\u2019 integrated domains could serve as a scaffold to trigger the immune response, while mammalian antibodies could let them recognize a host of other pathogens.\u00a0\nTo turn their concept into practice, Kourelis still needed a framework for where and how to engineer the receptors. His answer was bolstered by an earlier project by colleague and Ph.D.student Aleksandra-Ola Bialas, who investigated how the Pik-1 receptor arose fifty million years ago. Critically, by looking at the evolutionary origins of Pik-1, Bialas\u2019s work helped delimit the boundaries of the domain that Kourelis was so interested in.\u00a0\u00a0\n\u201cSo fifty million years ago, nature actually did this engineering and integrated the domain into this [Pik-1] receptor,\u201d Kamoun said. \u201cAnd if you understand how nature has done it, you could repeat it in the lab.\u201d\nEven with Bialas\u2019s contribution, the process to pare down potential candidates was arduous. It required iterations of revisiting basic science, tweaking existing combinations, and, at some point, sheer brute force, Kourelis recalled. \u201cSometimes we were like, \u2018Let\u2019s drop in as many nanobodies as we can and see if some of them work,\u2019\u201d Kourelis said. \u201c\u2018And then, if a few work, even if they don\u2019t work great, let\u2019s understand what\u2019s going on there.\u2019\u201d\nEventually, he engineered eleven pikobody candidates to recognize fluorescent proteins. They were vetted for autoimmune responses and cell death responses until only four pikobodies remained. After introducing a live Potato virus X, which was engineered to express fluorescent proteins, two pikobodies were found to halt viral spread substantially. And if used together, these two pikobodies proved to be even more effective.\nNow, Kourelis and Kamoun are looking toward future applications for pikobodies. They are both enamored with the potential of \u201cdesigner\u201d domains, with each plant tailored with pikobodies against diseases that might threaten it. They even speculated that, with advanced artificial intelligence, computers may someday design the binding domains, circumventing the need for antibodies altogether.\nFor Kourelis, one of the challenges lies in accounting for\u2014and staying ahead of\u2014pathogen evolution. As he looks to apply his model and develop a toolkit of new receptors, he hopes to identify target sequences that will be long-lasting. If they can pick target sequences that are unlikely to change, then the pathogen is less likely to evolve to resist that receptor. \u201cThen again, I like to say, \u2018Never bet against the pathogen,\u2019\u201d Kamoun said.\u00a0\nIn the book-lined office from which Kamoun and Kourelis take this Zoom interview, it is not difficult to envision them collaborating in a laboratory. Kourelis fields a question. Kamoun modifies Kourelis\u2019s answer, then raises another point, which reminds Kourelis of another idea. Even as they talk to me, their conversation with each other never ceases.\nTheir dialogue\u2014revising, rephrasing, circling\u2014reflects the cycles it took Kourelis to get to his top-performing pikobodies. But this is their process and, perhaps, the reason they are successful. Kourelis emphasized multiple times that they regard themselves as scientists first, and engineers second. No matter what science-fiction universe plant-animal hybrids and pikobodies seem to resemble, for Kourelis and Kamoun, these ideas are firmly rooted in listening to what already exists\u2014to plants, to other scientists, to each other\u2014before they create something new.\n\u201cThere\u2019s a more fundamental understanding in seeing how, in nature, these proteins have evolved, how these domain integrations have happened,\u201d Kourelis said. \u201cYou have to understand before you can take the next step. You have to understand nature by making it.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/plant-animal-hybrids/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Cyborg Zebrafish",
            "author": "Nathan Mu",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Cyborg-Zebrafish-Court-Johnson-349x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Courtney Johnson\nThe human body is a machine. At a fundamental level, it depends on electrical currents within cells and electrical signals between cells to function. So, in a sense, the body produces its own electricity. But what happens if this power gets unplugged? This is the problem that researchers have faced in trying to cure diseases such as Parkinson\u2019s, Alzheimer\u2019s, epilepsy, and depression. In the brain\u2014where electrical signaling is paramount\u2014any small unplugging can throw off the system of electrical currents and quickly lead to improper function. Without a way to fix an improper pattern of electrical signaling, that part of the brain will slowly lose its charge and fizzle out, leading to these diseases.\u00a0\nA team led by organic bioelectronics researchers Xenofon Strakosas and Hanne Biesmans of Link\u00f6ping University in Sweden may be on track to develop a viable solution to this problem. They have targeted this issue of restoring dysfunctional electrical pathways by harnessing the body\u2019s chemistry to form an electrode, or electrical conductor that helps produce a current, within the brain. \u201cThe really cool thing about this electrode is that it is a soft polymer that forms in situ, or within the brain, unlike metal electrodes that are harsh and rigid, and require open skull surgery,\u201d Biesmans said. Any implant in the human body that does not belong there runs the risk of causing inflammation and inducing an immune response that will try to fight the implant. Current standards for inducing artificial electrical currents in the brain, such as gold electrodes, are not optimal. Biesmans\u2019 team\u2019s primary goal was to develop a \u2018softer\u2019 alternative that could be formed within the body.\u00a0\nTheir approach was to create a gel mixture that, once injected into the brain, could self-assemble into a polymer that was able to restore electrical activity. There\u2019s a popular saying that \u2018the answer you seek is within you,\u2019 and that\u2019s the advice that the researchers followed. Previous researchers at Stanford had used an outside solution\u2014genetic modification\u2014to produce soft electrodes. However, this pathway comes with its own problems when it comes to human application due to ethical concerns over modifying human DNA. \u201cWith our simple injectable gel, there\u2019s no need for genetic modification. And in the long term, maybe there is also no more need for open skull surgeries,\u201d Biesmans said.\nThis gel cocktail concoction is composed of monomers, or building blocks, as well as enzymes that will be used to make the polymer electrode. The powerful part of this research is that it takes advantage of the enzymatic breakdown of two types of biological sugars found in the body to assemble these monomers into a polymer electrode. First, glucose or lactate\u2014two types of sugars in the body\u2014are converted into hydrogen peroxide by common enzymes known as oxidases. Next, hydrogen peroxide is used by horseradish peroxidase (HRP), a naturally occurring enzyme, to start the polymerization process. And that\u2019s it\u2014a simple, two-step process links together the monomer components from the injected gel to form a soft electrode directly in the body.\nBut even the coolest products still need to be tested for quality, and that\u2019s why Biesmans and her team came up with a set of seven criteria ranging from fluidity to biocompatibility and stability to assess the electrodes. The first test they ran assessed the effectiveness of their injected electrode gel on 0.6 percent agarose gels, which is a well-known model for simulating brain chemistry and conditions. \u201cIn the early stages of research, if you don\u2019t know much, you don\u2019t want to go straight to zebrafish or animal models because you don\u2019t know what works yet,\u201d Biesmans said. In this initial stage of testing, the researchers went through at least fifty to sixty different injectable electrode gels to find a few that were promising enough to continue working with. \u201cSome gels were too thick and did not even make it into the agarose gels,\u201d Biesmans said.\u00a0\nThe team then moved on to demonstrating the conductivity, stability, and biocompatibility of the gel and the formed electrode. It would have been ideal to test these long-term effects with zebrafish, but this was not possible. \u201cOur ethical permits did not allow us to keep the zebrafish alive for more than three days, so we had to find a different way,\u201d Biesmans said. Instead, the researchers used electrode arrays to test for electrical currents maintained by the electrode polymer. They also exposed the polymers to harsh sound energy and live cell conditions to ensure that the polymer would not degrade. Both tests showed excellent results and confirmed the stability of the gel.\nThese tests showed that the gel performs well, but is it safe to use? This was the team\u2019s next question and perhaps the trickiest because of the potency of glucose oxidase enzymes. These enzymes can quickly produce lots of hydrogen peroxide, which can kill cells at very high concentrations. \u201cWe had to find an optimal balance between lactate oxidase and HRP enzymes so that we could get rid of the hydrogen peroxide as fast as it was being produced,\u201d Biesmans said. Finally, the team had a breakthrough and found that a twenty-seven to one ratio of HRP to lactate oxidase worked best. \u201cWe were finally able to tune the amount of hydrogen peroxide so that we are not creating more problems than we are fixing,\u201d Biesmans said.\nThe final hurdle for Biesmans and her team was to test their gel in two live models: zebrafish and medicinal leeches. In zebrafish, the gel was introduced in the tailfin first, followed by the brain and heart. The gel turns deep blue when successfully polymerized, and the team saw this beautiful color in all three locations. Their hard work had finally resulted in a working electrode, without noticeable side effects on the zebrafish. One of Biesmans\u2019 favorite experiments was soaking zebrafish hearts in the gel cocktail. \u201cI really like that the polymer formed around the arteries, where you find glucose and lactate. It\u2019s not covering the entire heart. That was a nice demonstration of the specificity of this gel,\u201d she said.\u00a0\nLeeches were another nice proof of concept for demonstrating the effectiveness of this polymer electrode since they are easy to visualize. \u201cLeeches have one central nerve, and if you stimulate the nerve, it will contract immediately. So, you get instant visual proof of whether your stimulation worked,\u201d Biesmans said. A key finding from the leech model was that the polymer electrodes produced a gentler, tissue-friendly current as opposed to the stronger, harsher current produced by gold electrodes.\u00a0\nEven with the success of this initial experiment, there is still much work to be done. Biesmans and her research team plan to further optimize the current gel, test new versions of gels with different monomer building blocks, and introduce their current gel in mice models. Biesmans is also working on trying to induce a similar gel-based polymerization in single cells, as opposed to tissues. \u201cOverall, we are working on building up this toolbox of monomers and techniques for so many different applications,\u201d Biesmans said. These applications include treating various diseases requiring electrical stimulation by forming polymer electrodes at many different sites with disparate properties.\nThis is just the beginning of exploring electrical patterns in the brain. While this team focused on restoring electrical activity, there are also projects such as Elon Musk\u2019s Neuralink program that seek to use machines to interpret the meaning of the brain\u2019s electrical signals. Perhaps this research will lead us towards a future of not just cyborg zebrafish, but cyborg humans that fully utilize the brain-machine interface. This makes organic bioelectronics a highly interdisciplinary field, and for Biesmans, this has been one of her favorite aspects of the work. \u201cIt\u2019s interesting and fun to work with all these collaborators from different disciplines together. So, let\u2019s see where it brings me,\u201d Biesmans said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/cyborg-zebrafish/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Seeding Robots",
            "author": "Madeleine Popofsky",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Seeding_Robots-Kara_Tao-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao\nLook, up in the sky! It\u2019s a bird! It\u2019s a plane! It\u2019s\u2026 hundreds of autonomous self-burying seed carriers? These small wooden contraptions are built with a unique design that lets them bury a seed into the ground after dropping from a great height. While unlikely to drop into your backyard, this new invention spearheaded by Lining Yao of Carnegie Mellon University and Teng Zhang of Syracuse University could change the face of reforestation via air. The design for these carriers is inspired by Eroidium seeds, and they are made using natural materials such as wood. The carriers provide a nature-based solution to our man-made problems regarding habitat loss, forest shrinkage, and even agricultural complications.\u00a0\nAerial seeding\u2014when seeds are scattered by plane, drone, or helicopter\u2014is an invaluable technique when it comes to wildland restoration, reforestation, and agriculture, especially for large swaths of hard-to-access land. However, the scattered seeds often fail to penetrate the ground. This dramatically decreases their chances of germination, as they can get eaten by wildlife or swept away by harsh weather conditions.\u00a0\nThe device is closely modeled on the seeds of Erodium, a flowering plant that has seeds with a special design: a coiled body and single twisting tail that allows them to bury into the soil. \u201cIt\u2019s very hard to reproduce the performance and also the biodegradable nature of the Erodium seeds,\u201d Zhang said.\u00a0\nAfter many rounds of testing, the final design has a twist: three tails instead of one. \u201cThese three points provide a stable contact between the structure and the soil,\u201d Zhang said. To picture the device, imagine a propeller with three blades circling each other on top\u2014these are the three tails. In the center, where the three tails meet, a coil extends downward in a straight line\u2014this is the coil body. At the end of the coil body lies the seed tip, where the seed is stored. In addition to the three tails, the other main innovation is the coil, which provides the mechanical force to allow the carriers to drill into the ground. The researchers treated the wood used to make the coil body with multiple rounds of chemical treatment and mechanical deformation in order to create its twisting shape.\u00a0\nThe carrier is rain-driven\u2014another concept borrowed from Erodium seeds, which change shape depending on humidity. The wood cells in the coil swell during rainfall, with those on the inside swelling more than those on the outside, causing the coil to unwind and the seed to be drilled into the ground. As the coil dries, the cells on the inside shrink more than those on the outside, promoting another coiling mechanism in the opposite direction that further embeds the seed.\u00a0\nThe main challenges faced by the researchers included field tests that could be done best only in the spring, resulting in months of wait time until conditions were suitable, in addition to day-of weather concerns. Furthermore, the researchers created a simulation to test the device\u2019s performance which proved difficult, considering friction and the many connections between the tails and coil body.\nThe carriers have a few issues: they can be negatively affected by extreme weather conditions, the tip-coil connection can sometimes break, and the tails can tangle during release. The team aims to fix these issues as well as test other types of materials. The tested carriers were made of white oak, but other woods or materials could potentially be used with the design. Having a larger material library will enhance the feasibility of production in different regions. Additionally, the researchers are exploring other dimensions for the seed carriers that could improve their performance.\u00a0\nCurrently, the carriers are lovingly crafted by hand\u2014which is not a production method that can continue long-term. The team is now focusing on producing on an industrial scale. \u201cThe cost [of production] is really about the time and the effort. The material cost is relatively cheap,\u201d Zhang said.\u00a0\nYao, Zhang, and their team are currently seeking partners and stakeholders to expand their impact. \u201cResponsive and functional structures that are powered by renewable energy could play a critical role in natural contexts, for ecological purposes such as restorations and environmental monitoring,\u201d Yao said.\u00a0\nWhen faced with a problem, sometimes the best inspiration is to look to nature. That has certainly proved to be the case with these self-drilling seed carriers. And in ten years\u2019 time, maybe the future of our world\u2019s forests will be saved by a swarm of plucky, three-tailed robots falling from the sky.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/seeding-robots/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Impossible Star",
            "author": "Elizabeth Watson",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/The-Impossible-Star3-Yurou-Liu-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Yurou Liu\nMost of the stars we see in the night sky are billions of years old, their light only just now reaching us from light-years away. But what lies beyond what we can see? The reach of the universe extends far beyond the stars that we\u2019re able to observe with the naked eye.\nA team led by Florian Pei\u00dfker, a postdoctoral researcher at the University of Cologne\u2019s Institute of Astrophysics in Germany, recently discovered a newborn star named X3 whose existence defies all odds. Dubbed \u201cthe impossible star,\u201d X3 is located over twenty-five thousand light-years away and is currently undergoing early stages of stellar formation in the vicinity of Sagittarius A*, the supermassive black hole at the heart of our galaxy. Star formation so close to a black hole was thought to be theoretically impossible, but X3 persists all the same.\n\u201cI enjoy thinking about the opportunity to witness processes nobody else has seen before,\u201d Pei\u00dfker said. The paper, published in The Astrophysical Journal, is the product of two and a half years of work and explores how X3 was able to form in spite of Sagittarius A*.\nStar formation typically requires two conditions: relatively low temperatures and high gas density, neither of which holds true for the environments created by black holes. The area that Sagittarius A* occupies, known as the Galactic Center, is extremely hot and volatile.\n\u201cThis source should not exist in the first place because of the harsh environment of the supermassive black hole Sagittarius A*,\u201d Pei\u00dfker said. \u201cThe fact that we observe such a young object so close implies that this is not the only [such object]. It furthermore shows that star formation can occur, although the classical criteria are not fulfilled.\u201d\nPrevious research in the field identified clumps of silicon monoxide (SiO) gas near Sagittarius A* that may have been dense enough to permit high-mass star formation. A study in 2014 suggested that these clumps originated from the Circumnuclear Disk (CND), a ring of molecular gas that surrounds Sagittarius A*. It was proposed that some SiO clumps found within the CND either had high enough velocity gradients or had experienced a sufficient decrease in angular momentum to spiral closer to Sagittarius A* than would be otherwise possible. This process, called molecular cloud inspiraling, was thought to be part of what could foster stellar formation so close to a black hole.\nThe team behind Pei\u00dfker\u2019s study sought to build upon this work. They compiled data on X3 spanning three decades from four different telescopes, including the Very Large Telescope in Chile, to better map out the X3 system and its surroundings. The team divided the X3 system into three components\u2014designating the young stellar object as X3a and two neighboring thermal blobs as X3b and X3c\u2014and collected data about nearby stars and gas clusters. The analysis helped the team confirm the star\u2019s proximity to Sagittarius A* and better understand its origins by examining its characteristics.\nIn addition to the accretion of the SiO gas clumps discussed in previous research, the team believes that rotating regions of dust and gas in the Galactic Center, called stellar disks, may also have been key to X3\u2019s formation. The thickness of these disks would have been sufficient to lower the temperature within the region for star formation to be feasible, while simultaneously protecting the area from the black hole\u2019s radiation.\nAs they rotate, these stellar disks become dense enough to create massive gas clusters conducive to high-mass stellar formation. The team believes that one of these clusters, IRS 13, was instrumental to the formation of the X3 system. Based on the team\u2019s data points, the timeline for this formation theory aligns with our current understanding of this region\u2019s stellar history.\nPei\u00dfker was excited upon confirming X3\u2019s proximity to Sagittarius A*, but joked that the process of discovery was far more prolonged than an ordinary surprise reaction. \u201cFor six months, I ran day-in and day-out simulations to fit the data points,\u201d Pei\u00dfker said. \u201cBack then, my daughter demanded milk almost every three hours each night. So I woke up, gave baby milk to my daughter, and started simulations with the new parameters. I did this around the clock.\u201d\nPei\u00dfker hopes to build upon this work in the future to learn more about how the mechanisms of stellar formation respond to unconventional situations, which could lay the groundwork for a richer understanding of star evolution and our universe at large.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/the-impossible-star/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Carbon Sea Scene",
            "author": "Sophia Zhao",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Perimeter-Sophia-Zhao-387x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Sophia Zhao\nWrought into a cycle,\ncarbon schleps from one stop\nto the next. Perhaps I recall it\nswept along the atmosphere, or\ngathered by the ground.\u00a0\nBut in this primordial painting,\u00a0\nlumbering green bacteria\u00a0\nnose for warmth in the ocean,\ntheir cellular frames tousling the tides.\nEventually, they dissolve\u00a0\nlike salt, and carbon stretches\u00a0\ndown to retire under the sand. And in\u00a0\nthis dizzying deepsea, the muddy\u00a0\nseafloor, slumbering beneath\u00a0\ncarbon\u2019s gray lines like a shutter\u00a0\nover the dark, unsheathes\u00a0\nthe largest passage.\nSlate-streaked rocks from the byway\npull open their pores. Quietly,\u00a0\nI watch as carbon rolls out\u00a0\ntoward the surface.\n\n\nArtist\u2019s Statement\nI wanted to convey research\u2019s brilliant ability to shift preconceived notions through my poem, \u201cA Carbon Sea Scene,\u201d which offers a window into the findings of Lidya Tarhan, Jiyuan Wang, and their colleagues recently published in Nature. Inspired by their stepwise discovery of an abiotic deep-sea carbon sink, I aimed to depict my own gradual understanding of their research by crafting a metaphoric \u201cpainting\u201d representative of their study. To draw out the beauty of the authors\u2019 breakthrough, I relied on a poetic structure that \u201cstreche[d] down\u201d the page\u2014much like how the carbon cycle transcends depth\u2014to emphasize the rich information that the deepest waters hold. Phrases such as \u201ctousling the tides\u201d and \u201cseafloor, slumbering\u201d maintain a steady rhythm that crescendos with \u201cpull open their pores\u201d\u2014the most pivotal moment of this poem, and ultimately, the research of Tarhan, Wang, and their colleagues.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/a-carbon-sea-scene/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Undergraduate Profile: Charnice Hoegnifioh (YC \u201924)",
            "author": "Emily Shang",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Han_15-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Photography by Hannah Han\nA double major in Classical Civilizations and Molecular Biophysics and Biochemistry, Charnice Hoegnifioh (BF \u201924) is studying the science behind ancient makeup and skincare artifacts. Hoegnifioh was recently awarded the Edward A. Bouchet Fellowship and the $35,000 Beinecke Scholarship, which will support her academic research and post-graduate studies in the medical humanities, respectively.\nHoegnifioh fell in love with biochemistry in high school. She especially enjoyed conducting experiments involving spectroscopy, the study of the emission and absorption of electromagnetic radiation by matter. After participating in the MIT Introduction to Technology, Engineering, and Science program in high school, she realized that she wanted to devote her undergraduate studies to biophysics. At the same time, she loved Latin, and her passion for Classics was cemented by a school trip to Greece. Ultimately, she found that \u201cfollowing her passion\u201d at Yale meant loading up on five credits of Classical Civilization courses in her first year, while also researching ultrafast protein folding in the Davis Lab. She decided to pursue a double major and focus her time on honing her skills in these two areas.\nOne of Hoegnifioh\u2019s most recent classes applied spectroscopy and isotopic dating\u2014the analysis of materials based on the decay rates of unstable elemental isotopes\u2014to examine seals from the ancient Near East. Traditionally, these seals, which were ubiquitous in Mesopotamia and used for administrative and decorative purposes, were dated based on their iconography since their styles could be traced back in time. Hoegnifioh explained that studying the seals\u2019 isotopic proportions can allow researchers to determine their geographical origins. \u201cBy looking at isotopic ratios of materials, you can differentiate whether a material or mineral came from Scandinavia or the Middle East,\u201d Hoegnifioh said.\nAs an Edward A. Bouchet Fellow, Hoegnifioh will study abroad in Germany, Greece, Italy, the United Kingdom, and France this summer and visit archaeological sites to research ancient cosmetic artifacts and their effects on healing. One artifact she\u2019s particularly excited to see is an ointment tin from ancient Rome, excavated by the Museum of London twenty years ago, that still shows the preserved fingerprints of the original owner. Beyond the Museum of London, Hoegnifioh will go to the archeological museum in Frankfurt to view their exhibition of paint pots. \u201c[Cosmetics] were posited as healing outward feminine flaws but also inward flaws in women. So I\u2019ll be going to some healing sanctuaries and learning more about healing authority and what ingredients were thought [to have] curative properties,\u201d Hoegnifioh said.\nHer work will culminate in her senior thesis, tentatively titled \u201cRemedies for Roman Beauty: Curative Cosmetics during the Roman Empire.\u201d Hoegnifioh\u2019s interest in cosmetics began during her summer internship at Harvard, where she conducted a research project on the painful and poisonous aspects of beauty as a first-year student. Through her research, she learned that one of the most popular misconceptions about beauty routines in the classical world is that the ancient Romans unknowingly used lead within the cosmetic pigment. \u201cIt turns out that the Romans were actually aware that white lead was extremely toxic, as there was a treatise written that lead shouldn\u2019t be used in pipes or buildings because it will lead to poisoning. But women were still being hurt, so I wanted to investigate why these societal standards were coming before women\u2019s health,\u201d Hoegnifioh said.\nHoegnifioh cites multiple major influences in her journey throughout Yale, the first being her Latin professor from her first year, Irene Peirano Garrison, who left Yale to teach at Harvard but remained her close confidant and advisor. Peirano Garrison advised Hoegnifioh to pursue a Ph.D. in the humanities and guided her through an ongoing graduate project on makeup in antiquity. \u201cHer impact on my life is beyond words. I would not be where I am without her and her motivational presence in my life,\u201d Hoegnifioh said. She also cites Jessica Lamont, an assistant professor of Classics, and Milette Gaifman, the Andrew Downey Orrick Professor of Classics and History of Art, as other advisors who have guided her through her undergraduate studies.\nWhen asked what advice she would give to underclassmen, Hoegnifioh emphasized that double majoring in two disparate fields is achievable given proper preparation, and she hopes that no one is deterred because of the prerequisite courses. \u201cPlanning is key, but don\u2019t hold yourself to super strict standards because things change. So allow yourself that flexibility,\u201d Hoegnifioh said. \u201cRemember that imposter syndrome is real, but you are talented, and if you\u2019re at Yale, you definitely deserve to be here.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/undergraduate-profile-charnice-hoegnifioh-yc-24/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Who Were The First Cowboys In The World?",
            "author": "Jamie Seu",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/sunset-5643846_1280-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay\nStirrups. Leather boots. The Wild West. Cowboys have been a subject of fascination for centuries, appearing in every aspect of American pop culture from clich\u00e9 Halloween costumes to Hollywood blockbusters. However, the modern perception of these equestrian cavaliers encapsulates only a minuscule piece of the long, intertwining history of humans and horses\u2014a history that, according to recent archaeological findings, could date back over five thousand years.\u00a0\nWhile evidence of equine domestication has been well-documented throughout history, proof of ridership and determination of the practice\u2019s exact origins have been difficult to establish. In a paper published in Science Advances, a team of researchers from Finland, Romania, Bulgaria, Hungary, and New York analyzed over two hundred skeletal remains to unravel these mysteries. They found the earliest bioanthropological evidence of horseback riding to date in the skeletons of five Yamnaya individuals, a people noted for their expansion across Eurasia during the Early Bronze Age in the third millennium BC. Each skeleton was analyzed according to six specific criteria indicative of \u201chorsemanship syndrome.\u201d The five skeletons displayed at least four of the six traits, including wear on the pelvis and femur, stress-induced vertebral degeneration, and alterations in certain bone shapes and sizes.\nThe use of horses as a mode of transportation marked a dramatic transition in societal evolution, dictating patterns of migration and facilitating trade between previously isolated locations. So while the first cowboys were not quite the gun-toting, saloon-loving buckaroos we make them out to be, they\u2014and their speedy, four-legged sidekicks\u2014may have been some of the most influential figures in history.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/qa-who-were-the-first-cowboys-in-the-world/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: What is the World\u2019\u2019s Most Efficient Form of Urination?",
            "author": "Victor Nguyen",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/insect-4369745_1280-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay\nHas inspiration ever hit you while you were on the toilet? For scientists studying the potty period of the glassy-winged sharpshooter, a half-inch-long insect in the Cicadellidae family, a revelation between physics and biology was born. Known to be serious agricultural pests, sharpshooters relieve themselves by forming a small droplets of urine at their anal styluses, which are an appendages involved in excretion. Eventually, theis droplets grows to a diameter of 0.725 millimeters, and the anal styluses launches theeach particulates repeatedly, accelerating up to forty times the force of gravity.\nSharpshooters developed this bathroom behavior due to their water-heavy diets. The leafhoppers feed on plant xylem sap, which has a small nutrient-to-liquid ratio. As a result, they drink up to three hundred times their body weight. A closer analysis of this phenomenon, published by researchers at Georgia Tech in Nature Communications, showed that sharpshooters developed this biological mechanism to conserve energy given their small size and energy output.The sharpshooter\u2019s urinary facilities mark a notable discovery because they are the first observation of superpropulsion in a biological system, a phenomenon in which a projectile moves faster than the launcher that propelled it. Applications of the sharpshooter\u2019s mechanisms have a future in electronics. Researchers investigating the sharpshooters foresee how the insect\u2019s energy-efficient solution can be used to remove solvents in micro-manufacturing or to eliminate water from complex surfaces. This intersection of the physical and biological sciences sets a precedent for finding unorthodox answers. Wherever and whenever inspiration or the need to relieve strikes, innovation may soon follow.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/qa-what-is-the-worlds-most-efficient-form-of-urination/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: The Darkness Manifesto",
            "author": "Faith Pena",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/australia-melbourne-landscape-night-500x297.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Wallpaper Flare.\nYou\u2019ve probably flown over a city at night and noticed the bright glow of lights staring back at you through the airplane window. As intriguing and surreal as it feels to see such a sight, these lights are disrupting the behavioral patterns and circadian rhythms of many organisms across the globe, from insects and bats to bioluminescent creatures and humans. In his newly released book, The Darkness Manifesto, Johan Ekl\u00f6f describes the myriad consequences related to light pollution and urges readers to defend the darkness.\u00a0\nThe majority of nature\u2019s activities, such as mating and pollination, occur at night because eighty percent of all organisms are nocturnal. Humans are diurnal organisms (active during the day) and, as a result, have resorted to artificial light to extend our activities into the night. Ekl\u00f6f claims that we have entered a new era: the Anthropocene, in which humans have had a critical impact on the Earth\u2019s ecosystems. In particular, he argues that man-made sources of light are disrupting Earth\u2019s natural rhythms by generating light pollution.\nEkl\u00f6f devotes several chapters to describing the ways in which light pollution has thrown off the reproductive cycles of organisms across the planet. For instance, he claims that the pollination rate of some plants like apple trees has slowed down because moths, which serve as pollinators, get easily confused by artificial sources of illumination. For animals like our beloved friend Nemo, the consequences of light pollution are as severe as eggs failing to hatch since clownfish larvae rely on the darkness to signal when it is time to break free from their sacs. Without complete darkness at night, the behavioral patterns of organisms are becoming increasingly out of tune, and as a result, the ecosystems they inhabit are being destroyed.\nBut it isn\u2019t just plants and animals that are affected. We humans are facing serious consequences as well. Because humans aren\u2019t nocturnal, we rely on our natural sleep cycles to rest. But true rest is difficult to achieve when we are using our phones too late into the night. Blue light from our phones tricks our brains into thinking it is still daytime, so we produce insufficient levels of our natural sleep hormone, melatonin, making it difficult to fall asleep. Similarly, Ekl\u00f6f states that people who work night shifts are at a higher risk of hormonal cancers such as breast and prostate cancer. We can prevent a multitude of serious health conditions by restoring our natural circadian rhythms and avoiding light at night.\nIn his manifesto at the end of the novel, Ekl\u00f6f calls upon readers to cherish and learn more about the darkness due to its importance in our behavioral patterns. Some countries, like France, are already moving towards decreased use of artificial light at night, and Ekl\u00f6f hopes that more countries will follow suit. \u201cThe darkness is not the world of humans. We\u2019re only visitors,\u201d Ekl\u00f6f reminds readers. It\u2019s not too late to change our habits and start protecting the darkness.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/science-in-the-spotlight-the-darkness-manifesto/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Quantum Cryptography",
            "author": "Matthew Dobre",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/physics-6936704_1280-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nIn 1933, Nobel Prize-winning chemist Sir William Bragg said, \u201cLight brings us the news of the Universe.\u201d Though it would take decades before scientists better understood the properties of light, researchers today are devising ways to utilize this resource to store information by uniting information theory and quantum mechanics, a subfield of physics that governs the behavior of photons, or light particles.\nAmong the general public, anything that includes the word \u201cquantum\u201d elicits a degree of awe. Even Einstein was troubled by one of the theoretical implications of quantum mechanics, which he called \u201cspooky action at a distance.\u201d Today, Einstein\u2019s boogeyman is called entanglement. When two particles are entangled, their quantum states, which may include properties like geometric orientation, angular momentum, and energy, are inextricably linked. A change in the state of one particle will immediately affect its twin. For example, consider a pair of entangled mittens: one is given to a lab assistant named Bob, and the other to his partner, Alice. No attempt is made to observe either mitten. Bob is then sent to a neighboring solar system. Up to this point, nobody in the universe knows the handedness of either Alice\u2019s or Bob\u2019s mittens. In fact, by the postulates of quantum mechanics, their handedness will be indeterminate until they are observed. If this experiment was repeated many times, it would reveal that when Alice observes her mitten, she will have a right-handed mitten half the time, and a left-handed mitten the other half. Eerily, Bob\u2019s mitten will instantaneously acquire the opposite handedness, even though he\u2019s two million light years away from Alice.\nThese same principles of entanglement have been used to send data over thin air. In 2015, a research team in Vienna transmitted information by changing the relative angular momentum, or \u201ctwistiness,\u201d of entangled pairs of photons. In quantum mechanics, angular momentum can only take on values in discrete quantities, separated by a constant \u2018step size.\u2019 These entangled particles stored information by acting analogously to computer bits, which can only have a value of zero or one. In the experiment, each twist served as an alternative channel of communication, enabling ultra-high-speed data transmission.\n\u00a0A group of physicists from the Beijing Institute of Technology (BIT) recently expanded on this research to create an unprecedented storage system. Instead of transmitting information via distinct light channels, they stored several unique data sets at a time by creating holograms made of entangled photon pairs. Though holograms seem to be a quintessential element of science fiction, they already have applications in everyday life. Used as a security feature in credit cards, passports, and banknotes, holograms are stacks of slightly misaligned images that are difficult for a computer to read. The physicists generated holograms made of twisted, entangled photon pairs by using \u03b2-barium borate crystals to manipulate the relative angular momentum between the particles, creating corkscrew patterns of light that resemble rotini pasta. To prove their setup worked, the researchers encoded words in the holograms and used twisted light to reconstruct the data by measuring the coincidence between the particles\u2019 angular momentums.\nBy increasing the number and diversity of twists in a single hologram, the system securely encrypted information since the odds of guessing the degree and direction of the twisted light\u2019s path became very low. For instance, seven distinct twists, which is a relatively small system, led to millions of potential combinations.\nMany quantum technologies are sensitive to noise. However, the researchers asserted that entanglement can diminish the effect of classical noise sources, which include mechanical vibrations and thermal fluctuations. Thus, the decrypted output was of a higher quality compared to other similar systems.\nThis technology, however, is still in its infancy. Utilizing six forms of entangled light, the group was able to decode an image of the acronym \u201cBIT\u201d by measuring the orbital angular momentum states of the particles over the course of twenty minutes, which is far from practical. Fortunately, the group is optimistic that these difficulties can be overcome with improvements in quantum technology. Though holographic data storage is still in a nascent stage, today\u2019s scientists are utilizing techniques that the founders of modern physics laid the groundwork for\u2014but may not have even understood.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/quantum-cryptography/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Fatal Attraction: Using Fly Pheromones Against Disease",
            "author": "Cindy Mei",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Fly-Pheromones-Court-Johnson-500x349.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Court Johnson.\nFrom evoking long-forgotten memories through nostalgic scents to detecting imminent danger through noxious odors, smells hold undeniable power. Our sense of smell has served as a prime mechanism for survival since the beginning of time. Much of the work in the lab of John Carlson, a Yale professor of Molecular, Cellular, and Developmental Biology, is dedicated to studying the intricate mechanisms of Drosophila (fruit fly) olfaction: how do these insects detect and behave in the presence of volatile pheromones? An example of chemosensation, these pungent odorants\u2014chemical compounds that have a smell\u2014produced by organisms facilitate sexual attraction and mating by affecting behavior. The lab is interested in studying chemosensation as a method to control populations of insects that spread disease\u2014such as the tsetse flies, insects that are responsible for spreading African trypanosomes, the causative agents of African sleeping sickness in Sub-Saharan regions.\n\u00a0In a paper published in Science earlier this year, a team of researchers conducted a study to find natural odorants that may control the behavior of tsetse flies. Led by Shimaa Ebrahim, a postdoctoral researcher in the Carlson lab, the project was conducted in collaboration with Hany Dweck, an associate scientist in the Carlson lab, and Brian Weiss, a senior research scientist at the Yale School of Public Health. \u201cI fell in love with the [tsetse fly],\u201d Ebrahim, who studies the courtship behavior of Drosophila, said. Weiss echoed Ebrahim\u2019s fascination, pointing out behaviors unique to the tsetse flies, such as the live birth and nurturing of their young, in contrast to the majority of insects, which lay eggs.\u00a0\nImportantly, tsetse flies feed exclusively on vertebrate blood, leading to the transmission of Trypanosoma brucei (trypanosomes), a classification of protozoan parasites that cause African sleeping sickness and nagana in humans and domesticated animals, respectively. These diseases have devastating effects: nagana is responsible for an average loss of 4.5 billion dollars in resources every year in Africa. If left untreated, African sleeping sickness has a one hundred\u00a0 percent mortality rate. Unfortunately, access to treatment is not available everywhere. \u201cMost of the drugs used to treat sleeping sickness are arsenic-based and horribly toxic. Very recently, there\u2019s been some newly-developed medications, and they\u2019re much less toxic\u2014but they\u2019re much more expensive,\u201d said Weiss, who studies tsetse flies and their associated microorganisms.\nTo find alternative solutions, the researchers turned their attention to preventative measures. According to Weiss, the best solution to reduce fly populations is to use traps, as they are cheap and effective. However, not much is understood about the chemical signaling of tsetse flies, which may be key to luring the flies to traps. \u201cIf you want to control any insect that could cause disease or damage to any crop, you have to study their behavior to find the way to control this insect,\u201d Ebrahim said.\u00a0\nThe role of smell in mating\u00a0\nThe researchers utilized the tsetse fly species Glossina morsitans. While Glossina fuscipes is the most abundant species in Kenya, they are difficult to rear in the insectary, according to Weiss. To examine possible odorants in sexual attraction, the researchers first studied tsetse fly mating behaviors. When paired together, G. morsitans males initiate mating with G. morsitans virgin females within seconds, and copulation continues on average for an hour. However, this reaction was not observed when G. morsitans males were paired with mated females, suggesting that there may be a difference in chemical signaling that results in the male\u2019s behavioral responses.\nTo determine whether differences in mating are driven by olfaction, pheromone extracts were obtained from the exoskeleton, also called the cuticle (the layer that covers the extracellular surface of the fly), of male and female flies that were soaked and gently shaken in hexane for ten minutes. Dummy tsetse flies made out of yarn were sprayed with these extracts and placed in a container with male G. morsitans, and a measure of attraction was determined by the percentage of males that initiated mating and stayed attached to the decoy flies for more than five minutes. However, the males were not attracted at all, suggesting that any odorants associated with mating are stored beyond the cuticles.\u00a0\nAfter soaking another set of tsetse flies in hexane for twenty-four hours, it was observed that males were attracted sixty percent of the time to dummies sprayed with extracts from virgin females and twenty-seven percent of the time with extracts from mated females, with no response observed with male extracts. This observation indicates that there may be a difference in the composition of the extracts that made male flies more attracted to virgin than mated female G. morsitans. The longer soaking time may also explain why these compounds were not detected as potential pheromones in earlier research.\nDiscovery of a key pheromone\u00a0\nTo determine if differences in compound composition were responsible for mating behaviors, the researchers obtained the chemical profile of the extractions via gas chromatography-mass spectrometry (GC-MS), which separates and detects different compounds. GC-MS identified three fatty acids and three fatty acid methyl esters that were not present in the ten-minute hexane immersion, which suggests the pheromones stored in internal glands may play a part in facilitating attraction.\u00a0\nTo test this hypothesis, the researchers repeated the previous experiment by spraying the dummy flies with each of these six compounds. They found that the male flies were strongly attracted to certain compounds that are present in higher levels in virgin females, such as methyl palmitoleate (MPO)\u2014which attracted G. morsitans males eighty-seven percent of the time even when diluted\u2014methyl oleate (MO), and methyl palmitate (MP). The male fly stayed attached to the dummy for a prolonged period of time, suggesting that these compounds also act as arrestants\u2014halting all motion\u2014to prevent premature interruption of mating. Clearly, smell seemed to play a powerful role in mating!\nNext, the researchers sought to investigate cellular mechanisms that may facilitate the observed behavioral responses. Removing G. morsitans males\u2019 antennae eliminated their attraction response, suggesting that the observed behavioral responses in mating are facilitated by scent. Furthermore, research has suggested that volatile odors are detected via the trichoid sensilla, a sensory organ located in the antenna of the fly.\u00a0\nIn a method called single-sensillum electrophysiology, the researchers obtained recordings of trichoid sensilla response to odors detected in the air by antenna. Initially, only MPO elicited excitatory responses from both sexes, but particularly from males. After reducing the distance from which the odor was delivered, activation in neurons was seen with MP, MO, and MPO, correlating with the behavioral results observed in earlier experiments. However, there\nwas little to no response in olfactory neurons to these six compounds in G. fuscipes, another\ntsetse species that is the prominent vector of trypanosomes in east Africa. This finding suggested\nthat these pheromones are specific to G. morsitans mating mechanisms. Indeed, it was found that G. morsitans males made no attempt to mate with untreated G. fuscipes females; however, when G. fuscipes females were sprayed with MPO, the males began to engage, suggesting that MPO may act as an aphrodisiac, a stimulant for sexual desire, for G. morsitans males.\nCould infection change mating?\nThe last study examined if these findings held for tsetse flies infected with trypanosomes, which is the ultimate target for traps to prevent the spread of African sleeping sickness. There were no changes in single-sensillum electrophysiology, meaning there was no change in neuronal response. However, there were significant behavioral changes observed in mating.\u00a0\nWhen paired together, uninfected virgin female G. morsitans mated with infected and uninfected males at the same frequency. However, uninfected virgin male G. morsitans mated with uninfected females one hundred percent of the time over infected females, suggesting that there may be a compound that lowers the sexual receptivity of infected females and acts as a repellent against G. morsitans males. The group hopes to further study twenty-one compounds that were identified in GC-MS as specific to infected flies. \u201cI\u2019m interested to study if this compound is produced as a defense against the parasites,\u201d Ebrahim said.\u201cWe don\u2019t know if those compounds were produced by the tsetse fly in response to an infection, or maybe they were produced by the parasites themselves,\u201d Weiss said.\nHarnessing the power of pheromones\nThe results of the study suggest that MPO acts specifically as an attractant, aphrodisiac, and arrestant on G. morsitans males to activate circuits that mediate olfactory attraction, sexual desire, and the halting of movement, respectively. The usage of MPO in traps holds great promise from both an environmental and economic perspective. \u201cCompounds from the fly itself [\u2026] will be less toxic if we want to use it in the field compared to other compounds like DEET,\u201d Ebrahim explained. These natural compounds are also much less expensive than DEET, which makes implementation of tsetse fly control more realistic in developing countries.\u00a0\nIn the future, the researchers hope to test MPO in Kenya with collaborators, who are currently using tsetse fly host odors such as cow urine as attractants. \u201cIf we combine MPO with natural host odors, it might increase the efficiency of control for a trap,\u201d Ebrahim said. \u201cA more specific odor might attract more flies and reduce the number of cases of infection by trypanosomes.\u201d\u00a0\nHowever, there are challenges validating field work with lab work, since the flies in the experiment are different from those found in a typical African savanna. In addition, in the real world, there are many fluctuating and uncertain factors, according to Ebrahim. Despite these challenges, the group remains undeterred, and their passion stays vibrant. \u201cYou will have to be optimistic and creative for the biggest experiments you design,\u201d Ebrahim said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/fatal-attraction-using-fly-pheromones-against-disease/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Alumni Profile: Amymarie Bartholomew (YC \u201913)",
            "author": "William Archacki",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Han_2-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Photography by Hannah Han.\nThis June, graduates from Yale\u2019s Class of 2013 will flock back to campus for their ten-year reunion. For Amymarie Bartholomew (YC \u201913), the trip will be as simple as a walk down Science Hill from her new lab at Kline Chemistry Laboratory. Appointed an assistant professor in January of this year, Bartholomew now works in the chemistry department alongside many of the faculty members she had as teachers and mentors during her time as an undergraduate.\nBack and better than ever, Bartholomew is a doctorate-wielding chemist whose work focuses on synthesizing stimuli-responsive inorganic materials. The graduate-level course she teaches, \u201cMolecular Materials,\u201d reflects the aims of her research: to produce materials that change their physical, magnetic, and electrical properties in response to interactions at the molecular level. For instance, the absorption of light might change the way bonds form, or an increase in temperature might alter the way electrons behave in a magnetic field.\nBartholomew thinks of her work as a search for new ways to apply these tiny molecular changes to the creation of useful materials. \u201cI\u2019ve always had a lot of ideas for things to synthesize and things to try, and I think in chemistry\u2014as well as in other fields\u2014it\u2019s really about just trying things,\u201d Bartholomew said. \u201cBeing able to see which of my ideas hold promise and which of them are able to move forward\u2014I think that\u2019s really exciting.\u201d\nOne project the lab group is working on seeks to use the molecule azobenzene to produce electricity from sunlight. For a long time, scientists have known that azobenzene can switch between two shapes: one that bends back on itself and one that is long and straight. When high-energy ultraviolet light strikes azobenzene crystals, they tend to flex and deform as their many constituent molecules switch between the two shapes. Bartholomew\u2019s research is taking this behavior of azobenzene to new heights. By creating larger molecules that contain multiple azobenzene components bonded at special angles, Bartholomew and her collaborators have produced a material that rotates around a central axis when exposed to visible light. Under a microscope, crystals of this material appear to continuously roll like long axles, performing the kind of mechanical work that can generate electricity. Bartholomew hopes that this single-step conversion from solar energy to mechanical work will provide a starting point for more efficient solar power.\nBartholomew also focuses on the kinds of stimuli-responsive changes that could pave the way for new nanoscale electronics. Like the azobenzene complexes, most of Bartholomew\u2019s materials are crystalline in structure. Not only does the ordered pattern of crystals make for useful physical properties, but it also provides chemists with an insight into how and why stimuli responses occur. \u201cIf you ever need to find me, I\u2019m probably trying out crystals on the diffractometer in the crystal lab,\u201d Bartholomew said. \u201cI love being able to make something, crystallize it, and then use those crystals to determine the three-dimensional structure of what I\u2019ve made.\u201d\nThe research that Bartholomew has carried out in her first months as a professor has largely taken place thanks to generous colleagues who have lent their research spaces to her. After all, it takes time to acquire all the equipment necessary to run a cutting-edge chemistry lab. Bartholomew\u2019s own space is just a short walk from the lab of chemistry professor Nilay Hazari, where Bartholomew conducted research as an undergraduate. Bartholomew explained that Hazari acts as a model for her now that she has the responsibility of mentoring. Bartholomew also credited Professor Kurt Zilm, the instructor of her undergraduate physical chemistry class, for showing her how to teach chemistry. \u201cI think pedagogically I definitely took a lot from that class\u2014hopefully. You\u2019ll have to ask the graduate students in my class now if that\u2019s the case, but that\u2019s the aim anyway,\u201d Bartholomew said.\nNow with the classroom and the lab under her control, Bartholomew is putting her own creativity to the test. Fortunately, Bartholomew has an endless stream of fresh ideas in her niche of synthetic chemistry. \u201cI sit at home and think of new things we should try to make, and I have to sketch them out at like ten p.m. and send myself a weird email with two sentences of an idea,\u201d Bartholomew said. To handle the strange world of molecular materials, there may be no better approach.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/alumni-profile-amymarie-bartholomew-yc-13/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Tracking Carbon\u2019s Underwater Dive",
            "author": "Tori Sodeinde",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Tracking_carbon_dive-03-Luna-Aguilar-500x350.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Luna Aguilar.\nCarbon: it\u2019s in the atmosphere, the oceans, the solid Earth, and even in us. This element is found all throughout Earth\u2019s environment and exists in numerous chemical forms. One form of carbon, calcium carbonate (the major component of limestone and chalk), is the main form in which carbon in the ocean and atmosphere is returned to the earth. The precipitation pathways of carbonate minerals in the ocean are referred to as the marine carbonate factory and greatly influences abiotic and biotic geochemistry, including ocean acidity.\u00a0\nDespite its important role in ocean chemistry, there has been little consensus on how the marine carbonate factory has changed throughout Earth\u2019s history. It is challenging to find well-preserved and reliable markers for its status over billions of years. However, Lidya Tarhan, an assistant professor of earth and planetary sciences, and Jiyuan Wang, an Agouron postdoctoral fellow in Tarhan\u2019s research group, along with colleagues from Yale\u2019s Department of Earth and Planetary Sciences, Northwestern University and University of Miami, recently developed a novel technique to trace the history of the marine carbonate factory. By measuring the ratios of different isotopes (atoms of the same element with different masses) of strontium within carbonate samples, they uncovered a more definitive history of carbonate precipitation and mineral saturation states from the ancient Precambrian to the recent Phanerozoic Eon, and published their findings in Nature. During the Precambrian, contrary to previous conjecture, a major proportion of carbonate was buried in the deep sea through abiotic processes, rather than in the shallow marine environment like reefs that dominate most of the Phanerozoic marine carbonate factory.\nThe Marine Carbonate Cycle\nThe marine carbonate factory is one piece of a bigger puzzle, the carbon cycle, which encompasses the cycling of carbon through nature. The carbon cycle can be divided into short-term and long-term cycles. The short-term carbon cycle involves living organisms. Photosynthesizers, largely phytoplankton and algae, absorb carbon dioxide into their cells and use it to generate carbohydrates through photosynthesis. The carbohydrates can be broken down later to provide energy, releasing carbon dioxide back into the ocean and atmosphere.\nIn the long-term carbon cycle, rain combines with atmospheric carbon dioxide to form carbonic acid, which falls to the earth and slowly dissolves bodies of rock. This releases ions, including calcium, that are then carried through rivers to the ocean, where they combine with dissolved carbonate ions to form calcium carbonate, a solid in water. This process is called carbonate precipitation and can occur abiotically (without living organisms).\nHowever, many marine organisms also use calcium and carbonate ions to build their shells. When they die, these shells and other sediments form rock, sequestering carbon within the ocean floor and the geologic record. Some bacteria can also facilitate precipitation of calcium carbonate in their surroundings\u2014for instance, by taking up carbon dioxide during photosynthesis. Regardless of the route, precipitation of dissolved carbonate into solid calcium carbonate incorporates other ions including strontium, an alkaline earth metal. This study exploited the incorporation of strontium into carbonate precipitates to gain insight into the history of the marine carbonate cycle.\nStrontium in the Marine Carbonate Factory\u2019s History\nThe metal strontium has multiple stable isotopes, including strontium-88 and strontium-86. When carbonate precipitation occurs in the ocean, it incorporates trace amounts of strontium, but the two isotopes are incorporated at different ratios depending on environmental conditions. Strontium-88, the heavier isotope, is incorporated into carbonate minerals less often than the lighter strontium-86, but higher saturation of carbonates in the ocean leads to both faster precipitation and an even lower strontium-88 to strontium-86 ratio (\u03b488/86Sr) in carbonates. The ratio of these strontium isotopes in carbonates, in particular, is a novel proxy for the history of the marine carbonate cycle because this signature is tied closely to precipitation rates, rather than\u2014like many other isotope systems\u2014seawater temperature or the type of carbonate mineral in which strontium is incorporated. Thus, strontium stable isotope ratios can serve as a marker for changes in the marine carbonate factory, specifically the rate of carbonate precipitation which, in turn, reflects marine carbonate saturation state at the time of precipitation.\u00a0\nHowever, using stable isotope measurements has not previously been possible due to technical limitations. Luckily, with the resources of the Yale Metal Geochemistry Center, the researchers were able to develop a novel method using mass spectrometry to measure stable strontium isotope ratios with five-decimal place precision, according to Wang. \u201c[Our work] opened the door toward using the stable strontium isotope proxy to reconstruct long-term records in Earth\u2019s history\u2014and will, we hope, allow us and others to tackle new and exciting questions down the road,\u201d Tarhan said.\nUnexpected Sources of Carbonate Precipitation\nWhile shallow regions of the ocean like reefs and carbonate platforms are commonly thought of as hotspots for carbon deposition, which is true today, Tarhan and Wang found an unexpected phenomenon during the Precambrian, the interval preceding the explosion of organisms that created calcium carbonate shells around 540 million years ago. They found evidence of an unforeseen level of abiotic contribution to the marine carbonate cycle in deep ocean waters during this time. \u201cA major part of carbonate was buried outside of the shallow marine environment during Earth\u2019s early history, which is radically different than previously envisaged,\u201d Wang said.\nWhen tracing the ratios of strontium isotopes in carbonate samples formed in shallow seafloor sediments, the researchers found a marked decrease in \u03b488/86Sr values during the transition between the Precambrian era and the Phanerozoic era (the interval in which biomineralizing animals caused skeletal carbonates to become a large contributor to the marine carbonate factory). This decrease implies slower precipitation and a lower carbonate saturation state in Phanerozoic relative to Precambrian oceans, which is consistent with the increase in precipitation due to calcifying animals in the Phanerozoic period.\u00a0\nAdditionally, the Precambrian \u03b488/86Sr record also suggests the unexpected presence of a large, non-skeletal carbonate sink within the Precambrian deep ocean\u2014one formed as a result of the activities of bacteria living in seafloor sediments devoid of oxygen. This condition was likely characteristic of much of the Precambrian deep seafloor, leading to carbonate precipitation in the spaces between grains of previously deposited sediment.\nIt is difficult to directly confirm the ancient history of the deep oceans, as the constant shifting of Earth\u2019s tectonic plates leads to subduction, plates layering over each other on the\u00a0 deep seafloor, which would have contained this missing piece of the Precambrian carbonate record. \u201cThe deep oceans have been something of a \u2018black box\u2019 for much of Earth\u2019s history, due to the continual loss of deep-sea sediments with seafloor subduction,\u201d Tarhan said. However, this study has unveiled an aspect of this murky history. \u201cThe deep sea, among other muddy stretches of the ancient seafloor, may have been an important locus of carbonate sediment accumulation prior to the emergence of any carbonate-biomineralizing organisms, and this was the baseline state until biomineralizing animals evolved in the shallow oceans approximately 540 million years ago,\u201d Tarhan said.\nLooking to the Future\nThis new research challenges past assumptions about the main players in the marine carbonate factory and helps fill in the history of oceanic geochemistry prior to the evolution of marine calcifying animals. This research could also be used to predict the future. As humans continue to pump carbon dioxide into the atmosphere, the increased emissions alter the natural carbon cycle. While this study focused on Earth\u2019s ancient history, the mechanisms underlying the carbon cycle remain the same, so clarifying the mechanism of past changes can help us extrapolate how human actions may now affect the carbon cycle.\u00a0Tarhan\u2019s lab is currently trying to quantify the behavior of strontium isotopes as it relates to changing seawater carbonate chemistry under ongoing climate change. \u201cThe discoveries in this study enable us to better understand how carbon cycled among Earth\u2019s different layers and how Earth maintained its habitability under different levels of CO2,\u201d Wang said. \u201cThis is crucial information that can be used to perceive and predict the behaviors of our Earth and oceans [during] contemporary climate change.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/tracking-carbons-underwater-dive/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A New Approach to an Old Foe",
            "author": "Johnny Yue",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/614C02C8-6BC6-4E6C-B3B9-31F245B09347-375x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Naiem Nassiri\nThoracoabdominal aneurysms (TAAAs) occur when the aorta\u2014the artery carrying blood from the heart to the rest of the body\u2014balloons and weakens, which can lead to internal bleeding. Up until the past few years, TAAA surgery required highly invasive surgeries with high chances of debilitating side effects, including paraplegia, or lower body paralysis.\u00a0\nEndovascular Debranched Aortic Repair (EDAR), a new surgical technique performed at Yale, was first invented by Patrick Kelly of Sanford Health in South Dakota. Vascular surgeon Naiem Nassiri learned about the technology under Kelly\u2019s guidance. \u201cI built six prototypes on my breakfast table, and some took up to six hours to build,\u201d Nassiri said. Together with Prashanth Vallabhajosyula, director of Yale\u2019s Aortic Institute, the medical duo has implemented EDAR to treat the weakened aorta in a minimally-invasive manner. \u201cTAAA surgery used to involve patients getting their entire chest, abdomen, and diaphragm split open, and the procedures were attached to high morbidity and mortality,\u201d Vallabhajosyula said.\u00a0\nBut EDAR simply involves a stent that is inserted into the body through two small penetrations made in the groin using a needle. The stent, compressed in a tube, is delivered through blood vessels to the aorta. \u201cWe\u2019ve done about sixteen cases and haven\u2019t encountered any paraplegia cases,\u201d Vallabhajosyula said.\nEDAR shows tremendous promise to treat TAAAs. \u201cWhat is wonderful about this platform is that at any time, you can decide to stop the operation and bring the patient back at a later date,\u201d Nassiri said. \u201cThis minimizes the harm for the patient.\u201d With the surgeons\u2019 expertise, TAAA patients now have new hope for better outcomes.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/a-new-approach-to-an-old-foe/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Taking a Peek at Pandora\u2019s Cluster",
            "author": "Ignacio Ruiz-Sanchez",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "The black background of outer space is studded with white bursts of light\u2014some are sharp lines, while others are surrounded by a white hazy glow. In the foreground sits a star from our own galaxy, shining among a giant group of galaxies located four billion light years away from Earth: Pandora\u2019s Cluster. After the launch of NASA\u2019s James Webb Space Telescope, we\u2019ve been fortunate to witness images from the distant corners of our universe, but these are the first, detailed images of Pandora itself.\nScientists have been monitoring this galaxy cluster for over a decade, utilizing the most advanced technology available, mainly the Hubble Space Telescope, to get a glimpse of Pandora. However, none have achieved as much as the Webb Telescope to capture stellar pictures of the cluster, unveiling never-before-seen details. The new images were a tireless effort by the Ultradeep NIRSpec and NIRCam ObserVations before the Epoch of Reionization (UNCOVER) program, whose team of astronomers included several Yale scientists. The team captured thirty hours of data using Webb\u2019s Near-Infrared Camera (NIRcam), with wavelengths capable of detecting the earliest stars in the process of formation and nearby galaxy populations. What\u2019s even more exciting is that the telescope captured Pandora as a megacluster, meaning the combined mass of the four galaxies creates a powerful gravitational lens to expose other very large distant galaxies in the early Universe.\nWhile strikingly beautiful, these images are not just potential dorm-room posters or lock screens\u2014this achievement could ultimately help us discover other hidden galaxies, further unraveling the mysteries of our Universe.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/taking-a-peek-at-pandoras-cluster/",
            "captions": []
        },
        {
            "title": "Sink or Swim",
            "author": "Lea Papa",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/19752898086_12b3f731c2_o-500x281.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Sarah T. Friedman\nWhen we think about global warming, many of us visualize melting ice caps or lament the threat of mass extinction, undoing the work done by millions of years of evolution. But could climate change also threaten the forward progress of evolution? A recent study investigating the role of changes in water depth in the rapid speciation, or formation of new species, of fish in polar latitudes strongly suggests that yes, global warming could affect evolution\u2019s progress. The study specifically points to the potential negative impact of warming waters on the ability of fish to rapidly speciate and, therefore, further their evolution.\u00a0\nPublished by Yale researchers Sarah Friedman and Martha Mu\u00f1oz, the paper addresses the relationship between the remarkably rapid speciation rates of fish in polar latitudes and the ability of those polar fish species to move through the \u201cdepth gradient\u201d\u2014the intervals of water depth populated by different fish species in a body of water. By mapping the evolution of depth occupation across species of fish, the researchers were able to support their hypothesis that the ability of fish species to traverse water depths may act as an engine for biodiversity.\nFriedman was prompted to explore this idea after reading a paper that revealed that despite the higher biodiversity among fish in tropical regions, fish in the polar regions show faster rates of speciation. This discovery was both utterly surprising and intriguing to Friedman, who worked with Mu\u00f1oz\u2014an assistant professor of Ecology and Evolutionary Biology at Yale\u2014to pursue research that could further probe this finding. \u201cWhen you look at the global scale, you\u2019re going to see more species in the tropics,\u201d Friedman said. \u201cBut what they found was that speciation rates are actually fastest towards the poles, which is [a] really interesting and counterintuitive result.\u201d\nAfter intensive research into the prior literature on this phenomenon, Friedman hypothesized that shifting water depth may be the mechanism for rapid fish speciation in polar latitudes. The presence of deep waters in polar latitudes seemed to lower the barrier for fish to move across the depth gradient, allowing for more physical space between fish groups. This separation promotes more rapid speciation than in shallow, lower latitudes, where more barriers prevent fish from creating space between one another, thus slowing speciation.\nTo investigate their hypothesis, the researchers used phylogeny, a common evolutionary biology technique that visualizes the ancestry and genetic relationships between different groups through the creation and analysis of phylogenetic trees. Because of limitations caused by the COVID-19 pandemic, Friedman and Mu\u00f1oz analyzed existing data on fish evolution in this meta-analytic approach to reach their conclusions about biodiversity and speciation rates in polar-region fish\u00a0\nBy the end of their extensive research, the team\u2019s findings supported their hypothesis. \u201cI think it was really reassuring to find what I hypothesized to be true,\u201d Friedman said. \u201cThose clades that are rapidly speciating are also those ones that are moving across the depth gradient pretty rapidly as well.\u201d The relationship between rapid speciation rates and the ability to traverse a wider depth gradient explained the surprising speciation rates in the polar latitudes.\u00a0\nFriedman and Mu\u00f1oz also consider other individual findings from their study to be particularly intriguing, including one that suggested a pipeline of biodiversity exchange across latitudes, particularly from polar to tropical latitudes. \u201cIn fact, what we discovered is that speciation is faster at the poles, reflecting greater depth transitions, and that diversity is later transported to the tropics, so the polar regions are actually supplying species to the tropics,\u201d Mu\u00f1oz said.\u00a0\nWhat could these findings mean for biodiversity and speciation in the era of extreme climate change and warming waters? According to Dr. Friedman, the effects will be disastrous. Because of the constant cold of the poles, there is little difference in water temperature throughout the depth gradient, meaning that the fish species through the gradient in the poles are similarly adapted for temperature, which contributes to how easily polar fish move between shallow and deep water. \u201cAs temperatures, and especially those surface temperatures, start warming up due to global warming, it\u2019s going to increase the barriers to moving along that gradient,\u201d Friedman said. Could global warming stall evolution? According to the researchers, this may be an extreme conclusion. Nevertheless, their research opens our eyes to a previously unknown harm of climate change, re-emphasizing the need for meaningful action.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/sink-or-swim/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Dynamic Duo",
            "author": "Casey McGuire",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/unnamed-2-500x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Yazhe Wang.\nIt\u2019s a diagnosis that strikes fear in the hearts of patients and their loved ones: glioblastoma, a type of brain cancer that is notoriously aggressive and difficult to treat. However, hope may be on the horizon, as researchers from Yale and the University of Connecticut (UConn) have developed a groundbreaking new therapeutic approach for those battling this devastating disease. The treatment loads tiny particles called nanoparticles, developed by Professor Mark Saltzman\u2019s lab at Yale, with proteins that target the tumor cells, designed by Professor Raman Bahal and his team at UConn. Currently, the best treatment for glioblastoma is the removal of the bulk of the tumor during surgery, followed by radiation and chemotherapy. However, the median survival is only fifteen months. This new treatment combines two cutting-edge technologies, nanoparticles and peptide nucleic acids, to tackle this lethal disease and provide hope for future patients.\nNanoparticles are particles that can infiltrate cells due to their small size. Saltzman\u2019s lab has extensively researched nanoparticles as a vehicle to deliver drugs to specific areas of the human body. The polymer-based nanoparticle developed by his team can penetrate the brain and reach the tumor cells. Saltzman underlined the importance of the nanoparticles remaining at the tumor site and continuing to deliver the drug over time. \u201cYou can only administer the therapy after surgery directly into the brain and you cannot re-administer, but we want the therapy to last a long time,\u201d Saltzman said. \u201cWe designed nanoparticles with certain properties to allow for this behavior.\u201d The particles have an affinity for tumor cells due to their bioadhesive coating, and they will stick around to slowly release the drug inside the cells.\nThe drugs encapsulated in the nanoparticles were designed by Bahal, who was a postdoctoral researcher and collaborator of Saltzman\u2019s at Yale before moving to UConn. Bahal\u2019s team developed peptide nucleic acids, or PNAs, to be loaded inside the nanoparticles. These proteins are synthetically constructed to be complementary to a certain sequence of microRNA, or short strands of RNA that regulate gene expression in cells. The tumor cells of glioblastomas overexpress certain microRNAs, leading to more tumor growth and decreased patient survival. Past studies suggest that two of these upregulated microRNAs, miR-10b and miR-21, are the most significant in glioblastomas. These microRNAs have been shown to exacerbate tumor growth and invasion, while decreasing the effectiveness of Temozolomide, the type of chemotherapy typically used for glioblastomas. The researchers loaded a mixture of the PNAs against miR-10b and miR-21 into the nanoparticles.\nAfter surgery, this treatment can be administered directly into the brain to target the remaining cancerous cells. Therefore, this treatment would be an addition to the current standard of care. During mouse trials, this therapy improved survival and also enhanced the efficacy of the chemotherapy. \u201cThe results are very promising, and I think there is an opportunity here,\u201d Saltzman said. He described how the researchers are striving to move towards more extensive safety testing and eventually clinical trials.\nGlioblastomas account for just a fraction of cancer patients. In 2022, brain and other nervous system cancers added up to 1.3 percent of cancer cases in the United States, and 14.5 percent of these nervous system tumors were glioblastomas. Despite this seemingly low percentage, Saltzman has researched drug delivery systems for glioblastomas for around thirty-five years and defends its importance as a focus of research. \u201cIt\u2019s rare, but not as rare as you would think,\u201d Saltzman said. Even though his results were published in early February in Science Advances, he still receives one or two emails a day from people searching for new treatments for a family member suffering from a glioblastoma. Saltzman\u2019s driving force for his glioblastoma research and this project is the hope it provides for patients. \u201cI\u2019ve become fascinated with this challenge and want to do something that really helps people,\u201d Saltzman said. \u201cAlong the way, I have met a lot of individuals with glioblastoma. They are not alive anymore and that has had a huge impact on me. It feels more like a mission now than just an interesting project to work on.\u201d\nSaltzman\u2019s nanoparticles loaded with PNAs present a novel and precise approach to address the currently inadequate landscape of therapeutic options for glioblastoma. When integrated into the standard of care, this dynamic duo has the potential to improve survival rates, finally giving glioblastoma patients a fighting chance.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/a-dynamic-duo/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Carbon Footprint of Care",
            "author": "Jessica Le",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/hospital-waste-1-500x281.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of HCWH Europe\nWhen someone is planning to get a prostate biopsy\u2014the main diagnostic test for prostate cancer\u2014the environmental impact of their impending procedure is not usually at the forefront of their mind. However, a Yale-led study by Associate Professor of Urology Michael Leapman did just that: the team examined the environmental impacts of common screening methods like prostate magnetic resonance imaging (MRI) and prostate cancer procedures, estimating that a single transrectal prostate biopsy has the same CO2 emissions as a round-trip flight from New York to San Francisco.\u00a0\nOn a global scale, healthcare systems are a major source of pollution and constitute over four percent of global CO2 emissions. Although the environmental impacts of medical procedures are not currently considered when making medical decisions, Leapman urges for a change in attitude within the medical industry to prioritize environmental stewardship that aligns with patient interest without compromising patient care. \u201cCarbon impact comes into question when we have excessive medical care,\u201d Leapman said.\u00a0\nUnnecessary over-screening is a common occurrence, and invasive procedures such as prostate biopsies actually have the potential to harm certain patient populations. As early as fifty years old, men are advised to consider undergoing a biopsy screening to catch prostate cancer in its early stages. Overall, these procedures are shown to reduce death rates; however, for patients who are over seventy or have existing comorbidities, this invasive diagnostic procedure would risk unwarranted side effects, major hospitalization, or even death. This form of medical care is often considered low-value and may harm both the planet and the patient.\u00a0\n\u201cThe story is more than just the carbon footprint of one procedure. It is also about making better healthcare decisions that equip patients and physicians with more reliable information for who might need what intervention,\u201d Leapman said. Approximately one million prostate biopsies are performed per year in the United States alone, with more than half of the patients evaluated found to not have prostate cancer at all. His research found that performing one hundred thousand fewer biopsies would avoid over eight million kilograms of CO2 emission, the equivalent of burning 1.1 million gallons of gasoline (larger procedures, such as surgeries, may easily account for more than ten times that amount).\u00a0\nHowever, this issue addresses a broader problem facing healthcare management. Leapman noted that physicians are not proactive in considering the economic burden, much less the environmental burden, of expensive procedures. Introducing carbon footprint as a price to be considered when making important medical decisions should be implemented in a holistic conversation around when exactly to prescribe medical treatment. This ensures that the patient understands the broader benefits and risks of undergoing an expensive procedure, encouraging physicians and patients to be more considerate of both economic and environmental costs.\u00a0\nLeapman emphasizes that global climate change directly influences public health. \u201cHealthcare providers are not doing a good job if what we are doing hurts the community and our world,\u201d Leapman said. However, the movement towards environmentally friendly healthcare is not easy and faces many barriers to progress. Leapman\u2019s study found that energy expenditure is the largest contributor to the overall carbon footprint calculation (approximately forty percent). In general, hospitals require an immense amount of resources and energy. However, they work within a very thin financial margin for extra expenses, making it difficult for individual practitioners and hospitals to prioritize advocating for greener energy sources. \u201cFederal regulation and oversight may need to come in if our overall goal is to improve public health,\u201d Leapman said. \u201cWe need to make some hard decisions about the resources we allocate to ensure we are being good stewards of the environment.\u201d\u00a0\nLeapman hopes that generating more data to clearly illustrate the environmental impact of healthcare will help increase awareness and target areas of excessive medical care. By doing so, necessary modifications can be made to decrease superfluous resource use. Therefore, doctors can make better decisions when choosing appropriate patients to undergo certain procedures, in the interest of both the patient and the planet. Consider the environmental cost of care\u2014the Earth will thank you.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/the-carbon-footprint-of-care/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Teaching Machine Learning",
            "author": "Maya Khurana",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Machine learning is often thought of as the silver bullet for solving puzzles in science. With enough data in any given subject, a model with some impressive predictive properties can theoretically be created to produce an abundance of helpful information. But sometimes, machine learning isn\u2019t perfect. In their recent paper, Guannan Liu and his colleagues at the Schroers Lab at Yale explore the limitations of machine learning models and how we can incorporate human learning into new models to strengthen their predictive power.\u00a0\nLiu, a Ph.D. candidate in Mechanical Engineering and Materials Science, has spent most of his time at Yale studying machine learning and its capability to solve complex materials science problems. The study of glass-forming ability is a canonical example of one of these problems. It is quantified by the minimum cooling rate required to prevent the formation of undesired crystalline structures, resulting in a glass with an amorphous atomic structure. Studying glass-forming ability by performing hands-on experiments in the lab can be tedious, and this is where machine learning comes in to potentially accelerate the process. \u201cSimply put, machine learning is trying to make inferences from data, and maybe predict something from [that] data,\u201d Liu said.\u00a0\nBut there\u2019s a catch\u2014previous machine learning models designed to predict the glass-forming ability of metallic glasses have fallen short of providing useful insights on the subject. Metallic glasses are alloys, which are made by combining two or more elements. \u201cYou have to have meaningful features that describe the particular alloy after the mixing of elements,\u201d Liu said. Liu contextualized this idea by offering an example. \u201cFor atomic size, it\u2019s not the average [element size] that matters but the difference in size,\u201d Liu said. \u201cThis allows space to be filled as much as possible, favorable for glass formation.\u201d Models that lack such information and instead arbitrarily use statistical functions to construct features do not truly capture the essence of the alloy\u2019s glass-forming ability.\u00a0\nThe other issue with the previous machine learning model for the glass-forming ability of alloys was its limited capacity to make new predictions.\u00a0 \u201c[In] the previous model, usually the task was interpolation\u2013the model was only predicting things that were similar to the dataset,\u201d Liu said. In other words, the model could not make any predictions for new and unfamiliar data\u2014it could only work inside the bounds of the dataset.\u00a0\nTo rectify these errors, Liu and his team worked on a new machine learning model: one that incorporated scientific insights from human learning. \u201cOur model used extrapolation, [or] prediction into unknown space,\u201d Liu said. This way, they were able to align their machine learning model with the reality that they have observed in the lab. Take, for instance, the property of atomic size again. Larger differences in size result in better glass-forming ability because the atoms are able to pack in more tightly. It is properties such as these that Liu and his team were better able to account for in their model, and their approach worked. \u201cWe found that our model was actually very successful in predicting glass-forming ability,\u201d Liu said.\u00a0\nUnlike its predecessors, this model was much better at extrapolation. \u201cOur model can predict alloys that are more distinct from the training set,\u201d Liu said. \u201cWe concluded that physical insights are really needed [to develop effective machine learning models].\u201d\nThis project is far from the end of Liu\u2019s work with machine learning for materials science. He has three main goals moving forward. \u201cThe first is to use machine learning to test [our] current understanding of complex material science problems,\u201d Liu said. It can be hard to quantify the efficacy of foundational rules within material science, so Liu plans to use machine learning to evaluate these guiding principles. Secondly, Liu strives to combine machine learning and high-throughput fabrication methods to discover new metallic glasses.\u00a0\nFinally, Liu will investigate the contexts in which machine learning can be helpful. His goal is to determine what kinds of problems it can help solve and what circumstances limit its utility. \u201c[We want to] have a viewpoint that can be meaningful for the community as to what machine learning is useful for [versus] situations where machine learning would be hard to use,\u201d Liu said. This research will ensure that machine learning models are taking all possible human insights into account while making inferences from data. Clearly, machine learning can be an extremely valuable tool if it is wielded skillfully.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/teaching-machine-learning/",
            "captions": []
        },
        {
            "title": "Free As a Bird",
            "author": "Mia Gawith",
            "authorLogo": "",
            "date": "November 16, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-10-363x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pxfuel.\nWe all recognize the signs: the sickening thud on the window, the flutter of feathers hitting the ground, and the stomach-churning dread of peeking outside. As one of the top causes of bird deaths, bird-window collisions kill almost one billion birds per year. However, a new project at Yale University seeks to challenge this reality: the Yale Bird-Friendly Building Initiative, a collaboration between Yale Law School\u2019s Law, Ethics and Animals Program, the Yale Peabody Museum of Natural History, the Yale Offices of Sustainability and Facilities, and the American Bird Conservancy.\nLaunched in the spring of 2022, the Initiative aims to mitigate bird-window collisions and adopt bird-friendly designs on Yale\u2019s campus and beyond. The Initiative records the location, time, and cause of all reported bird deaths, preserving the carcasses for future insight. \u201cIf I find a dead bird or someone else brings it to me, I want to preserve it because it gives them a second life in a way, because they become imminently useful,\u201d said Kristoff Zyskowski, collections manager at the Yale Peabody Museum. The Initiative found that designs with highly reflective, transparent glass and nearby trees create a deadly optical illusion, luring birds to their death.\n\u201cOur ultimate goal, in my view, is for Yale to be the gold standard of what it looks like to be a bird-friendly campus,\u201d said Viveca Morris, executive director of the Law, Ethics, and Animals Program. Future developments involve retrofitting Yale buildings and implementing new design regulations on campus and beyond. By saving countless birds, this project sets its sights on a new vision of wildlife sustainability.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/free-as-a-bird/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Changing Language of Our Changing Climate",
            "author": "Pratiksha Bhattacharyya",
            "authorLogo": "",
            "date": "November 14, 2023",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/CarbonEmissions-500x281.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr/ Nick Humphries.\nResearchers from the Yale Program on Climate Change Communication (YPCCC) are using a novel method to measure public opinion on climate change\u2014studying how people react to different phrases used to describe emissions of carbon dioxide and methane. \u201cOver the last few decades, there has been an increased interest in the terms \u2018carbon emissions\u2019 and \u2018greenhouse gasses,\u2019\u201d said Matthew Goldberg, an author of the study and associate research scientist at the YPCCC. The team asked study participants questions about climate change, which were identical between participants apart from the specific phrase used to describe carbon emissions\u2014either \u201cgreenhouse gas emissions,\u201d \u201ccarbon emissions,\u201d or \u201ccarbon pollution.\u201d\nThen, the team tracked differences in responses based on the phrases used. \u201cWe were interested in getting a holistic perspective of these terms,\u201d Goldberg said. A key finding was that different reactions to these phrases revealed more about the general associations that participants held with each term. For example, the phrases \u201ccarbon pollution\u201d and \u201ccarbon emissions\u201d evoked more negative reactions and correlated with a greater understanding of the environmental harms of climate change than the phrase \u201cgreenhouse gas emissions.\u201d\u00a0\nThese insights are crucial for policymakers and environmentalists who want to effectively communicate the urgency of addressing climate change. By paying attention to how people react to the different words used to describe these crucial issues, we can gain insight into how we can best emphasize the need for action. Experts can tailor messaging to better resonate with their audience by being cognizant of widely held associations with key scientific phrases in their communication.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2023/11/the-changing-language-of-our-changing-climate/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Deep Learning",
            "author": "Sophia Burick",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/4788637130_f0ccc2aa40_c-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nSevere aortic stenosis (AS) is a common form of valvular heart disease that involves the aortic valve becoming unusually narrow, affecting five percent of people above the age of sixty-five. Early diagnosis is essential to successful intervention. Usually, AS is detected through Doppler echocardiography, or ultrasound imaging of the heart. However, performing Doppler echocardiography requires access to specialized equipment as well as professionals who know how to operate the equipment and interpret the results. This discrepancy between the large population of individuals at risk for AS and the small amount of resources available for its diagnosis makes it difficult to achieve early diagnosis of AS, negatively impacting patient outcomes.\nResearchers at the Cardiovascular Data Science (CarDS) Lab at Yale recently published in European Heart Journal a creative new approach to making AS diagnostic tools more accessible\u2014combining deep learning with simple ultrasound scans. Handheld devices that use ultrasound imaging to visualize the heart are much more widely available than the equipment necessary for Doppler echocardiography, but the images and videos alone produced by these ultrasound scans are difficult to use to diagnose AS. \u201cPatients are often not seen by a cardiologist until they are very late in their disease stage,\u201d Evangelos Oikonomou, a postdoctoral fellow in the CarDS Lab, said. \u201cThere\u2019s a big opportunity to diagnose the disease earlier in this patient population.\u201d\nThe researchers at the CarDS Lab developed a novel deep learning model that is capable of using 2D echocardiograms, which are produced by simple ultrasound imaging, to identify AS without specialized Doppler equipment. Deep learning is a kind of machine learning that employs computer networks built to resemble human neural networks\u2014in short, it teaches computers how to learn like humans.\n\u201cYou train the algorithm by showing it multiple different images and giving feedback to the algorithm as to whether its prediction [about what the image is] is correct or wrong,\u201d Oikonomou said. \u201cWhat the algorithm does is every time it gets [its prediction] wrong, it tries to adjust its approach and learn something from its errors.\u201d These deep learning algorithms are often more perceptive to patterns than humans, allowing them to reach conclusions that might not be apparent to a doctor trying to interpret ultrasound images. \u201cThat\u2019s where the performance of an AI algorithm may actually exceed that of a human operator,\u201d Oikonomou said.\nTo develop their algorithm, the researchers needed to train it to be able to recognize severe AS. To do this, they sourced a massive amount of 2D cardiac ultrasound videos from patients in the Yale New Haven Health system with no AS, non-severe AS, and severe AS. Using this dataset, the algorithm learned how to identify specific phenomena in the videos associated with each class of AS diagnosis. Once the researchers trained the algorithm to learn what to look for, they had to validate that the algorithm was truly capable of differentiating non-AS, non-severe AS, and severe AS ultrasound videos. To prove the algorithm\u2019s success, they had it sort a new dataset from different patients in New England and California. The deep learning algorithm proved highly accurate in sorting the videos across all patient datasets.\nThe researchers\u2019 vision is that their algorithm can be used by any medical provider with a simple ultrasound scanner to catch AS early. This removes the existing barriers to AS diagnosis, like specialized Doppler echocardiography equipment and the training of medical providers to accurately interpret results, making AS diagnoses more accessible to patients and simpler for providers. If the algorithm is widely used, it could be a major step forward for successful AS intervention. \u201cHopefully, we can make this as cost-efficient as possible,\u201d Oikonomou said. \u201cIt\u2019s very easy to do\u2014it takes two or three minutes, and people can probably be screened once in their lifetime.\u201d\nBeyond its immediate impact in improving outcomes for AS patients, this deep learning algorithm reveals the broader potential of applying cutting-edge computer science to healthcare. \u201cI think this could be applied to other things such as hypertrophic cardiomyopathy, which is a genetic heart condition that is very common but most people don\u2019t ever get diagnosed,\u201d Oikonomou said.\nWith increasingly high patient burdens and medical staff stretched thin, it\u2019s inevitable that some patients will slip through the cracks of the healthcare system. Machine and deep learning models could be used across a variety of applications to identify diagnoses that are sometimes missed by medical staff. The CarDS Lab\u2019s algorithm is proof of the great positive impact that computer science and artificial intelligence stand to have on patient care and outcomes.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/deep-learning/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Too Strange to Be True?",
            "author": "Proud Ua-arak",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/plasma_electricity_red_blue_purple_ball_lightning_energy-852020-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nThe concept of electrons may have first been introduced in our chemistry classes with neat, easy-to-follow Bohr models. But what happens when they don\u2019t act the way scientists anticipate? Graduate student Kirsty Scott and Professor Eduardo H. da Silva Neto from the Yale Department of Physics set out to discover the nature of these so-called \u201cstrange metals.\u201d\nAccording to basic quantum mechanics, an electron can be described as a quantum mechanical wave. \u201cBut in the strange metal phase, the wave description seems to not be applicable, which leaves\u00a0us in a position where even the most advanced theories don\u2019t seem able to explain what\u2019s going on,\u201d da Silva Neto said.\u00a0\nThe researchers were determined to uncover what happens at the electron level within these metals. Using a method called resonant inelastic X-ray scattering, they found a \u2018quasi-circular\u2019 pattern in the way electrons scatter at low energies. This means that when an electron changes direction while moving, it is free to change to any direction. \u2018Quasi-circular\u2019 patterns have typically been assumed to be necessary for strange metals, but have not, until now, been directly measured.\nMatter matters. Scott, the leader of this study, believes that knowledge of the materials we use shapes our technology and therefore the society around us, as evidenced by historical periods like the \u201cStone Age\u201d and the \u201cBronze Age\u201d being defined by the materials of their time. Scott is enthusiastic about being part of a scientific endeavor where the study of novel material behaviors could usher in society\u2019s next epoch.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/too-strange-to-be-true/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Keep An Eye On It",
            "author": "Johnny Yue",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/keep-an-eye-on-it_final-draft-Luna-Aguilar-e1704579335331-500x446.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Luna Aguilar.\nWhat if you suddenly had blurry vision, couldn\u2019t recognize familiar faces, or had difficulty adapting to dimly lit places? This is the reality for people with age-related macular degeneration, also known as AMD, one of the most prevalent causes of vision loss that affects around 200 million people in the world.\nIn AMD, damage occurs in the macula, an oval-shaped area at the center of the retina. The retina consists of a layer of cells known as photoreceptors, which are crucial for converting light entering the eye into signals sent to the brain. The macula is specifically responsible for sharp and central vision. Thus, someone with AMD usually has difficulty deciphering fine details. There are limited effective therapies for the disease\u2014current treatments such as vitamins and minerals only slow disease progression, but do not stop or reverse it.\nYale scientists are among those who have joined the cause to find out more about AMD disease pathology. From discovering possible therapeutic targets for AMD and other neurodegenerative diseases to uncovering a quantum chemistry reaction in the retina, their findings could not only inform potential AMD treatments, but also offer applications far beyond the eye.\nA Window Into Neurodegeneration\nIn a recent study published in Nature Communications, Yale Assistant Professor Brian Hafler and a team of Yale researchers found that AMD, which is itself a neurodegenerative disease of the retina, could serve as a system for understanding other neurodegenerative diseases such as Alzheimer\u2019s disease and multiple sclerosis. To arrive at this finding, they developed a novel approach to understanding AMD and its cellular pathology.\nHafler and his team utilized single-cell data and machine learning techniques to pinpoint the populations of cells in the retina that play a prominent role in the disease progression of AMD. This study built upon previous research in the retina which highlighted the overall role of inflammation in the pathology of macular degeneration, Hafler explained. The team isolated 70,973 individual retinal cells from seventeen different human retinas with different stages of disease and healthy controls. \u201cThis allowed us to build a unique road map into the genetic networks driving inflammation in macular degeneration and hopefully to develop new therapeutic targets,\u201d Hafler said.\nTo analyze these cells, the team designed a novel collection of machine learning tools which they termed \u201cCellular Analysis with Topology and Condensation Homology,\u201d or CATCH. At the core of CATCH is a method known as diffusion condensation, which identifies similar groups of cells based on how they are pulled toward the weighted average of neighboring cells in space. This method enabled the team to pinpoint two populations of activated glial cells (cells whose primary role is to support neurons): astrocytes and microglia. Astrocytes provide neuroprotective, structural, and metabolic nourishment to nerve cells, while microglia are the immune cells of the brain and mount responses to pathogens. Both were found to be activated in the early phase of AMD.\u00a0\nSurprisingly, similar activation profiles were found to dominate the early phases of other neurodegenerative diseases, such as Alzheimer\u2019s disease and multiple sclerosis. This association led the researchers to believe that early stages of neurodegenerative disease progression generally utilize a common mechanism involving the activation of glial cells. It also suggests that the retina can potentially be a unique system for developing new therapeutic strategies to treat neurodegenerative diseases.\nThen, using single-cell data from Alzheimer\u2019s and multiple sclerosis studies, Hafler and his team were able to characterize specific cellular interactions that induce inflammation, which may be a common characteristic of neurodegenerative disease progression. They first identified interleukin-1\u03b2, a protein that signals immune cells to mount and induce a response, that was derived from the microglial cells activated in AMD. Using a computational technique, they found that interleukin-1\u03b2 signals for astrocyte activation are pro-angiogenic, meaning that they enhance blood vessel formation. This observation lined up with the typical symptoms observed in wet AMD, an advanced stage of AMD. In late stages of AMD, blood vessels can abnormally form, grow, and leak beneath the macula. This bleeding can distort the retina and impair one\u2019s central vision.\u00a0\nHafler\u2019s study suggests that targeting astrocytes and microglia should be further considered when attempting to treat neurodegenerative diseases. Anti-angiogenic medications are currently the primary treatment, but they are only effective in advanced stages of the disease. To fill in the gap, interleukin-1\u03b2 may be an effective target. With Hafler\u2019s deep understanding of AMD both in a clinical and research setting, his results show promise towards moving forward in the fight against AMD. \u201cMy clinical practice is what drives my benchwork in the lab,\u201d Hafler said. \u201cWhen medical research is applied to patient care, we can uniquely translate novel therapeutic approaches for diseases like AMD.\u201d\nHow Does Melanin Protect The Retina?\nA second study, published in PNAS, found a quantum chemistry reaction that could explain how melanin protects the retina from age-related macular degeneration. Yale scientist Douglas Brash, a physicist by training and co-author of the study, did not expect to investigate AMD. But one day, he performed an experiment on melanocytes, which are special melanin-producing cells. Melanin is a natural pigment that shows up across the body, from the eyes to the skin. In the skin, melanin accumulates with UV-light exposure. In the retina, melanin exists in tiny granules at the photoreceptor layer; however, its function is almost completely unknown. Brash wanted to see what would happen when melanocytes were UV-irradiated. Cells that are UV-irradiated develop a specific type of DNA damage called cyclobutane dimers.\u00a0\nBrash eventually showed that, when exposed to UV radiation, melanin was oxidized by free radicals\u2014meaning that its chemical structure lost electrons\u2014to produce dioxetane, a chemical compound on melanin that then splits to give a molecule with a similar high-energy state to ultraviolet light in sunlight. The radicals and dioxetanes continued long after the UV light was turned off. Dioxetane\u2019s high-energy state was a specific kind called a triplet state, which is capable of initiating reactions that ordinary chemistry cannot. He also knew that melanin was found in many places in the body, such as the eye and the ear, and the two radicals behind its oxidation, superoxide and nitric oxide, were found in many conditions such as inflammation.\u00a0\n\u201cThese [are] events that can\u2019t not happen. Why aren\u2019t we dead?\u201d Brash recalled thinking. Could the high-energy reaction cause deafness and blindness? A surprising clue to the exact opposite conclusion came from Ulrich Schraermeyer, an ophthalmologist at the University of Tubingen in Germany, who had heard about Brash\u2019s work with melanin chemistry. Schraermeyer had an idea that completely opposed the norm ten years ago. He suggested that perhaps melanin actually had a protective role in the retina.\u00a0\nFor years, he had been working on studies to show that when melanin was associated with another molecule called lipofuscin, the retina was less susceptible to macular degeneration. Lipofuscin, a pigment that accumulates in the retina with age, is associated with neurodegeneration in AMD, but its exact composition is unclear. While Schraermeyer was convinced of the critical involvement of melanin in AMD prevention, he could not figure out the chemistry. And while Brash was intrigued by melanin having a protective role, the mechanism would need to be proven.\nIn Schraermeyer\u2019s initial experiments, he proved many drugs could actually slow or prevent macular degeneration in mice and monkeys. Brash noticed that these drugs were all chemicals that could create triplet states, the unique high-energy chemical state that Brash had previously created in melanin after it was treated with radicals. This led to their theory that the dioxetane in melanin that led to the triplet state was the step responsible for melanin\u2019s protective role in the retina.\nIn his initial experiments, Schraermeyer showed that under electron microscopy, a type of imaging technique used to visualize subcellular structures, melanin was often seen together with lipofuscin in the retina in what is called melanin-lipofuscin (MLF) granules. He observed that MLF granules accumulated in the eyes of humans above the age of sixty. Building on this observation, the group showed that the toxic lipofuscin component of MLF granules could be degraded by treating mice with a non-melanin molecule that was in a triplet state. The degradation was blocked if mice also received a molecule that siphons the triplet energy away.\u00a0 Thus, it seemed like melanin chemiexcitation, using chemicals to create a high-energy state, and melanin-lipofuscin association could be studied as a pathway for lipofuscin degradation.\u00a0\nSchraermeyer believes that upregulating melanin in the retina could be a therapeutic target. Having already shown that people lose melanin in the retina with age, he theorizes that the melanin is being used up in its protective role throughout one\u2019s life. Brash, on the other hand, is convinced about the importance of dioxetane chemistry, but not so much about melanin itself. \u201cI\u2019m willing to bet that as you get older, the melanin may well contribute to AMD, so it\u2019s like a double-edged sword,\u201d said Brash. Brash\u2019s therapeutic goal is to get triplet-state precursors into the eye so that dioxetane chemistry can be harnessed for AMD prevention.\u00a0\nSeeing Eye-to-Eye\nWhile Hafler and Brash took two very different approaches to characterizing some of the underlying mechanisms of AMD, their findings both pave a new way forward for the development of potential treatments. With scores of scientists studying AMD from various specialties and backgrounds, the pursuit of an effective treatment that accounts for multiple mechanisms grows increasingly hopeful\u2014while potentially also addressing diseases beyond the retina as well.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/keep-an-eye-on-it/",
            "captions": [
                ""
            ]
        },
        {
            "title": "COVID-19 Nasal Spray",
            "author": "Evelyn Jiang",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/COVID-19_Nasal_Spray_Kara_Tao-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao.\nTraditional vaccines, such as those developed against smallpox and tetanus, have relied upon the introduction of weakened or inactivated pathogens into the body to stimulate the immune system, effectively priming it to recognize and counteract these pathogens in the future. For several decades, however, scientists have pursued an ambitious mission to harness the untapped potential of messenger RNA (mRNA) as a replacement for the pathogens in vaccines. By introducing mRNA, a small piece of genetic material that instructs cells to produce part of a pathogen, the vaccines would theoretically trigger an immune response without causing disease. Scientists envisioned mRNA vaccines harnessing the body\u2019s own cellular machinery to combat pathogens. Their collective efforts, spanning years of research, pushed mRNA vaccine technology to the brink of reality.\nThen came the COVID-19 pandemic, a crisis of unprecedented proportions that necessitated a rapid global response. In a mere eleven months, Pfizer/BioNTech produced the first mRNA vaccine to ever achieve full FDA approval for use in the United States. As of September 2023, over eighty percent of the U.S. population has received at least one dose of an mRNA COVID-19 vaccine, fundamentally altering the pandemic\u2019s trajectory and saving millions of lives in the U.S. alone. Yet the quest for innovation continues. In a study recently published in Science Translational Medicine, a team of Yale scientists ventured into a new frontier in vaccinology: the development of a nasally administered COVID-19 mRNA vaccine using nanoparticles.\u00a0\nThe Promise and Pitfalls of Respiratory Delivery\nCurrent intramuscular mRNA vaccines, typically injected into the upper arm, excel at activating immune defenses in the bloodstream, but they are not as effective in rallying protective responses in the upper airway and lungs. Thus, for a viral respiratory illness like COVID-19, the allure of an inhalable mucosal vaccine stems from its geographical advantage. When a virus enters the body through the nasal route, the respiratory mucosa (the lining of the respiratory tract) becomes the primary battleground for early encounters. Notably, the Omicron variant has been recorded in higher concentrations in the lungs than in the rest of the body. According to Benjamin Goldman-Israelow, an assistant professor of internal medicine at the Yale School of Medicine and one of the authors of the paper, mucosal vaccines are better designed to engage the immune system precisely at this entry site, enhancing the body\u2019s ability to mount a swift and targeted response there.\u00a0\nThe effectiveness of the oral polio vaccine, which played a significant role in the global effort to eradicate polio, is grounded in the same principle. Following ingestion, the vaccine induces a strengthening of immune defenses within the virus\u2019 favored environment\u2014the gastrointestinal tract. This localized approach minimizes the delay associated with the migration of immune defenses from the bloodstream to the environment of interest, thereby reducing the window of vulnerability and bolstering protection against invading pathogens.\nWhile the promise of inhalable vaccines is compelling, it is not without its challenges. Only one mucosal vaccine currently exists to combat pathogens entering through the nasal route: a nasal spray comprising of weakened flu viruses known as FluMist. While this nasal spritz proves reasonably effective in children\u2014occasionally even surpassing the performance of its injected counterpart\u2014its potency wanes significantly in adults. This may be because the pre-existing immunity built up over a lifetime of influenza exposure can inhibit the vaccine\u2019s effects before it can establish new protection, according to Goldman-Israelow. Thus, developing a mucosal vaccine tailored for respiratory viruses presents a unique challenge, and there is no well-established template to follow.\nMark Saltzman, the Goizueta Foundation Professor of Biomedical Engineering at Yale and a senior author of the paper, shared that there were several fundamental challenges in devising an effective mucosal vaccine. The effectiveness of mucosal vaccines relies heavily on how well they can reach and activate immune cells in the mucosal surfaces. To reach cells in the lungs, the vaccine must be able to overcome physical barriers, such as cilia and mucus, meant to prevent debris and pathogens contained in inhaled air from reaching the lungs\u2019 small air sacs, or alveoli. Phagocytic cells, which actively participate in the body\u2019s immune surveillance by destroying microbes and debris, introduce another obstacle. These cells may engulf vaccine particles, thwarting their intended journey to the site of action and potentially compromising the vaccine\u2019s effectiveness.\u00a0\nFinally, respiratory mucosa is especially prone to producing unwanted immune reactions. While current mRNA vaccines employ small fat-based capsules called lipid nanoparticles (LNPs) as their delivery vehicles, these components have been noted to incite inflammation when administered via nasal routes. In the development of nanoparticles tailored for inhalation, the team would have to maximize mRNA delivery efficiency while minimizing detrimental inflammatory responses in the respiratory tract.\nInhaling Nanoparticles\nPolymers are molecules formed from repeating smaller chemical units known as monomers. Visualize them as molecular chains built from identical building blocks repeated in succession, much like LEGO bricks assembling into a chain. The Saltzman group designs and tests incredibly tiny nanoparticles made from polymers for drug and gene delivery to treat cancers and other diseases. When the COVID-19 pandemic struck in 2019, Saltzman began thinking about how this technology could be applied to inhalable vaccines. He drew inspiration from the work of Akiko Iwasaki, the Sterling Professor of Immunobiology at Yale and a senior author on the study, who is a leading expert on the mucosal immune response.\u00a0\nIn 2020, Saltzman\u2019s lab began working on this project and produced biodegradable polymers, called poly(amine-co-ester) (PACE), which can form so-called \u201cpolyplexes\u201d with mRNA. The PACE polymers represent a third-generation polymer-based delivery system for nucleic acids like mRNA, distinct from the lipid nanoparticles (LNPs) commonly used in vaccines. The conventional approach in the field has involved employing hydrophobic, or water-resistant, polymers, which have proven somewhat successful in other drugs for delivering nucleic acids. However, these early polymers were prone to becoming positively charged and associating with negatively charged nucleic acids. Administration of these agents could inactivate enzymes, exhibit general toxicity, and affect cell membranes. \u201cThe positively charged particles just weren\u2019t well-tolerated in tissues,\u201d Saltzman said.\u00a0\nDuring the development of the PACE polymers, his team took a different approach. The researchers alternated or substituted some of the positively charged (cationic) groups with hydrophobic groups. This design delicately balanced two forces holding the polymer-nucleic acid complex together: hydrophobic and electrostatic interactions. The hydrophobic component was situated inside the complex, while a mild positive charge resided on the outer surface. The researchers postulated that reducing the charge density within the polymer structure would enhance tolerability and minimize potential side effects. This breakthrough allowed them to create a versatile family of PACE materials compatible with various types of nucleic acids. The researchers found they could fine-tune the polymer\u2019s hydrophobicity and charge based on the specific contents and objectives of their delivery system.\u00a0\nTranslating Success\nThe researchers tested the ability of the PACE-mRNA polyplex delivery system to induce cell-type-specific mRNA expression in the lungs, which would indicate that the system was effective at precisely delivering the nucleic acids to lung cells. Using PACE-mRNA polyplexes in mice, they were able to show that the mRNA was primarily incorporated in epithelial cells lining the airways and antigen-presenting cells in the lungs, which capture, process, and present components of foreign molecules to other immune cells to initiate further responses. The delivery system was successfully used for multiple doses without causing significant inflammation or immune reactions.\u00a0\nTo explore the practical applications of the delivery system, the researchers then engineered an inhalable mRNA vaccine encoding the spike protein of SARS-CoV-2, the virus responsible for COVID-19. \u201cWith the PACE-delivered mRNA, we were able to see the induction of immune cellular responses within the respiratory tract, as well as in systemic circulation,\u201d Goldman-Israelow said.\u00a0 The intranasal vaccination prompted the production of circulating CD8+ T cells specific to the viral antigen, which serves as a rapid response team, ready to track down and destroy virus-infected cells anywhere in the body.\u00a0\nIn the lymph nodes, the vaccine stimulated the formation of germinal centers, which are specialized areas where immune cells undergo intense training and maturation. This training process resulted in the expansion of memory B cells, which \u201cremember\u201d the virus\u2019 unique features, enabling the immune system to recognize and neutralize it more effectively upon future encounters.\u00a0\nThe researchers found that the vaccine also led to the production of antibody-secreting cells (ASCs), another critical group of immune cells. ASCs are responsible for manufacturing antibodies, which are proteins that can specifically target and disable the virus. The combined action of memory B cells and ASCs enhances the body\u2019s ability to fend off the virus. Collectively, these findings illustrate the practical applicability of PACE polyplexes for delivering mRNA therapeutics to the lungs.\nFuture Steps\nSince most individuals have already either contracted SARS-CoV-2 or received an mRNA COVID-19 vaccine, the focus is now on providing booster shots that can keep up with new variants. According to Saltzman, this plays to the nasal vaccine\u2019s strengths. \u201cThe beauty of the whole thing is that you wouldn\u2019t have to change the delivery system; just exchange the mRNA,\u201d Saltzman said.\u00a0\nGoldman-Israelow, who is also a practicing physician, shared a similar perspective. \u201cLooking more long-term, we know that vaccine hesitancy plays a big role\u2026 If we can get intranasal booster-type vaccines going, especially for respiratory illnesses, these will enhance protection and reduce transmission.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/covid-19-nasal-spray/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Barnacle Breadcrumbs",
            "author": "Madeleine Popofsky",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Barnacle_Breadcrumbs_Kara_Tao-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao.\nIt was March 8, 2014\u2014a day like any other\u2014when 239 people took to the skies aboard Malaysia Airlines Flight 370 on their way from Kuala Lumpur to Beijing. Some were going home after a long time away. Others were world-famous calligraphers returning from a business trip. Some may have been scared of flying and clutched the armrests as the plane took off. But after that fateful day, none of those 239 people, nor the plane they sailed away on, were ever seen again. And despite years of intensive searching\u2014using everything from submarines to sonar imaging\u2014their final resting place has yet to be discovered.\u00a0\nOver a year later, on July 29, 2015, Gregory S. Herbert, Associate Professor of Paleobiology at the University of South Florida, was watching the news and saw that a piece of the missing aircraft\u2019s wing, called a flaperon, had been found on R\u00e9union Island. Herbert instantly knew that he had to make some calls. A clue that could unlock the location of the lost plane had been unearthed, and he was uniquely qualified to decode it.\u00a0\u00a0\nHerbert\u2019s background lies in stable isotope geochemistry; specifically, he decodes ocean temperatures from barnacle shells. If a drifting object has barnacles, scientists can potentially use these temperatures to track its path through the ocean. And barnacles, clinging to the flaperon, were clearly visible on the TV screen. \u201cI knew immediately that there were sea surface temperatures recorded in those barnacles,\u201d Herbert said. \u201cSome of the barnacles were fairly large, and they could have recorded the whole drift.\u201d\u00a0\nHerbert tried to contact the French authorities, who had possession of the flaperon, and the Malaysian officials, who were running the investigation. Both attempts failed. However, Herbert was not deterred, and the third time proved to be the charm: the Australian authorities, who helped coordinate the search since the plane\u2019s likely final location nears their territory, enthusiastically agreed to look over his proposal.\u00a0\nBased on satellite data, the plane\u2019s final resting place is thought to lie somewhere in the Indian Ocean along the seventh arc, between latitudes twenty and forty degrees S. However, this is an extremely large area that the plane may not even be in. But with the technique Herbert and his colleagues have developed, scientists can say for sure whether the plane is in the seventh arc, and can pinpoint its location to a smaller and more easily searchable area.\nBarnacles grow in daily layers, similar to the rings trees produce every year. Each of these layers encodes chemical data about their surroundings at the time of growth. Different isotopes of oxygen are deposited at different sea surface temperatures, with a known relationship between their ratio and the temperature. Scientists can analyze this ratio through \u03b418O values to determine the temperature the barnacles experienced each day, and match that data with different temperature currents that run through the Indian Ocean. Other scientists had previously jumped on this information to produce temperature and location models for the aircraft, but in their rush to complete the work, they failed to use experimental controls, leading to large uncertainties in their results.\u00a0\nDespite these apparent problems with the previous studies, Herbert had a difficult time securing funding for his study. In the end, the Florida Aquarium decided to fund his research, as it could also be used to benefit sea turtles. Sick sea turtles will float for weeks and thus develop barnacles on their normally clear front flippers. If these barnacles could be traced, scientists could begin to identify areas where sea turtles tend to get sick. Thus, a method was born that could both trace a missing plane and track sick turtles.\nThis new technique, created by Herbert and his colleagues, had two unique and vital components that set it apart from previous attempts. The project was the first to create an experimentally derived equation for the particular species of barnacle (cosmopolitan stalked barnacle, Lepas anatifera) that was attached to the flaperon. Barnacles were placed into tanks, stained with a marker (a fluorescent dye) that showed divisions between layers, and subjected to slowly changing temperatures. The scientists then anesthetized the barnacles and analyzed their layers for \u03b418O content. Finally, they created an equation that relates temperature and \u03b418O content.\u00a0\nThe second innovation centered around what to do with that temperature data. While temperature does vary throughout the ocean, there are large bands that are the same temperature throughout. \u201cJust knowing that first temperature doesn\u2019t tell you where the plane is; you have to do a lot more work,\u201d Herbert said. In other words, each new temperature recorded is needed to narrow down the search; knowing just the first temperature recorded by the barnacle is not enough.\u00a0\nThis extra work involved developing a modeling simulation using known sea surface temperatures and other data such as current velocity that is consistently recorded across the oceans. The simulation allowed the researchers to cast virtual flaperons adrift from various starting points, and then statistically analyze their routes to determine the most likely path each barnacle on each flaperon took based on its temperature data.\u00a0\nHerbert and others on the team applied this technique using previously published data for one of the smaller barnacles found clinging to the flaperon. First, they calculated the barnacle\u2019s age at each layer through an experimentally derived equation relating barnacle size to age. \u201cWe measured the size of the barnacle at each sample, at each temperature,\u201d Herbert said.\u00a0 \u00a0\nThey then cast 50,000 virtual flaperons adrift in different places along the band of the ocean defined by the barnacle\u2019s earliest temperature value. Then, they compared the temperature data these virtual flaperons experienced with the actual temperature data from the barnacle using a method called dynamic time warping. Eventually, this eliminated all but one virtual flaperon, which was the only one to end near where it was actually found: in waters near R\u00e9union Island.\u00a0\nHowever, the timeline for applying this new and promising technique will have to wait on the French government, which has custody of the largest barnacles. These are the only barnacles that could have recorded the entire drift of the flaperon. \u201cI have a feeling that they\u2019re still sitting on these shells because there were three French scientists who worked on them, and their work was very rushed, and they did not get any sort of a conclusive result,\u201d Herbert said. The French government likely wants to keep the samples until the foundational work that will allow for conclusive results has been completed. Thus, it is possible the French government will release the barnacles in light of these new findings.\u00a0\nIn the meantime, the next step is to improve the model and equations. \u201cI just wanted to demonstrate how to do the method first,\u201d Herbert said. To begin, Herbert and others have already started work on a more accurate barnacle age model, since shell size is not the most accurate predictor. They also want to improve the flaperon motion model used; for example, accounting for the fact that a flaperon does not behave like an idealized buoy, and instead drifts slightly left. Finally, the researchers need to perform a sensitivity analysis. This involves running the model thousands more times with different errors factored in to see how dramatically these errors change the results. This work would take up to a year, even if the larger barnacles from the French were provided immediately.\u00a0\nHowever, hopes are high. Of the five drifters in the simulation that best matched the known barnacle\u2019s path, four of them started in the same location, tightly clustered together. \u201cWe\u2019re not just looking for a single temperature, we\u2019re looking for a sequence, a very unique sequence of temperatures. And there aren\u2019t that many drift origins, and drift pathways, that could possibly be consistent with that,\u201d Herbert said. When asked if the plane would ever be found, Herbert didn\u2019t hesitate.\u00a0\n\u201cYes,\u201d he said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/barnacle-breadcrumbs/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Phonon Phenomenon",
            "author": "Annli Zhu",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/ysm_atoms1-Annli-Zhu-471x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Annli Zhu. \nCommunication is a natural part of life. Humans talk, birds chirp, and even trees interact through their root networks. To maintain this essential aspect of life, we adapt our methods to overcome communication challenges: a team meeting that once had to be held in a boardroom can now be effectively held on a Zoom call. For quantum computers\u2014a system that looks to advance past the capabilities of classical computing\u2014communication occurs by leveraging quantum particles and their properties, components of sub-atomic interactions that have historically been challenging to harness.\u00a0\nRecently, physicist Mo Li and his colleagues at the University of Washington were able to overcome one such challenge: dealing with unpredictable photon emitters. They achieved this by designing a deterministic emitter\u2013\u2013one where they can determine where the photon is emitted\u2013\u2013and in doing so, they discovered that their emitter produced a strong interaction between two important quantum quasiparticles: photons and phonons. Now, Li is hopeful that further research can use this interaction to advance communication in quantum computing systems and overcome some challenges in the field.\u00a0\nIn classical computers, information is stored in bits: either 0 or 1. Quantum computers use quantum bits\u2014called \u201cqubits\u201d\u2014which can exist in a \u201csuperposition\u201d state of being both 0 and 1 at the same time, like Schr\u00f6dinger\u2019s cat. This allows them to consider many possibilities simultaneously. Through a process called entanglement, qubits can be connected in a way such that the state of one qubit instantly influences the state of another, no matter how far apart they are, enabling quantum computers to perform complex calculations literally faster than light can travel. This means quantum computers have the potential to revolutionize fields like cryptography, drug discovery, and more. However, because they are highly sensitive to environmental conditions, require extremely low temperatures, and use extensive space, they are expensive to build and difficult to scale.\nAlthough many subatomic particles can be used for quantum computers, scientists prefer to use photons\u2014tiny, massless particles of light\u2014to transmit quantum information because they travel at, well, the speed of light. But photons are difficult to reliably produce, control, and capture. Traditional methods of photon generation\u2014through so-called \u201cquantum emitters\u201d\u2014involve taking advantage of defects in various atomic lattices, which are patterned arrays of bound atoms. However, these defects often emit photons unpredictably, which is undesirable for highly precise quantum computers.\u00a0\nTo address this problem, the team of scientists at the University of Washington set out to build a \u201cdeterministic\u201d quantum emitter. \u201cWe want to engineer it in such a way that we can say \u2018we want an emitter here\u2019 and it indeed emits there,\u201d said Li, Professor of Electrical & Computer Engineering and Physics and leader of the research team.\nTo achieve this goal, the team used two single-atom layers of tungsten and selenium, similar to existing quantum emitters. Then, they draped these layers over hundreds of nanoscopic pillars, creating tiny bumps in the 2D lattice that isolated the target regions. By shining a precise pulse of laser light at an electron in the material, they were able to free it for a very short period of time. Each time an electron returned to its place, it emitted a single photon encoded with quantum information\u2014a successful quantum emitter.\nAmidst their successes with the deterministic emitter, Li and his colleagues noticed something intriguing in their data. \u201cThe emitter ideally is supposed to generate a very sharp peak in energy at one wavelength associated with the photon, but when we looked a little bit closer, there [was] a group of satellite peaks on the sides, and we wondered where that [came] from,\u201d Li said.\u00a0\nAs they analyzed the data, they came to an exciting conclusion: phonons\u2014quantum quasiparticles that are a unit of vibrational energy\u2014may be responsible for these satellite peaks. The energy is caused by the vibration between two atomic layers, and such motion has been described as \u201catomic breaths.\u201d\n\u201cIt\u2019s not uncommon,\u201d Li said. \u201cIt\u2019s called phonon replica, and it appears in other systems as well, but in our system, it\u2019s very pronounced.\u201d Normally, the phonon replica will appear as a group where intensity is strongest at the shortest wavelengths, and then rapidly decays. In their system, however, the phonon replica is the strongest in the middle and weaker at the side peaks. This indicated that the \u201ccoupling\u201d\u2014the phonon interaction with the emitter or the mechanical vibration between the two atomic layers\u2014is very strong and overwhelms the emission that has no interaction with the phonon, creating this irregular array of peaks.\n\u201cEvery time [the emitter] takes a breath, it emits one phonon and that phonon is taken out of one photon. So, the optical photon that is emitted is reducing energy by exactly one phonon,\u201d Li said.\nPhonons have been historically difficult to leverage for quantum computation, but they have great potential when coupled with photons. While photons are very popular for communication due to their speed, storing information on them is difficult. On the other hand, because phonons vibrate at a much lower frequency, future advancements in quantum technology may allow them to live much longer than photons, acting as temporary information storage. This is where the phonon-photon interaction comes in.\n\u201cThey can exchange information. When you want to stall the quantum information there, you convert them into phonons. The information will stay there; a little while later you can come back and read it out. But if you\u2019re ready to send that information out of the system to another system, then you convert it into a photon,\u201d Li said.\u00a0\nLeveraging this deterministic emitter and strong coupling activity could advance quantum computing systems by improving inter-computer communication. Excited, Li shared some of his ideas for future research that may be able to translate his findings into something specifically useful for quantum computing. One idea is the possibility of building a similar system with more than one emitter. But what would this achieve?\n\u201cBecause the phonons are localized, if the two emitters are close enough, the vibrations will interact with each other. This is a way to make two emitters talk to each other,\u201d Li said.\u00a0\nUnlike photons, which don\u2019t couple with each other, the phonon\u2019s properties suggest a possibility of coordinating two or three emitters\u2014by coupling the phonons instead. Since the photons cannot interact, they can instead \u201ctalk through\u201d the phonons before flying off to their destinations. If an effective two- or three-emitter system is achieved, it could revolutionize the way quantum computers communicate with each other.\nThis theory may also be able to address the issue of scaling in quantum computers\u2014 something that has greatly challenged researchers in the field. While larger computers with more qubits are more powerful in completing tasks, they are difficult and expensive to build and maintain. Currently, IBM\u2019s 433-qubit computer is the largest in the world. \u201cBut [433 qubits] isn\u2019t enough to do any realistic quantum computing,\u201d Li said. \u201cMaybe some toy models, but nothing to the level of what quantum computers promise in theory.\u201d\nInstead, just like in classical computers, tasks would benefit from being modularized, split up to be completed in parallel by multiple smaller computers. But while classical computers can operate at room temperature, most quantum computers require extremely low-temperature and low-noise environments in order to facilitate the precise manipulation of qubits. On the other hand, any communication between computers, achieved by sending photons through fiber-optic cables, happens at a frequency five orders of magnitude higher than that at which quantum calculations are performed. \u201cWe need something to bridge this energy gap,\u201d Li said, \u201cThis is where our emitters have their potential.\u201d\nThe team\u2019s breakthrough in photon-phonon coupling would allow these spatially separate quantum computers to solve the problem of effective transduction: converting signals between mediums without loss of information. This gives researchers the potential to build scalable, modularized quantum computing networks.\n\u201cThe holy grail of this research would be to make two, maybe three, or more, emitters talk to each other,\u201d Li said. \u201cThis will allow us to realize the full potential of quantum computing.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/the-phonon-phenomenon/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Scent-sational Memory Boost",
            "author": "Kenny Cheng",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/The_Smell_of_Memory_Final_Draft-Angelique-de-Rouen-500x347.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Angelique Rouen.\nCrying over a textbook with exams approaching? Can\u2019t remember the name of that familiar face? The solution may lie right under your nose\u2014literally.\nIn a paper published in the Frontiers of Neuroscience, scientists at the University of California, Irvine (UCI) found that the cognitive capacity of older adults increased by a whopping 226 percent when exposed to a different fragrance every night for six months. Participants of the study simply placed one of seven different essential oil scents\u2014eucalyptus, lavender, lemon, orange, peppermint, rose, and rosemary\u2014into a two-hour diffuser each night to reap the benefits of improved memory. By stimulating the neural networks in the brain with uncommon odors, the researchers found that the critical memory pathways of participants were significantly strengthened along with memory test scores when compared to the control group.\u00a0\nThe association between olfactory stimulation and memory has, in fact, long been established. For example, young adults who have trained as sommeliers\u2014and have therefore been exposed to dozens of wine odors every day for months\u2014have thicker brains, specifically in the entorhinal cortex, an area heavily associated with memory capacity. Another more recent example is the loss of smell as a result of COVID-19, which can lead to symptoms of poor memory and \u2018brain fog.\u2019 However, the most remarkable example of the relationship between smell and memory was demonstrated in South Korea where dementia patients were exposed to forty odors twice a day, resulting in a 300 percent memory improvement compared to other dementia patients who did not receive this olfactory stimulation. So, what sets the new UCI study apart?\n\u201cWe\u2019ve automated the process of olfactory enrichment. After all, it\u2019s unrealistic for patients to open forty bottles of perfume and sniff each one every day,\u201d said Michael Leon, Professor of Neurobiology and Behavior at UCI and a co-author of the paper. \u201cThe advantage of using odors at night is that odors can\u2019t wake you up. Unlike other sensory systems, the olfactory system doesn\u2019t go through the thalamus, which is connected to the sleep centers. You can wake somebody up with a noise or bright light or by touching them, but you can\u2019t wake somebody up with an odor, even if the odor is of frying bacon.\u201d\nWhile many people may be familiar with aromatherapy, in which scents from an essential oil are used for therapeutic purposes, \u201colfactory enrichment\u201d is a distinct concept. The benefit does not come from one particular scent\u2014instead, olfactory enrichment is reliant on long-term exposure to a multitude of new scents to stimulate the nervous system.\nLeon\u2019s team has now constructed a diffuser device capable of automatically delivering forty odors at night, aptly named MemoryAir. But wouldn\u2019t the novelty of these scents wear off?\n\u201cNo,\u201d Leon answered. \u201cIt turns out that people are not very good at identifying odors, let alone forty of them. So people will get that novel experience even if they do it over the course of many months. Although, we do have plans to introduce new odors in the future.\u201d\u00a0\nFrom their research, Leon and his partners are optimistic about the wider implications of their work for the treatment of dementia patients and for society at large.\n\u201cWe believe everybody in the modern affluent world is chronically deprived of olfactory stimulation. In fact, if you take a deep breath now, you probably wouldn\u2019t smell anything at all,\u201d Leon said. \u201cThe human brain evolved at a time when there were plenty of odors around. So, the good thing about being in the affluent world is that you don\u2019t have a lot of odors. The bad thing about not having a lot of odors is that your brain is deteriorating or at least not fulfilling its full potential because it doesn\u2019t get that stimulation.\u201d\nWhile the long-term effects of our odorless modern life remain a mystery, Leon argues that olfactory enrichment may be a simple and inexpensive tool for the prevention and treatment of dementia. But first, this technology needs to be tested on a larger pool of patients\u2014particularly those diagnosed with dementia. Additionally, there were concerns about the small size of the study group since some participants were removed to limit confounding factors that the COVID-19 pandemic may have introduced.\u00a0\nEven so, the next time you\u2019re grinding for your next exam past midnight, remember that novel scents\u2014both pleasant and unpleasant\u2014may boost your memory.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/a-scent-sational-memory-boost/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Brick of Life",
            "author": "Ilora Roy",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/The_Brick_Of_Life-Miranda-Selin-354x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Miranda Selin.\nImagine walking down an old pathway, strewn with weathered stones, when you trip on a loose brick. You might be irritated, but what if those mundane little bricks were more than an annoyance? What if they hid the secrets of civilizations from thousands of years ago?\u00a0\nDuring a series of excavations beginning in 1949 led by Max Mallowan and other British archeologists, a clay brick was excavated from the ancient city of Kalhu in Mesopotamia, today known as Nimrud, Iraq. The brick dates back 2,900 years to 879 B.C., which was during the reign of King Ashurnasirpal II over the Neo-Assyrian Empire from 883 B.C. to 859 B.C. The Neo-Assyrian empire was remarkable for many reasons, including advancements in astronomy and mathematics, as well as impressive architecture. The excavated \u201cbrick of life\u201d was once part of King Ashrunasipal\u2019s palace. It is a sundried concoction of straw, animal dung, and mud from the Tigris River, with an Akkadian inscription on it that reads: \u201cthe property of the palace of Ashurnasirpal, king of Assyria.\u201d\u00a0\nThe unassuming brick, which had broken horizontally into two pieces, was then donated to the National Museum of Denmark in 1958. Later, a group of scientists digitized it, splitting the brick again, but this time vertically. However, this split wasn\u2019t troublesome\u2014in fact, it was quite the opposite, as it allowed researchers to study uncontaminated material inside the brick. In an interview with Troels Pank Arb\u00f8ll, Assistant Professor of Assyriology at the University of Copenhagen and a key figure in the project, he conveyed optimism and enthusiasm for the potential discoveries on the horizon. The brick is a portal to a bygone era that invites us to peer into the archives of history.\u00a0\nThe researchers took five separate samples from the cracks in the clay and analyzed them to produce the aDNA\u2014ancient DNA\u2014of thirty-four taxonomic groups of plants. Each crack offered a look into the past. This was done through two cutting-edge sequencing techniques\u2014a process in molecular biology that involves determining the precise order of the building blocks of DNA molecules. The first technique is amplicon sequencing, which selectively amplifies and sequences specific DNA regions within a larger genetic sample. The second is metagenomic shotgun sequencing, which enables the exploration of all genes across all organisms within a complex sample. These precise and critical sequencing techniques were vital tools in uncovering the truths behind the fragile aDNA, which is highly degraded due to its age. The pursuit of these invaluable insights demanded patience and unwavering commitment.\nScientists are certain that the DNA is uncontaminated since all of the samples came from the core of the brick, which has not been exposed to the outside world since the brick was first created roughly 2900 years ago. Such certainty is remarkable, as it is rare for aDNA so old to remain untouched. The species found in the clay brick include specimens correlated with different types of Iraqi flora, carrots, parsnips, celery, birch, and more. This aDNA has bridged gaps in our understanding of the Neo-Assyrian Empire, serving as a portal into the past.\u00a0\nThe brick\u2019s aDNA can also help us to look into the future. By studying the species in such bricks, researchers may notice differences and similarities between plants from 2900 years ago and today. These observations will be important to combat climate change and help our ecosystem because the past furnishes researchers with invaluable insights into patterns of biodiversity loss, teaching us how to mitigate similar perils in the present day. \u201cThe goal would be, in due time, to establish a dataset of historical biodiversity for reference in current discussions,\u201d Abr\u00f8ll said. Examining how ecosystems responded and adapted in the past can shed light on their resilience and capacity for recovery in the future.\u00a0\nBeyond advancing our understanding of the ecosystem and our history, this discovery shows the necessity of interdisciplinary collaboration. When discussing the possible future for research around endemic plants in Iraq, Arb\u00f8ll emphasizes the importance of collaborating with scientists when researching the history of these plants. \u201cIt is our hope that future studies with more concrete identifications of ancient DNA might help speed this process up,\u201d Arb\u00f8ll said.\nSo, the next time you encounter a tricky loose brick, consider the possibility that it might harbor a treasure trove of secrets, bridging the chasm between antiquity and modernity\u2014a testament to the unyielding wonders concealed within the world\u2019s most unassuming corners.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/the-brick-of-life/",
            "captions": [
                ""
            ]
        },
        {
            "title": "An Eel-ectrifying Invention",
            "author": "Sharna Saha",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Teeny_Tiny_Droplet_Batteries1-Sonia-Jin-380x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Sonia Jin.\nAll the devices you own right now\u2014whether it be your computer, phone, or the TV on which you watch your favorite shows\u2014would be useless without one essential component: a battery. As technology has improved, batteries have gotten more lightweight and hidden. But while they are small enough to operate our phones and TVs, they aren\u2019t small enough for bio-integrated devices\u2014technology that can stimulate our cells.\u00a0\nWhen a premature baby is born, their whole body is covered in wires and sticky tape to measure temperature, blood pressure, respiratory rate, and heart rate. These wires and tape frustrate both the baby and mother, limiting their ability to interact and move. Using a bio-integrated device would allow them to avoid all this trouble, but currently, bio-integrated devices don\u2019t have a power source that can operate at the microscopic scale and still simulate human tissue.\nUniversity of Oxford researchers Yujia Zhang and Linna Zhou from the Hagan Bayley lab group have developed a miniature battery capable of altering the activity of human nerve cells. These researchers were inspired by nature and took a cue from ocean life: their device mimics electric eels by using internal ions to generate electricity.\u00a0\nElectric eels have been intensely studied over the years. In fact, Zhang was inspired by a paper that studied the energy mechanism of the eels. In it, Thomas B. H. Schroeder, Anirvan Guha, and Michael Mayer developed a large-scale hydrogen power source using that same mechanism. Zhang and his team had a simple thought: \u201cMaybe we can shrink this down via a droplet technique.\u201d\u00a0\nThe miniature power source they envisioned came to life using a chain of five nanoliter-sized droplets of a conductive hydrogel (a 3D network of polymer chains that contain a large quantity of absorbed water). For comparison, one strand of human hair is 80,000 to 100,000 nanometers wide.\nEach droplet has a slightly different composition, which creates a salt concentration gradient. At first, the droplets are separated from their neighbors by a membrane made of lipids which prevents ions from flowing between the droplets. But when the structure is cooled, it changes the medium, and the power of the structure is activated. When the droplets on the ends of this chain are connected to electrodes, their energy is released and transformed into electricity. Electricity then enables the hydrogel structure to act as a power source for external components.\u00a0\nLiving cells could also be attached to this device, which means that their activity would be impacted by the ionic current. When the power source is \u201cturned on\u201d (by cooling the structure), the neurons are able to \u201ctalk\u201d to each other via calcium signaling.\nTheir five-droplet units were only the beginning. By combining twenty of these five-droplet units in series, Zhang\u2019s team was able to illuminate a two-volt LED light.\u00a0 In the future, the team hopes to use a droplet printer to produce droplet networks made up of thousands of power units. With that amount of power, they can run bio-integrated devices long term.\u00a0\n\u201cThe major goal of this synthetic tissue project is to be able to interface with real tissues, creating a network between synthetic ones and biological ones,\u201d Zhang said. \u201cThis [project] is only one puzzle piece of the whole puzzle.\u201d\u00a0\u00a0\nIn this project, Zhang\u2019s team was able to stimulate neurons, but they are already working on stimulating heart tissues in a way that allows them to create a network of synthetic and real cells. Their end goal is to have a multifunctional interface to various tissues and organs, not just an interface for neurons. Through a full-body interface, the researchers would be able to control the communication of different types of cells, which will allow scientists to study cell development and tissue regeneration.\u00a0\nZhang says his team owes the majority of its success to its breadth of expertise\u2014their research involves engineering, chemistry, and biology. \u201cIt is very important for young scientists to understand the interdisciplinary nature of experiments, \u201d Zhang said. \u201cIt isn\u2019t enough to just be an expert in one field, but a lot of different fields. Only by combining these fields together can we truly solve these problems.\u201d\nIn the future, their new battery could have a notable impact on devices such as bio-hybrid interfaces, microrobots, and implants for improved disease monitoring, targeted drug delivery, and more. Zhang hopes that his team\u2019s research will make these ideas one step closer to reality.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/an-eel-ectrifying-invention/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Twinkle, Twinkle, Giant Star",
            "author": "Diya Naik",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/twinkle-star_final-draft-Luna-Aguilar-e1704576724111-395x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Luna Aguilar.\nA dying star shimmers and twinkles as its inner core, formerly a churning dynamo, sputters out its final breaths. Nuclear fusion combines atomic nuclei to birth new heavy elements that will soon occupy the cosmos. And then it happens: a fiery explosion, where the insides of the star fly everywhere. Left in the aftermath of the chaos is either a neutron star or a black hole.\nFor astrophysicists back home on Earth, understanding the characteristics of these explosive dying stars is the key to understanding our past and current universe\u2014everything from star formation to galaxy evolution to the very beginnings of our universe. But to really understand the characteristics of these stars, we need to start from the bellies of the beasts: the processes within these stars. This is done with asteroseismology. Asteroseismology applies the techniques of seismology\u2014which uses waves to understand the interior of the Earth\u2014to stars. In order to understand what is left behind after a star dies, you have to understand its internal structure back when it was still alive. This structure includes everything from the eddies of rotating plasma that twist deep within the furnace of the core to the light and heat that jostles from its surface.\nSo, how do we peer inside stars? We must turn an eye to their light. How bright is it? Does it change over time? Is it high-energy like an X-ray or is it low-energy like a radio wave? The answers to each question reveal a wealth of information on the energy released by the star: its temperature, its stability, and much more. By making predictions for what light outputs should look like, we can test the actual light of stars against our assumptions to see how well our physics match up with the real world. Any discrepancies reveal new avenues for future scientific exploration.\nFor astrophysics postdoctoral researcher Evan Anders and his research group at Northwestern University, one particular real-world signal caught their attention: red noise. Red noise is a ubiquitous, low-frequency twinkling in the light signals from massive, stable stars\u2014much like the static on a blank TV channel. These stars are called main sequence stars, a category which most stars, like our Sun, belong to. Real-life observations about a star allow researchers to eliminate possibilities and therefore gain a more precise understanding of the internal mechanics of the star.\n\u201cWe hoped this red noise was gravity waves because gravity waves give you a lot of information about the structure of the star,\u201d Anders said. \u201cThey\u2019re telling you about how big the core is.\u201d Gaining a more lucid understanding of the inside of the star, such as the size of its core, allows us to better understand the energy that the star releases and define the pressure it uses to create new elements. While scientists do have simple models for this task, these models fail to align with real-world data. They need a more detailed model built on empirical evidence, and gravity waves could provide that evidence.\nBut what is a gravity wave? We can see an example here on Earth: storms and winds push the ocean waters up, creating waves. But the Earth\u2019s gravity resists this upward movement, causing the wave to be pulled downwards, creating an oscillatory displacement. A similar thing happens in stars. \u201c[In gravity waves], you displace this [fluid] from where it wants to be and gravity pushes it back down\u2014and then you get this wiggly pattern,\u201d Anders said.\nDeep within the centers of stars, nuclear fusion of hydrogen into helium creates an inferno, generating immense amounts of bright hot plasma that have nowhere to go but out. When this material reaches the very edge of the core, it breaks free in a fourteen-day-long ripple before sinking back into the heart of the star. As fusion continues, the core roils with these cycles of hot to cool to hot to cool, churning gravity waves across the core. These waves propagate through the rest of the star, reverberating at different frequencies like guitar strings.\nModeling these waves with a supercomputer is extremely difficult, but Anders and his team designed a clever way of mimicking the red noise. Thanks to earlier models by one of the researchers (Northwestern fluid dynamicist and assistant professor Daniel Lecaonet), Anders and his team had previous models of wave formation and propagation that could be tweaked for higher accuracy.\u00a0\nAnders\u2019 simulations can be compared to a music studio\u2014recording raw music before passing it through a filter to create a specific effect. Anders\u2019 \u2018filter\u2019 consists of code that translates the waves created by core convection\u2014showing what they would look like distorted by the rest of the star outside of the core\u2014and thus what the waves actually look like leaving the star and reaching our eyes as light.\u00a0\nThe scientists created their filter based on a simpler model of how stars worked. The idea was that it would be easy to predict what the light signals from this rudimentary filter should look like. If the output of the program matched their predicted output, the scientists could go back and painstakingly craft a more advanced filter with all the physical complexities of the star\u2014a filter with enough refinement to see unique signals such as the red noise.\u00a0\nTheir basic filter demo passed with flying colors, and it was then time for the real deal. Anders\u2019 team set to work crafting a more accurate filter, one that captured the intricacies of the star\u2019s mechanics outside of the core, reflecting the true polyphony of physical effects of a star rather than just a few. If the glimmer of signal leaving the filter matches the hum of the red noise, then gravity waves are the source of the red noise.\nHowever, when Anders combined the waves generated by convection and the echo of gravity waves outside the core, the difference between the output signal and red noise was glaring. Their simulation revealed that gravity waves are far too muted to match the high-amplitude signal of red noise. But for scientists, a definitive no is just as exciting as a definitive yes. Knowing what the red noise isn\u2019t brings astronomers closer to understanding what it really is. The next theory in line is that the red noise comes from motions closer to the star\u2019s surface.\u00a0\nAnders has two directions he might take his future research. He might want to take the elaborate programs he developed here to further explore the waves within stars. \u201cWe use the amplitude of the wave to learn something about the process that\u2019s driving it,\u201d Anders said. The second direction, on the other hand, would be refining his simulation further. \u201c[We add] rotation, because stars, well, rotate,\u201d Anders said.\nThere are several possibilities for improvement in the team\u2019s research. They did not factor in the rotations that affect the cycles of plasma, nor did they include the effects of magnetic fields. However, their work still proves to be an important step in understanding the inner workings of stars. Listening to asteroseismology\u2019s music of the spheres brings us closer to understanding the massive stars that churn in our universe.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/twinkle-twinkle-giant-star/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Race Against Resistance",
            "author": "Sofia Arbelaez",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/50742494257_0c33398076_c-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nYale physician Onyema Ogbuagu has been involved in clinical trials for HIV for more than a decade. Trained as a medical student in Nigeria during the peak of the HIV epidemic there, Ogbuagu has seen HIV treatment evolve considerably over the course of his career. \u201cAt the time [I was trained], reversing immune deficiency was a dream,\u201d Ogbuagu said. Nowadays, directly managing HIV is a real option. However, multidrug resistance and therapeutic regimen complexity remain notable barriers to treatment.\nOgbuagu published a landmark phase-three clinical trial testing the effectiveness of Lenacapavir, a recently FDA-approved HIV treatment. Administered as a biannual injection, Lenacapavir is the longest-acting antiviral agent that has been approved for HIV treatment. As an antiretroviral therapy, Lenacapavir interrupts viral replication of HIV in the body, slowing the progression of the disease, improving immune function, and reducing the risk of HIV transmission. The treatment is of particular interest for patients demonstrating multidrug resistance.\u00a0\nLenacapavir contributed to a virologic suppression rate of over eighty percent, much higher than the average virologic suppression rates observed in other multidrug-resistant trials. \u201c[The trial] holds promise that we\u2019re able to reach certain people that wouldn\u2019t be successfully treated with [other] regimens,\u201d Ogbuagu said.\u00a0\nAs this medication is being tested to treat HIV, Ogbuagu is also hopeful that HIV treatment options may evolve into a wide range of different methods and frequencies of delivery. \u201cPeople could have the luxury of choosing a method that\u2019s effective and that fits their lifestyle and their preferences,\u201d he said. Ogbuagu\u2019s study certainly brings his hopes of creating simpler, more effective therapeutic regimens to improve quality of life closer to reality.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/a-race-against-resistance/",
            "captions": [
                ""
            ]
        },
        {
            "title": "It\u2019s All In The Stones",
            "author": "Patrick Wahlig",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/7976357294_ecaae78472_w.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nA tiny, three-inch fish might hold the key to unlocking an ancient secret of evolution.\u00a0\nTucked away in the southern Appalachian Mountains is the Greenfin Darter (Nothonotus chlorobranchius), a hardy fish that exhibits tremendous genetic diversity. Until recently, the driver of this diversity was unknown. Researcher Maya Stokes, along with Yale Professor Thomas Near and a team of dedicated scientists, set out to discover the mechanism behind what appears to be real-time allopatric speciation, or speciation prompted by geographic isolation, in the Appalachian Mountains.\u00a0\nNear puts the overall research question simply. \u201cWhy are we seeing species richness within the rivers themselves?\u201d he said. The answer lies in the stones\u2014erosion, to be exact.\u00a0\nThe Greenfin Darter is selective of its habitat, preferring hard metamorphic rock over soft sedimentary rock. Erosional processes in the Tennessee River, however, have exposed areas of sedimentary rock, separating regions of metamorphic rock. This has forced Greenfin Darter populations into isolation. The team\u2019s research displays that erosion of metamorphic rock has severely reduced gene flow between populations of N. chlorobranchius, driving genetic divergence up. This research\u2014an intersection between the fields of ichthyology (the study of fishes) and geoscience\u2014has allowed a novel explanation of species divergence in what Near calls \u201cgeologically quiet\u201d areas without tectonic influence.\nStokes is thrilled with the recent work. \u201cWe tried to quantitatively combine data sets across disciplines,\u201d she said. \u201cWe were able to integrate these datasets fairly seamlessly, which allowed us to highlight a novel geologic mechanism.\u201d As research endeavors become increasingly integrative, this study is an inspiring example of interdisciplinary success.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/its-all-in-the-stones/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Happy Spouse, Happy House",
            "author": "Sunny Vuong",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/pexels-timur-weber-8559962-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pexels.\n\u201cHeartbreak\u201d is purely figurative, referring to the sadness over a loved one wounding our emotional state, not our biological heart. However, a new study from researchers at the Yale School of Public Health indicates that the concept can become literal\u2014at least, for those married or in a committed relationship. The study found that among 1,593 adults who were treated for a heart attack, there was an independent association between severe marital stress and worse recovery through their first year after hospital discharge. This association was strong even after adjusting for patient demographics.\nThe authors of the study, doctoral graduate Cenjing Zhu and Professor of Epidemiology Judith Lichtman, found that when following up after a year on symptoms reported by patients such as depression, chest pain, and overall quality of life, a strong association with marital stress still appeared in every aspect of their recovery.\u00a0\nTo the researchers, this calls attention to a need for better awareness that marital stress and other factors in the psychosocial domain could be important factors during the recovery process. \u201cWe absolutely have to think about all of the acute care, but we also have to broaden our perspective to think about other aspects that may be contributing to how well somebody recovers,\u201d Lichtman said.\u00a0\n\u201cFrom a care provider perspective, there should be more prompting during their day-to-day communications with their patients about how they\u2019re doing.\u201d Zhu said. \u201cIt\u2019s not only about numbers in the clinical factors, but also their overall well-being.\u201d The study emphasizes the overlooked importance of overall social and mental well-being on physical recovery.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/happy-spouse-happy-house/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Representation in Animation",
            "author": "Abigail Jolteus",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Joseph_11-scaled-e1704574706608-500x280.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Photo Courtesy of Fareed Salmon.\nIn the past, in computer animation, many Black characters would have poorly animated braids, or more frequently, just have straight hair. For years, computer animations would use these inaccurate representations of tightly coiled hair, also known as afro-textured hair. Recently, as more people of color have been hired and cast for animation roles, the animation industry has moved towards becoming more diverse and inclusive than ever before.\u00a0\nHowever, this increase in diversity did not translate into more accurate animation of afro-textured hair. \u201cThe way that hair has been simulated, at least since the \u201890s, has been many line segments chained together, and making them small enough gives a smooth appearance,\u201d said Theodore Kim, an associate professor of computer science at Yale. Animating hair is achieved through various mathematical equations where the twists of each strand must be carefully simulated for accurate hair motion. \u201cTherefore, when a character shakes their head, you can see realistic movement,\u201d Kim said. However, this process only works for the overwhelming majority of animated characters who are white and have straight hair. \u201cThe trouble appears with the physics equations selected for simulation,\u201d he said.\nA team of computer scientists at Yale have created a novel physical model that allows for more accurate animation of tightly coiled hair, more realistically capturing the way it looks and moves. \u201cWe were concerned with three different types of elastic energy for hair: stretching, bending, and twisting energies,\u201d said Haomiao Wu, one of the lead researchers on the project. \u201cThese energies constrain how the strands behave in an elastic way. We proposed a different set of those three energies for a model so that it is more stable.\u201d In other words, they wanted to capture the true essence of afro-textured hair using sophisticated mathematical modeling.\nTheir isotropic, hyperelastic model was specifically designed for better simulation of tightly coiled hair. \u201cIsotropic means that no matter the direction, the restorative force is the same,\u201d said Alvin Shi, another one of the lead researchers on the study. Restorative force is the force needed for an object to return to its initial size and shape. In this case, it enables a hair strand to return to its initial coiled state, which better captures afro-textured hair. This model is also faster, simpler, and more robust than previous models.\nThe researchers devised this model by discarding the previous assumption for mathematical equations to simulate the curling pattern of each strand and instead consider large bends and torsions, as well as assuming, to a certain extent, that the hair is non-straight. While this model was designed for kinky, curly, or coily hair, the researchers discovered that it is also effective for straight hair.\nAs with all simulations, there are flaws. Some of these limitations include the scaling behavior of tight, coily hair and lack of variation in how the hair can look. Currently, the model can account for only two different appearances of afro-textured hair: a clumped look, well-defined curls, and a more picked-out look, or fluffed-out afro-textured hair. By decreasing the radius of a wisp\u2014a clump of hair strands common in afro-textured hair\u2014but keeping the same total number of hair strands, a more picked-out look is obtained. However, these looks are not incredibly realistic compared to real-life individuals with the same hair type. \u201cWe are looking to improve on the realistic aspect of our model,\u201d Shi said.\nFor the next steps, the researchers plan to conduct further experiments with the realism of the simulated hair and possibly test an anisotropic model, meaning the pattern is different in various directions, which could lead to better animations of different hairstyles with afro-textured hair.While no animated content or games are perfect, it is important that Black individuals see themselves adequately represented in the media that they consume. As the creators of one of the first models specifically for tight, coily hair, the team also hopes that other researchers will be inspired to conduct similar research. \u201cWe are looking forward to seeing more and more research in this field, not just from us but other researchers as well,\u201d Wu said. Ultimately, they want their model to lead to greater and better racial and ethnic representation in animated games and movies. \u201cIt might take longer than we wish for these techniques to be implemented, but we are hoping as soon as possible,\u201d Wu said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/representation-in-animation/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Cancer: Not Just Bad Luck?",
            "author": "Sebastian Reyes",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-11-500x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of NIH Image Gallery.\nIt is well known that our risk for cancer increases as we age, but we still don\u2019t understand why. How might the wrinkles marking the corners of our eyes relate to cancerous cells suddenly forming inside us? Previous research established a high correlation between cancer risk and the number of replications a cell undergoes throughout our life, leading to the hypothesis that random, unlucky mutations during cellular division are a notable driver of tumor formation. This aptly named \u201cbad luck\u201d hypothesis has been widely debated, with scientists questioning how the theory accounts for the impact of environmental factors. Now, researchers at Yale University are proposing an answer: an age-related chemical signature hiding in our genomes.\nThe study, conducted by recent PhD graduate Christopher Minteer and former Yale Assistant Professor Morgan Levine explores a set of epigenetic alterations called DNA methylation\u2014that is, chemical attachments to the genome rather than changes within the DNA sequence itself\u2014associated with aging and risk of diseases like cancer. Through the repeated replication of astrocytes, a type of cell found in the central nervous system ideal for this type of manipulation, Minteer\u2019s team was able to mimic the rapid, unconstrained replication of tumorous cells. Having achieved tumor-like growth, the team then designed an algorithm to quantify the epigenetic signals in the cells. They eventually identified a progressive methylation signature that they called CellDRIFT, the strength of which increased with age across multiple tissues and differentiated tumors from normal tissue.\u00a0\nThrough additional examination, Minteer\u2019s team found that the CellDRIFT signature was elevated not only in cancerous cells, but also in healthy tissues that were predisposed to tumor formation. They examined healthy breast tissue from breast cancer patients prior to treatment and found that even the tumor-free tissues displayed an elevated CellDRIFT signature compared to non-cancerous controls, suggesting that CellDRIFT could predate the formation of tumors and serve as a warning sign. They also found that its presence was strongly correlated with poor patient survival, meaning that CellDRIFT, along with related measures, may help researchers and clinicians predict cancer aggression.\n\u201cWe provided further context to the \u2018bad luck\u2019 hypothesis and created a tool to better study it,\u201d Minteer said. While the \u201cbad luck\u201d hypothesis links the majority of cancer risk to random, sudden mutations in the genome, the CellDRIFT signature appears gradually. It slowly increases over time, meaning that CellDRIFT increments can vary depending on environmental factors, such as exposure to carcinogens. Thus, CellDRIFT can help provide a more thorough and unified understanding of the previously known underlying causes of tumor formation.\nThe researchers also explored whether they could reverse or otherwise reset the CellDRIFT signature. Namely, they manipulated stem cells to \u201creset\u201d through a process known as Yamanaka factor reprogramming\u2014a process in which special genes are introduced to cells to transform them back into an unspecialized state, thus allowing them to re-develop into new types of cells. Each instance of Yamanaka factor reprogramming consists of three phases: initiation, in which the cell begins to show genetic signs of resetting, maturation, in which the bulk of the reprogramming process occurs, and stabilization, in which the cells settle into their new form. Minteer\u2019s team observed a dramatic decrease in CellDRIFT during the maturation phase, but the signature increased again once the cells entered the stabilization phase. In other words, they found promising evidence to suggest that although CellDRIFT cannot be stopped completely, it can be impeded, thus providing a new approach to preventive cancer treatments.\nMinteer\u2019s team also recognized that while CellDRIFT presence can be used to predict many aspects of cancer risk and aggression, calculating the signature is a difficult task in itself. Thus, they constructed a package to help clinicians and researchers quickly and efficiently quantify the signature, making their discovery more accessible to others unfamiliar with this field. \u201c[The package] is uniquely suited to serve as a resource in the lab,\u201d Minteer said. Although it still requires additional validation and experimentation, Minteer expressed excitement about the potential future uses of this package in both experimental and clinical settings.\u00a0\nWhile the use of epigenetic tools in clinics is still in its infancy, the findings of Minteer\u2019s team are promising. CellDRIFT is unique in that it considers the myriad of factors that trigger the formation of an individual\u2019s specific tumor, rather than reducing these factors to \u201cjust bad luck.\u201d This provision of tailored cancer diagnoses makes CellDRIFT a compelling tool for clinicians to understand the full cancer narrative, and its contribution to the debate about cancer\u2019s origin suggests a new, encouraging role for cancer prevention.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/cancer-not-just-bad-luck/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Super-Sizing Life\u2019s Smallest Secrets",
            "author": "Kara Tao",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/puzzle-2500333_1280-500x264.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nLet\u2019s turn the clock way back to when you consisted of only a small clump of cells. How does this tiny clump of cells know to transform into various cell types throughout your body, from hair and eyes to lips and legs? It turns out that these instructions are encoded in our genome. However, our genome is initially \u201csilent.\u201d It needs to be activated and reprogrammed through a process called zygotic genome activation so that our cells can properly differentiate into specific cell types in our body.\u00a0\nThe Giraldez lab at Yale specifically investigates the cellular mechanisms of this process, which involve a variety of interactions between protein \u2018factors\u2019 and DNA that work together to transform the \u201csilent\u201d state of the genome into the activated state. \u201cIt\u2019s kind of like erasing the blackboard and writing new instructions,\u201d said Antonio Giraldez, the Fergus F. Wallace Professor of Genetics. \u201cWe\u2019re trying to understand the factors that erase the previous instructions and the factors that instruct the genome to employ the first cascade of events that will lead to development.\u201d\u00a0\nTraditionally, researchers have relied on indirect biochemical methods to unravel the intricacies of this process, as the existing visualization techniques have presented considerable limitations. \u201cWe wondered if we could actually come up with a new way to visualize what happens inside of these clusters,\u201d said Mark Pownall, a member of the Giraldez lab who first looked into this research direction. In collaboration with the Bewersdorf lab at Yale, Pownall adapted their already-established technique of pan-expansion microscopy (pan-ExM), incorporating labeling of protein, RNA, and DNA to create Chromatin Expansion Microscopy (ChromExM). Pan-expansion microscopy involves fixing cells to an expandable gel called a hydrogel that swells via addition of certain functional groups. By layering multiple hydrogels on top of each other, the cells take on a larger size that can be better resolved under a microscope.\nThe cell, and specifically the chromatin that makes up our chromosomes, expands to become four thousand times larger, allowing for a never-before-seen look into the small-scale interactions that thus far, researchers have only been able to theorize about. \u201cThis has allowed us to start measuring distances that are ten times higher in resolution than what we have ever captured before,\u201d Giraldez said. \u201cThis has revealed how the models and the cartoons we are drawing from biochemical experiments can be visualized for the first time.\u201d\u00a0\nOne of the main concerns of expansion microscopy was whether the cell\u2019s proportions could be maintained during the expansion process. To ensure that the cell expanded proportionally, the Giraldez lab developed a technique where the initial cell was marked with parallel stripes, and if the stripes remained parallel after expansion, it would have exhibited proportional growth. \u201cThis showed us that we preserved these stripes really well after they were cleaved, which was one hint that we actually preserved chromatin structure,\u201d Pownall said.\u00a0\nWith this novel technique in hand, the Giraldez lab could finally visualize the specific factors involved in activating the genome. Using ChromExM, they were able to study the function of Nanog, a protein that binds to a \u201cgene enhancer\u201d region of DNA that stimulates the activation of genes involved in development. Although Nanog had been shown to interact with RNA polymerase, located at the promoter region of the gene where the polymerase would initially bind to initiate transcription of DNA to mRNA, it was unclear whether these structures actually required transcription to form. By using ChromExM, they found that the Nanog protein was initially in close contact with RNA polymerase, but once transcription was initiated, the protein separated itself from the growing strand of mRNA. The Giraldez lab termed this interaction the \u201ckiss-and-kick model,\u201d where transcription acts as the \u201ckick\u201d to separate the enhancer and promoter regions.\u00a0\nThe development of the human body is an incredibly complex process directed by genetic codes regulated by countless factors that interact with chromatin and different organelles in our cells. The novel technique of ChromExM not only allows us to visualize these processes, but is also accessible and applicable to other fields of study, as it only requires a confocal microscope that can be found in many research labs. \u201cI think that this could add a fundamental tool to the global toolbox to really understand how different molecules interact in the nucleus by visualizing these fundamental processes of life,\u201d Giraldez said. \u201cThe accessibility is great, and the possibilities to apply ChromExM to other approaches is very large.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/super-sizing-lifes-smallest-secrets/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Counterpoint: The Heaviest Air in the World",
            "author": "Ian Gill",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/40889571404_8174d548f9_c-375x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nSince the days of the Manhattan Project, nuclear physicists have concerned themselves with the study of certain atomic nuclei known as \u201cmagic nuclei.\u201d Protons and neutrons, also known as nucleons, occupy shells within the nucleus corresponding to different energy levels. When these shells are full, our leading nuclear theory predicts the resulting isotope to be significantly more stable than other isotopes of similar mass and neutron-to-proton ratios.\u00a0\nMagic nuclei are unique because they have a full shell of either protons or neutrons. Since magic nuclei were first discovered, scientists have been able to determine if a given nucleus is \u201cmagic\u201d by counting the number of protons and neutrons. Specifically, physicists predict that magic nuclei must contain exactly two, eight, twenty, twenty-eight, fifty, eighty-two, or 126 protons or neutrons. Following this pattern, 28O, the oxygen isotope consisting of twenty neutrons and eight protons, was predicted to be \u201cdoubly magic,\u201d since it has a magic number of both protons and neutrons.\u00a0\nOxygen, 16O, in its natural form, has six protons and six neutrons. To test the stability of 28O, a team of physicists with experimental operations based in the RIKEN Radioactive Isotope Beam Factory in Wako, Japan, worked to produce the isotope. The generation and detection of 28O was a highly technical feat: researchers shot a high-energy beam of calcium-48 atoms at a beryllium target, producing fluorine-29, which is only one proton away from the desired 28O. The team then propelled the fluorine-29 atoms into a wall of liquid hydrogen, knocking off the necessary proton and creating 28O. Using a specialized detector, the physicists observed the emission of four neutrons and a stable 24O isotope, indicating that 28O had in fact been present before decaying into 24O. To their surprise, however, the decay of 28O failed to demonstrate the high stability expected of a \u201cdoubly magic\u201d isotope, raising a host of new questions about its atomic structure.\nNumerous results from the experiment suggested that, contrary to expectations, 28O does not have a full shell of neutrons in its nucleus. The first piece of evidence was the almost immediate decay of 28O on a faster timescale than the researchers were able to measure, indicating that the supposed stability of the isotope does not hold up experimentally.\nThe researchers also computed the spectroscopic factor, a number between zero and one that describes the stability of the nuclear structure based on how much the arrangement of nucleons changes when a proton or neutron is removed. In a nucleus with full shells, the structure is very rigid, so removing one nucleon doesn\u2019t cause widespread change in the arrangement of the surrounding nucleons, resulting in a high spectroscopic factor. On the other hand, if the structure of a nucleus is very unstable, removing one nucleon sets off a cascade of structural changes, yielding a low spectroscopic factor. Interestingly, the spectroscopic factor found by the team was much lower than what would have been expected if 28O had a full shell of neutrons.\nBased on this data, the team concluded that despite having the correct number of protons and neutrons to fill both nuclear shells, some of the neutrons in 28O occupy higher energy levels instead, making the isotope not \u201cdoubly magic.\u201d 28O is not the only exception to the typical rule for identifying \u201cdoubly magic\u201d nuclei: 24O, which contains sixteen neutrons and eight protons, has historically demonstrated the stability that comes with being \u201cdoubly magic.\u201d In light of these results, physicists are left with two major questions: What criteria can be used to predict if a nucleus is \u201cdoubly magic?\u201d And why is it that the numeric rule tends to hold, but has a few select exceptions?Future experiments aim to gain more context for the stability of 28O and to explore how nuclei with high neutron-to-proton ratios, such as 30O, behave. Through these experiments, scientists hope to broaden their grasp of the nuclear shell model as a whole, gaining insight into phenomena taking place from a scale as small as that of a single isotope, to the scale of an entire neutron star. Alternatively, it\u2019s entirely possible that these further investigations could reveal deep flaws with our current approach towards the structure of the nucleus, and perhaps even serve as a starting point for new theories. As for now, we can only be certain that there is much work to be done to fully understand \u201cmagic nuclei.\u201d\n\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/counterpoint-the-heaviest-air-in-the-world/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: \u201cWriting for Their Lives\u201d",
            "author": "Keya Bajaj",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Jane-Stafford-image-1-500x401.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Smithsonian Institution Archives.\nIt is late 1937, and the American Society for the Control of Cancer convenes for a press dinner under the dim chandeliers of the Harvard Club. All the invitees are welcome to attend, except one: America\u2019s premier medical journalist, Jane Stafford. To seat a woman at the table would have \u201cconsiderably changed the character of the dinner,\u201d admitted the organization\u2019s publicity director; besides, the University Club didn\u2019t allow women entry anyway. Thrumming below the frenzied fever of twentieth-century scientific exploration was a culture of leaving women out of a conversation they pioneered, when they were the ones deconstructing scientific jargon.\nIn her newly released book Writing for Their Lives, historian Marcel Chotkowski LaFollette chronicles the untold story of eight female science journalists who made science intelligible to the average reader and put its latest advances on the front page, but who were themselves omitted from the headlines. These women disseminated scientific discoveries through published stories and columns, breaking both the news and the professional paradigms of the time.\n\u201cHistorians of science have tended to write about scientists, not those who wrote about science,\u201d LaFollette writes. In her novel, LaFollette attempts to lift the \u201chistorical fog\u201d that has hidden the pioneering efforts of these women. In 1921, Science Service, a small Washington, D.C.-based science news organization, gave a group of dedicated female science journalists their footing. Emphasizing meritocracy instead of gender, Science Service boasted a female majority in its cohort of editorial staff writers; Jane Stafford was just one of them.\nJane Stafford\u2019s wide news sweep encompassed everything from schizophrenia to public health epidemics, with a particular focus on cancer. Her work involved expository pieces, like one in 1928 contesting the nicotine-free contents of a tobacco brand. She brought a potent mixture of journalistic strengths to the newsroom: the ability to decipher volumes of dense scientific literature, a dexterity with language (specifically in her allusions to Classical myths and iconography), and an ability to speak truth to power.\u00a0\nIn 1945, Science Service reported news of the atomic bomb, explaining the science behind history as it unfolded in real time. While other news outlets succumbed to sensationalism, the female journalists at Science Service collaborated to present a more measured report of the Hiroshima-Nagasaki events. Martha Morrow reported on the physics; Jane Stafford explored radiation and physiology; Helen Davis wrote about its chemistry; and Marjorie Van de Water discussed the bomb\u2019s socio-psychological effects. As \u201ccareer women,\u201d they braved both the pressures of the news cycle and the inherent misogynies of a male-dominated scientific community.\nWhile occasionally dry in its journalistic tone and factually heavy in its ambitious scope, LaFollette is successful in her detailed account of the hidden figures of scientific journalism. If it took time for science to leave the confines of laboratories and trickle into our lives\u2014learning from curbside newsstands, on the taxi radio, and over morning cups of coffee\u2014Writing for Their Lives shows us that it took far longer to decide who got to tell those stories. \u201cThe paths to success [for female journalists] were riddled with the potholes of institutionalized bias along with the gaping gullies of entrenched and unapologetic misogyny,\u201d LaFollette writes.\u00a0It would be 1973 before the Harvard Club would open its doors to full-time women members. By then, Jane Stafford had already established fundamental journalistic practices, co-founded the National Association of Science Writers, and served as president of the Women\u2019s National Press Club\u2014all while not being allowed to sit in on dinners.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/science-in-the-spotlight-writing-for-their-lives/",
            "captions": [
                ""
            ]
        },
        {
            "title": "That Magnetic Touch: Asteroids Hitting Asteroids",
            "author": "Elizabeth Watson",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/ysm_asteroids-Annli-Zhu-1-e1704580232745-384x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Annli Zhu.\nIn 2017, scientists unearthed a magnetic puzzle in our own solar neighborhood, beginning with samples taken from a series of iron-rich meteorites that had fallen to Earth. Upon analyzing the samples, the team detected evidence of magnetism. This discovery was important because it meant that the parent asteroid of these meteorites was somehow capable of internally generating its own magnetic field\u2014a phenomenon that was difficult to explain.\u00a0\nThe same year this discovery was made, planetary scientist Zhongtian Zhang, now at the Carnegie Institution for Science\u2019s Earth and Planets Laboratory, began his graduate studies at Yale. Zhang was intrigued by the results of the meteorite analysis, but like the rest of the scientific community, he was confused as to how an asteroid like this one could feasibly generate a magnetic field. \u201cThe community had been puzzled with this as well, and I hadn\u2019t been able to come up with a solution for a long time,\u201d Zhang said.\nSix years later, in a paper published in the Proceedings of the National Academy of Sciences this July, Zhang and David Bercovici, Frederick William Beinecke Professor of Earth and Planetary Sciences, may have figured out the origin of these magnetic meteorites. The secret may lie in asteroids, and what happens when they collide with one another.\nThe Paradox of Magnetism\nPlanetary bodies generate magnetic fields through mechanisms known as \u2018dynamos.\u2019 In general, dynamos rely on convective motion, in which less dense material rises up as more dense material sinks down. Take Earth, for example: the iron-nickel core at the heart of our planet solidifies from the inside out in a process called outward solidification, causing the convective motion necessary to generate a magnetic field. Understanding dynamos can provide insights into a planetary body\u2019s internal structures and evolutionary histories.\nThe cores of asteroids, however, are a different matter altogether. Meteorites originate from asteroids, which are fragments of rocks in space that date back nearly 4.5 billion years. Meteorites that are rich in iron, specifically, come from the cores of asteroids. There are approximately 1.3 million asteroids in our solar system, most of which reside in the Asteroid Belt between Jupiter and Mars. Of these, only eight percent are made of metal. The liquid cores of these metal asteroids are known to cool from the outside in through a process called inward solidification. This is why these metal asteroids were not thought to be capable of generating their own magnetic fields\u2014inward solidification directly inhibits convection and suppresses the traditional magnetic field dynamo.\nWhen Asteroids Collide\nWhen thinking about this paradox, Zhang turned to a previous project of his on rubble-pile asteroids, which are formed when asteroid fragments coalesce into new objects due to gravitational forces. \u201cI started to think of things in terms of collisions and formation of rubble piles,\u201d Zhang said. \u201cI was thinking that this may be the solution to the problem that\u2019s been on my mind for quite a while.\u201d\nZhang deduced that in order for the metallic core of an asteroid to become exposed in the first place, a collision must have taken place in a process termed \u2018mantle unstripping\u2019 by means of another asteroid. The force of an asteroid hitting another asteroid would cause the mantle of the original asteroid to be broken down, exposing the resulting asteroid fragments, alongside the core, directly to the environment of space.\nIn the aftermath of a collision, an asteroid\u2019s molten core would have broken apart and reformed, and if a small portion of metal fragments were able to cool down sufficiently before falling back into the molten core, they would sink downwards. Bercovici compared the process to dropping ice cubes in hot tea, except the ice cubes sink. These cold fragments that sink to the center would then extract heat from the overlying liquid and cause the outward solidification capable of driving a magnetic field. Meanwhile, the inward solidification that occurred from the surface would produce cold material to preserve this field. \u201cIt provides an implication about how asteroids work, [how they were] formed and disrupted,\u201d Zhang said. \u201cIt provides a new scenario for people studying magnetic fields.\u201d\nInitially, Zhang set out to determine the size of the asteroid fragments necessary to power a dynamo in this fashion. The ideal fragment would be small enough to cool efficiently in the vacuum of space, but also large enough to remain sufficiently cold after sinking through the hot liquid region of the core, according to the two researchers. Zhang modeled the thermal regulation of the fragments and determined that the ideal fragment size is approximately ten meters, which coincided with his calculations for the average fragment size created by these collisions. \u201cIt turns out that fragmentation size is right in the Goldilocks regime for having the \u201cright\u201d ice cubes,\u201d Bercovici said. \u201cBottom line\u2014that was cool, pun not really intended.\u201d\nTo Psyche And Beyond\nZhang performed additional modeling and determined that the convection generated from this theory would be adequate to power a magnetic field for at least one million years. This research could have important implications for what we understand about asteroids, including NASA\u2019s future Psyche Mission.\nPsyche is an asteroid that has long been a subject of fascination for some members of the scientific community, as it may be the iron-nickel core of a planet that formed billions of years ago. The mission recently launched on October 13, 2023, and is anticipated to reach Psyche in 2029. Once in orbit, the hope is that the mission will allow scientists to develop a deeper understanding of our solar system\u2019s history, as well as that of our own planet, through the information collected from Psyche. Zhang and Bercovici\u2019s research could be crucial to understanding Psyche\u2019s origin, as well as planetary evolution as a whole. Bercovici is also a principal investigator on the Psyche Mission, which was the source of funding for this project.\n\u201cI decided to be part of the mission because of my interest in planetary sciences in the first place,\u201d Zhang said. \u201cIt was also a personal interest in these kinds of things and being part of the Psyche mission bolstered me to look at this as a problem of magnetic fields and meteorite observations.\u201d Zhang hopes to expand this work in new directions in the future, hopefully involving information about metal asteroids obtained from the Psyche Mission to understand the asteroid\u2019s history.\nBercovici enjoyed working with Zhang over the course of the project, citing Zhang\u2019s tenacity after having published several \u2018hard-won\u2019 papers. \u201cZhongtian is one of the most creative, deep-thinking, and versatile students or colleagues I\u2019ve had the pleasure of working for,\u201d Bercovici said. \u201cSometimes he was like a mustang bolting into the hills with new ideas, and my job was to help him close the loop and explain his ideas clearly. Having students and postdocs much smarter than me is always fun, and my job is to make sure they communicate well with mere mortals, like myself.\u201d\nTo understand the universe, one must acknowledge its mysteries\u2014including the ones that exist in our own solar neighborhood. After six years of mystery, this magnetic meteorite puzzle may finally have been solved, and its lessons applied forward, thanks to the work of these two Yale researchers.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/that-magnetic-touch-asteroids-hitting-asteroids/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Perimeter: Integration or Invasion?",
            "author": "Isaiah Asbed",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Perimeter_Kara_Tao-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao.\nOn my desk sits a brain. Until 1984, it was kept in a Brown University neuroscience lab. It\u2019s now found below a wrinkled Scarface poster, illuminated by LEDs. It\u2019s just a plastic model, and the right side of the medulla is broken off a little. But regardless of its idiosyncrasies, it\u2019s a brain. It has a cerebral cortex, tinted pink and indented by the peaks and valleys of gyri and sulci. At its base is its cerebellum, darkened by dense collections of cell bodies. It even has a pineal gland, Descartes\u2019 seat of consciousness, buried deep within the cerebrum.\nAnd that\u2019s almost enough to make you believe, despite its literal plasticity, that electrochemical signals are running around in there, from axon to dendrite, from neuron to neuron. Because it\u2019s those signals that make a collection of gray and white matter a brain. An almost entirely self-contained network of cells that uses electrical messages from our sensory receptors to conceive of a world both external and internal.\nWe recognize that this consciousness, granted to us by the synapses between neurons, is something sacred. And yet, for millennia, we\u2019ve altered it. When a Tiwanaku shaman, exploring a river valley deep in ancient Bolivia, came across a psilocybin mushroom, his dendrites proliferated, making his nerve networks more intricate than ever before. Receptors typically bound by serotonin were inundated by psychedelics, permanently changing both his synapses and the worlds they created.\nBut now, we\u2019ve moved beyond chemical alteration. Perspective can dictate whether we\u2019ve shifted to integration or invasion. We\u2019ve invited machines into our neural web, and by doing so, we\u2019ve let them become a part of our consciousness. Functionally both dendrite and axon, electrode arrays can not only receive and process information, but also directly stimulate neighboring neurons through electrical signals, alternately activating and inhibiting their fellow world creators. Abilities previously reserved for biological matter have been ceded to imitations.\nInstinct might tell us not to tamper with what we hold sacred. But we, like that early shaman, can be grateful that we don\u2019t give instinct too much power. Because our relationship with these machines is, for now, more mutualistic than parasitic. Their integration with our synapses will give us revolutionary insights into the worlds within that grayish-pink model on my desk.\u00a0 Research into disorders like epilepsy will develop faster than ever before, and the brain\u2019s connection with prosthetic limbs will strengthen dramatically. As long as we don\u2019t surrender ourselves completely to this technology, the changes these machines bring can be for the better.\nArtist\u2019s Statement:\nWhen I was young, I read the story of John Henry\u2014the existentialist slave turned railroad worker who gave his life to prove that even in an age of rapid industrialization, man was still greater than machine. When he collapsed from exhaustion, and his victory over steam power turned pyrrhic, I felt angry. I didn\u2019t know it then, but that was the birth of an inherently human distrust for mechanization.\nWhen I grew up, and the stories I encountered began to evolve, I saw the movie Awakenings, based on the work of neuroscientist Oliver Sacks. As I watched him manipulate the neurotransmitters that determine our responses to stimuli, almost to the point of curing an incurable form of encephalitis, I felt a growing attachment to our cells and the signals that produce conscious thought.Somewhat predictably, I\u2019ve always had my suspicions about the brain-machine interface. Reading Song et al.\u2019s article on the newest biocompatible electrode array didn\u2019t change that. But it did make me consider the conflict between the human instinct to cast off the help of machines and the human desire for progress. And now, I\u2019ve started to wonder which impulse\u2019s victory is in our best interests.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/perimeter-integration-or-invasion/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Exercise as Therapy for Chemotherapy-Related Nerve Damage",
            "author": "Kenna Morgan",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Morgan_Figure1-1-500x334.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nThanks to revolutionary treatments that have emerged in recent decades, those diagnosed with cancer have strong reasons to be more hopeful than ever before. Although advanced therapeutics have allowed for an encouragingly large population of cancer survivors, many overlook what happens after treatment is completed. Research investigating cancer therapies is certainly critical, but further work is needed to address post-treatment quality of life and side effects as well.\u00a0\n\u201cDuring their treatment, [ovarian cancer survivors] have this whole medical team providing information and the help they need, but after that, some patients described standing at a cliff, not knowing where to go,\u201d said Anlan Cao, a PhD candidate at the Yale School of Public Health. Compared to the vast support system present during the course of treatment, cancer survivors are often left feeling unsure of how to proceed afterward.\u00a0\nThese worries are especially heightened by adverse effects that persist even after treatment ends, including chemotherapy-induced peripheral neuropathy (CIPN). CIPN is one of the most common side effects of ovarian cancer treatment, producing unpleasant symptoms like numbness, pain, and altered perceptions of touch as a result of damage to neurons. Unfortunately, besides the medication duloxetine (which can only be used in a small subset of CIPN cases), there are no approved therapies available to effectively treat CIPN.\nAs a result, researchers including Cao and members of Melinda Irwin\u2019s and Leah Ferrucci\u2019s research group (which studies cancer survivorship in the School of Public Health) have been investigating lifestyle factors as a potential treatment for CIPN. By analyzing data from the Women\u2019s Activity and Lifestyle Study in Connecticut, a randomized controlled trial that had already been shown to improve general health-related quality of life, they were able to discover that a six-month aerobic exercise intervention significantly improved CIPN among patients who had undergone treatment for ovarian cancer.\nWomen in the intervention arm, which entailed telephone counseling that encouraged moderate-intensity aerobic exercise (primarily brisk walking), reported having fewer CIPN-related sensory, motor, and auditory problems compared to an attention control group which had telephone calls discussing general health topics.\u00a0\nThese findings suggest aerobic exercise could be a worthwhile therapeutic for ovarian cancer survivors experiencing a common treatment side effect. This is highly encouraging for cancer survivors, as it gives them more autonomy in their recovery process. \u201cThey don\u2019t have to rely solely on doctors and drugs; they can actually exercise and improve these really nasty symptoms,\u201d said Cao.\u00a0Future research has the potential to shed light on other lifestyle factors that may similarly improve treatment side effects and quality of life among cancer survivors, and Irwin\u2019s and Ferrucci\u2019s research group has already begun studying how comprehensive lifestyle interventions could improve side effects and quality of life during cancer treatment. Pain and numbness caused by nerve damage are major reasons that patients are unable to fully adhere to chemotherapy regimens, therefore contributing to reduced survival rates. Taken together, these studies may offer hope to minimize distress and symptoms during and after chemotherapy treatment, and ultimately both save and improve lives.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/exercise-as-therapy-for-chemotherapy-related-nerve-damage/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Shhhhh\u2026 Can You Hear That?",
            "author": "Yossi Moff",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/PREFERRED-IMAGE_Moff_Figure2-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nFor a long time, silence has been thought of as the mere absence of sound. But what if we can perceive silence, in the same way we perceive sounds?\nWe are constantly hearing sounds, all around us. When we hear sound\u2014a question, a joke, a line of music\u2014we don\u2019t simply hear a random assortment of sound waves. Our brain parses through and separates the sound waves into discrete segments, allowing us to comprehend what we just heard. This process is known as auditory event segmentation.\nSo, we know that sounds are parsed and sorted into auditory segments. But what happens when there is silence? Does event segmentation simply turn off, or does our brain also segment silence in the same way it segments sound?\nThis question is exactly what Rui Zhe Goh, a PhD student in philosophy and psychology at Johns Hopkins University, researches under the mentorship of philosopher Ian Phillips and psychologist Chaz Firestone. To collect data, Goh and his team took a few previously tested auditory illusions and replaced the original sound illusion with silence. \u201cWe\u2019re asking if silences also elicit a segmentation process. And to find that out, we ask whether these illusions that happen with sound also happen with silences,\u201d Goh said.\nIn the first experiment, called \u201cOne-Silence-Is-More,\u201d researchers played two different sound clips to their test subjects. The first clip consisted of one continuous silence, while the second clip contained two short silences. Both durations of silence were the same, yet the subjects perceived the one continuous silence to be longer than the two short silences. This was a promising result\u2014the auditory illusion still worked, even with silence.\nIn the second experiment, the \u201cOddball Silences\u201d illusion, Goh focused on the perception of partial silences. In other words, what happens when there are two sounds playing, and only one of them goes silent? It turns out that we perceive the lengths of these partial silences differently, depending on what the preceding partial silences were. \u201cDifferent silences \u2018sound\u2019 different,\u201d wrote Goh in his research paper, published in the Proceedings of the National Academy of Sciences (PNAS).\nIn the final set of experiments, \u201cSilence-Based Warping,\u201d subjects heard two tones played, with a pause between them. The first time the tones were played, there was complete silence. But in the second test, there was embedded silence\u2014background noise played before and after the silence, that disappeared when the two tones were played. Subjects perceived the two tones to be farther apart when played in embedded silence than in complete silence, as would be expected if embedded silences were indeed segmented into auditory events. This illusion confirmed for Goh and the other researchers that our brain can perceive silence as it does sound, segmenting it for interpretation. \u201cIt\u2019s a bit counterintuitive to think perception can retrieve what\u2019s not there. But even when there is no sound out there in the world, we can still get a perceptual experience,\u201d Goh said.\nFor Goh, philosophy and silence are deeply intertwined. What began as a philosophical question about whether silence is perceived led to his scientific experiment, and ended with empirical evidence that demonstrates silence can be heard, not just inferred. Moving forward, Goh is excited to tackle other philosophical questions through a scientific lens, continuing to expand our framework of perception.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/shhhhh-can-you-hear-that/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Does Money Make You Happy? Kind Of\u2026",
            "author": "Daniel Y. Wang",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wang_Figure2-500x335.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nIn his novel Anna Karenina, Leo Tolstoy famously penned: \u201chappy families are all alike; every unhappy family is unhappy in its own way.\u201d While this novel was written over a century ago, Tolstoy\u2019s statements about the relationship between happiness and income have remained in public interest ever since. Most recently, researchers including cognitive scientist Gal Zauberman at the Yale School of Management have discovered relationships between income and happiness within different income brackets, painting a clearer picture of the true impact of income on well-being.\nIn his recent study published in the Journal of Economic Behavior and Organization, Zauberman and his co-author, Bouke Klein Teeselink, created two \u2018Anna Karenina\u2019 plots: one that depicts a positive relationship between income and well-being that eventually levels out, and one depicting a negative relationship between income and deviations in reported well-being that eventually levels out.\nThe idea of an asymptotic positive relationship between income and well-being has previously been posited. As one\u2019s income increases, on average, they would receive smaller and smaller boosts to their well-being. Zauberman\u2019s research dove into how the distribution of people\u2019s well-being was impacted by income changes. He uncovered that those with higher incomes have similar happiness levels, while those with lower incomes had widely different levels of happiness (recalling Tolstoy\u2019s quotation). Moving up the income bracket, there are fewer people who report having low levels of well-being. Zauberman coined the term \u201cmisery\u201d to explain this shrinking demographic in the upper classes of society.\u00a0\nZauberman believes that his research can prompt change in our current \u201credistributive\u201d economic policies, which are policies about moving money from one income bracket to another. \u201cWho are we moving?\u201d Zauberman asks. \u201cMaking somebody happy, happier, is not as important as making somebody who lives in misery [happier].\u201d Such data about differences in well-being could greatly aid the government in increasing citizen well-being by crafting economic policies that maximize happiness.\u00a0\nHowever, there are still many steps to be taken in this field of research. People\u2019s subjective realities clearly influence their perception of happiness, but how do people of different religions or races respond to income changes? Who tends to be more or less sensitive to changes in income? While Zauberman touts the potential for this research to further shape policy, he also believes it could challenge subjective well-being as a deciding factor in policy. Would it make sense to distribute more income to one group because they are more sensitive to income changes?\nAll in all, while Zauberman\u2019s research demonstrates how far we\u2019ve come in the debate of whether money improves happiness since Tolstoy, his research also uncovers the unexpected complexities behind the relationship between income and well-being. This work also emphasizes that perhaps Tolstoy\u2019s assertion is an oversimplified view of the role money plays in our lives, reflecting the nature of science: answering questions will pose more questions.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/a-definitive-answer-to-whether-money-makes-you-happy-kind-of/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Caught by the Tail: Taming Self-Destructive Killer T-Cells",
            "author": "Jiya Mody",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Mody_Figure1-500x281.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of iStock.\nImagine reprogramming a weapon to target only the \u2018bad guys\u2019 while sparing the good ones. That\u2019s essentially what chimeric antigen receptor (CAR) T-cell therapy does. CAR-T cells are the specially engineered superheroes of our immune system, meticulously designed to seek out and destroy cancerous cells while sparing the healthy ones in our bodies.\u00a0\nBut like our favorite heroes, CAR-T cells face their own challenges. They can become fatigued from overstimulation or trigger severe immune reactions known as cytokine release storms. At Yale University, the Sidi Lab introduced a revolutionary approach that involves synthetic cytotoxic T lymphocyte antigen-4 (CTLA-4) fusion to engineer CAR-T cells. By fusing the regulatory cytoplasmic tail of CTLA-4 with CAR-T cells, they have enhanced CAR-T cell therapy\u2019s effectiveness by preventing CAR-T cell fatigue. CTLA-4 acts like a traffic patrol for the immune system, preventing immune responses from going haywire.\nXiaoyu Zhou, a postdoctoral fellow and first author on the paper published in Nature Immunology, noted how surprising the discovery was. \u201cEventually you\u2019re going to find something where [a discovery] not only perfectly fits your story, but where you could make a difference,\u201d Zhou said.\nBy using CTLA-4 to regulate the molecular dynamics of CAR-T cells, the Sidi Lab\u2019s researchers are opening new doors for cancer therapy. Unlike other immune checkpoints, CTLA-4 operates extrinsically, meaning its regulatory function is influenced from outside the cell. This extrinsic mechanism enables precise and dynamic control over immune checkpoint modulation.\u00a0\nHowever, the road from laboratory discovery to clinical application presents its own set of difficulties. The Sidi Lab is diligently working on refining this technology to be antigen-responsive, meaning it could adapt to different types of cancers and solid tumors. There are new questions now, but much like a superhero\u2019s unwavering determination, Zhou\u2019s driving force\u2014good old curiosity\u2014remains steadfast.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/caught-by-the-tail/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Fabrics of the Future: Accessories With Informed Touch Applications",
            "author": "William B. Wang",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Wang_Figure2-334x500.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Brandon Martin/Rice University.\nPersonal devices that stimulate our sight and hearing have skyrocketed in development over the past few decades; however, this has left our sense of touch, ironically, untouched. A textile-based touch-influenced haptic device developed by mechanical engineers at Rice University sets to bring a new dawn to the wearable accessory industry. Inspired to assist those around the world with visual and hearing impairments, these researchers wish to use the sense of touch to revitalize accessible communication.\u201cAround a billion people suffer from loss of hearing or loss of vision,\u201d said Barclay Jumet, a mechanical engineering PhD student who is the lead author of the study published in\u00a0Device. \u201cWe wanted to address these concerns through a last-resort pathway of communication\u2014the sense of touch, or haptics.\u201d\nComposed of multiple fluid-based cells, these wearables can be easily applied to a user\u2019s forearm. The cells generate point-force cues, where users will feel gentle taps with half-second delays that go down their arms as they come into contact with various obstacles and dynamic environments. Moreover, these heat-sealable textiles are resilient to wear and tear, making them ideal for daily use.\u00a0\nInstead of using voltage and current, these wearable devices utilize the flow of fluids, enabling researchers to program soft materials without using electronics. Fluidic signals\u2014such as pressures and flow rates\u2014help control the delivery of complex haptic cues, including sensations like vibration, tapping, and squeezing. A small, lightweight carbon dioxide tank affixed to the wearable feeds airtight circuits within the device, causing quarter-sized pouches\u2014up to six on each sleeve\u2014to inflate with varying force and frequency.\nExtraordinarily, these devices are also extremely user-friendly. \u201cWe\u2019re extremely excited to introduce intuitive feeling cues into this device,\u201d said Daniel J. Preston, assistant professor of mechanical engineering at Rice University and corresponding author of the study. \u201cFor example, if we want to tell someone to go forward or to the left or right, we introduce patterns in the point-force cues that feel natural to the user\u2014essentially, they are inclined to move in those directions, as opposed to having to learn how to interact with the haptic device.\u201d These parameters can also be adjusted based on the user\u2019s desired applications for the wearable.\nBuilding on their approach from previous research related to textile logic, the Rice researchers faced little struggle in developing this haptic device. \u201cIn one of our prior publications, we implemented digital logic circuits to introduce memory storage and decision-making into wearables,\u201d said Preston. \u201cWe were in a good position to translate this knowledge to the haptic domain, building this wearable that can deliver various navigation cues.\u201d\nIn the future, Jumet and Preston aim to expand the application of their wearable device into clinical and everyday settings. \u201cSurgeons could benefit from the enhanced training regimen that haptics enables,\u201d said Jumet. \u201cEveryday people like ourselves could also enjoy entertainment like movies or games to a greater degree by having this additional dimension of touch added to these activities.\u201d The applications of touch-based devices are broad, and their introduction to the broader public could be closer than we think.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/fabrics-of-the-future-2/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Surviving Climate Change: How An Endangered Songbird Adapted to a Warming Climate",
            "author": "Vivian Wang",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/48173361441_b291f09999_c-500x490.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nIn recent years, global temperatures have risen by an average of 0.32 degrees Fahrenheit per decade, a rate that has doubled since 1981. Faced with the ever-growing stresses of warming temperatures and habitat degradation, animals are forced to either relocate or attempt to adapt to their mutating environments. In San Diego, California, a small songbird with an olive-brown back and a pale-yellow belly has encountered its fair share of dramatically warm temperatures coupled with chaotic weather patterns. Struggling to keep pace with these harsh conditions, the now endangered southwestern willow flycatcher had no other resort but to adapt to survive.\nDespite the recent surge in studies on physical and behavioral responses to climate change, research surrounding genetic adaptation remains limited as it involves tracking subtle changes in populations over decade-to-century-long timescales. However, a team of biologists led by postdoctoral researcher Sheela P. Turbek at Colorado State University was able to investigate past evolutionary patterns leveraging recent advances in historical DNA analysis.\u00a0\n\u201cOver the past ten years, the technology for sequencing whole genomes from historical specimens has advanced considerably,\u201d Turbek said. In their recently published paper in Nature Climate Change, the team tracked evolutionary changes in southwestern willow flycatchers to search for patterns and shifts in genetic diversity within populations by comparing contemporary and historical genome data collected in San Diego over a one-hundred-year period.\nBy comparing the genetic sequences of the San Diego willow flycatcher population to\npopulations in other regions of the US, the researchers discovered that the San Diego willow flycatcher population had become more genetically similar to other nearby populations in recent history. Drier climates and habitat destruction in the Pacific Northwest and Desert Southwest regions may have driven populations in those areas out of their original habitats and into San Diego. Next, interbreeding between immigrant and native populations likely introduced new genetic variants into the San Diego population, a process known as gene flow.\nThis increase in genetic variation tends to boost the chances of population survival because the population has a more diverse pool of individuals, some of whom may adapt better to the new and changing habitat. Turbek and her team theorize this may be the reason why the southwestern willow flycatcher was able to cope with changes to their environments.\nAlthough climate change created drier, hotter conditions for some southwestern willow flycatcher populations, those near San Diego instead faced more intense precipitation and humidity. To evaluate how the songbird genetically adapted to these pressures, Turbek\u2019s team extracted DNA from over 200 rare contemporary and historic samples, searching for changes in genomic regions associated with two major climate-linked variables: dew point temperature\u2014the temperature at which water vapor starts to condense\u2014and precipitation level. Comparing these results to nearby populations outside of San Diego, they found that the birds\u2019 genetic codes have shifted independently of genome patterns in the Pacific Northwest and Desert Southwest, in the direction of adaptation to higher dew point temperature and precipitation over the past century. This discovery further supports the narrative that willow flycatchers in southern California have evolved to withstand the effects of climate change. \u201cOur findings suggest that wild organisms have some capacity to cope with changing climate conditions over a century-long timescale,\u201d Turbek said.\nThe team\u2019s findings provide valuable insight into how wild populations have responded to climate change on a genetic level and the crucial role of gene flow in allowing animals to adapt to their changing habitats. As climate change continues to ravage entire ecosystems, Turbek\u2019s team believes that maintaining genetic diversity could be the key to preserving endangered life.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/surviving-climate-change/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Following Your Own Path: Designing Shapes That Can Roll Along Any Trajectory",
            "author": "Isabel Trindade",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/261895700_c8d006c104_c-500x374.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nImagine laying a cylinder on its side at the top of a ramp and letting it go. What do you imagine would happen? Nothing particularly exciting: it would roll in a straight line down the ramp. Now imagine if it was something more complicated\u2014a cone, perhaps, or some elaborate polyhedron. Suddenly, the path begins to seem less predictable.\nMathematicians have long been investigating the rolling patterns of complicated solids such as these. But there is an even broader question: if you draw any kind of seemingly random periodic path, can you find a shape that would follow that trajectory when rolling down an incline? Recently, a team of mathematicians including Yaroslav Sobolev sought to explore this. \u201cFor me, it was just a useless but addictive puzzle that is easy to state, easy to think about, easy to solve, but which seems bottomless when you dig further into the underlying mathematics,\u201d Sobolev said.\u00a0\nHe had first heard about shapes like sphericons and oloids from a Youtube video in 2020 and decided to create his own shapes. He first designed a trajectoid\u2014a solid shape that periodically reverts to its original orientation when rolling down a slope\u2014and then designed an algorithm that could compute the correct shape to match a given trajectory without having to search mathematical literature for solutions. \u201c[The algorithm] succeeded as a joke and was promptly forgotten for the following 1.5 years,\u201d Sobolev said.\nHowever, the team recently published their work in Nature, claiming that for almost any given periodic path on an inclined plane, they could develop a trajectoid to roll along it. They accomplished this by developing an algorithm to determine the precise indentations needed on the solid to alter its path to fit the trajectory. They 3D-printed the shapes, embedded a steel ball for weight, and then experimentally validated their trajectoids by tracking their rolling paths and comparing them to the originally drawn ones (Figure 1).\nBut is this possible for any periodic path? The team found that for a given periodic path, a matching trajectoid would only exist if there exists a sphere which, after rolling along some number of the path\u2019s periods, would restore its original orientation. \u201cIf your path satisfies this mathematical condition, computing the trajectoid\u2019s shape [and manufacturing it] is pretty straightforward,\u201d Sobolev said.\nSurprisingly, they found that almost any random path fulfilled their condition, as long as the sphere was required to restore its original orientation after two periods. \u201cFor several months, we were trying to find even a single path for which this condition failed,\u201d Sobolev said. The only paths that failed had a very specific symmetry and a sharp corner. Any path lacking these two characteristics satisfied the condition, and a matching trajectoid could be found.\nAs noted in the article, the existence of trajectoids for most paths could have unexpected implications in fields such as quantum and classical optics, which remain to be explored. There are also applications outside of science. Sobolov mentions the work of Henry Segerman, who created shapes that never roll in one direction and were used for circus performances. However, Sobolov notes that their study was largely motivated by a fundamental curiosity about shapes, their trajectories, and the unexpected things they can do.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/following-your-own-path/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Complexity of Microbial Coexistence",
            "author": "Fareed Salmon",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Microbes-1.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Wander Lord.\nThe human gut is home to hundreds of bacterial species making sure that you get the nutrients you need from food. But how are these trillions of bacteria able to coexist within the constrained space of our intestines\u2014or in any space for that matter?\nCurrently, there are two opposing views on how these species coexist. Some ecologists believe that it is an additive effect, where coexistence in a community requires every species to be able to live with each other as pairs outside of the community. Another perspective proposes that coexistence is instead an emergent property of the community and isn\u2019t solely explained by the nature of the constituent species.\u00a0\nUltimately, explaining the diversity of microbial communities is a fundamental ambition of ecology because of microbes\u2019 wide-ranging functions in multiple environments. The presence of these two opposing views motivated a group of Yale ecologists led by Alvaro Sanchez to experimentally determine the mechanism behind such coexistence. They first created twelve representative communities, each containing a diverse array of microbes. They then extracted individual species from each community and tested their ability to coexist with each other as isolated pairs.\nThe result was clear: most pairs of species could not coexist: one would often competitively exclude the other. This finding indicates that the ability for species to coexist is an emergent property of communities rather than an intrinsic property of the species. Moreover, this competitive exclusion showed signs of a hierarchy system. In most communities that were tested, the lower-ranking microbes were excluded.\u00a0\nHaving understood that microbial coexistence is an emergent property, researchers are now trying to explain what contributes to it. Some suggest evolutionary origins while others hint at environmental resources. However, further experiments must be done to discover what influences coexistence in microbial communities.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/the-complexity-of-microbial-coexistence/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Carbon Dioxide\u2019s Green Leap",
            "author": "Vamsi Gorrepati",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Carbon-Poillution-500x333.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Robert S. Donovan.\nMethanol has long been considered a promising candidate for sustainable energy production because it is an energy source that can be derived from various carbon-based resources including biomass and coal. Even the greenhouse gas carbon dioxide (CO2) can be turned into methanol. However, while both are simple single-carbon-based molecules, efficiently converting one to the other remains a challenge. The process first requires converting CO2 to carbon monoxide (CO), which is relatively efficient, but the subsequent transformation of CO into methanol involves multiple steps, each of which reduces the overall effectiveness of the reaction. This inefficiency limits our ability to utilize carbon dioxide as a feedstock for sustainable fuel production.\nRecently, however, a team of chemists led by Yale professor Hailang Wang designed an innovative approach to convert CO into methanol. The team first recognized CO\u2019s low solubility in an aqueous electrolyte, which slows the reaction because fewer CO molecules reach the necessary reactants. To solve this, they introduced a microporous layer into the electrode structure, helping facilitate the transport of CO. This approach increased the methanol Faradaic efficiency (FE)\u2014a measure of how effectively electrical charge is used in the reaction\u2014from forty percent, well below the standard of practical application, to sixty-six percent. Additionally, they identified the first electron transfer to CO as the rate-limiting step, with water as the primary proton source. To address this, the researchers utilized bicarbonate and high-pressure conditions to assist the proton transfer, achieving an impressive methanol FE of eighty-four percent.\nThese results pave the way for the future of methanol production, strengthening its case as a sustainable energy source. This research demonstrates how targeted adjustments can vastly improve efficiency, nearly doubling the previous record. Such progress opens the door to producing a clean energy source and decreasing greenhouse gas emissions at the same time, combining two essential environmental strategies.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/carbon-dioxides-green-leap/",
            "captions": [
                "A coal fired power plant on the Ohio River just West of Cincinnati"
            ]
        },
        {
            "title": "Moir\u00e9 Materials",
            "author": "William Archacki",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Meet-Moire-Materials-Steve-Blanco-e1704579947554-500x314.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Steve Blanco.\nThe moir\u00e9 effect is a phenomenon you can witness with just a marker and paper. First, take your marker and draw a honeycomb pattern of hexagons on two sheets of paper. Now lay them atop one another askew, rotating the top sheet slightly. By combining these two lattices, you should see regular, repeating patterns much larger than any individual hexagon. This is the moir\u00e9 effect in action: from a distance, the overlapping hexagons make a larger tessellation that seems to alternate between light and dark regions.\nNow imagine if atoms stood at the vertices of every hexagon on the paper, connected to their neighbors by chemical bonds. That\u2019s the structure of a moir\u00e9 material. At an atomic scale, the repeated patterns of the moir\u00e9 effect change how light interacts with a material and, in turn, how the material transmits electrical signals resulting from light.\nIn a recent Nature Materials publication led by Fengnian Xia, professor of electrical engineering at Yale, the team innovated upon moir\u00e9 materials. By finding a more controllable way to produce the moir\u00e9 effect at an atomic scale, they have made a material that has a wide range of useful physical properties that may pave the way for a new generation of optical sensors.\nScientists vs. Thermodynamics\nThe new moir\u00e9 material recipe by Xia and his colleagues starts with three simple ingredients: tungsten, sulfur, and selenium. When heated in a furnace through a process referred to as chemical vapor deposition, these three elements combine into flat, hexagonal lattices. The vertices are occupied by atoms of tungsten, sulfur, and selenium. After heating for a second time with a supply of the same elements in different ratios, an additional layer forms on top of the existing hexagonal lattice, this time with a slightly different spacing between its atoms\u2014a different lattice constant. The alignment of differently-spaced layers signals success: the moir\u00e9 effect is present. Now, it\u2019s a matter of lattice size rather than rotation.\nIt has historically been a challenge for researchers to fabricate moir\u00e9 materials because of the natural way that layers form. The most stable way for two identical layers to stack results in a perfect alignment that never produces the moir\u00e9 effect. So, rather than using the conventional \u2018twistronics\u2019 approach to moir\u00e9 material fabrication, which fights against thermodynamics to force the layers to rotate, this new approach from Xia\u2019s group relies on variations in the spacing of atoms. In their recipe, the moir\u00e9 effect is created by stacking hexagons of different sizes, rather than different orientations.\n\u201cTwisting two layers at a specific twist angle is not the most stable form of matter,\u201d said Matthieu Fortin-Desch\u00eanes, a postdoctoral fellow in Xia\u2019s research group and first author on the paper. \u201cBasically, we came up with an approach to directly grow these moir\u00e9 patterns with tunable spacing. Instead of twisting, we grow them with different lattice parameters to tune the moir\u00e9 periodicity.\u201d\nBy precisely varying the concentrations of sulfur and selenium relative to tungsten, the researchers saw that the pattern they form has a \u201ctunable period\u201d. In other words, they can control how large the patterns appear. With a tunable period, there is a new world of possibilities. \u201cIf you\u2019re able to tune the periodicity, you\u2019re able to tune the properties of the material,\u201d Fortin-Desch\u00eanes said. Tuning properties is a big deal for electrical engineers. The next step is figuring out how to leverage these tunable properties for use in real technologies.\nTiny Materials, Big Implications\nWorking on these materials has gotten Xia and his colleagues thinking a lot about light. What kind of information can we glean from light? For one answer, look to the astronomers. When studying exoplanets, they often examine the spectra of light that passes through the planets\u2019 atmospheres. By using spectroscopy, a crucial analytical technique that works like forensics for light, they deduce which gases are floating around in a breath\u2019s worth of air many millions of miles away.\nAnd waves of light have more parameters than just their spectra. Measuring light\u2019s polarization can give insights into what substances the light has interacted with. For example, light that reflects off water is polarized because the process of reflection forces all the light waves to oscillate within the same plane. Other parameters of interest like intensity or coherence can each be measured with dedicated pieces of lab equipment. For Xia, these parameters of light pose an exciting question: What if it was possible to pick up on the wealth of information provided by light using just a single sensor?\u00a0\nThe new moir\u00e9 material has a special way of interacting with light and transmitting electric current. Just as bumps on a hill change the way water flows, moir\u00e9-induced variations in the invisible landscape of the material\u2019s electric potential change how electrons move from one point to another. Incoming light gets absorbed by the material and starts a flow of electrons, and when that flow of electrons is recorded as a current or its corresponding voltage drop, information about the light\u2019s source is conveyed somewhere within the data. The challenge, then, is to decode the data and reveal the secrets hidden within the material\u2019s electric signals.\n\u201cThis material is highly tunable, and it interacts with light very strongly. That would allow us to combine this reconfigurable material with the latest deep learning algorithms,\u201d Xia said. \u201cIn another 2022 paper, we used deep learning to realize the detection of many parameters of light simultaneously.\u201d Their approach\u2014referred to as deep sensing\u2014could change how scientists use light. Rather than just spectroscopy, scientists could tap into new information carried by light if they watch how all the parameters change together.\n\u201cWe can relate this to image recognition,\u201d Xia said. \u201cThis high-dimensional photoresponse contains all the information we want to know, but we don\u2019t know how to extract this information.\u201d In the same way that a deep learning algorithm figures out to differentiate images of cats from images of dogs, an algorithm might learn to correlate the complex electric signals from the sensor to any kind of data a scientist might be examining. \u201cLet\u2019s assume you want to know the concentration of a certain gas. You can do that by measuring the absorption spectrum. But you don\u2019t have to do that. You can skip that process. You can go directly from the photoresponse to the concentration of the gas if you do enough training correctly,\u201d Xia said.\nNot Just Tungsten\nAlthough the recent paper only covers one moir\u00e9 material, the researchers behind it are hopeful that the fabrication process can be applied in other ways. \u201cThe intention of studying the growth mechanisms is to understand the fundamentals of the growth processes and then try to extrapolate to other systems,\u201d Fortin-Desch\u00eanes said. Of special interest is graphene, a substance made of two-dimensional sheets of carbon atoms, which could be mixed with silicon in the same way that sulfur was mixed with selenium. The hope is that each new system may have its own set of unique properties that can be applied to electrical engineering challenges of the future.\n\u201cSince we have so many properties that emerge and that can be easily tuned, we can expect that we will find something that is very useful using these moir\u00e9 materials,\u201d Fortin-Desch\u00eanes said. Novel fabrication methods, such as this one, are creating possibilities for new atomic arrangements of materials. By changing the way energy and electrons dance at the quantum scale, researchers may reshape the future of semiconductor devices.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/moire-materials/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Venus\u2019 Skincare Routine",
            "author": "David Gaetano",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Aphrodites_Skincare_Routine_Kara_Tao-500x386.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao.\nBeneath the endless search for the perfect skincare routine is a desire to maintain our youth against the ravages of time. Yet despite the wealth of commercially available aloe creams and collagen powders, the march of age inevitably slows the skin renewal process, leaving wrinkles and rough, dry skin. Likewise, the history and age of a planet can be deciphered from its surface by, for instance, dating the oldest rocks and crystals in its bedrock. But what if a planet\u2019s surface appears much younger than its actual age?\u00a0\nVenus, the second planet from the sun, is estimated to be 4.5 billion years old. It is theorized that the planet was named after the Roman goddess of beauty due to its dazzling brightness in the night sky. However, Venus has another claim to its name: its youthful appearance. The planet\u2019s surface is less than one billion years old, which is young considering the long history of the geophysical time scale. According to a recent paper published in Nature Astronomy, the secret to Venus\u2019 strikingly young surface may lie in volcanic events triggered by early energetic collisions.\u00a0\nThese interplanetary collisions have always fascinated Simone Marchi, a planetary scientist at the Southwest Research Institute (SwRI), who teamed up with Yale geophysicist Jun Korenaga and SwRI Sagan Fellow Raluca Rufu to investigate the effects of early collisions on Venus\u2019 surface. \u201cVenus comes with its own mystery and there are a lot of things that we don\u2019t know,\u201d Marchi said. \u201cSo I thought, maybe there is something we can say about Venus by studying these early processes.\u201d\u00a0\nAre Collisions The New Collagen?\nImagine an object just short of the mass of the moon colliding with the surface of Venus. This is the scale at which high-velocity collisions occur on Venus\u2019 surface. When such objects collide with planets at this scale, it adds to the surface in a process called accretion. The team\u2019s research suggests that late accretion events\u2014the buildup of new matter in and throughout a planet\u2014greatly contributed to Venus\u2019 overall geological makeup.\nEarlier projects conducted by Marchi and colleagues examined the consequences of these large-scale impacts on Mars and Earth, but Marchi had something different in mind for Venus. To understand the effect of late accretions on Venus, Marchi was interested in studying the planet through the lens of geophysics\u2014the study of a planet\u2019s structure and atmosphere. In doing so, the team could figure out how Venus\u2019 volcanic activity, which appeared to play a major part in its youthful surface, was linked to the collisions. \u201cProcesses like [volcanism] are connected to the geophysics of the planet, so that gives us the motivation to try to understand how this early energetic event could affect the geophysical evolution of the planet,\u201d Marchi said, referring to the collisions that produced late accretions. His work on Venus explored the relationship between these late accretion events and the planet\u2019s prolonged volcanic activity, particularly noting that the connection between these two phenomena lies in Venus\u2019 superheated core.\u00a0\nHot To The Core\nVenus has the most volcanoes out of all planets in our solar system. Through simulations, the researchers were able to draw some important conclusions that alter how we think about the relationship between a planet\u2019s geological makeup and planetary accretion.\u00a0\nThe team found that the early high-velocity collisions not only created a magma ocean on Venus\u2019 surface, but also led to a dramatic heating of the planet\u2019s core. Furthermore, due to the insulating nature of Venus\u2019 surface, the planet\u2019s super-heated core could remain at very high temperatures. This possibility is particularly intriguing because it differs from Earth, where the presence of plate tectonics cools down the planet\u2019s interior very efficiently. Venus, however, lacks tectonic plates, creating a different geological composition.\u00a0\nWhen choosing a model, the researchers assumed stagnant lid convection on Venus, meaning these tectonic plates were completely absent. Their results of simulating stagnant lid convection starting from high-velocity impacts on Venus suggest that the planet\u2019s core remains super-heated, which helped sustain volcanism for billions of years. Geological features such as vast volcanic plains and volcano domes found on Venus are the result of these conditions that can all be traced back to late-accretion events which heated up the core in the first place. Venus\u2019 youthful appearance is thus the culmination of these features, perceived as a result of the constant magma flow that smooths the surface over time.\nWhile there have been hypotheses about Venus\u2019 youthful surface before, none have attempted to explain it through the planet\u2019s internal core temperature and dynamics. \u201cSimone was interested in combining [these] very short-time scale impact dynamics with long-time scale metal dynamics,\u201d Korenaga said.\u00a0\nWhat About Earth?\nLike Earth, Venus is a terrestrial planet, and is often regarded as Earth\u2019s \u201csister planet\u201d due to their similarities in size and orbit around the Sun. Why, then, did Earth\u2019s surface fail to fight the passage of time? By comparing these findings to the relatively well-known composition of Earth, it is plausible to conclude that Earth, unlike Venus, did not experience late accretion events that affected its core temperature to such a great extent.\u00a0\nWhile Earth\u2019s large volume of surface water broke down the crust and uppermost mantle of the planet to form tectonic plates, Venus is closer to the Sun than the Earth, causing Venus to rapidly lose surface water through evaporation. This geophysical difference is significant, as plate tectonics reduce internal heat. In addition, the researchers ran a simulation and found that the mean impact velocities of late accretions on Venus were larger than those of Earth. In other words, small celestial bodies called planetesimals hit Venus harder and faster. The lower-velocity impacts on Earth would lead to less core heating and an inability to sustain the long-lived volcanic activity seen on Venus. These key differences are what lends the \u2018planet of beauty\u2019 its distinct, youthful surface.\u00a0\nFuture Directions\nMarchi and Korenaga hope to use their model to make predictions and further explain the mystery of Venus.\u00a0 \u201cThis difference in late accretion by itself may not explain all the differences [between Earth and Venus], but it may help to push it towards the right direction,\u201d Korenaga added. The collaboration with Korenaga, who has studied the origin of life on terrestrial planets for over a decade, highlights a key link between late accretion and the early history of planets. As it did for Venus, late accretion played a significant role in Earth\u2019s early history and has a lasting impact on its present surface features, contributing substantially to the geological record of the planet. Thus, understanding late accretions has other far-reaching implications for related projects.\u00a0\nAccording to Marchi, these energetic events could drastically alter the chemistry of the atmosphere. For example, large-scale impacts can lead to the heating of the crust, generating a hydrothermal system that could serve as a possible reservoir for microbes to thrive. \u201cWe strive to understand whether or not these early impacts could have had anything to do with the origin of life on Earth,\u201d Marchi said.\nMuch of Korenaga\u2019s work in the past has focused on early Earth and investigating the geophysical catalysts for life. \u201cThe role of late accretion is important to discuss generally, for how you can build a habitable planet,\u201d Korenaga said. He argues that late-stage cosmic collisions have a large impact on whether or not a planet can produce life. In particular, this research helps us better understand the geological makeup and formation of planets, a key ingredient for a given planet\u2019s potential to sustain life.\nAs a planetary scientist, Marchi is also involved in space missions and is currently one of the leaders of the Lucy Mission, a NASA space probe with the goal of reaching Trojan asteroids near Jupiter. Recently, there has been a revival of interest in Venus in space exploration. NASA selected two future space missions to explore Venus in the coming decade, and the European Space Union has proposed its own mission.\u00a0\nFor next steps, the authors hope to build off of this work and potentially explore the geophysics of Earth and Mars, which could hold more mysteries of their own. \u201cThe work for Venus is definitely not done,\u201d Marchi said. \u201cBut we\u2019ll try to push the new idea forward to make predictions and try to test that as much as possible\u2014with new missions as well.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/venus-skincare-routine/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Can AI Determine The Scent of A Compound Based On Its Chemical Structure?",
            "author": "Ximena Leyva Peralta",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/figure1-2-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Unsplash.\nScientists have long known that the chemical structure of a molecule influences its smell. However, it\u2019s still unclear how tiny structural changes in a molecule\u2019s structure can turn a sweet, delicate scent into a fishy stench.\nEnter artificial intelligence (AI). Researchers from the start-up Osmo based in Cambridge, Massachusetts trained a type of AI system called a neural network to predict a compound\u2019s odor based on its structure. The scientists instructed the system to assign descriptors from a list of fifty-five, such as \u201cgrassy\u201d or \u201cfruity,\u201d to a scent. The AI system then generated an odor map by screening roughly five thousand well-studied molecules.\u00a0\nTo test the validity of this map, a panel of fifteen trained study participants sniffed a set of compounds with undocumented scents. Their answers were averaged to account for genetic differences, personal experiences, and preferences. The researchers found that the AI system achieved results comparable to the human assessments for fifty-three percent of the molecules.\nThis new odor map could be a helpful reference tool when designing new scents in the food or perfume industries. But it doesn\u2019t seem to reveal much about how humans interpret smell. Odor descriptors are quite subjective, and it\u2019s unclear if averaging the answers of a group of people is the best way to obtain a \u201ccorrect\u201d description of a smell.\u00a0\nMost smells in the real world come from a mixture of compounds. The next frontier for the AI system may be to chemically describe the complex smoky smell of freshly brewed coffee or the aromatic sweetness of a new perfume.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/qa-can-ai-determine-the-scent-of-a-compound-based-on-its-chemical-structure/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Undergraduate Profile: Harper Lowrey (YC \u201924)",
            "author": "Nyla Marcott",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Talpins14-333x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Photo Courtesy of Liana Talpins.\nHarper Lowrey (YC \u201924) first became fascinated by the wide-ranging implications of science after reading a book with her mom called Lab Girl as a child. \u201cMy mom read it and said that she could never work in science, while I was like, \u2018Ooh that sounds fun,\u2019\u201d Lowrey said. \u201c[I find inspiration] when things get rough, but there are cool results that come out of the struggle.\u201d\nLowrey, who grew up in Colorado, always enjoyed exploring the outdoors and first became interested in pursuing a career in research after participating in a summer camp at the University of Colorado Boulder. During the camp, she stayed at the university\u2019s research station and had the opportunity to learn from mycologists\u2014scientists who study fungi. \u201c[I was] so enamored by the concept of being able to study the world, which I think was probably the start that led me into academic science,\u201d Lowrey said.\nLowrey was determined to continue studying biology in college. When applying to Yale, she was selected for the Hahn Scholars program, which seeks to recruit high-achieving students with extensive STEM research experience. As a first-year, Lowrey joined the Gendron Lab, where she investigated how plant circadian clocks use post-translational regulation to control the amount of protein active in a system at one time.\nAlthough conducting research could have been an intimidating experience, members of the Gendron Lab made sure that Lowrey felt like a valued member of the group. \u201cI was immediately treated like somebody who had ideas that were important, which I think is a really great environment in science, instead of like, \u2018You need to sit there and be quiet and learn from other people.\u2019 I have really benefited from being a part of the team and working towards our common goal,\u201d Lowrey said.\nLowrey\u2019s research in the Gendron Lab is focused on understanding how the growth restrictor gene, CFH1, is controlled by a plant\u2019s circadian clock. Circadian clocks allow plants to predict changes in their environments on a 24-hour cycle and are responsible for the regulation of a variety of functions essential for survival, such as growth and defense. In the absence of CFH1, plants develop very long hypocotyls, the first seedling stems that occur after germination. Lowrey\u2019s research has helped uncover CFH1\u2019s role in controlling hypocotyl growth in Arabidopsis thaliana, a common plant model species. A manuscript that includes Lowrey\u2019s research has been submitted for peer review and will likely lead to further research regarding how CFH1 works in other plant species.\nIn addition to conducting research at Yale, Lowrey participated in molecular biology research on transgene silencing\u2014the loss of gene expression transferred from one organism to another\u2014at the Donald Danforth Plant Science Center in Missouri. In the summer after her junior year, she also conducted research at the Cold Spring Harbor Laboratory on argonaute proteins, which are integral in RNA interference. Both experiences provided her with the opportunity to meet other plant biologists and to contribute to postdoctoral research projects. \u201cYou learn a lot when you are new to a place\u2014getting new techniques or doing different things\u2014and I feel like it also helps increase my scientific confidence,\u201d Lowrey said.\nWhile Lowrey\u2019s research is designed to increase knowledge of plant physiology and is not specifically linked with industry interests, she recognizes the complexities that arise when conducting plant biology research more closely tied to industry. \u201cI do think a lot more thought needs to be about what products we are trying to produce\u2014especially if we\u2019re talking about agriculture and products that are going to the market. Just because something is cost-effective or we will make money from it is not the only reason to make that kind of thing,\u201d Lowrey said.\nIn April, Lowrey\u2019s commitment to research earned her the prestigious Goldwater Scholarship. She is now working to complete her major in Molecular, Cellular, and Developmental Biology, as well as certificates in French and Education Studies. After graduation, she plans to pursue a Ph.D. in plant molecular biology. As Lowrey continues to study science, she finds enjoyment in building a deeper understanding of the world and hopes to help others do the same by running her own lab and mentoring the next generation of scientists.\n\u201cLong term, my goal is academia,\u201d Lowrey said. \u201cI am really interested in thinking about what kinds of things are important in how we\u2019re teaching and policies around teaching. It is important that college professors know how to teach [\u2026] in ways that are equitable and effective.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/undergraduate-profile-harper-lowrey-yc-24/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: \u201cThe Roots of the U.S. Black Maternal Mortality Crisis\u201d",
            "author": "Samuel Obioma",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/154579054_ccac391302_c-500x333.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\n\u201cHalf of all medical student respondents did not believe that Black patients felt pain the way Whites did. So did a lot of practicing physicians,\u201d a study published in PNAS reported. If asked when this study was conducted, many might guess sometime in the twentieth century, or earlier.\nThe actual year was 2016.\u00a0\nThis revelation was just one of the many disturbing findings revealed in \u201cThe Roots of the U.S. Black Maternal Mortality Crisis,\u201d a podcast jointly produced by Scientific American and Nature in August. The podcast opens by examining Georgia\u2019s new law that bans abortions after six weeks of conception, before launching into an explanation of its past precedents and future ramifications on pregnant Black women.\nHistorically, unintended pregnancy rates are higher among Black women compared to White women. Due to income disparities, job insecurity, and overall underinsurance, Black women have less access to long-acting reversible contraceptives (LARCs) and must resort to using condoms, which are a less effective form of contraception. Higher rates of unintended pregnancy, coupled with increased susceptibility to mistreatment during childbirth, contribute to the racial disparity in maternal mortality rates: Black women are three times more likely to die in pregnancy than White women.\nThe podcast makes a strong effort to show that socioeconomically disadvantaged Black women are not alone in this phenomenon. Serena Williams and Shalon Irving, for instance, are both healthy, educated, affluent women whose obstetrician-gynecologists dismissed their concerns.\u00a0\u00a0\nIrving visited her doctor multiple times and reported swelling in her right leg and a weight gain of nine pounds in two weeks. She was ordered to \u201cwait it out\u201d and died in 2017 due to birth-associated complications caused by high blood pressure. Williams, on the other hand, told her doctors that she thought she had a pulmonary embolism. Even though she had experienced one before, her physician ignored her claim, and she nearly died.\nBoth of these cases could have been avoided if their own doctors had listened to them.\nIs there any hope left? Since Roe v. Wade was overturned last year, more awareness has been raised about this issue than ever before. This increased public attention may not only help lower the Black maternal mortality rate but also help reduce the factors that contribute to the issue, such as implicit racial biases among physicians.\n\u201cThe Roots of the U.S. Black Maternal Mortality Crisis\u201d integrates interviews with researchers, historians, and family members of women who died from mistreatment, providing a holistic view of the Black maternal mortality crisis. By referencing the complicated, interwoven history of childbirth and slavery, analyzing existing stereotypes, and hypothesizing how ever-changing legislation will affect Black women in the United States, this podcast calls us to question, analyze, and change our existing healthcare system.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/science-in-the-spotlight-the-roots-of-the-u-s-black-maternal-mortality-crisis/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Modern-Day Trephination: How Do You Safely Insert An Electrode Into The Brain?",
            "author": "Andrea Ortega",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/1148930404_c8f7fc6294_c-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nIn 6,000 B.C.E., North African physicians treated head ailments with trephination\u2014the practice of drilling holes into patients\u2019 skulls without anesthesia. Luckily, modern-day trepanning is much less invasive. A research team in Geneva, Switzerland is employing flexible, biocompatible materials in electrocorticography (ECoG), the monitoring of electrical activity associated with the brain. Normally, to detect the brain\u2019s signals, neurosurgeons must carve out a ten-square-centimeter section of the skull and insert electrodes through the hole, positioning them on the surface of the cerebral cortex. By creating a new soft, deployable ECoG system, the team has revolutionized neural recording by minimizing risks of infection and brain damage that accompany the removal of a large section of the skull.\nThe novel soft ECoG system is composed of six spiral-shaped, folded arms that form a cylindrical \u201celectrode array,\u201d which extends through a one-square-centimeter incision in the skull. The system works by administering fluidic pressure into each arm, causing the arms to slowly expand within the one-millimeter space between the skull and the brain\u2019s surface. Each component of the array is embedded with strain sensors, which monitor the deployment of the soft arms and tell the user when to stop applying pressure.\nIn an in vivo experiment performed on a miniature pig, the soft robotic electrodes yielded successful readings of sensory activity and did not cause any structural damage. Thus, ECoG could play a large role in mapping regions of the brain associated with epilepsy, recording the brain\u2019s functions, and controlling the movement of prosthetic limbs. Further advances are still necessary, but soft robotics demonstrate extraordinary capabilities in laying the groundwork for these advancements.\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/qa-modern-day-trephination-how-do-you-safely-insert-an-electrode-into-the-brain/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Alumni Profile: Ilana Yurkiewicz (YC\u201910)",
            "author": "Himani Pattisam",
            "authorLogo": "",
            "date": "January 6, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Han_1-346x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Hannah Han.\nWriter, Copy Editor, News Editor, Features Editor, and eventually Editor-in-Chief: during her time at Yale, Ilana Yurkiewicz (YC \u201910) wore many hats at the Yale Scientific Magazine (YSM). But she didn\u2019t leave science writing behind after graduation. Even now, as a clinical assistant professor of primary care and population health at Stanford, Yurkiewicz combines her passions for writing and medicine in her work as a science journalist, author, and physician. \u201cYSM was where I got my start. I always had an itch to write and take complex scientific concepts and make them understandable for people,\u201d she said.\nAs an undergraduate, Yurkiewicz explored the depths of a liberal arts education, taking philosophy courses and writing seminars in addition to a typical pre-med workload of chemistry and biology. She also conducted genomics research in a bioinformatics lab studying DNA testing for genetic conditions, which sparked her interest in bioethics and the intersection between science and the humanities. She graduated in 2010 with a degree in Molecular, Cellular, and Developmental Biology.\n\u00a0After Yale, Yurkiewicz took a year off and completed the American Association for the Advancement of Science (AAAS) Mass Media Science and Engineering Fellowship in science journalism, where she worked as a science and health reporter at The News & Observer in Raleigh, North Carolina. \u201cI had a couple of stories on the front page, and it was always really exciting to see that [\u2026] It\u2019s always been really important to me that we bridge the gap between hospitals and laboratories with everyday lives,\u201d Yurkiewicz said. Following her passion for bioethics, Yurkiewicz also interned for the Presidential Commission for the Study of Bioethical Issues before attending Harvard Medical School.\n\u00a0During her time at Harvard, Yurkiewicz continued writing, creating a blog column called \u201cUnofficial Prognosis\u201d for Scientific American where she shared reflections on her medical school experiences with hundreds of thousands of readers. \u201cI had full editorial freedom to write about whatever I thought was interesting,\u201d Yurkiewicz said. She then moved across the country to complete her residency in internal medicine, followed by a fellowship in oncology and hematology, at Stanford. Now, as a faculty member there, she co-directs a primary care center for cancer survivors.\n\u00a0In July, Yurkiewicz published her debut book, Fragmented: A Doctor\u2019s Quest to Piece Together American Health Care, which she worked on for two years. Fragmented was inspired by her own experiences as a physician navigating the healthcare system and making decisions based on fragmented medical records. \u201cI found myself always working in a partially blindfolded state to stitch together patient stories,\u201d Yurkiewicz said. She first became interested in the topic after delving into the history of converting paper patient notes into a digital format, and she began to investigate how medical records can vanish when patients transfer between medical facilities. Fragmented zooms out to investigate barriers beyond record-keeping that fracture a patient\u2019s story into pieces, and she explores how doctors and patients can piece them back together.\nIn the future, Yurkiewicz hopes to write a second book chronicling her experiences as a physician providing primary care to cancer survivors. She plans to focus on the \u2018hard questions\u2019 of life, death, and serious illness that cancer patients must grapple with throughout their diagnosis and treatment journeys. \u201cMy patients often ask me to write stories to share their experiences and advocate for them,\u201d Yurkiewicz said. She explained that she takes great care to convey empathy and compassion and to protect confidentiality while exploring complex issues that her patients face.\n\u00a0For Yurkiewicz, writing journalistic pieces with nuance and depth has the power to impact a large audience. Through her work, she aims to empower people to advocate for more comprehensive solutions to reform the healthcare system. \u201cIllness is a great equalizer, and my focus [is] to write for everyone\u2014physicians, policymakers, patients, and the general public,\u201d Yurkiewicz said. But she also hopes to someday explore a new genre. \u201cI wrote stories for fun at Yale,\u201d she said. Her \u2018pipe dream\u2019 is to return to those roots and write a science fiction novel, grounding her stories in real science.\u00a0 Although she has pursued her passion for science writing alongside medicine, patient care has always been Yurkiewicz\u2019s highest priority, and she has periodically taken breaks from writing to focus on honing her medical practice. \u201cThere are ebbs and flows in the busy doctor life, but science writing always comes back,\u201d she said. Balancing multiple professional hats as a physician and journalist is difficult, but Yurkiewicz emphasizes that it is possible. Her advice for students interested in both: \u201cPursuing a career in science journalism and medicine is a harder path, but if you really care about something, you will do it well.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/01/alumni-profile-ilana-yurkiewicz-yc10/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Mind Control: How Newborn Babies Control Their Brains",
            "author": "Andre Botero",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/early-brain-development-mapping-neurosince-1.jpg-500x333.webp"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Neuroscience News.\nBabies can often seem a bit out of control, but it\u2019s not their fault\u2014at birth, babies are just beginning to develop the networks in their brains necessary to properly transition between mental states. The ability to control that transition, called network controllability, relies on connections formed by our brains\u2019 white matter. Researchers at the Yale School of Medicine have recently uncovered new information about how network controllability in infants arises. Their study sought to discover to what extent full-term and preterm infants possess network controllability and measure how this controllability at birth affects cognitive function in the future.\nYale professor Dustin Scheinost and graduate student Huili Sun used functional magnetic resonance imaging (fMRI) data from infants\u2019 brains to model brain dynamics and development. fMRI can be used to assess which areas of the brain consume more oxygen during cognitive tasks and to detail white matter activity. With fMRI data, Scheinost and Sun discovered that at birth, the frontal and occipital lobes have the highest average network controllability. Also, compared to term infants, preterm infants\u2019 controllability matured faster to catch up to term-born peers.\nThis research has opened doors for future investigation into neonatal brain connectivity. \u201cWe are starting to see the sample sizes increase, and we are in a position where we can actually start applying some of our more complicated methods to infant imaging data,\u201d Scheinost said. This research also gives hope for discovering risk factors for abnormal brain development. \u201cWe do have some follow-up studies on how factors such as maternal mental health or socioeconomic status can affect babies\u2019 brain maturation, which is giving us some exciting results,\u201d Sun said. Scheinost and Sun\u2019s research leaves much to the imagination for the future of neonatal technological advances and provides hope for further progress in that field.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/mind-control-how-newborn-babies-control-their-brains/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Defining Antimatter: A Matter of Time",
            "author": "Megan Kernis",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Screen-Shot-2024-01-29-at-6.10.27-PM-500x279.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of CERN Courier\nPhysicists theorize that before the Big Bang, our universe was composed of equal parts matter and antimatter. If this is true, why are we composed of only matter rather than antimatter or some combination of the two? The difficulty in dissecting this question lies in the lack of knowledge we have about antimatter.\nAntimatter is the opposite of matter. For every particle, there is an equal and opposite particle, and when these particles collide, they destroy each other. If we were able to collect antimatter and touch it, it would vaporize us and a considerable radius around us. Nonetheless, a team at CERN, the European Organization for Nuclear Research, discovered a way to study antimatter and prove that antihydrogen atoms respond to gravity like regular matter. Their study paves the way for further research on the acceleration of antihydrogen atoms and brings us one step closer to understanding the differences between matter and antimatter.\nIn a recent publication in Nature, experimental particle physicist Jeffrey Hangst and his collaborators used a new technology called the ALPHA-g apparatus to test antihydrogen\u2019s gravitational attraction to Earth. This vertical, four-story apparatus was designed and built by CERN to store antihydrogen atoms. \u201cThere\u2019s no store you can go to and buy a machine that will produce and trap antimatter,\u201d Hangst said. The apparatus\u2019s vertical orientation is designed to assess the behavior of antihydrogen atoms as they drop down the structure. Researchers can then observe whether the atoms fall and escape through the bottom opening due to the force of gravity, or escape through a top opening, suggesting that they don\u2019t experience gravity.\nThe experiment revealed that antimatter, like regular matter, generally falls and escapes through the bottom of the trap, with minor exceptions due to natural random fluctuations in the movement of atoms. This aligns with scientists\u2019 hypotheses, but Hangst\u2019s team was cautious to leave behind all expectations while designing their experiment. \u201cAs an experimental scientist, you\u2019re not allowed to have expectations,\u201d Hangst said. \u201cYou have to be completely neutral and design an experiment that will get any outcome.\u201d\nThe thoughtful design required to produce informative results is a delicate art. \u201cSomething that\u2019s overlooked in science is that the people who do the best job, who make the breakthroughs, are not just intelligent, but they\u2019re creative and they think in a different way,\u201d Hangst said. The basis of this experiment rested in the abilities of the novel ALPHA-g apparatus. Moving forward, this technology will have to be reimagined with great precision to determine the acceleration of antihydrogen atoms, as opposed to just assessing their general response to gravity.\nDespite the mysteries surrounding antimatter, physicists like Hangst and his team at CERN are inching closer to uncovering the truth with each new experiment. Their determination is the driving force behind this operation, and the new knowledge about antimatter they uncover may reshape our understanding of the universe in the coming decades.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/defining-antimatter-a-matter-of-time/",
            "captions": [
                ""
            ]
        },
        {
            "title": "To Worry or Not To Worry: How Stress Strengthens Memories",
            "author": "Alistair Lam",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/2204059683_9ae889398a_o-357x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr.\nStress is a common experience that often garners a negative reputation. Most of us associate stress with lowering our abilities to perform everyday tasks and increasing our chance of errors. Previous neuroscience research generally agrees that stress negatively impacts our cognitive abilities, such as learning and memory, which are associated with a critical brain region called the hippocampus. However, these studies have also discovered an interesting conundrum: we seem to remember emotionally charged memories better under stressful conditions. \u201cA lot of previous research has instead focused on the ways in which stress-related emotional memory enhancements can be explained by other brain regions, such as the amygdala,\u201d said Brynn E. Sherman GSAS \u201922, a Yale PhD graduate in psychology.\u00a0\nA recent study by Sherman and colleagues shed light on the underlying mechanisms within the hippocampus that enable stress to enhance memories involving emotional information. In the experiments, participants were given either a placebo or hydrocortisone pill, the latter of which contained cortisol, a key hormone involved in stress. Subsequently, participants were shown pictures of household (neutral) or alcohol-related (emotional) objects on various backgrounds while in an MRI scanner, which recorded brain activity using functional magnetic resonance imaging (fMRI). The next day, participants were tested on their memories of the objects and object-background pairings. \u201cOne notable thing about this study is that we used a double-blind, placebo-controlled design\u2026 meaning that neither the participants nor the experimenter knew which pill was which,\u201d Sherman said. This design allowed the study to randomize the order of administering cortisol and strictly control for potential confounding effects that may arise in similar investigations.\nThe findings were telling: cortisol significantly increased connectivity within subareas of the hippocampus compared to the placebo. Moreover, such connectivity led to enhancements in emotional memories under cortisol. \u201cThis enhancement was specific to the hippocampal circuit; amygdala-hippocampal connectivity was not altered by hydrocortisone,\u201d the researchers concluded in their paper. \u201cA lot of previous research has focused on how stress hurts the hippocampus. In the current study, though, we show that stress can have positive effects on the hippocampus, which can explain some of the benefits for emotional memory under stress,\u201d Sherman said. Additionally, alcohol-related images, which can induce both positive and negative emotions, allowed the researchers to hypothesize that positive emotions can strengthen memories, not just negative ones that have been extensively examined by prior studies.\u00a0\u00a0\nLooking ahead, there are still many questions to be answered before we can fully understand the relationship between stress and memory. \u201cThe hippocampus is typically thought of as supporting episodic memory, which is our ability to form a distinct memory for a unique experience. But the hippocampus also supports a few other kinds of memory, including a type of memory called statistical learning, which is our ability to form links across related memories,\u201d Sherman said. \u201cI\u2019m really interested in extending this out and understanding how stress impacts different kinds of memory that are supported by the hippocampus.\u201d\u00a0\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/to-worry-or-not-to-worry-how-stress-strengthens-memories/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Leveling Up Video Games for Healthcare: How One Lab is Changing the Game for Adolescent Health Education",
            "author": "Sarah Li",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Gamer_at_Gamescom_2015_20430203215-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Flickr\nIn the twenty-first century, it is nearly impossible to see adolescents not engaged in some kind of digital media. Video games are among the most popular digital pastimes, and parents are concerned. Parents often worry about excessive screen time, potential addiction, and the impact of playing video games on academics, physical activity, and social interactions. They may also be concerned about the content of some games, including violence and inappropriate themes. Nothing good can ever come out of spending more time in-game, right?\u00a0\nWrong. Lynn Fiellin MD \u201996, formerly a head of the play2PREVENT Lab at Yale and now a professor of biomedical data science at Dartmouth, is making strides to bring more relevant topics into video games such as healthcare promotion and risk prevention. Playtest! is a video game designed to help increase HIV testing rates among adolescents. Despite making up nearly twenty percent of new HIV infection cases in the US in 2020, only nine percent of US high schoolers are ever tested for HIV. Fiellin sought to establish a relevant link to these adolescents to improve HIV awareness amongst the age group.\nIn the study, 287 Connecticut adolescents between fourteen and eighteen years old were randomly assigned to play Playtest! or a set of control games. Each participant was assigned to play for one session\u2014typically lasting an hour\u2014for four to six weeks, aiming for six hours of gameplay. Immediately following gameplay, and then at three months and six months after the first session, these adolescents were evaluated on their attitudes around HIV testing and counseling (HTC), with intentions, knowledge, self-efficacy, and behaviors as other measured outcomes. The results were astonishing: those adolescents who were in the Playtest! group saw improvements across the board, results that were essentially absent in the control group. \u201cOur games focus on teaching teens accurate knowledge and important skills to make better decisions so that they can lead happier and healthier lives,\u201d Fiellin said.\nFiellin\u2019s work soared in relevance during the COVID-19 pandemic, when adolescents essentially moved their entire lives online. Seeing the increased demand for their video games, Fiellin established Playbl, a sister organization spun out of the lab in order to commercially distribute their video games. Through this commercial organization, community institutions such as schools and support groups gained more streamlined access to these games.\u00a0\n\u201cplay2PREVENT  have demonstrated a strong impact on a number of outcomes in teen health and, as such, have the data behind them to show they are an important resource for all teens,\u201d Fiellin said. And that impact extends beyond the video game on HIV awareness; Playbl offers four other video game interventions on current healthcare issues, including ones for mental health, opioid misuse, smoking/vaping prevention, and reframing negative thoughts. The play2PREVENT Lab hopes to shed new light on a traditionalist\u2019s view on video games, demonstrating that in the digital age, gaming may not be so bad after all.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/leveling-up-video-games-for-healthcare-how-one-lab-is-changing-the-game-for-adolescent-health-education/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Wild Weather Stations: Using Animals to Track Climate Changes",
            "author": "Helen Shanefield",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/sea-turtle-1851102_1280-500x375.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Pixabay\nImagine your weather forecast came from a seal swimming in the Pacific, or a bird flying hundreds of feet above you. This idea is rapidly becoming a reality in the world of climate research. As we face a biodiversity crisis driven by climate change, researchers are looking for new ways to measure changes in temperature and weather patterns that may affect ecosystems.\u00a0\nExisting technologies for measuring climate data, such as weather stations on land and buoys at sea, are absent across certain geographical regions, creating information gaps. In a piece published in Nature Climate Change, Yale graduate student Diego Ellis-Soto, along with Yale biologist Walter Jetz and collaborator Martin Wikelski, analyzed the use of animal-borne sensors (ABSs) as an alternate method of measuring climatic conditions. An ABS is like a modern GPS backpack that an animal wears, which provides researchers with a myriad of data.\u00a0\n\u201cWhat\u2019s really neat about this is that increasingly, besides giving us information on where an animal is [in terms of] latitude, longitude, and time, which we use for conservation, we get data like, \u2018How many square kilometers does a giraffe need?\u2019\u201d Ellis-Soto said. \u201cWhere are animals thriving, and where are they dying?\u201d\nFor instance, when researchers used ABSs on African bush elephants to measure the environmental temperature, the ABS data had a high overlap with satellite and weather station measurements for that same region. Understanding the intersection of temperature trends and animal movement can help scientists determine the best conservation methods for species as they lose their habitats. \u201cThat can benefit both our understanding of how animals will do under climate change, but also help us humans in understanding our weather better, which is probably the most important thing we have for human survival, \u201d Ellis-Soto said. For now, these walking weather stations may be science\u2019s best hope for navigating the warming world.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/wild-weather-stations-using-animals-to-track-climate-changes/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Letter from the Editors: The Failure Issue",
            "author": "Alex Dong",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Preface: The last magazine of each calendar year is, as per Yale Scientific Magazine tradition, a themed special issue. This letter, co-written by your outgoing 2023 managing team\u2014Alex Dong, Madison Houck, and Sophia Li\u2014examines why we have chosen to focus on failure as our central theme. We will also explain how each section of this special issue has been modified to cover a different aspect of our theme, while highlighting several notable articles exclusive to this magazine. We hope you enjoy reading Vol. 96 No. 4: The Failure Issue!\n***\nAs anyone from an undergraduate student to a tenured professor could tell you, failure is a natural, necessary part of science. The scientific method is predicated on a constant cycle of failures and successes that drive experimental work forward. Arguably, a failed experiment can be more generative than a successful one, yielding new questions and research directions. And yet, most major scientific journals exclusively publish success stories. These stories are then picked up by journalists and communicated to the public, while a long history of failed experiments remains obscured from view. It\u2019s an open secret\u2014we all know success doesn\u2019t come easy, but we don\u2019t seem to want to hear about a series of mistakes without groundbreaking innovation to show for it.\nWhen the 2023 Nobel Prize in Physiology or Medicine was announced in October, science journalists began reporting on the incredible stories of Katalin Karik\u00f3 and Drew Weissman. Although their contributions to the mRNA COVID-19 vaccine have undoubtedly shaped our world today, their work was consistently underestimated and disregarded for years until the right set of circumstances recently led to a breakthrough (pg. 30). Inspired by their story and its subsequent public reception, our final issue of the year seeks to examine the theme of failure broadly across science and science journalism. How do scientists regard failure? How have initial failures led to great progress? And how have overhyped innovations fallen by the wayside?\u00a0\nIn this spirit, we also asked: How has our own magazine failed in the past? The Yale Scientific Magazine (YSM), the nation\u2019s oldest collegiate science publication, has existed in some form or another for 130 years. It\u2019s easy to evaluate the failures of others critically and even to perceive them as avenues for growth, but it\u2019s much more difficult to examine oneself. This year, as we moved our historical archives from our old offices in Welch Hall and 305 Crown Street to the Benjamin Franklin College Library, we had the opportunity to delve into the evolution of YSM over time.\nOur magazine\u2019s past has included missteps ranging from the comical\u2014like the \u201cTroubled Years\u201d where YSM rebranded to focus on student affairs rather than science from 1918 to 1926\u2014to the incredibly serious, like the magazine\u2019s promotion of eugenics and other pseudoscientific ideas in the 1900s. Ultimately, this is another reason why our managing team felt that \u201cThe Failure Issue\u201d was so important to create. As our magazine continues to grow and change, it is our responsibility as young journalists to understand our organization\u2019s past and to learn from it.\n***\nIn this special issue, we have modified our usual sections to reflect this endeavor of examining and reflecting upon failure.\u00a0\nOur \u201cShorts\u201d section, which has replaced \u201cNews,\u201d begins with a timeline of notable scientific failures throughout the ages\u2014whether that be Aristotle\u2019s disproven theory of spontaneous generation in the 4th century BC or the fall of the now-infamous biotech company Theranos (pg. 6). This section then presents short profiles of three unconventional scientists: Brian Nosek, who studies the reproducibility of new discoveries and how to make the research process more transparent (pg. 9); Marc Abrahams, who founded a magazine and prize ceremony to honor unusual, imaginative, and humorous science (pg. 10); and Stuart Firestein, who investigates why failure is the driving factor behind scientific success (pg. 11).\nFor our Full-Lengths section, we went back to YSM\u2019s archives and selected decades-old articles to examine how our scientific understanding of various subjects has evolved\u2014or been subverted\u2014over time. For instance, a YSM article written in 1941 discredited one hypothesis about the origins of the solar system that has, in fact, developed into the theory widely accepted by physicists today (pg. 12). In another article, we reflected on a Lyme disease vaccine covered by YSM in 1993 with a seemingly promising future that was never actualized (pg. 16).\nOur Features section focuses on more contemporary scientific discourse and the trial-and-error nature of experimentation. For example, a 130-year-old assumption about seawater ion distribution was recently debunked (pg. 26), bringing forth a need to reevaluate past research that relied on it. Over the past three years, there have also been intense back-and-forths in science, such as an ongoing debate about life on Venus (pg. 30) and the multiple attempts\u2014and failures\u2014to create room-temperature superconductors (pg. 32).\nThese ideas, decades ago, might have sounded like the stuff of science fiction. In our Special Sections, we have included a reprint of a 1951 YSM article interrogating the impact that intelligent robots may have on society through this lens of science fiction (pg. 34). We then wrote a side-by-side comparison of those ideas with the very real developments of artificial intelligence and machine learning today (pg. 35).\nSo, what have we learned? Some inventions and innovations were hailed as the next big breakthrough, only to fall short of expectations. Other discoveries were not given a second glance but turned out to have world-changing impacts. Either way, failure in science is ubiquitous. With the benefit of hindsight, it can be easy to discount the striving and the seemingly innumerous number of times we\u2019ve barked up the wrong tree. Yet we must keep in mind that no experiment will be the \u201cfinal one\u201d or the \u201ccapstone\u201d of a field\u2014the work will never be finished. There will always be something more to question or explore.\n***\nWith that, it is now time for us to pass over the reins to the next masthead. It has truly been an honor to serve you all as your 2023 YSM Managing Team this year. We would like to thank our incredible contributors across all five branches\u2014Editorial, Production, Business, Web, and Synapse\u2014without whom none of this would have been possible, as well as our 35 masthead members for their leadership, initiative, and tenacity.\nWe would also like to express our deepest gratitude to the Yale Science and Engineering Association and its president, Milton Young, for their instrumental guidance and support this year. Finally, thank you, our readers, for your continued engagement with YSM\u2014you are the reason we do what we do. Here\u2019s to science, to striving, and to failure.\n\nSincerely,\nAlex Dong, Editor-in-Chief\nMadison Houck, Managing Editor\nSophia Li, Managing Editor\nVol. 96 No. 4\nDecember 2023\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/letter-from-the-editors-the-failure-issue/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Marc Abrahams: Mission Improbable",
            "author": "Mia Gawith",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Figure-1-7-317x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Marc Abrahams.\nHave you ever wondered about the physics behind why our cereal becomes soggy in milk, the most efficient way to turn a doorknob, an advanced toilet that analyzes what we excrete, or a method of identifying narcissists by looking at their eyebrows? The ideas may seem silly\u2014improbable, even\u2014but this is exactly the type of research that Marc Abrahams celebrates.\nAfter graduating in applied mathematics from Harvard University, Abrahams spent the early years of his career running a software company and writing humorous, inquisitive articles about science. But one day, a question struck him: Were there any journals that would publish the type of bemusing\u2014yet very real\u2014topics he wrote about?\nIn 1995, Abrahams took matters into his own hands and co-founded a magazine that did just that: the Annals of Improbable Research (AIR). AIR\u2019s website reads: \u201cReal research, about anything and everything, from everywhere\u2014research that\u2019s maybe good or bad, important or trivial, valuable or worthless.\u201d Four years earlier, Abrahams had also founded the Ig Nobel Prize Ceremony\u2014an honor bestowed to researchers of both the unusual and the imaginative.\u00a0\nEvery year, traditional Nobel Laureates award Ig Nobel Prizes to the winners in a grand ceremony, which took place at Harvard University before the COVID-19 pandemic. Thousands of award nominations come in every year, but only a select few are chosen. 1,100 spectators crowd into a room as paper airplanes fly in a dizzying flock above their heads and mini opera songs are bellowed across the stage. And looming above it all is the official mascot, \u201cThe Stinker\u201d\u2014a rendition of Auguste Rodin\u2019s The Thinker statue fallen onto its back with its buttocks in the air.\u00a0\nIf that mental image made you pause and chuckle (internally or externally), then the ceremony did exactly what it intended. Abrahams\u2019 work injects fun into science\u2014the AIR and the Ig Nobel Prizes are united by an important goal: \u201cto honor achievements that make people LAUGH, then THINK.\u201d\u00a0\nAbrahams argues that research is a process of discovery, one that ascribes importance to topics over time. Sometimes, the most important scientific advancements can be overshadowed for many years, their importance not discovered until much later. \u201cSometimes it\u2019s years, sometimes it\u2019s decades, and sometimes it\u2019s centuries before people realize you can use [a discovery] to do something, and it changes everything,\u201d Abrahams said. \u201cThe fact that something doesn\u2019t seem important doesn\u2019t really mean it\u2019s not.\u201d\nAs such, Abrahams brings attention to research that is often overlooked in the scientific community, and which the public may otherwise never learn about. From this perspective, humor acts as the driving force behind the success of the AIR and Ig Nobel Prizes. On the one hand, humor can draw in both scientists and non-scientists alike. It\u2019s one thing to sit in a crowded auditorium and watch researchers be solemnly awarded prizes; it\u2019s another thing to watch the same researchers present their research in an exciting, often quick-witted way.\u00a0\nAt the same time, people may begin to pause and contemplate scientific research in ways they never had before. If you heard about a group of scientists who invented a toilet that analyzes excrement, you might be slightly grossed out at first, but you might also start to wonder: What technologies did they develop? Does this have applications for public health? Can we utilize the technology somewhere else?\u00a0\n\u201cThis is a way of bringing a lot of stuff to people\u2019s attention\u2014stuff they would probably try to normally stay away from,\u201d Abrahams said. \u201cBut now it\u2019s the thing they want to know about most.\u201dAbrahams is known by many monikers: \u201cthe Puck of Science\u201d by The Journal of the Academic Medical Association and \u201cthe nation\u2019s guru of academic grunge\u201d by The Washington Post, to name a few. But talking to him, while he cracks jokes with a blown-up banner of \u201cThe Stinker\u201d behind him, reveals who he is at heart: a scientist, guided by humor, with a profound drive to revitalize science.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/marc-abrahams-mission-improbable/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Stuart Firestein: Fascination with Failure",
            "author": "Kavya Gupta",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Han_1-1.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Stuart Firestein, the former chair of Columbia University\u2019s Department of Biological Sciences, is a neuroscientist who studies the olfactory system, but he\u2019s also an expert in something else\u2014failure. In 2015, Firestein released a book, titled Failure: Why Science Is So Successful, that places failure at the heart of the scientific process.\nFirestein\u2019s journey toward the topic of failure began while he was teaching a large cellular and molecular neurobiology lecture course at Columbia. For many years, his students were expected to read an excessively long textbook, titled Principles of Neuroscience. \u201cIt\u2019s a book about the brain that weighs twice as much as the brain,\u201d Firestein said.\u00a0\nFirestein noticed a critical gap between what students were learning in the classroom and what the researchers were doing in the lab. \u201c[Students] must have thought that the process of science is to get a lot of facts, put them in these books, and force [students] to memorize them and spit them back up on an exam, which is a very unpleasant experience,\u201d he said. \u201cAnd that\u2019s not true either. [Scientists] don\u2019t accumulate facts\u2014we accumulate questions.\u201d\nThe experience led him to create a new course called \u201cIgnorance,\u201d which consisted of a variety of science faculty members meeting with students once a week for two hours to talk about everything they don\u2019t know. \u201cWhat\u2019s their question?\u201d Firestein asked. \u201cWhy did they settle on that as the important question? What are the other questions they\u2019re ignoring while looking at this one? What are the questions this question will lead to?\u201d\u00a0\nThe course became very popular as students began to understand scientific research not as a quest for facts, but rather as an investigation of ignorance. This course not only inspired Firestein\u2019s first book, Ignorance: How It Drives Science, but also served as a jumping-off place for his contemplation of the role of failure in science.\nAccording to Firestein, failure is the best way to identify the questions that lay at the root of our scientific ignorance. \u201cLet\u2019s say you do an experiment, and it fails,\u201d Firestein said. \u201cThere must be something you didn\u2019t know when you set this up. We have to do some experiments before this experiment to figure out what it is we\u2019re missing.\u201d In Firestein\u2019s view, failure is an essential part of the scientific process that reveals our ignorance in actionable ways. Failure points the finger at what we don\u2019t know, which allows us to then turn around and ask more meaningful questions about science. \u201cIt\u2019s a way of gaining knowledge in the same way as a successful experiment. It is no less valuable, no less important, and no less a part of the process,\u201d Firestein said. \u201cSo, things should fail. In fact, I think they should fail at a fairly high rate.\u201d\nDespite its importance to scientific discovery, many students still struggle greatly with embracing failure. \u201cWe tend not to accept failure easily,\u201d Firestein said. \u201cWe tend to see it as a negative.\u201d He looks at natural failures in our environment to justify why we should be more open to failing.\n\u201cIf you look at the top predators, like lions and tigers, I think most of us think that they can just go out anytime they get a little hungry and bag a snack somewhere,\u201d Firestein said. \u201cBut that\u2019s not actually true. When you look at the predator-prey literature, you find these big critters are successful fewer than twenty-five percent of the time they go after something. Seventy-five percent of the time, the critter escapes.\u201d Even the top of the top encounter failures, yet they learn from them and continue to try, whether by changing their methods or trying a new approach.\u00a0\nSimilarly, Firestein argues that accepting the natural likelihood of failures is especially important. \u201cIt is a regular part of the process,\u201d he said. \u201cIt\u2019s not like success and failure are two sides of a coin, but rather like two horses pulling a wagon in the same direction in their own particular way.\u201d\u00a0\nThis is sometimes hard to understand, especially for young scientists who have struggled with accepting their failures in the past, but it\u2019s a key part of finding the most fascinating scientific questions. \u201cThe truth, the correct answer, is narrow,\u201d Firestein said. \u201cIt\u2019s just narrow, and it doesn\u2019t go anywhere. Whereas there are endless ways to screw up, and many of them are quite interesting. They take you down new pathways. Quite often, the screw-ups are really where the data comes out.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/stuart-firestein-fascination-with-failure/",
            "captions": [
                "Stuart Firestein, chair of the Department of Biological Sciences at Columbia University, poses against a gray backdrop."
            ]
        },
        {
            "title": "Brian Nosek: A Crisis of Research Reproducibility",
            "author": "Nathan Wu",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/staff-nosek-brian-500x500.webp"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Center for Open Science.\nReplication is a key tenet of the scientific method. In theory, any discovery should be reproducible with identical procedures. However, scientists have become increasingly aware that in practice, most studies\u2019 findings may be irreplicable, hinting at systemic flaws deep within scholarly research. After all, how can science be trusted if it builds upon unrepeatable results?\nFew understand these flaws better than Brian Nosek (GRD \u201802), co-founder and director of the Center for Open Science (COS). In 2015, Nosek and the COS made waves when they published a study in Science in which less than half of their attempts to replicate one hundred psychology experiments were successful. The study was among the first to empirically characterize the extent of the reproducibility crisis, drawing attention from scientists and non-scientists alike.\nNosek traces his interest in interrogating the scientific process to a research methods class taken during his PhD at Yale. Nosek recalls reading papers detailing common issues in scientific practice, from publication bias to ignoring null results, and their solutions. What shocked him was that these studies dated back to the \u201860s. \u201cWe\u2019re reading these papers in the 1990s, and for me, it was like, \u2018wait a second\u2014we\u2019ve known the problem, we\u2019ve known the solution; thirty years later, we\u2019ve done nothing\u2026 what\u2019s going on?\u2019\u201d Nosek said.\u00a0\nThis lack of progress led Nosek to take an interest in improving his own research methodology. One year, he collected data at the beach to obtain larger sample sizes. The next, he created a website to collect data on implicit biases, long before online data collection was commonplace. This would grow to become Project Implicit\u2014since its creation, over twenty million people have taken an implicit association test on the site.\nWhen Nosek became a professor at the University of Virginia, his focus shifted beyond improving just his own methodology. \u201cWe started thinking about how we could build tools to help others do the same,\u201d Nosek said. However, this technology-building work was ineligible for most grants, limiting its scope. All this changed in 2013 when Nosek received five million dollars from the Arnold Foundation to scale up his operations, thus creating the COS.\nThe COS was originally centered around two projects from Nosek\u2019s lab: the psychology \u201creproducibility project\u201d and the creation of the Open Science Framework (OSF). The OSF is a tool to help researchers document and share their experimental progress, all while promoting open science practice: making the entire research process transparent. Unlike the traditional system of only publishing completed work, the OSF tracks a project\u2019s whole journey, including the initial research plan, any changes to it, null results, and more.\nThe COS has grown substantially since its creation. In 2020, it introduced the Transparency and Openness (TOP) Factor, a metric to evaluate research journals\u2019 adoption of the best practices of open science. In 2021, it released the results of a replication project focusing on cancer biology research. Open science has been growing, too. \u201cIf you look at every key performance indicator, the growth over the last decade has been nonlinear,\u201d Nosek said. The OSF now has over half a million users, and many others have conducted studies evaluating replicability in fields from ecology to economics.\u00a0\nNosek hopes to add tools to the COS to help not only those producing research, but also those utilizing it. \u201cWhat we want to do in the next ten years is [add] in the interaction between the research producer and the research consumer,\u201d Nosek said. \u201cThe consumer could be policymakers or people way outside of the process.\u201d Facilitating dialogue between research producers and consumers could hold researchers accountable for the thoroughness of their experimentation and reporting.\nSo, how do we fix the reproducibility crisis?\u00a0\nNosek believes that changes to the publication process are required. Under the current model, scientists are rewarded for producing publishable findings. His proposed alternative is the \u201cRegistered Reports\u201d model, where peer review is conducted prior to data collection, shifting the focus from getting results to having watertight methods. \u201cRegistered Reports changes the reward system for researchers\u2026 the decisions at journal level are no longer about the outcomes\u2014they\u2019re about the questions,\u201d Nosek said.\nDespite his familiarity with the challenges of the knowledge production process, Nosek\u2019s belief in science is unwavering. \u201cThe reason to trust science is because science doesn\u2019t trust itself,\u201d Nosek said. While mistakes are inevitable when pushing the boundaries of knowledge, what matters is that science is open for revision. For all the flaws plaguing the research process, science\u2019s self-correcting nature remains ever-present.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/brian-nosek-a-crisis-of-research-reproducibility/",
            "captions": [
                ""
            ]
        },
        {
            "title": "How Do You Feel?: A Bicellular Mechanism of Touch Detection",
            "author": "Tori Sodeinde",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Corpuscles_Figure1-1-390x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image courtesy of Yury Nikolaev.\nA light brush across the skin, the vibration of your phone in your hand when you receive a text, the sharp jab when you accidentally poke yourself with a pencil\u2014we constantly receive various tactile stimuli, but how do our bodies sense these different types of touch? The skin contains many kinds of mechanoreceptors, which are cells or minuscule organs that respond to different intensities of pressure and frequencies of vibration. However, the detailed mechanism of touch detection by mechanoreceptors has not yet been elucidated.\nTo bridge this gap, Yury Nikolaev, Luke Ziolkowski, and colleagues in the Bagriantsev and Gracheva labs at Yale University used microscopy to resolve the structure of a type of mechanoreceptor called Meissner\u2019s corpuscles in mallard ducks. Their findings point towards a novel bicellular mechanism of touch detection, in contrast to the canonical, single-cell-type-mediated mechanism.\nVertebrates detect touch in the skin using tiny organs called mechanosensory corpuscles, which contain sensory neurons and glial cells. Sensory neurons detect stimuli by sending electrical signals called action potentials, while glial cells provide structural support for neurons. Meissner\u2019s corpuscles are a type of mechanosensory corpuscle responsible for detecting low-frequency vibrations and fine touch, and they include both sensory neurons and a type of glial cell called lamellar cells. Stimulating the sensory neurons within Meissner\u2019s corpuscles transmits a signal to the brain that is interpreted as the sensation of touch.\nThe researchers used a cutting-edge microscopy technique called enhanced focused ion-beam scanning electron microscopy (FIB-SEM) alongside machine learning to resolve the structure of mallard duck Meissner\u2019s corpuscles, and they found an unexpected structure. \u201cWe are the first to reveal the structure of any corpuscle using this technique,\u201d Nikolaev said. The corpuscle contains stacks of lamellar cells integrated among sensory neurons. Typically, only sensory neurons are thought to be capable of detecting touch, but previous work done by Nikolaev indicated that these lamellar cells were responsive to mechanical stimuli. This prompted the researchers to investigate whether lamellar cells could trigger action potentials in the sensory neurons, thereby acting as secondary touch sensors. \u201cThere was some prior evidence from other types of nerve endings where there were occasionally non-neuronal cells that were detecting touch and helping communicate that to the sensory neuron,\u201d Ziolkowki said.\nWhen researchers triggered action potentials in lamellar cells, they found that the sensory neurons also transmitted action potentials. In contrast to direct stimulation of sensory neurons, which produces consistently timed action potentials, lamellar cell-induced neuron firing time varies considerably. This variability indicates a unique role for lamellar cells in touch sensing, possibly allowing for more sensitive and specific touch sensing.\nWhile this research was performed on ducks, their Meissner corpuscles are very similar to those of other mammals, so it is likely that humans have a similar bicellular system involving cooperating lamellar cells and sensory neurons. Nikolaev and Ziolkowski will continue investigating the nature of the interactions between lamellar cells and neurons, challenging the paradigm of a simpler, unicellular model for touch detection and expanding our understanding of how we use touch to perceive the world.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/how-do-you-feel-a-bicellular-mechanism-of-touch-detection/",
            "captions": [
                ""
            ]
        },
        {
            "title": "A Researcher\u2019s Guide to Physician Care and Gender Equity: Optimizing The Physician-Patient Experience",
            "author": "Kayla Sohn",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "For women physicians, the gender gap contributes not only to lower salaries, but also to higher rates of burnout. On average, women physicians spend more time during each patient visit, often to counsel and educate patients, but this extra time has not historically been reflected in their pay. A recent Yale study analyzed electronic health records (EHR) to highlight work output differences between male and female physicians, and potentially improve policy development by enhancing patient treatment in ambulatory care.\nResearchers used work relative value units (wRVUs) to measure the monetary value of health care services performed. They found that there was little difference between the number of wRVUs male versus female physicians made per patient visit. However, while male physicians went through more clinical hours and patient visits each month, female physicians spent more time with each patient. In 2021, a change in the Evaluation & Management (E/M) code played a significant role in closing the gap in compensation by altering how documentation gets factored into physician billing. The code allows physicians to be compensated based on the time spent in each visit, rather than just the complexity of care given. This change allows physicians, especially women, to provide patients with the counseling they need.\u00a0\nAnalyzing physician and practice characteristics, the team also found that teamwork could improve physician productivity. The researchers hope to shed light on policies that prioritize team-based interventions to create an environment where burnout is reduced and patient care is optimized. \u201c[The physicians] have more support allow[ing] [them] to practice at the top of their licenses,\u201d said Ted Melnick, associate professor of emergency medicine at Yale School of Medicine.\nThe next steps of this study focus on expanding their dataset nationwide to discover more factors that contribute to physician productivity such as inbox messaging and team stability. \u201cMany think the most important part of hospital experience is the patient, and of course it\u2019s super important, but it\u2019s also essential we don\u2019t [place] burnout [on] physicians,\u201d said Huan Li, a Yale PhD student.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/a-researchers-guide-to-physician-care-and-gender-equity-optimizing-the-physician-patient-experience/",
            "captions": []
        },
        {
            "title": "Memories of Death: Cardiac Arrest Patients Recall Death Experiences",
            "author": "Hien Tran",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "How might life replay before death? Many survivors of near-death experiences have told stories about how every stage of life flashed before their eyes. These visions have ranged from moral evaluations of how their life was lived to highlights of their achievements and regrets. Until now, these were just stories\u2014recounts from one person to another. However, Sam Parnia, an NYU Langone Medical Centre Associate Professor of Medicine, and his lab recently found support for this concept of consciousness before death.\nParnia and his colleagues conducted a seven-year-long study in the US and UK which involved 567 patients who received CPR following cardiac arrest. Out of these patients, fifty-three survived and twenty-eight completed interviews. Eleven of these patients reported memories and perceptions that were suggestive of consciousness during cardiac arrest. In addition to interviewing these patients, the study also collected recounts of near-death experiences from other cardiac arrest survivors in the community. One of the main challenges was the low survival rate of patients, a tragic circumstance that limited the interviews that could be collected.\nIn the study, resuscitated patients exhibited signs that they were conscious during experiences of death. \u201cI could see what was going on. [\u2026] I stood next to the bed. It was very odd,\u201d one patient said. \u201cI remember seeing my dad,\u201d another patient said. In line with this, one of the key discoveries Parnia\u2019s lab presented was how the brain remained robust and active thirty-five to sixty minutes after starting CPR. They detected brainwaves well into CPR that suggested normal brain activity.\nThis discovery redefined current assumptions about brain activity after oxygen deprivation. \u201cThe brain dying after five to ten minutes due to oxygen deprivation is incorrect,\u201d Parnia said. The study challenged the conventional wisdom that the brain is severely damaged after five to ten minutes without oxygen\u2014a claim that implied CPR should not be performed for more than ten minutes because the patient would be in a vegetative state if revived. This study suggests potential for the development of medicine that preserves the brain after resuscitation and brings back patients with full consciousness in the future.\nNot only is Parnia\u2019s project interesting to the field of consciousness in cardiac arrest,\nbut it is also intriguing to the wider public. The lab categorized patient recollections based on themes to further support recounts that have simply been passed by word of mouth. The study presents itself as a leap forward in modern medicine as it fosters an understanding of the relationship between death and consciousness.\nAn understanding of the relationship between consciousness, life, and death could build solid foundations for end-of-life care. \u201cJust because a patient cannot respond to the stimuli or show signs of awareness, we should not always assume that the patient does not sense or hear what we are doing or talking about,\u201d said Linh Tran, a physician involved in the study.\u00a0\n\u201cWe\u2019d like to explore in more detail in real time what happens to the brain across the\nentire spectrum as well as consciousness for ever longer periods of time between life and\ndeath,\u201d Parnia added. Ultimately, understanding the role of consciousness in life and death is the next step to understanding human existence\u2014the journey that Parnia and his lab have begun to explore.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/memories-of-death-cardiac-arrest-patients-recall-death-experiences/",
            "captions": []
        },
        {
            "title": "Alien X-Rays: Analyzing the X-Ray Emissions of Comets",
            "author": "Max Watzky",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "When \u2018Oumuamua was discovered hurtling around the sun in October of 2017, it was the first large object from interstellar space ever seen in our solar system. \u2018Oumuamua promised to be of enormous scientific value; as a remnant from a far-away solar system, it seemed to hold information about the way planets develop. In the end, however, \u2018Oumuamua proved quite challenging to study. When examined with visible and infrared light, it looked like a rocky asteroid, but it sped up during its journey around the sun like an icy comet shooting off a tail of gas. The mystery of \u2018Oumuamua may never be solved, but thanks to a team of astronomers at Yale, we\u2019ll be more prepared the next time an interstellar object swings by. The team, led by Yale graduate student Sam Cabot, developed a model to study and classify interstellar objects using X-rays, a novel technique that could help us learn more about their composition and origins.\nUsing X-rays to study an object like \u2018Oumuamua might seem counterintuitive. \u201cX-rays usually emanate from the hottest, most extreme objects and environments in the galaxy,\u201d Cabot said. \u201cYou would never expect X-rays to come from asteroids, comets, or anything else that\u2019s cold or rocky.\u201d But solar wind\u2014streams of plasma that emerge from the upper atmosphere of the sun\u2014can light up cold objects like \u2018Oumuamua in unexpected ways. Ions from the solar wind snatch electrons from certain types of cold gas, which then release x-rays as they lose energy. Importantly, this process can even visualize gasses like hydrogen or nitrogen that are invisible to astronomers using other methods. If an interstellar object emits these gasses, Cabot\u2019s team found, x-rays might offer a critical window into its nature and composition.\nFor their study, Cabot and his team developed a model to predict the X-ray emissions from different types of interstellar objects, based on their unique properties. They found that if \u2018Oumuamua had an invisible halo of gas\u2014which would have explained its strange acceleration\u2014it might have emitted x-rays. If we had been able to study these X-rays, we would have gained valuable information about \u2018Oumuamua\u2019s composition, perhaps shedding light on how it developed. \u201cThen there\u2019s a new challenge: figuring out where interstellar objects come from and how they form,\u201d Cabot said. \u201cJust encountering \u2018Oumuamua tells us that our understanding of how planets and solar systems form is incomplete.\u201d\u00a0\nWhen the Vera C. Rubin Observatory is completed in Chile in 2025, it will begin scanning the sky for transient astronomical events, perhaps discovering new interstellar objects like \u2018Oumuamua in the process. Cabot and his team hope that their technique will shed light on these interlopers, helping us learn even more about the development of distant solar systems, as well as our own. \u201cThere are lots of problems in astronomy that are very important, that people have spent a lot of time trying to make progress on, often incrementally,\u201d Cabot said. \u201cIt\u2019s not too often that you get a brand-new line of research, like \u2018Oumuamua provided for us.\u201d We may have missed our chance with \u2018Oumuamua, but perhaps x-rays will help us solve the mysteries of our next interstellar visitors.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/alien-x-rays-analyzing-the-x-ray-emissions-of-comets/",
            "captions": []
        },
        {
            "title": "Revisiting PFAS: What Happened To The \u201cBrilliant Future\u201d of Forever Chemicals?",
            "author": "Evelyn Jiang",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Capture-decran-2024-02-11-a-10.33.07-AM-500x354.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Luna Aguilar.\nLife on Earth depends on interactions between carbon and hydrogen, as they come together to form bonds that serve as the backbone of many organic molecules. However, it is the element fluorine that forms the strongest single bond with carbon. Chemists tried to create these carbon-fluorine bonds in the late 1800s, and by the early 1930s, they succeeded by replacing hydrogen atoms with fluorine in organic molecules.\nTheir breakthrough led to the development of some of the most resilient compounds in organic chemistry today: per- and polyfluoralkyl substances, or PFAS, which all contain fluorine-carbon chains. This extensive family of synthetic compounds comprises thousands of chemicals known for their exceptional durability and resistance to degradation, earning them the fitting nickname \u201cforever chemicals.\u201d\u00a0\nSince their introduction into the market in the 1950s, PFAS have been incorporated into a wide range of products, from waterproof garments to non-stick pans to firefighting foam. However, mounting evidence indicates that these forever chemicals have infiltrated not only our consumer goods, but also our drinking water, our soil, and even our bodies.\u00a0\n\u201cA Wonder of Modern Science\u201d\nThe birth of PFAS can be traced to the so-called \u201cChemical Century,\u201d which witnessed notable advancements in the field and the increasingly widespread use of synthetic chemicals across society. The chemical industry was deeply connected to military power and warfare during this period. For instance, DuPont\u2019s Teflon (polytetrafluoroethylene)\u2014one of the most notorious PFAS\u2014was used during the Manhattan Project when creating warheads, liquid-fuel tanks, and even the atomic bomb dropped on Nagasaki in 1945.\u00a0\nSeveral of the researchers involved in the Manhattan Project would go on to join the multinational company 3M to further develop PFAS. By 1951, the company began producing perfluorooctanoic acid (PFOA), a PFAS. PFOA was sent to a DuPont plant in Parkersburg, West Virginia, where commercial Teflon products would be manufactured. Around the same time, 3M also began producing Scotchgard, a brand of fabric stain and water-repellant sprays, using another PFAS called perfluorooctane sulfonic acid (PFOS).\nPFAS were also used in Apollo space missions and emerging medical technologies, as seals on ventilators and as a coating for medical catheters. It seemed PFAS could be used in everything, everywhere, and was heralded as a \u201cwonder of modern science.\u201d The optimism of the era is reflected in the pages of the May 1956 issue of the Yale Scientific Magazine (Vol. 30 No. 8), which proclaimed that \u201cfrom [Teflon\u2019s] unique characteristics a brilliant future can be inferred.\u201d\nUnique Chemical Characteristics\nAs past YSM writer Robert J. Lontz laid out in that article, PFAS owed its industrial desirability to a unique combination of properties that made it well-suited for a wide range of applications.\nLontz first pointed out that the strong dielectric properties of PFAS make it an excellent electrical insulator, capable of preventing the flow of electric current through the material. Due to the strength of its carbon-fluorine bonds, PFAS are also chemically inert, meaning they remain stable and unreactive when subjected to various other chemicals or environmental conditions.\u00a0\nTeflon also offers, as Lontz wrote, a \u201cwaxy, slippery surface.\u201d PFAS are well-known for their non-stick and low-friction properties, and have thus been used to create surfaces that do not adhere to other materials, making them easy to clean. Finally, PFAS are inherently water-repellent. They form a protective barrier on surfaces, making them ideal for applications such as water-resistant clothing or any materials that need to repel moisture.\u00a0\nA Double-Edged Sword\nNearly seventy years after Lontz\u2019s article was published, it has become clear that the same unique characteristics that led to PFAS being dubbed \u201cforever chemicals\u201d are closely intertwined with their potential health and environmental risks. \u201cCertain members of the PFAS family have come to light as biologically and environmentally persistent compounds with bioaccumulation potential in the last few decades,\u201d said Gary Ginsberg, the director of the Center for Environmental Health for the New York State Department of Health, a former member of the EPA\u2019s Science Advisory Board, and a clinical professor at the Yale School of Public Health.\nIn contrast to other persistent organic compounds, which primarily accumulate in fats, PFAS behave differently. Being water-soluble, they can follow natural solubility pathways by dissolving in water and infiltrating groundwater. This dispersal can lead to additional ecological impacts, including uptake into fish and drinking water supplies.\u00a0\nIn 1998, Wilbur Earl Tennant, a farmer from Parkersburg, West Virginia, noticed his cows were dying from a mysterious illness. He approached lawyer Robert Bilott who would go on to investigate the DuPont company, whose chemical plant was located in the town. By 1999, Bilott filed a federal lawsuit against DuPont for dumping PFOA waste into local water supplies. In April 2003, the Environmental Protection Agency (EPA) initiated a comprehensive review of the synthetic chemical, raising concerns about its prevalence.\nOf particular concern to the EPA was the early evidence suggesting that traces of PFOA could already be detected in the blood of nearly all U.S. citizens. According to a study based on 2011-2012 data from the National Health and Nutrition Examination Survey (NHANES), PFAS was detected in the blood of ninety-seven percent of Americans tested.\u00a0\nThis statistic becomes all the more alarming when considering the well-established health hazards associated with PFAS exposure, which include cancer, thyroid disorders, developmental issues, and disruptions to the immune system. \u201cOne of the main drivers for the dose-response [of PFAS] seems to be their unusual propensity to have long human half-lives on the order of three to six years,\u201d Ginsberg said.\u00a0\nScares & Successes\nBoth PFOA and PFOS were phased out of production and use in the U.S. in the mid-2000s through industry agreements with the EPA. Data from the NHANES, which has done bio-monitoring work since the late 1990s, has shown that levels of PFOA and PFOS levels in the U.S. population have been declining. Notably, blood PFOS levels declined by more than eighty-five percent from 1999 to 2018, and blood PFOA levels declined by more than seventy percent.\u00a0\nMany state policymakers have been increasingly focusing on the issue of PFAS, particularly over the past five years. Notable actions were taken by Vermont, which established maximum contaminant levels for PFAS in water, and Minnesota, which prohibited specific flame-retardant chemicals in furniture and children\u2019s products. In 2020 and 2021, states continued to address concerns about PFAS with numerous bills, targeting regulation in firefighting foam, consumer products, and drinking water.\u00a0\nAccording to Ginsberg, current concerns include occupational exposures and the toxicology of newer generations of PFAS. Krystal Pollitt, an associate professor of epidemiology at the Yale School of Public Health, shared a similar view. \u201cOne of the challenges with measuring these chemicals is that there are over ten thousand PFAS and current EPA methods only cover about twenty of them,\u201d she said.\nGiven the known health risks associated with PFAS, it is perplexing that it took until March 2023 for the EPA to propose the National Primary Drinking Water Regulation (NPDWR). If enacted, the NPDWR would represent the first national drinking water standard for PFAS, imposing enforceable limits on levels of six common PFAS chemicals\u2014including PFOS and PFOA\u2014in drinking water. Unfortunately, this much-needed measure arrives far too late for many who have already endured the adverse effects of PFAS exposure in the seven decades since its introduction into commercial use. Why did it take so long to take federal action against PFAS?\u00a0\nThe Precautionary Principle\u2019s Call\nThe heart of the issue lies within our regulatory systems. \u201cThe challenge lies not only in regulating PFAS but in regulating any chemical or substance,\u201d Ginsberg said. He explained that it has been decades since the EPA last determined the need for a new maximum contaminant level or implemented additional regulations for any substance. This is due in part to the challenges surrounding implementing new regulations and navigating through multiple levels of governmental policy review.\nThe story of PFAS and the NPDWR underscores a disconcerting reality that, for decades, there has been a failure within regulatory and legislative frameworks to proactively address emerging environmental and health threats. While the EPA is working to be more predictive of such threats by employing advanced Toxcast testing methods and their Unregulated Contaminant Monitoring Rule testing program to detect emerging contaminants in drinking water, it has become evident that creating meaningful change within this system is a process that takes time.\u00a0\n\u201cThe optimal way forward would be to regulate PFAS as a class,\u201d Pollitt said. As of now, researchers including Pollitt are still working to understand the health impacts of PFAS. They employ various methods, such as measuring PFAS levels in biological samples and collaborating with numerous epidemiologists to develop scalable solutions for assessing exposure. Had the precautionary principle, which advocates that a substance be proven safe before being released into the market, been integrated into our regulatory framework, this could have been a different story. We would not only foster a culture of prevention rather than reaction, but also show that public health and environmental safety take precedence over economic interests.\nThe story of PFAS serves as an urgent call for change and as a stark reminder of what can happen when scientific innovation goes unchecked. And this story is not unique. \u201cLook at pesticides and DDT; it was only after decades of broad use without appropriate safety testing and risk assessment when they were then phased out,\u201d Ginsberg said. \u201cPFAS is just one example of us not doing our homework before releasing chemicals to the market.\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/revisiting-pfas-what-happened-to-the-brilliant-future-of-forever-chemicals/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Timeline of Scientific Failures",
            "author": "Keya Bajaj",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Annli Zhu.\nIntroduction\nThe scientific method\u2014observation, analysis, and conclusion\u2014optimistically presumes a cycle of discovery without errors. But on the lab bench, in the chemical hood, and under the lens of the most well-resolved microscope, any successful research project is also fraught with failure. This timeline aims to chronicle a brief history of scientific failures\u2014to acknowledge the mistakes and missteps built into the process of scientific discovery, and thereby to better appreciate what it takes to discover the science that makes it into the pages of a textbook and scrawled onto a classroom blackboard. The pursuit of scientific knowledge is continuous and unrelenting\u2014a test of patience and tenacity. We hope to demystify the process of scientific discovery by shedding light on the struggles it entails both for the novice and the seasoned researcher alike.\n4th Century BC: Spontaneous Generation\nAristotle formalized the theory of spontaneous generation, which stated that living organisms could be generated spontaneously out of nonliving matter. Common beliefs dictated that snails came from mud, scallops came from sand, and fleas came from dust. The theory wasn\u2019t formally disproved until the 19th century.\nVarious Times: All That Glitters Is Not Gold\nFor centuries, alchemy attracted scores of scientists, including Isaac Newton, who hoped to transform base metals into gold and discover the elixir of life. Of course, these attempts were wholly unsuccessful. Still, they paved the way for chemistry as we know it today.\nEarly 1700s: The Theory That Burned Out\nIn the 18th century, the existence of a fire-like element called phlogiston was posited. Advancements in chemistry revealed that it was flawed, and by the end of the century, the theory was abandoned.\n1828: The Life\u2014and Death\u2014of Vitalism\nVitalism was the theory that organic molecules could only be made by living systems that possessed a \u201cvital force\u201d integral to synthesis. In 1828, Frederick Woehler heated ammonium cyanate and produced urea, artificially synthesizing an organic molecule and discrediting the theory.\n1840s: The Failure of Phrenology\nPhrenology was the widespread belief that the shape of one\u2019s skull could be examined to determine personality traits. The theory proposed that the brain was composed of a variety of muscles with different functions that were smaller or larger depending on how frequently they were used. This practice of measuring the skull\u2019s lumps to assess a person\u2019s mental traits was largely disproven by the 1840s and was eventually dismissed as pseudoscience.\n1862: A Guesstimation Gone Wrong\nLord Kelvin used thermodynamic calculations to estimate the age of the Earth and the Sun. His numbers\u2014that Earth was somewhere between twenty-four million and four hundred million years old\u2014were a gross underestimation. Today, we know Earth\u2019s true age is about 4.5 billion years.\n1887: The Disappearing Act\nIn the 19th century, it was believed that the medium for light waves was an unseen substance that filled the universe: aether. In 1887, Michelson and Morley performed an experiment to detect aether wind. They compared the speed of light in perpendicular directions to detect the relative motion of matter through \u201caether wind.\u201d Unsurprisingly, light traveled at the same speed in both directions, leading to the dismissal of this theory.\n1912-1953: The Paleontological Prank\nIn 1911 and 1912, fossils discovered in Piltdown, England were believed to be those of the Piltdown Man, the missing link between apes and humans and the \u201cearliest Englishman.\u201d However, by 1953, it was discovered that the fossils were nothing but an elaborate forgery, involving a modern human skull and orangutan jawbone.\n1918-1926: YSM\u2019s \u201cTroubled Years\u201d\nThe Yale Scientific Monthly, founded in 1894, was the predecessor to the Yale Scientific Magazine. While it took off in its early years, it faced its biggest hurdle in its 19th volume. The editorial board of the Monthly began focusing on student affairs at Yale\u2019s Sheffield Scientific School. This choice diluted scientific content, until 1926, when the magazine was revived in its original vision and resurrected as the Yale Scientific Magazine, which launched in 1927. The period from 1918 to 1926 has been dubbed by YSM\u2019s Wikipedia page as \u201cThe Troubled Years.\u201d\n1928: The Serendipity of Penicillin\nIn 1928, Dr. Alexander Fleming noticed mold growing on his Petri dish on staphylococcus bacteria. Something seemed to prevent the surrounding bacteria from growing\u2014which we now know to be penicillin. This accidental discovery paved the way for the rise of antibiotics and their therapeutic benefits.\n1953: Pauling\u2019s Triple Trouble\nIn 1953, Watson and Crick famously announced their discovery of DNA\u2019s double helix. Just earlier that year, though, chemist Linus Pauling, a two-time Nobel Prize winner, proposed that DNA comprised three intertwined strands, which we know today to be false. In stark contrast with the success of his model for protein structure, his DNA model was incorrectly built inside-out, with three strands instead of two.\n1962: Reversing Cellular Irreversibility\nUntil the late 19th century, it was widely believed that cell differentiation was irreversible: a cell, once specialized, could not return to its original stem cell state. In 1962, John Gurgeon, among others, proved this wrong by defining the cell reprogramming technique, cloning frogs using nuclear transfer from differentiated cells, thus reversing differentiation.\n1998: A Vexing Claim About Vaccines\nIn 1998, Dr. Andrew Wakefield of the Royal Free Hospital School of Medicine published a study in The Lancet claiming that the measles, mumps, and rubella vaccine caused autism. The medical community quickly condemned the research study as clearly flawed in its design, and it was eventually retracted and declared fraudulent in 2011. However, Wakefield remains a popular figure among the growing anti-vax movement.\n2017: Flat Earth Fanatics\nIn November 2017, the first annual Flat Earth International conference was held in Raleigh, North Carolina. Contrary to popular belief, the \u201cscientific\u201d theory that the Earth was flat rather than a sphere was most popular in the late 19th and early 20th century. Despite overwhelming (and obvious) evidence of Earth\u2019s spherical nature, a small, yet vocal, contingent of people continue to promote the theory of a flat Earth.\n2022: Theranos: From A Single Drop To A Huge Flop\nIn November 2022, Elizabeth Holmes, former CEO of infamous health tech company Theranos, was sentenced to over eleven years in prison for defrauding Theranos investors. Valued at ten billion dollars at the heights of its hype, Theranos claimed to have developed a blood test that could use just a single drop of blood to rapidly and accurately diagnose an array of health conditions. However, it was revealed shortly thereafter that Theranos had never in fact developed a functional blood test device, resulting in Holmes\u2019 eventual arrest.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/timeline-of-scientific-failures/",
            "captions": []
        },
        {
            "title": "Rediscovering Cosmic Origins",
            "author": "David Gaetano",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Origins-of-the-Universe-Annli-Zhu-498x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Annli Zhu.\nIt is easy to take for granted the vast scope of scientific understanding that humans have acquired over hundreds of thousands of years on Earth. Today, for example, the origin of the solar system is relatively well understood. But not too long ago, we were searching for an answer among a sea of endless theories.\u00a0\nAn article from the 1941 edition of the Yale Scientific Magazine (Vol. 15 No. 4), titled \u201cThe Origin of the Solar System,\u201d is a time capsule that provides a firsthand account of the scientific community\u2019s understanding of the solar system\u2019s origins at the time. The writer, Lyman Spitzer Jr., was a well-respected Yale faculty member who earned his PhD in physics from Princeton University in 1939. In his piece, Spitzer sought to analyze contemporary understanding of the origin of the solar system and place doubt on the existing theories of the time.\nEighty years later, this article revisits Spitzer\u2019s analysis. By reflecting on evolving scientific understanding, we can help provide motivation for further scientific advancement, as the cosmos still leaves much to be discovered.\nEarly Theories\n\u201cThe rise and subsequent decline of the most important theories of the origin of the solar system are an instructive chapter in the history of science and cast light on the problems which an ultimately successful theory must face,\u201d Spitzer wrote. At the time of his article, there were many different hypotheses surrounding the formation of the solar system, yet none could truly be rigorously proven. In fact, Spitzer criticized two of the leading hypotheses for their lack of concrete evidence.\u00a0\nThe first theory he analyzed was the nebular hypothesis, which argued that the sun was first created out of a huge, rotating cloud of gas and dust in space, which was then flattened into a disk. This disk would have subsequently condensed to form the sun and various planets seen in the solar system today. He argued that this hypothesis was impossible due to the conservation of angular momentum, which means that the sun would have to rotate much faster than observed to maintain the known laws of the universe.\u00a0\nThe second hypothesis Spitzer examined was coined the encounter theory. This idea proposed that the solar system was formed from the collision of two stars. This would give rise to the planar nature of the observed solar system as well as the debris and planets that orbit around the sun. However, Spitzer was not a fan of this hypothesis either. He argued that the debris pulled from the near-collision of two stars would not have been able to condense into planetary objects like the ones observed today in the solar system. Such rapid cooling of the nebular gasses would have manifested into something more akin to an explosion rather than spherical planets, according to his theoretical calculations. \u201cThe origin of the solar system may well be a riddle which science will never wholly solve,\u201d he concluded.\nAdvancements in Scientific Technology\nThe foundation of scientific study is rooted in empirical evidence and a rigorous commitment to skepticism. Spitzer\u2019s article did not seek to reject ideation, but rather to adhere to the scientific method\u2019s demands that theories be substantiated with empirical data. \u201cThere\u2019s nothing wrong with having an idea of how something might work without being able to go out and measure it,\u201d said Charles Bennett, a professor of physics and astronomy at Johns Hopkins University. \u201cIn the end, you need to match simulations with observations to know that what you\u2019re doing is right.\u201d\nSpitzer\u2019s critiques shed light on the technological limitations of his time, which prevented many scientists from being able to experimentally prove their conclusions. Spitzer acknowledged that the mathematics required to go back two billion years is an \u201cambitious calculation\u201d that would probably never be attempted.\nToday, the scientific landscape has evolved significantly. Technological advancements, particularly in computing technology and simulation power, have revolutionized our ability to create intricate models of the formation of the solar system. Further, the Hubble Space Telescope has even been used to photograph stars surrounded by accretion disks of gas and dust, signaling an early stage of planetary formation. These new findings have proven pivotal: while Spitzer discounted the nebular hypothesis in his article, now we know it was not far off.\u00a0\nThe Winning Hypothesis\u00a0\nSince Spitzer\u2019s time, scientists have been able to conclude that the solar system was very likely created through the collapse of a nebular cloud of gas and dust from a nearby supernova. Today, the \u201csolar nebula hypothesis\u201d is widely accepted to be the most accurate account of the solar system\u2019s origins.\nAvi Loeb, a renowned theoretical physicist and professor at Harvard, described the formation of the solar system as a series of events caused by a nearby supernova event, which is a massive explosion of a star that releases immense amounts of energy and material into space. The solar system formed about 4.6 billion years ago\u2014just about one-third of the existence of the universe\u2014from a giant cloud of gas and dust. The shockwaves from the supernova then triggered the collapse of this cloud. As it collapsed, gravity pulled the material together at the center, forming the sun, which is mostly composed of helium and hydrogen.\nOver time, small particles of leftover mass in the form of dust and gas began to condense in orbit around the early sun. This then created the rocky planets closest to the sun\u2014where the hydrogen would be absorbed more quickly\u2014leaving the gaseous planets like Jupiter and Neptune further away in orbit. \u201cThe universe started from a pretty uniform distribution of matter. There were small differences in the density of matter, and they grew over time because of gravity,\u201d Loeb said. This process led to the diverse and fascinating solar system we know today.\u00a0\nOne article, written by Michael Perryman of the University of Bristol, explained that this current \u201csolar nebula hypothesis\u201d accounts for early issues with the nebular hypothesis, such as the angular momentum discrepancy that Spitzer highlighted. Somehow the sun maintained most of the mass, but only a tiny percentage of the angular momentum of the solar system. The new theory reconciled this discrepancy by more chronologically describing the process by which the nebula compressed into a disk before beginning the sequential process of planetary formation.\nA Glimpse Forward: Finding Life\nAlthough the mystery of the origin of the solar system is somewhat resolved, there are natural questions that these resolutions leave unanswered. One such question is the existence of extraterrestrial life. By studying the formation of our solar system and the emergence of life on Earth, scientists can gain valuable insights into the potential habitability of other planets and celestial bodies. \u201cLooking for life around stars is a very exciting frontier,\u201d Loeb said. \u201cOne can search for signatures of microbial life. But one can also search for intelligent life.\u201d\u00a0\nLoeb highlighted the notion that the laws of physics, chemistry, and biology are universal, suggesting that the conditions conducive to life on Earth may very possibly exist elsewhere in the cosmos. This perspective enables scientists to assess the likelihood of life on exoplanets.\nSpitzer, eighty years ago, was simply hoping to figure out how the solar system formed. Now that we know the conditions that led to life within our solar system, we can launch a new quest for life beyond our planet. We have the means to explore the broader cosmic environment and likewise form new hypotheses, critiques, technologies, and conclusions in the ongoing pursuit of alternative forms of life.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/rediscovering-cosmic-origins/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Invention and Innovation: A Brief History of Hype and Failure",
            "author": "Ximena Leyva Peralta",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/lz-127-graf-zeppelin-over-toyko-1929-7d5c3e-500x398.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Flickr\nIt is the late 1910s. Airship travel between German cities has just become a reality. Newspapers report that a trip across the Atlantic will soon take place. Airships seem to be the future of transportation.\nBut during the following decades, airship accidents keep happening. In 1937, one explodes during its flight from Frankfurt to New Jersey. Thirty-five passengers are immediately killed, and the era of airship travel abruptly ends.\nIn his book Invention and Innovation: A Brief History of Hype and Failure, Czech-Canadian policy analyst and scientist Vaclav Smil examines the failures that arise when a product or process fails to meet expectations. He first distinguishes between invention (creating new ideas and products) and innovation (introducing, adopting, and mastering inventions). \u201cThere could be plenty of invention without commensurate innovation,\u201d he explains. In his book, Smil examines three categories of failures: \u201cunfulfilled promises, disappointments, and eventual rejections.\u201d\nThe first category comprises inventions that were initially praised but were eventually viewed with widespread suspicion. One example that Smil cites is chlorofluorocarbons (CFCs), nonflammable hydrocarbons widely adopted as refrigerants in 1930. Fifty years later, it became clear that CFCs cause substantial damage to the ozone layer, and international measures were instituted to eliminate their use. A second example is dichlorodiphenyltrichloroethane (DDT). DDT was introduced as a powerful insecticide in the 1940s and successfully prevented five hundred million deaths due to malaria, but was eventually linked to adverse effects on the environment. However, its success in saving lives meant that DDT required more nuanced regulations.\nThe second category consists of technical advances that the public immediately welcomed but that ultimately ended in disappointment. For instance, airships seemed like they would dominate air travel between the 1910s and 1930s, but their instability, coupled with the rapid development of airplanes, cut their lives short. Nuclear fission, the splitting of atoms, is a second example: in the 1970s, there was widespread scientific agreement about its success, and General Electric predicted the end of fossil-fueled energy generation by 1990. As of 2022, only ten percent of world energy is generated by nuclear reactors.\nThe third category includes inventions that we keep waiting for. The first example Smil provides is travel in a near vacuum, called a hyperloop, whose origins trace back to the 1820s. However, as of 2023, there are no operating hyperloop lines. Another highly anticipated invention he lists is nuclear fusion, the combination of atomic nuclei. Thought to be the ultimate clean energy source, it is still far from commercial implementation. Smil notes that mass media has inaccurately labeled all fusion advancements as breakthroughs instead of proof-of-concept experiments.\nAlthough dense at times, Smil\u2019s data-driven and articulate writing delivers sharp critical analyses of humankind\u2019s greatest failures. He contrasts positive opinions about inventions with data supporting their negative repercussions. In the final chapter, Smil warns readers against the myth of ever-growing innovation. \u201cSuccess is only one of the outcomes of our ceaseless quest for invention,\u201d he says. Just as our past is plagued by disappointment, our future will inevitably be filled with scientific failures\u2014some of which will hopefully, one day, lead to eventual success.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/invention-and-innovation-a-brief-history-of-hype-and-failure/",
            "captions": [
                ""
            ]
        },
        {
            "title": "The Ticking Clock to Fight Ticks",
            "author": "Cindy Mei",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Lyme-Vaccine-in-Limbo-3-393x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Diya Naik.\nTick spray might not be the first thing you think of when preparing to go backpacking. However, if gone undetected, these small arachnids can feed and feed, increasing the likelihood of transmission of dangerous bacteria. Named for the city of Lyme, Connecticut, where it was first detected, Lyme disease is most commonly spread by Ixodes ticks and is the most common tick-borne illness in the Northeast region of the United States. If left untreated, the disease can cause debilitating effects on the heart, joints, muscles, and nervous system. According to the CDC, reports of Lyme disease have doubled in the United States since 2000, reflecting a growing need for prevention.\nIn 1993, the Yale Scientific Magazine reported on a novel vaccine being tested against Lyme disease (Vol. 67 No. 2). The writer, Emily Ho, estimated that the vaccine would be \u201cavailable for the public sometime in 1995.\u201d However, as of today, there are no Lyme disease vaccines available for humans. What went wrong?\nRevisiting the Past\nThe story began in 1988, when Erol Fikrig\u2014then a postdoctoral researcher\u2014met with Richard Flavell, who was the newly appointed chair of immunobiology at the Yale School of Medicine. \u201cWe decided, why don\u2019t we make a vaccine against Lyme disease?\u201d said Fikrig, now the Waldemar von Zedtwitz Professor of Medicine at Yale. So, they started looking for a target.\nLyme disease is caused by Borrelia burgdorferi, which is a pathogenic spirochete (a type of slender, spiral-shaped bacteria). It was known that a key part of protection against Lyme disease in animals is mediated by humoral immunity, a type of immune response that can be passive or active. In active immunity, B cells (a type of white blood cell) produce antibodies that specifically recognize and destroy an encountered foreign antigen, conferring future protection against that antigen. In passive immunity, blood serum containing these antibodies can be transferred to other animals to confer protection against the target antigen.\nPreviously, it was shown that immunization of hamsters with serum-containing antibodies against B. burgdorferi prevented infection when the hamsters were challenged with the bacterial strain. However, scientists did not know what specific antigens trigger the production of protective antibodies against Lyme disease. Fikrig and Flavell would have to solve that mystery.\nIn their 1990 paper published in Science, Fikrig and Flavell\u2014along with collaborators Stephen Barthold and Fred Kantor\u2014hypothesized that a possible candidate for the antigen was outer surface protein A (OspA), which is a lipoprotein (a particle composed of fats and proteins), on B. burgdorferi. To test this hypothesis, the gene for OspA in a B. burgdorferi strain was cloned into the bacteria E. coli, such that the E. coli would express OspA. Mice then received either the OspA-transformed bacteria or a control. Four weeks later, an antibody response was detected in mice that received the OspA-transformed bacteria, suggesting that humoral immunity had developed in response to OspA.\nThe team found that the mice that received the OspA-transformed bacteria were successfully protected from infection from B. burgdorferi. While the control mice showed evidence of arthritis, inflamed heart tissue, and infection in blood and spleen cultures, mice that received the OspA-transformed bacteria showed no sign of infection\u2014all signs pointed towards successful immunity. Lastly, the researchers found that the serum of the protected mice conferred similar prevention against infection when injected into new mice, demonstrating effective passive immunization.\u00a0\nStudies like this one paved the way for a human vaccine against Lyme disease. Indeed, in the YSM article published thirty years ago, which covered a similar study highlighting the potential of the OspA vaccine, the writer was optimistic about the vaccine\u2019s release in 1995.\u00a0\nWhat happened, then, over these three decades?\nLYMErix and The Revival of The OspA Vaccine\nAccording to Fikrig, biopharmaceutical company GlaxoSmithKline signed an agreement with Yale to develop the vaccine. Fikrig and Flavell advised them as they developed a three-dose vaccine for humans, under the name LYMErix. The last phase of clinical trials for the vaccine enrolled over ten thousand patients in endemic areas, and demonstrated that LYMErix was safe and effective in reducing the occurrence of Lyme disease in humans. Following FDA approval, LYMErix was released to the public in 1998.\u00a0\nUnfortunately, LYMErix\u2019s success was short-lived. The vaccine was discontinued in 2002, even though it remains FDA-approved.\u00a0\nLYMErix\u2019s brief time on the market saw low demand and a potential onslaught of lawsuits alleging the vaccine caused arthritis. \u201cThese rumors were circulating that the vaccine was making people sick. There was absolutely no evidence for that, and there still is absolutely no evidence for that,\u201d said Flavell, who is now a Sterling Professor of Immunobiology at Yale. However, the controversy, combined with the lack of interest, was enough for GlaxoSmithKline to remove LYMErix from the general public. There has not been another Lyme disease vaccine for humans since then.\nHowever, that may soon change. Major pharmaceutical companies such as Pfizer and Valneva are now interested in developing a new Lyme vaccine. The principle behind how these new vaccines would function is similar to findings from past research. \u201cYou need a high titer [concentration] of OspA antibodies to work in both [the old and the new vaccines]\u2026 they\u2019re fundamentally the same in that regard,\u201d Fikrig said. The new vaccines are now being tested in clinical trials, offering the possibility that a human vaccine for Lyme disease may soon return to the market.\u00a0\nBeyond Lyme Disease: A Vaccine Against Ticks\nWhile pharmaceutical companies try to revive OspA vaccine efforts, Fikrig and Flavell have moved on. They are searching for success with a different approach\u2014one that might be able to prevent all tick-borne illnesses. Besides Lyme disease, Ixodes ticks are also carriers of illnesses such as babesiosis, Powassan virus, and anaplasmosis, which can cause debilitating health effects in humans. Fikrig and colleagues utilized an anti-tick approach to a vaccine in their recent paper published in Science Translational Medicine in 2021.\u00a0\nThe idea of using an mRNA vaccine for tick immunity was formulated in 2019 in collaboration with Drew Weissman, who is now a co-winner of the 2023 Nobel Prize in Physiology or Medicine for his work on mRNA vaccine technology (which was foundational for the development of the Pfizer-BioNTech COVID-19 vaccine). The mechanism of these vaccines relies on the delivery of mRNA, which directs the production of a small, harmless piece of a target antigen in host cells so that the immune system will learn to mount a response against them if encountered again. Rather than targeting specific antigens associated with Lyme disease, the researchers focused on the source\u2014proteins found in the tick\u2019s saliva, which is secreted into humans at the site of the bite.\nAfter identifying nineteen salivary proteins with high immunogenicity (ability to trigger an immune response), the researchers created a cocktail of mRNA encoding those proteins. They placed this cocktail, called 19ISP, in lipid nanoparticles\u2014which protect the mRNA from premature degradation\u2014for delivery. Two weeks after injecting it into guinea pigs, antibodies against ten of the nineteen proteins were detected in the serum of the immunized guinea pigs, while none were observed in the control group, suggesting that exposure to 19ISP triggered a humoral response.\u00a0\nFollowing this, the guinea pigs then underwent tests to examine whether 19ISP vaccination was effective in generating tick immunity and resistance against Lyme disease. \u201cWe showed that if you give [19ISP] to a guinea pig and then put ticks on it, the ticks feed very poorly, you get redness where the ticks feed, and the [ticks] detach and die quickly. And then we showed that if you put ticks that have the disease-causing agent in them, the guinea pigs will not get Lyme disease,\u201d Fikrig said.\u00a0\nIn comparison, control guinea pigs had low rates of tick detachment, did not show redness, and were susceptible to B. burgdorferi. These results suggest that 19ISP may be a viable solution in both the early detection of tick attachment and the facilitation of tick detachment. \u201cI think we have a vaccine that can increase tick recognition and prevent Borrelia transmission,\u201d Fikrig said. \u201cAnd hopefully, at some point, that may be available to the public. We don\u2019t know yet, but it may be useful in preventing more than just Lyme disease.\u201d\nFuture Directions\nThe \u201canti-tick\u201d approach is crucial because Ixodes represent just one genus of ticks that carry illness. Other ticks pose their own threats. Saliva from Amblyomma ticks, for example, is thought to cause red meat allergy in humans, according to Fikrig. The tick\u2019s saliva proteins may contain the sugar molecule alpha-gal, which is found in most mammals but not in humans. When the tick\u2019s saliva is transferred to humans, alpha-gal is flagged as a foreign antigen, triggering a severe immune response when alpha-gal is encountered again, such as in red meat and milk. \u201cI think that our anti-tick vaccine can be the first ever vaccine against an allergic condition,\u201d Fikrig said. In the past, it was demonstrated that immunity to Ixodes ticks can protect against other disease-spreading tick species (e.g. Amblyomma and Dermacentor); however, their specific 19ISP cocktail has yet to be tested for this cross-protection.\nIn addition to solving these mysteries, Fikrig and Flavell are working with a worldwide network of collaborators to explore whether the anti-insect approach can be applied to other infectious diseases. Flavell highlighted that this approach may be applicable to other creatures that spread disease. \u201cWe\u2019ve brought together a consortium of people to develop this concept, and if we\u2019re very lucky, we could hopefully make a dent in diseases like malaria, which is a huge problem,\u201d Flavell said. Despite previous roadblocks in the history of Lyme disease vaccines, the researchers have continued to forge ahead to meet greater success than before\u2014and pioneered an approach that could revolutionize vaccines for allergies and broader infectious disease prevention.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/the-ticking-clock-to-fight-ticks/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Nature vs. Nurture: Is Alcohol Use Disorder in Our Genes?",
            "author": "Matthew Blair",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Nature-vs-Nurture-Patricia-Joseph-500x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Patricia Joseph.\nIt is no secret that the genes we inherit from our parents determine simple physical traits such as hair color and height. That comes down to a mixture of certain genes, which include a randomness component related to the allele\u2014or gene variant\u2014we inherit. But when it comes to more complex human features, the connection to our genes is less clear. The impact of genes on behavior like alcohol use or even sexual orientation has long been the subject of scientific debate.\nIn an article published in the Yale Scientific Magazine in 1929 (Vol. 3 No. 2), Yale Professor R. P. Angier weighed in on this \u2018nature vs. nurture\u2019 debate. He questioned if our traits are impacted not only by complex genetic combinations, but also by the environment in which we live. He discussed two major schools of thought: the instinctivists and the environmentalists. The former hold the belief that our instinct, which we inherit and thus have no control over, drives our actions. The environmentalists differ. They believe that only the most basic of actions\u2014like knowing how to swallow or turn one\u2019s head\u2014are inherited, while all other actions are learned through a process of trial and error. Angier himself took a binary approach to this debate, concluding that traits fall into one category or the other. \u201cAlcoholism used to be labeled as a hereditary trait,\u201d he wrote, \u201cNo competent medical man thinks so nowadays.\u201d\u00a0\nSince then, the current understanding of genetics and environmental factors has combined these two schools of thought, with alcohol misuse serving as an interesting test case. Both genetics and our environment play a role. \u201cOne is not against the other, but rather they both contribute to the predisposition to psychiatric and behavioral traits,\u201d said Renato Polimanti, an associate professor of psychiatry at the Yale School of Medicine. So, how did we come to prove Angier wrong?\u00a0\nThe Unique Case of Alcohol Use Disorder\nAlcohol use disorder (AUD) is a leading cause of death and disability worldwide and is characterized by frequent and problematic drinking behaviors, such as binge drinking, loss of control, and continued drinking despite harmful consequences. In the 170 years since the term \u201calcoholism\u201d was first classified as a behavior, problematic drinking has been a widely studied condition to settle the nature versus nurture argument.\u00a0\nEarly on, it was believed that alcoholism was inherited. This simple view, however, quickly started to change. By 1929, as Angier wrote, the general view had completely reversed: alcoholism was primarily seen as the result of environmental factors. When AUD was classified as a brain disorder in 1956, as we generally understand it today, this issue took a far more complicated turn.\nAs it turns out, there is no \u201calcoholic\u201d gene in the human genome, nor is there an absolute \u201cAUD-causing\u201d environment or situation. Alcoholism has a substantial impact on both mental and physical health and can present different features among affected individuals. Due to this, the mechanisms and possible causes of alcoholism cannot be as easily identified as diseases such as hemophilia, which presents clear physical symptoms. But in the decades since Angier\u2019s article, scientists have made strides in figuring out the mystery of what really underlies this unique disease.\nSearching for AUD in Our Genes\nIn 1990, an initially promising study of the genetic basis of alcoholism was conducted by Kenneth Blum, a professor at the University of Texas Health Science Center. The study found that there was a very strong connection between the D2 dopamine receptor gene and the development of alcoholism or problematic drinking behaviors. In their patient sample, the researchers found that in those with AUD, all had a higher frequency of one specific allele in the dopamine D2 receptor gene, suggesting that it was strongly associated with AUD.\nHowever, one year later, Joel Gelernter, a professor of genetics and neuroscience at the Yale School of Medicine, along with his team could not find the association between the D2 dopamine receptor gene and AUD, showing a lack of replicability in the earlier study.\u00a0\nWhile the D2 dopamine receptor gene did not have the effect expected on alcoholism, the study contributed to moving forward genetic research. \u201cWe know now that it was only a first step of a very long road of complex genetics,\u201d said Renato Polimanti, a colleague of Gelernter at the Yale School of Medicine. In contrast to Angier\u2019s conclusion that AUD is decided by the environment, scientists have since found multiple genetic players.\nThe effort to uncover the genetic mysteries of AUD was\u2014and is\u2014long from over. Between the D2 dopamine receptor findings in the 1990s and 2020, researchers have identified more than a dozen variants for AUD. In 2020, a research team including Gelernter, Polimanti, and Hang Zhou, an assistant professor of psychiatry at Yale, was able to greatly expand upon previous findings regarding alcoholism through a genome-wide association study published in Nature Neuroscience.\nThe team was able to identify twenty-nine genes linked to increased risk of problematic alcohol use\u2014nineteen of them novel\u2014in the human genome, extending the known genetic architecture of the disorder and giving other scientists a wider breadth of targets for follow-up studies. Researchers found that six to eleven percent of the phenotypic variation\u2014referring to differences in what physical and behavioral traits are expressed\u2014could be explained by genetic information.\u00a0\nThe goal of genetic studies, however, is not only to find associations but also to understand how these variants might promote the development of AUD. In their study, the Yale team discovered that the risk genes were correlated to changes in certain brain regions. This finding suggested to researchers that the risk variants promoted certain brain pathways that contribute to the development of behavior patterns and disorders.\nSuch pathways are not exclusive to AUD. The researchers discovered a strong genetic correlation between problematic alcohol use and 138 other conditions, including substance abuse disorders, depression, and schizophrenia. \u201cAUD has many variants across the genome that are involved in the predisposition of this trait, but these variants are not only predisposing to AUD, they are predisposing to many things,\u201d Polimanti said. \u201cIt can depend on where [risk variants] play a role, maybe in sensitivity to a substance, or to addiction pathways in the brain, or to reward systems.\u201d\nMoving Forward\nThis research does not mean AUD is solely explained by genetics. Rather, in AUD, only about fifty percent of the risk appears to be attributed to our genes. This is relatively small in comparison to schizophrenia, where genetics can explain eighty percent of the disease predisposition. Therefore, as research progresses, consideration must still be made for the environment\u2014the \u201cnurture\u201d\u2014that individuals were raised and live in. \u201cGenetic variants among individuals cannot explain everything. We need to spend more time in gene discovery before bringing it into patient care,\u201d Zhou said.\nBeyond addressing the nature versus nurture debate, this research has a broader aim. According to Polimanti and Zhou, geneticists hope to be able to bring their findings to human healthcare in order to help predict and treat certain illnesses. This is called precision medicine, wherein a person\u2019s treatment plan can be specially tailored based on their unique genetic makeup.\nUntil we get there, research will continue focusing on identifying genetic variants and possible mechanisms behind risk. Polimanti explained that for certain illnesses like cardiovascular disease, the field of genetics is expected to transform treatments in the coming years. \u201cWe will keep doing gene discovery and use increasingly advanced technology to deliver this information and get a deeper understanding of the role genetics play in human health,\u201d Zhou said.\nThe study of AUD has been marked by both successes and failures. Now, we enter an exciting time where genetic and environmental studies promise great strides for the understanding of our human genome and real changes in clinical care. Nature and nurture, instinctivists and environmentalists, the D2 dopamine receptor and twenty-nine other discovered genes, and, now, precision medicine, are all important themes in the long and evolving story of alcoholism and scientific discovery.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/nature-vs-nurture-is-alcohol-use-disorder-in-our-genes/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Right Idea, Wrong Target?",
            "author": "Madeleine Popofsky",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Gene-Therapy-for-Parkinsons-Disease-Jungbin-Cha-Jaime-500x347.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Jungbin (Jaime) Cha.\nWhy do treatments fail? Sometimes there is an issue with the treatment\u2019s target. Other times, the translation from an animal model to humans presents too big of a gap. Over the history of research on gene therapy, such failures have brought scientists closer to success.\u00a0\nThe idea behind gene therapy is to treat genetic diseases at their source by altering a missing or faulty gene. For Parkinson\u2019s disease\u2014in which loss of dopamine-producing (dopaminergic) neurons leads to slowness of movement and other severe motor symptoms in late stages\u2014this approach has shown promise, but success has, thus far, been out of reach.\u00a0\nPast research on gene therapy had targeted a part of the basal ganglia\u2014which is responsible for motor control\u2014called the striatum. In mouse models, this was quite successful, and several papers were published on different genes targeting this area. One of these papers, published in 1994, was covered in the Yale Scientific Magazine by Gautam Mirchandani (Vol. 66 No. 2), who called it a promising study. The proposed therapy was designed to target the gene for tyrosine hydroxylase (TH), an enzyme that is critical for synthesizing dopamine in a Parkinson-like disorder. \u201cHopes are that such a treatment will soon be available for human benefit,\u201d Mirchandani wrote. Yet, these techniques have all since failed.\u00a0\nThe problem, in many of these cases, was actually the target. While easy to target in a mouse, the basal ganglia in humans has enlarged dramatically over the course of evolution. Since the striatum forms such a large part of the basal ganglia\u2019s structure, it was simply too large of a target. \u201cIt is very difficult to cover it by injecting a virus,\u201d said Jim Surmeier, a professor of neuroscience at Northwestern University Feinberg School of Medicine. He is one of the many scientists taking up the task of turning the coal of past failures into the future diamonds that will let gene therapy shine. \u201cWe fail more often than we succeed,\u201d Surmeier said. \u201cWhat distinguishes really good researchers is the ability to learn from your failures.\u201d\nA New Target?\nSurmeier\u2019s research challenges prevailing theories regarding the function of dopaminergic neurons and their site of action in Parkinson\u2019s disease. Previous researchers had assumed that loss of dopamine in the striatum was sufficient to cause the primary motor symptoms associated with Parkinson\u2019s. However, Surmeier developed a new animal model for Parkinson\u2019s that involved disrupting Complex 1, an important protein for energy generation, in the mitochondria of dopaminergic neurons. The difference in this model was that, unlike most animal models for Parkinson\u2019s which cause rapid onset of the severe motor symptoms, this model more closely mimicked human Parkinson\u2019s with its slow onset. Motor symptoms only became apparent several months after gene editing. This more realistic model led to both a new potential cause of Parkinson\u2019s in humans and a better lens through which to study how brain circuits contribute to the disease.\nUsing this model, Surmeier discovered something unexpected. \u201cWhen there was clear loss of striatal dopamine release, the animals were not Parkinsonian, contrary to the prediction of the classical model,\u201d Surmeier said. His new theory takes into account the structure of the basal ganglia. While the striatum is a large complex within this structure, there are other nuclei\u2014clusters of neurons that perform a specific function\u2014modulated by dopaminergic neurons. One of these, which sits between the basal ganglia and the rest of the brain, is the substantia nigra pars reticulata (SNr). While the traditional model of Parkinson\u2019s focuses on almost solely treating the striatum, Surmeier proposed the SNr as a new target for gene therapy. \u201cThe basal ganglia are organized like a funnel, with the SNr at the mouth of the funnel. Targeting the mouth of the funnel is the best way to control the output of the basal ganglia,\u201d Surmeier said.\u00a0\nNow armed with a location, Surmeier needed a gene. In his study published in Nature in 2021, he targeted aromatic acid decarboxylase (AADC), a key enzyme that converts the precursor levodopa into its final form of dopamine. Levodopa is commonly used as a treatment for Parkinson\u2019s. However, its effects wear off with time and more advanced forms of the disease since the dopaminergic neurons that are dying are the primary producers of AADC. Thus, over time, the brain begins to lack sufficient AADC to convert levodopa into dopamine. In this trial in mice, Surmeier was able to use gene therapy to give a new group of neurons the ability to express AADC\u2014those in the SNr\u2014which relieved motor deficits in Parkinsonian mice.\nThroughout the process, Surmeier emphasized that one has to be willing to both challenge past assumptions and learn from past failures. When he first received the data from his new Parkinsonian model, Surmeier was skeptical enough to ask others to repeat similar experiments, again and again, when his results did not match preconceived notions. \u201cIn science, we never have truth in our hands,\u201d Surmeir said. \u201cIt is always an approximation.\u201d\nYet Another Target?\nSurmeier\u2019s work is only the tip of the iceberg when it comes to developing gene therapies for previously intractable diseases. His successful process of choosing just the right nucleus for targeting, and just the right enzyme to target for modification, is the result of not just personal failures, but also the failures, and successes, of many of his colleagues.\u00a0\nOne such colleague is Krzysztof Bankiewicz at the Ohio State College of Medicine. Bankiewicz has been interested in dopamine and Parkinson\u2019s disease since the 1980s, when he joined one of the first clinical trials to restore normal dopamine levels in the brain to reverse Parkinsonian symptoms. The clinical trial intended to transplant cells that could produce dopamine into the striatum. But despite trying many stem and fetal cell lines, many dopaminergic cells did not survive the transplantation process. It did not seem like cell transplantation was going to work.\u00a0\nThe advent of gene therapy, where a clinician can change just one gene at a time as opposed to transplanting entire new cell lines, was exciting to Bankiewicz. He began studying specific gene-delivery systems and experimenting with different targets in the brain for the delivery of enzymes that could convert levodopa into dopamine. He also tried many variations of the viral vector, which is used to deliver a properly functioning copy of a gene in gene therapy. After twenty years of repeated failure and learning, he has managed to launch clinical trials intended to deliver genes of interest to treat many neurodegenerative diseases, such as pediatric Parkinson\u2019s disease. He looks at commonalities between diseases to figure out the best way to approach new ones. \u201cIn this way, the disease itself becomes more of an application for the operating system,\u201d Bankiewicz said. The operating system is the common pipeline that enables him to optimize a gene therapy\u2019s chance of clinical success.\nBankiewicz is currently trying to develop gene therapies for neurotrophic factors, which are proteins in the brain that support the development and maintenance of neurons (since neuronal damage and death characterizes various dementias). He has worked on increasing the production of the protective brain-derived neurotrophic factor to the entorhinal cortex, a key memory center in the brain, to slow and possibly even reverse memory loss in Alzheimer\u2019s disease. He is currently working on a trial to increase the production of glial-derived neurotrophic factor that promotes dopaminergic neuron survival, which may ameliorate Parkinson\u2019s disease symptoms. He says that there are other diseases to address through the neurotrophic factor pathway, including Huntington\u2019s disease and childhood dementias.\u00a0\nBankiewicz\u2019s theory also supports the development of various gene therapies to reduce and replace proteins that misfold and aggregate in various neurodegenerative diseases. For example, he is currently working on a trial to reduce levels of alpha-synuclein, which accumulates in Parkinson\u2019s disease and multiple system atrophy, and is interested in developing a trial to replace the protein progranulin which leads to amyloid protein accumulation in patients with fronto-temporal dementia.\u00a0\nBankiewicz\u2019s research is especially important because gene therapy can be a highly effective treatment that works for most patients, regardless of their disease etiology. This means that it does not matter whether a patient has a genetic cause for their disease or if their disease is idiopathic (unknown cause). For example, when patients are given levodopa, the drug addresses their symptoms regardless of the cause of their Parkinson\u2019s disease. Similarly, gene therapy addresses common disease pathology, such as loss of dopaminergic neurons or levodopa resistance in Parkinson\u2019s disease, regardless of whether it is driven by idiopathic or familial factors. This means it has a higher chance of working across patient populations.\u00a0\nMoreover, gene therapy is a one-time surgical treatment, which is clinically preferable for patients, whose alternatives are either to live with a deep-brain stimulation electrode within their head, spend the rest of their life taking a medication that progressively loses its effectiveness, or let their disease continually advance. Bankiewicz stated that his patients feel safe undergoing the treatment, knowing that its effects are very localized. \u201cThey love the idea of just getting one therapeutic for life,\u201d Bankiewicz said.\u00a0\nThis field has made significant leaps since YSM last reported on the 1994 study on gene therapy. Bankiewicz\u2019s and Surmeier\u2019s clinical trials may bring treatment to hundreds of thousands of people who would otherwise live without the hope of recovering from or surviving their disease. Yet all this would not have been possible without countless mistakes. If Bankiewicz has learned one thing along the way, it is that scientists are hardly right every single time. \u201cOne lesson that I tell my students and scientists: don\u2019t be afraid to try. You learn from your failures. So, don\u2019t be afraid to fail,\u201d he said.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/right-idea-wrong-target/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Q&A: Why Is \u201cDisruptive\u201d Science Dwindling, While \u201cHype\u201d Language Is On The Rise?",
            "author": "Sunny Vuong",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/pexels-photo-3735769-500x333.webp"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pexels.\nFind yourself wondering where the hype is? Look no further than recent language trends in science. Researchers in Japan and Canada examined 901,717 successful grant application abstracts submitted to the National Institutes of Health and found a significant increase in the use of promotional language from 1985 to 2020. The 2022 study, published in The Journal of the American Medical Association, identified 139 adjective forms associated with hype, such as \u201cnovel,\u201d \u201ccritical,\u201d and \u201ckey,\u201d with 130 of these showing an increase in frequency by 1,378 percent.\nIn a separate trend, researchers from the Universities of Minnesota and Arizona explored whether scientific innovation is becoming more or less disruptive. They created the CD index, which measures disruptiveness by examining whether subsequent works cite the study itself (an indicator of greater disruptiveness) or the study\u2019s references. The findings, published by Nature in January 2023, revealed that papers published since 1945 are less likely to be disruptive and more likely to consolidate existing knowledge. While older manuscripts from the 1950s tended to use words evoking discovery (such as \u201cproduce\u201d or \u201cdetermine\u201d), recent research favored words referring to incremental progress (such as \u201cimprove\u201d or \u201cenhance\u201d). Researchers concluded that a balance between disruptive research, which pushes boundaries, and incremental research, which refines existing knowledge, is essential to scientific advancement.\nAlthough these phenomena are revealing about modern scientific trends, it\u2019s still unclear what the reasoning is behind them. Hype language and disruptiveness in science have yet to be declared as inherently good or bad\u2014that may be for scientists now exploring these tendencies to decide.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/qa-why-is-disruptive-science-dwindling-while-hype-language-is-on-the-rise/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Science in the Spotlight: Serendipitous Science: Acts of Accidental Brilliance in the Lab",
            "author": "Jamie Seu",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/wasp-6220978_1280-500x332.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\n\u201cOops!\u201d is not a word you want to hear in the lab. Unfortunately (or not), accidents are a common reality in research. But sometimes, these mistakes can bring about valuable revelations, as discovered by the nominees of NPR\u2019s Golden Mole Award for Accidental Brilliance.\nA podcast presented by Skunk Bear, NPR\u2019s science-centered YouTube channel, highlights five instances of serendipitous scientific discovery, including the story behind the winner of the Golden Mole, Elizabeth Tibbetts. A biologist at the University of Michigan, Tibbetts was researching wasp behavior when she stumbled upon a fascinating revelation: wasps can recognize each other\u2019s faces, just as humans can.\u00a0\nThe realization started with a careless mistake. To study wasp behavior, Tibbetts taped and watched video footage of the insects, analyzing interactions between colony members. She color-coded each wasp with a dot of paint, a critical step that allowed her to distinguish between the insects. One day, however, she discovered that she had forgotten to paint a few wasps, leaving her with what she thought was a frustrating waste of a recording. But something caught her eye\u2014she realized that the wasps had discernible facial features. \u201cI could still tell them apart, just by their natural patterns,\u201d Tibbetts said. Upon closer inspection, Tibbetts identified unique colors, patterns, and \u201ceyebrow\u201d structures that allowed her to differentiate them. The question then became: If she could distinguish between individuals, could the wasps themselves tell each other apart?\nAccording to prior research on insect behavior, the answer was no. But Tibbetts was determined to investigate the subject herself. \u201cMaybe if I had more experience, I wouldn\u2019t have pursued it, because maybe I would have thought it was implausible,\u201d Tibbetts said. Fortunately, she pushed on and determined that, yes, wasps can recognize each other. Furthermore, it is this ability that facilitates complex social interactions between members of a colony and allows for wasps to develop personal relationships.\u00a0\nTibbetts\u2019 serendipitous tale was one of hundreds of stories submitted to Skunk Bear. One notable runner-up was George Liu, a researcher at the University of California, San Diego, who discovered the novel use of pigment as a bacterial defense mechanism after his lab equipment was contaminated with bleach. Other memorable contenders included former Stanford University undergraduate Nate Cira and his adviser, Manu Prakash, who discovered the role of evaporation and surface tension in artificial chemotaxis, the movement of a particle in response to a chemical stimulus. While these stories only offer a glimpse into the myriad of ways in which discoveries can be made, they highlight the value of mistakes in research. Skunk Bear\u2019s Golden Mole Award takes a creative approach to emphasize this lesson, presenting the \u201cwhat\u201d and \u201chow\u201d of the research in an amusing manner. Any listener curious about the \u201cwhy\u201d will need to engage in some investigation of their own due to the podcast\u2019s brevity.\u00a0\nSkunk Bear\u2019s Golden Mole segment is worth a listen for any person, researcher or not, who could use a reminder about the importance of adaptability and perseverance. If we can learn anything from these scientists, it\u2019s that \u201coops\u201d can be okay sometimes. It might even lead to something great.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/science-in-the-spotlight-serendipitous-science-acts-of-accidental-brilliance-in-the-lab/",
            "captions": [
                ""
            ]
        },
        {
            "title": "When Science Fiction Becomes Fact: The Rise of \u201cThinking Machines\u201d",
            "author": "Ian Gill",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Archives_Vs_Today_-Anna-Olszowka-500x500.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Anna Olszowka.\nEditor\u2019s note: In the spirit of this special issue, we traveled back in time and dove into YSM\u2019s archives, seeking to track how our perception of scientific progress has changed over the last century. We found one YSM article written by Yale physics major Henry Thwing in 1951 (reproduced here), to which we asked one of our members to write a response (pg. 35). In this side-by-side comparison, we examine how our vision of artificial intelligence (AI) technology\u2014and how it is presented in literary science fiction\u2014has changed between the mid-twentieth century and the present.\nWill we one day live in a world dominated by thinking machines? This is the central question of Thwing\u2019s 1951 article in Vol. 25 No. 4 of the Yale Scientific and one that is often posed today. But perhaps a more pertinent question to ask is: do we already live in such a world? In his article, Thwing posits, \u201cIf a calculator could be made which would correlate data in ways other than those fed into it, then it would be a thinking machine much as those stipulated by science fiction.\u201d According to his definition, thinking machines are already deeply integrated into our society, from the Tinder and Hinge algorithms that determine who we might fall in love with to programs used by financial firms that shape economic development across the globe.\nWhat captures our attention, and our fear, most about Thwing\u2019s thinking machines is the possibility that they might be able to think autonomously. Most people would argue that social media algorithms and similar technologies don\u2019t \u201ccontrol\u201d our society in the way that past science fiction writers have described: they lack independence and only act on human command. But the possibility that machines could surpass this limit\u2014an idea that in Thwing\u2019s age was relegated to writers\u2019 rooms and dinner party conversations\u2014has become far less remote. With the advent of the language model-based chatbot ChatGPT, our society has had to grapple with artificial intelligence (AI) as a force capable of changing our entire way of life.\u00a0\nHere at Yale, for instance, the Schmidt Program on Artificial Intelligence, Emerging Technologies, and National Power under the Jackson School of Global Affairs describes its aim as to \u201cexamine how AI has the potential to alter the fundamental building blocks of world order.\u201d This is what the AI-related science fiction that Thwing describes aimed to do\u2014only now, this task has moved from the realm of speculation to the realm of academic inquiry and policy development. In a poll of 119 CEOs conducted by Yale School of Management professor Jeffrey Sonnenfeld, over forty percent indicated that they believed that AI had the potential to destroy humanity in the next five to ten years. While these respondents may not be the most technically knowledgeable on AI, the fact is that their opinions will govern how we integrate AI into our everyday lives.\nDespite recent advances, some believe that human-like, emotional AI will remain in the realm of fiction. In an opinion piece published in The Washington Post in April, Yale professor of computer science David Gelernter argues that software is fundamentally unable to experience consciousness. He suggests that the concept of a conscious computer is akin to a conscious toaster. AI will never be able to \u201cunderstand\u201d the world as humans do\u2014it will only be able to draw surface-level connections based on the data it receives.\u00a0\nWhether or not you agree with Gelernter, the fact remains that AI will play an increasingly significant role in our society. In his article, Thwing says, \u201cThe seeds of scientific fiction today will yield a harvest of new scientific discovery tomorrow.\u201d In this sense, his proposition is firmly validated. As for whether our technology will come to control us, I would argue that it always has, in the same way that we control it. Just as the invention of agriculture changed human social structures from small hunter-gatherer communities to larger sedentary settlements twelve thousand years ago, technological breakthroughs alter not only our ability to interact with the world, but also our core values as a species. Our values, in turn, mold how we employ and develop future technology.\u00a0\nThwing\u2019s article is fundamentally about the value of science fiction, and thus any analysis of his work would be incomplete without asking what will become of science fiction in the world of AI. I would argue that it will remain in the same place that it\u2019s always been in. Science fiction, and art in general, is not something that we produce for the sole purpose of mass consumption. Perhaps some science fiction novels of the future may be written by non-human authors, but this does not mean science fiction as a whole will become an automated process by which we will become \u201crobotic\u201d consumers. An AI-generated story might spark an idea for a different story written by a human author, which would in turn be incorporated into the AI database.\u00a0\nJust as humans mutually benefit from sharing their literary works with one another, the same may hold true for humans and AI. Beyond the specific details of how this relationship might work, one thing remains clear: humans will always dream about the world of tomorrow, and as long as we do, science fiction will always have a place in our collective consciousness.\n\n\n\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/when-science-fiction-becomes-fact-the-rise-of-thinking-machines/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Perimeter: A New Precipitation",
            "author": "Molly Hill",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Perimeter-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao.\n\nInto the earth the oil well dips like a crane, dredging up\u00a0\nSlick-oils, sucking, gulping from the seafloor ancient crud\n& festering remains of our ancestors: the turnover, the dredge,\u00a0\n\u00a0\u00a0Forgotten by all but time & rock & rot. Into the light they rain\n\u00a0\u00a0Upwards, unwilling, compounds of bodies torn from dark sleep,\n\u00a0\u00a0Filling test tubes, measured by blasts of radioactive sulfur. Cut up\u00a0\n\u00a0\u00a0\u00a0& compartmentalized, monomers polymerized, fumigated under an\n\u00a0\u00a0\u00a0Indoor sky, inhaling the spiky scent of fluorine. The reactive turns inert,\n\u00a0\u00a0\u00a0Carbon dead-eyed behind a veil of single bonds. Molecules forget the pull\n\u00a0\u00a0\u00a0\u00a0Toward entropy. They will never be bones again. They are stuck always in\n\u00a0\u00a0\u00a0\u00a0\u00a0Non-life, imitation bone\u2014teflon\u2014ugly name, ugly destiny, smooth vacuum\n\u00a0\u00a0\u00a0\u00a0\u00a0Of un-possibilities. Made here & there, again & again, more spilling out, frag-\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0menting, sifting into soil & water & bodies of fish & floating islands of plastic,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Until they gloss over the entire earth\u2014slick, smooth, white. Almost like snow.\n\n\nArtist\u2019s Statement:\nI read an article from a 1956 issue (Vol. 30 No. 8) of the Yale Scientific Magazine titled \u201cTeflon Resin: Preparation and Characteristics,\u201d further discussed in this issue on pg. 19. The article mostly describes how Teflon\u2014a DuPont brand name for a resin made from polymerizing tetrafluoroethylene\u2014was first produced. The Teflon polymer was originally discovered when a DuPont scientist noticed that it appeared in a powdery form when tetrafluoroethylene monomers were stored at super-atmospheric pressures. The article goes on to describe Teflon\u2019s unique properties, the modern, efficient manufacturing process, and the \u201cbrilliant future\u201d that the compound holds. I found it ironic and somewhat depressing to read this article\u2014which was full of excitement for the chemical\u2014from a modern perspective, knowing how damaging Teflon and other similar plastics have been to the environment.\nI wanted to reimagine the discovery and production of Teflon from the perspective of the molecules used to make it. If they could think, how might these molecules, which once made up the bodies of living creatures before decomposing into oil, feel about being dredged up from the ocean? Humanity\u2019s overconsumption and production of plastics disrupt Earth\u2019s natural cycles of renewal, in which the biological decays, but remains natural. Once extracted from the earth, the compounds used to make Teflon experience all sorts of unnatural transformations, which I tried to evoke in my poem. For example, \u201cradioactive sulfur\u201d is a reference to the process used by the researchers to estimate Teflon\u2019s molecular weight, and \u201cfumigated under an indoor sky\u201d represents the way the monomers are polymerized under intense pressure. The veil of fluorine is a response to one of the qualities of Teflon that the original article was so excited about: because the compound is essentially a string of carbons all single-bonded to fluorine, and C-F bonds are extremely strong, Teflon is remarkably inert, both chemically and physically. How might carbon molecules, which are used to interacting with the world through biological reactions, feel about being cut off from the world by these C-F bonds?\nFinally, I wanted to move beyond the scope of the original article to discuss the overproduction of Teflon and other plastics. The overproduction of plastic contributes to global warming, and plastic itself inevitably leaks into and pollutes the environment. I made my lines progressively longer, so the poem itself spills outward. In an age where more and more of the environment has been affected by humans\u2014with pollution and global warming changing even the atmosphere and weather patterns\u2014are we dooming ourselves to a world where artificial wonders such as Teflon replace natural ones?\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/perimeter-a-new-precipitation/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Room Temperature Superconductors? Not So Fast\u2026",
            "author": "Yamato Takabe",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Kara_Tao_Room-Temperature_Superconductor-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao\nThe world of \u201cBack to the Future,\u201d where levitating hoverboards and cars are the norm, might not be as distant as it appears, thanks to superconductors. That level of prevalence and accessibility, though, hinges upon the discovery of room temperature superconductors. Until now, superconductors have only been found at temperatures far below freezing point. But a few months ago, a potential breakthrough in the discovery of room temperature superconductors was made. Unfortunately, many scientists were skeptical.\nSuperconductors transmit an electrical current through themselves without losing any energy; in other words, they have no electrical resistance. Additionally, unlike normal conductors, which allow magnetic fields to pass through, superconductors repel external magnetic fields\u2014a property known as the Meissner Effect. This property allows superconducting materials to levitate in the presence of magnets: a macroscopic manifestation of quantum mechanical effects.\nWith these powerful properties, superconductors have incredible applications. Room-temperature superconductors would allow for lossless electricity transmission over long distances. This could lead to a more efficient and cost-effective electricity distribution in the power grid. And this isn\u2019t just a far-off future. Superconductors are already used in Magnetic Resonance Imaging (MRI) screening technology, which is widely used in the world of medicine. And the Maglev train, a levitating locomotive that can reach speeds of over 250 miles per hour, also relies on superconducting magnets to push it forward.\nHowever, these superconducting properties do not appear naturally. Superconductivity has only been observed when certain materials are held at extremely low temperatures, close to absolute zero (that\u2019s 0 Kelvin, or -273\u00b0C). Ever since superconductivity was first discovered back in 1911 by physicist Heike Kamerlingh Onnes, scientists have tried to observe it at the highest temperatures possible. While improvements have been made, these materials must still be kept at extremely low temperatures to express their superconductivity.\u00a0\nUnfortunately, maintaining low enough temperatures to trigger superconductivity is incredibly expensive. Superconductors are so useful that scientists are willing to pay large amounts of money in order to maintain their extremely cold environments. But what if this superconductivity could be triggered at a much higher temperature\u2014say, room temperature? Techniques that were previously limited by exorbitant costs would then become widely available. Furthermore, the scientists who uncovered this secret would be catapulted to international fame with their Nobel-Prize-caliber achievement.\nMany scientists have spent years dreaming of this mission: to achieve superconductivity at room temperature and ambient, or standard, pressure. On October 2020, the first instance of a notable advancement in creating a room temperature superconductor was reported by a team led by Ranga Dias at the University of Rochester, and Ashkan Salamat at the University of Nevada. They claimed to have observed superconductivity in a material known as carbonaceous sulfur hydride (CSH) at 288K (15\u00b0C). However, this breakthrough came with a condition: it occurred within a diamond anvil cell under immense pressure\u2014approximately 1.5 million times Earth\u2019s atmospheric pressure. Additionally, there were many concerns raised about the processing and analysis of the data presented in the paper.\nIn light of this, in September 2022, the journal Nature decided to retract the paper. Dias and Salamat claimed again in a second paper published in March 2023 that they had discovered a room temperature superconductor, but this time with lutetium hydride and nitrogen added to the sulfur hydride. They asserted that it had the properties of a superconductor at temperatures of up to 294K (21\u00b0C) with much lower pressure. However, this paper was also retracted by Nature on November 7, 2023, following similar concerns with their data.\nSukbae Lee and Ji-Hoon Kim, both physicists from Seoul, South Korea, are yet another duo of scientists who claimed to have achieved this groundbreaking accomplishment. In late July, they published non-peer-reviewed pre-prints of their work, which is common for research scientists. At first glance, their findings were truly groundbreaking. They had discovered a material they named LK-99 that demonstrated all superconductive properties under normal conditions, ostensibly achieving the world\u2019s first room-temperature superconductor.\nResearchers worldwide jumped onto this major breakthrough and tried to replicate it. Among the physicists who were reproducing and verifying the experiment was Yuan Li, a condensed matter theorist who leads a research lab at Peking University in China. Li collaborated with two other experimental physicists, providing interpretations of the measurements and observations. \u201cAt the beginning, it looked legit. The original authors, they do believe in what they are saying, and they are willing to disclose all the information to the scientific community so that everyone can, in principle, follow their steps and try to verify the observation,\u201d Li said.\u00a0\nYet when Li and his team began repeating the experiments detailed in the original publication, their data did not support the original claim. Because the scientists claimed that LK-99 had superconductor properties at room temperature, the properties should have been easy to replicate. Yet many physicists and material scientists, including Li, struggled during their replication processes. When testing the levitation of LK-99, Li and his team observed that LK-99 didn\u2019t fully repel the magnet. Instead, one corner of LK-99 touched the magnet, revealing that LK-99 was not levitating, but was still experiencing ordinary attraction to the magnet.\u00a0\nFurthermore, they discovered that its resistance was not actually zero\u2014a critical property of superconductors. With the evidence piling up against LK-99 being a room temperature superconductor, Li and his group published their findings in a scientific journal. It turned out that LK-99, at least at room temperature, was simply a semiconductor with ferromagnetic properties, or high susceptibility to magnetization. Along with papers from other groups that also disproved the original claim about LK-99, Li\u2019s paper helped relegate this highly-anticipated room temperature superconductor as one of science\u2019s many failed attempts.\n\u201cThis brings light to the high stakes of popular science and the need for competent \u2018referees\u2019 to overlook the process,\u201d Li said. Eye-catching research fields like superconductors could potentially revolutionize many industries, so there is naturally a lot more funding for these research projects, but also a lot more pressure to produce tangible results. More pressure for results means a greater likelihood of falsified, or in this case, prematurely published, research. Whether it comes from journal peer-reviewers or fellow scientists, regulation is needed to prevent misinformation or misconceptions from becoming mainstream science.\nDespite the failures, Li emphasized the importance of this research. \u201cAlthough papers were rushed, we should still thank the researchers for their effort and bravery to produce the research. Any information is useful information, thus furthering the story,\u201d Li said.\nIn the quest to discover a room temperature superconductor, we are reminded to be transparent and skeptical. As Carl Sagan famously said, \u201cExtraordinary claims require extraordinary evidence.\u201d It is not a sign of failure to question extraordinary claims; rather, it is an essential element of the scientific process that ensures the integrity of scientific knowledge. So, while the journey to achieving room temperature superconductivity may still be ongoing, the Sagan Standard serves as a guiding light\u2014reminding us to think boldly, but always demand extraordinary evidence in our relentless pursuit of scientific excellence.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/room-temperature-superconductors-not-so-fast/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Seawater Squabbles: Overturning A 130-Year-Old Assumption in Seawater Chemistry",
            "author": "Brandon Ngo",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/A_130_Year_Old_Assumption-Anna-Olszowka-500x349.jpg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Anna Olszowka\nLook back on the beaches you\u2019ve been to in the past decade. The serene sand, the soothing warmth of the sun, and most importantly, the refreshing splashes of the ocean waves. That same seawater may have contributed to a recent study that has overturned years of research. For over a century, scientists believed that charged particles, called ions, in seawater remained in relatively similar ratios across the ocean. However, a group of researchers have debunked this assumption, leading to concerns about the accuracy of past seawater studies that depended on it.\nMario Lebrato, a station manager and chief scientist at the Bazaruto Center for Scientific Studies in Mozambique, led the team that challenged this assumption about seawater ion proportions. Interestingly, the original intent of their study wasn\u2019t to test this assumption. \u201cOriginally, we were trying to understand how plankton grew in different seawater conditions,\u201d Lebrato said. His research team organized seawater samples from different parts of the world to analyze plankton growth. After measuring the composition of a few samples, Lebrato noticed significant differences in ion proportions between seawater from different sources. \u201cThis really triggered the project,\u201d he said.\u00a0\n\u201cIt all started with the question of: why are these waters so different in terms of oceanic versus coastal?\u201d Lebrato said. To further their investigation, his team organized partnerships with international universities, governments, and environmental agencies over seven years. They knew it would be hard to collect seawater samples worldwide without outside assistance or substantial funding. \u201cIt\u2019s almost impossible for anybody to organize over a hundred research cruises,\u201d Lebrato said. These partnerships ranged from organizations like the United States National Oceanic and Atmospheric Administration (NOAA) and Environment Canada, to small research cruises and individual scientists. Lebrato even received help from organizations that ventured into the Arctic Circle to retrieve seawater samples.\nAt the end of their seven-year project, Lebrato\u2019s team concluded that the original assumption about ion proportions in seawater was incorrect. According to Lebrato\u2019s research, there were significant deviations in major seawater ion ratios between samples, specifically in the open ocean. \u201cEverybody knew it was expected to find deviations from the coast, deviations near the rivers, and deviations in the poles near the ice. But nobody was expecting significant deviations on the open ocean,\u201d Lebrato said.\u00a0\nUpon discovering this flaw in this then-long-standing assumption on seawater ion ratios, Lebrato was initially worried about the international reaction to his team\u2019s research. \u201cI was pre-stressed because I was like, okay, maybe we\u2019re doing something wrong,\u201d Lebrato said. In the final stages of the research project, Lebrato\u2019s team rechecked all of the data with the owners of the labs, ensuring the results were consistent. They remeasured open ocean samples up to five times to validate their results. After the researchers published the project, the international science community accepted the discovery. Lebrato was especially pleased with these results.\nHowever, Lebrato\u2019s group of researchers could not pinpoint all of the exact causes for these deviations in ion ratios. It\u2019s possible that ocean and earth processes\u2014such as weathering, evaporation, particle movement from ocean waves, and ion production from sea animals\u2014contribute to these variances in the ion ratios of seawater. However, it is difficult to isolate the exact reasoning without further work. \u201cThe research basically opened a Pandora\u2019s box for people to start revising the topic and doing experiments on it,\u201d Lebrato said. After their paper was published, a wave of research proposals formed, with some looking to explore the cause of these varying ion ratios. Other research proposals looked to reevaluate the accuracy of past papers that relied on the now-overturned assumption.\nIt\u2019s important to keep in mind that overturning assumptions is necessary in scientific research and isn\u2019t a way to target other researchers. \u201cWe\u2019re not pointing fingers at anybody,\u201d Lebrato said. Instead, by debunking this assumption, new research opportunities have arisen to further investigate ocean chemistry. Revising and experimenting with these assumptions is a natural part of the research process and plays a crucial role in maintaining accuracy in the vast expanses of scientific literature.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/seawater-squabbles-overturning-a-130-year-old-assumption-in-seawater-chemistry/",
            "captions": [
                ""
            ]
        },
        {
            "title": "This Metal-Free Reaction Contains\u2026 Metal",
            "author": "Lawrence Zhao",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Kara_Tao_Metal_Free_Reaction_-500x375.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Kara Tao\nIt was the right time for a breakthrough, but was it too good to be true? In early 2021, a research group led by Professor Hua-Jian Xu at the Hefei University of Technology claimed to have found a new, nitrogen-based catalyst for the Suzuki reaction. The Suzuki reaction is a popular method among organic chemists to create new bonds between two carbon atoms, and in the past, it has always involved a palladium catalyst\u2014a substance that speeds up a chemical reaction.\u00a0\nHowever, researchers want to stop using palladium because the metal is toxic, difficult to recycle, and expensive, which limits their ability to use the Suzuki reaction to synthesize compounds in industry. Since 2003, scientists have promised a metal-free Suzuki reaction, but each time, they\u2019ve found evidence of palladium contamination in their attempts. Mere traces of palladium on a dirty stir bar could be enough to start a Suzuki reaction, so researchers must be extra careful that there\u2019s no palladium at all.\u00a0\nSo, when the scientific community heard about Xu\u2019s claims of a palladium-free Suzuki reaction, they were immediately skeptical. Although the Xu group included safeguards to avoid palladium contamination, scientists on X (formerly Twitter) quickly pointed out that Xu had used a palladium compound to make their Suzuki catalyst. Could palladium have somehow snuck into Xu\u2019s experiment, just like his predecessors\u2019? Chemistry professor Robin Bedford at the University of Bristol has been working with catalysts for over 30 years. \u201cI was one hundred percent confident that it was palladium-catalyzed, and I needed [more evidence] to be shifted from that position,\u201d Bedford said.\nBedford contacted other scientists who had doubted Xu\u2019s work on social media and asked if they would join him in investigating his hunch that palladium contamination was at fault. After assembling a team of investigators, Bedford tried to figure out what might have gone wrong. To Bedford\u2019s surprise, everything Xu did was reproducible to a remarkable degree\u2014the numbers were within one to two percent of reported values, which is an unusual feat for synthetic chemistry. However, the main issue lay in what Xu didn\u2019t do\u2014a control experiment that created the catalyst without using palladium. When Bedford used a different, palladium-free route to make Xu\u2019s catalyst, the catalyst no longer worked as advertised. Bedford did further testing which revealed that the metal was hiding in plain sight.\u00a0\nIt turned out that palladium had nestled itself in a stable compound that made it challenging to detect. Xu used a process that was unable to extract the palladium from these compounds, leading him to believe that there wasn\u2019t any palladium in the catalyst. However, when Bedford and his collaborators subjected it to hot, concentrated acid, the metal broke free. Unfortunately, Xu\u2019s palladium-free Suzuki coupling wasn\u2019t so palladium-free after all. Nine months after Xu\u2019s initial announcement, Nature Catalysis published the concerns that researchers like Bedford had voiced. In response to growing doubt, Xu swiftly retracted his paper.\nAlthough Xu failed to make a metal-free Suzuki reaction, his story is actually an example of success in the scientific method. \u201cThe scientific method is predicated on failure,\u201d Bedford said. Science tends to fall in line with existing beliefs, but Xu pushed the boundary of what was conventionally thought to be possible. Because Xu had to retract his work, the research may seem to be, at first glance, reprehensible. In reality, his effort to expand the breadth of human knowledge is admirable. Retractions carry a negative stigma in the scientific community because they often arise from papers with manipulated data. To encourage scientists to retract papers with errors made in good faith, Bedford suggests creating a separate distinction for papers like Xu\u2019s.\nBedford continues to search for new sustainable pathways to synthesize organic molecules. He is currently in the midst of publishing a proof-of-concept of an iron-catalyzed Suzuki coupling. Backed by almost 400 pages of data, Bedford\u2019s efforts underscore just how difficult it has been to eliminate palladium from the Suzuki reaction. While his work may not be more efficient than currently available procedures, it\u2019s a big step towards replacing palladium once and for all. One day, we might be able to cheaply make life-saving pharmaceuticals using a metal-free Suzuki reaction.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/this-metal-free-reaction-contains-metal/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Faster Than Lightspeed: These Neutrinos Were Faster Than The Speed Of Light\u2014Until They Weren\u2019t",
            "author": "Genevieve Kim",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/Faster-Than-the-Speed-of-Light_-375x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Yuanyu Chen.\nPhysics-bending findings. Irreproducible results. In 2011, news of neutrinos, neutral particles with infinitesimal mass, traveling faster than the speed of light topped science headlines, prompting widespread debate about the truth of these findings. The debate stemmed from the fact that Einstein\u2019s theory of special relativity says nothing can travel faster than light. But the Oscillation Project with Emulsion-tRacking Apparatus (OPERA) experiment at the underground Gran Sasso Lab (LNGS), had measured the velocity of neutrinos to be 0.0024 percent faster than lightspeed, contradicting Einstein. If OPERA\u2019s results were true, a core theory of physics would be shaken.\nThe premise of this measurement was simple: send a beam of neutrinos 730 kilometers from the European Organization for Nuclear Research (CERN) to the OPERA detector at LNGS and measure their time of flight. Yet, OPERA\u2019s primary goal was not to measure neutrinos\u2019 speed. The researchers conducted the additional measurement because OPERA was well suited to accurately determine neutrino velocity. The OPERA experiment had primarily been designed to test the phenomenon of neutrino oscillations, which occur when neutrinos oscillate between three known \u201cflavors\u201d: electron, muon, and tau. Located at the LNGS, the OPERA system aimed to be the first to detect the appearance of tau-neutrinos from the oscillation of muon-neutrinos during the 2.4-millisecond trip from CERN to Gran Sasso.\nThe researchers exhaustively checked every part of the experiment that could have caused the unexpectedly fast neutrino speed. They debated whether the research should be made public. Some didn\u2019t think the checks and tests on the equipment and experimental methods had been exhaustive enough. \u201cI was skeptical\u2014almost sure it was wrong,\u201d said Laura Patrizii, a member of the OPERA Collaboration. Putting it to a vote, the researchers pushing for sharing their potentially revolutionary findings won out.\nHowever, since many working on the project maintained that something had gone wrong, the Collaboration didn\u2019t submit for publication in a scientific journal and instead posted to arXiv.org, a non-peer-reviewed open-access archive. Meanwhile, the OPERA researchers continued to investigate still-unknown systematic effects that could explain the anomalous result.\u00a0\n\u201cExceptional results require exceptional checks,\u201d Patrizii said, paraphrasing Carl Sagan, astronomer and well-known science communicator. OPERA\u2019s error-searching efforts proceeded in tandem with labs across the world that tried to replicate the results\u2014to no avail. Other research groups noted that if the neutrinos were truly traveling at light-surpassing speed, they should have also been releasing energy. But no trace of this energy was seen in the experiment, increasing doubt about the measurements.\nIn 2012, OPERA finally disproved its own findings. The Collaboration found that there were two sources of error that had caused the observed relativity-defying speed. First, a connector measuring the time delay from a GPS receiver to the OPERA Master Clock was faulty, and second, the frequency of the Master Clock was out of specification. The researchers had calibrated the connector when it was securely plugged in, but during the experiment it had been partially disconnected, resulting in a distortion and delay of the signal. After the time delay was calculated and accounted for, the neutrino interactions with OPERA lagged by sixty nanoseconds. The neutrinos hadn\u2019t actually traveled faster than the speed of light\u2014the timing itself was incorrect. The search for an explanation was finally over.\nIn 2014 and 2015, OPERA papers shared the neutrino oscillation data. Like all other findings from CERN, they underwent multiple reviews and screenings before being released to the public. Today, the common worldwide policy for peer review even bans graduate students conducting research at CERN from including figures made for their own research in any university papers if the figures involve CERN projects that have not been finalized. Any results they do share from a non-finalized project leave CERN marked as \u201cpreliminary.\u201d This rigorous peer-review process reflects how the scientific process preserves scientists\u2019 credibility, just as researchers around the world constructively critiqued the neutrino speed findings.\u00a0\n\u201cThe \u2018case\u2019 of superluminal neutrinos is frequently referenced as an example of how science operates, highlighting the effectiveness of the scientific method and its provando e riprovando (trying and trying again) approach,\u201d Patrizii said. \u201cScience is not a belief system; it operates without dogma.\u201d The researchers\u2019 desire to ensure their findings\u2019 validity, even if it would negate what would otherwise be a groundbreaking finding, shows the scientific community\u2019s dedication to better understanding the universe. This case of the too-fast neutrinos, rather than being a scientific failure, was actually an example of the success of the scientific process.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/faster-than-lightspeed-these-neutrinos-were-faster-than-the-speed-of-light-until-they-werent/",
            "captions": [
                ""
            ]
        },
        {
            "title": "From \u201cNot Good Enough\u201d to Nobel Prize Winner",
            "author": "Annli Zhu",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/kariko-nobel-prize-final-Luna-Aguilar-500x379.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Art Courtesy of Luna Aguilar\nEarly in her career, Katalin Karik\u00f3 was confronted with a dilemma. As a researcher at the University of Pennsylvania, she had struggled to secure grant money and was faced with an ultimatum: either leave the university and abandon any hopes of becoming a tenured faculty member, or receive a demotion, setting her career back by years. It seemed that Karik\u00f3\u2019s deep interest in mRNA would soon see its end. What followed, instead, is a story of incredible persistence, dedication, and brilliance.\nBeginning in the 1960s, scientists had connected the dots of DNA\u2019s role in protein synthesis\u2014the process responsible for almost all cellular functions\u2014and mRNA was the critical missing piece. Short for messenger RNA, this helical strand of molecules represents DNA in a portable manner, allowing for information from the nucleus of the cell to be delivered to ribosomes where protein synthesis can occur.\nBy the 1970s, the concept of synthetic mRNA\u2014custom-created in the lab and introduced into the cells of patients\u2014created the prospect of initiating healing processes from within cells. Immediately, the possible range of applications seemed endless: could mRNA revolutionize vaccine development by prompting cells to produce key antibodies against convoluted viral infections? Could mRNA therapy enhance the immune system\u2019s abilities to detect and eliminate cancerous cells? Karik\u00f3\u2019s fascination with the potential of mRNA therapy inspired her life\u2019s research within the field, making the University of Pennsylvania\u2019s disregard of her work absolutely crushing. To better understand why, we must start from the beginning.\nKatalin Karik\u00f3\u2019s career in science began at the University of Szeged in her native Hungary, where she first learned about viruses and mRNA. There, she found herself surrounded by peers who seemed more academically prepared, whether more experienced in the lab or more fluent in English. In her recently published autobiography, Breaking Through: My Life in Science, Karik\u00f3 reflects on her time at university and playing catch-up with her peers. \u201cIf I have any superpower, it has always been this: a willingness to work hard and methodically, and refuse to stop,\u201d she wrote. This superpower would prove to be indispensable throughout her life.\nIn 1985, the company that had funded Karik\u00f3\u2019s postdoctoral research terminated her role. Following many fruitless attempts to secure a funded position across Europe, Karik\u00f3 finally found an opportunity to continue her research at Temple University in Philadelphia. She arrived in America with her husband, her daughter, and $1,200 in cash sewn into the stuffing of her daughter\u2019s teddy bear.\nWhile Karik\u00f3\u2019s work was going well, her supervisor proved to be hostile, threatening to revoke her visa if she left his lab. But Karik\u00f3 was determined to stay in America, and where there\u2019s a will, there\u2019s a way. In 1989, she found a position in the cardiology clinic at the University of Pennsylvania\u2019s medical school as a biochemist surrounded by doctors. \u201cWorking among MDs [gave me] the thing I valued most: a chance to learn,\u201d Karik\u00f3 wrote. \u201cBesides, when hadn\u2019t I been a fish out of water?\u201d\nAt first, her experience at UPenn was very positive. Alongside her boss, Dr. Elliot Barnathan, Karik\u00f3 worked on using mRNA to deliver proteins that would reduce the risk of blood clots in target areas, and she became even more convinced of the potential of her research.\nUnfortunately, this conviction was not shared by many. A critical metric for scientific success was\u2014and still is\u2014attracting funding, and Karik\u00f3 had been repeatedly rejected by grants that deemed her research too risky and slow. \u201cI published more slowly than others,\u201d she explained. \u201cI didn\u2019t want my scientific papers to be rushed. I didn\u2019t want to be so eager to publish that I risked contaminating the scientific literature with dubious results.\u201d\nKarik\u00f3 found UPenn to be increasingly impatient with her lack of funding and as a result, dismissive of her work. \u201cI was learning that succeeding at a research institution like Penn required skills that had little to do with science,\u201d she wrote. \u201cYou needed the ability to sell yourself and your work.\u201d\nIn January 1995, Karik\u00f3 was diagnosed with breast cancer. Soon after, her husband was forced to stay in Hungary due to visa complications. This time also marked five years since she joined UPenn, and per university policy, she must either be demoted or leave. Faced with a difficult decision at one of the most difficult points in her life, Karik\u00f3 nonetheless stayed true to her scientific calling, taking the demotion in order to continue her mRNA research.\nTwo years later, Karik\u00f3 met Dr. Drew Weissman, an immunologist who had just joined the university. Weissman was interested in vaccines, and Karik\u00f3 had just the expertise he needed to deliver antigens\u2014molecules that trigger an immune response against viruses\u2014with mRNA. The pair discovered that, by slightly altering one base nucleotide, they could safely administer mRNA without causing a negative inflammatory reaction. When combined with Karik\u00f3\u2019s previous work on mRNA delivery, the team had the final piece of the puzzle.\nThe pair excitedly submitted their mRNA vaccine research to Nature\u2014but their paper was rejected as merely an \u201cincremental contribution.\u201d When they finally convinced another journal to publish their work, it gained little attention.\nMeanwhile, UPenn was again getting impatient, citing Karik\u00f3\u2019s continued inability to secure funding. \u201c[All they cared about was] dollars per net square footage,\u201d she wrote. \u201cThe fact was, I barely cost this department anything\u2026 my salary was laughable compared with the neurosurgeons who surrounded me\u2026 I had no staff, no postdocs\u2026 I wasn\u2019t even a faculty member!\u201d When she appealed for her faculty position to be reinstated, the department responded that she was \u201cnot of faculty quality.\u201d\nFortunately, with their research finally published, Karik\u00f3 and Weissman\u2019s mRNA vaccines were recognized by a few. Realizing that UPenn was not going to support their work, the pair licensed their technology to the then-little-known BioNTech, where Karik\u00f3 assumed the role of vice president in 2013. Working in industry was refreshing, Karik\u00f3 explained. \u201cIt didn\u2019t matter whether you spoke with an accent, or whether you\u2019d attended an Ivy League school, or if you were good at schmoozing.\u201d Science was science.\nThen, in early 2020, all eyes turned towards the novel coronavirus. Suddenly, vaccine development was required at an unprecedented scale and speed, and BioNTech was at the forefront. The Pfizer-BioNTech vaccine\u2019s phase III trials came back successful within a year, making Karik\u00f3 a hero. After decades of obstacles, threats of deportation, demotions, and rejections, her superpower\u2014a fierce belief in her research and refusal to stop at any cost\u2014had finally helped her realize her dream.\nOn October 2, 2023, Katalin Karik\u00f3 and Drew Weissman were awarded the Nobel Prize in Physiology or Medicine for their work on mRNA vaccines.\nUPenn immediately acknowledged Karik\u00f3\u2019s and Weissman\u2019s Nobel Prize, coining them \u201cPenn\u2019s historic mRNA vaccine research team\u201d in a social media post (later marked as \u201cmisleading\u201d due to Karik\u00f3\u2019s lack of affiliation with the university over the past decade), accompanied by a press release that failed to mention Karik\u00f3\u2019s difficult history with the university. The post drew criticism from prominent members of the medical and scientific communities. One assistant professor from Stevenson University commented, \u201cA woman winning the Nobel Prize for the same work Penn called \u2018not faculty quality\u2019 & Penn CLAIMING CREDIT is exactly how misogyny in academia works.\u201d\nIndeed, Karik\u00f3\u2019s journey underlines prominent issues in academia. UPenn\u2019s self-congratulatory post highlights their attempt to mask their poor treatment and lack of support, while exemplifying the institutional desire to prioritize profit over genuine, innovative research. Finally, Karik\u00f3\u2019s narrative serves as an important reminder of the repeated undervaluation of women\u2019s work in science. While Karik\u00f3\u2019s story is one of triumph, it\u2019s important to call attention to the many shortcomings present in academia and to create an environment supportive of scientific innovation. In Karik\u00f3\u2019s words:\n\u201cWe can do better. Science, at its best, is about asking questions, trying things, and going wherever that inquiry takes you. It requires walking into the unknown\u2014the unknown is the very point!\u201d\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/from-not-good-enough-to-nobel-prize-winner/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Counterpoint: Reckoning With The Ghosts of YSM\u2019s Past",
            "author": "Samantha Liu",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/liu_article_photo-e1707678660157-500x357.webp"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Pixabay.\nIn 1903, Yale undergraduate Almer Mayo Newhall wrote on \u201cThe Position of the Negro within the Human Family.\u201d The piece opens with a promise to inspect \u201cwhat characterizes the inferiority of the Negro to the white man\u201d\u2014an \u201cinferiority\u201d which, by its final assertion, justifies that the North\u2019s \u201cslavery legislation was a failure.\u201d The article appeared in Vol. IX No. VI of the Yale Scientific Monthly, the precursor to the Yale Scientific Magazine.\nNewhall\u2019s piece is a damning, though hardly isolated, artifact within an extensive archive of racist scientific publishing at Yale and beyond. At the same time that the American Eugenics Society opened its headquarters on Hillhouse Avenue and North Carolina was enacting its first forced sterilization campaign in 1929, YSM was printing articles about \u201cThe Need of Immigration Restriction\u201d and \u201cextremely primitive, unpatriotic, seemingly indolent and childish \u2026 Africans of to-day.\u201d On one hand, the insidious context deflects blame from the undergraduates writing for Yale Scientific Monthly at the time. Systemic racism in the United States did not originate with scientific journalism, which reflects scientific research, which reflects public discourse. But publishing is not a passive process either. What gets published directly shapes public discourse, future research, and the policies that govern our social structures. And so scientific communication, if done poorly, reproduces harm and injustice.\nSo, where did Newhall go wrong? For one, it\u2019s bad science. He predicates neural behavior on phrenology, the shape of one\u2019s skull. He employs dubious-at-best methodologies, claiming that the \u201ctrained eye\u201d can detect more convolutions in the white man\u2019s brain. He uses evidence that is simply false, arguing, at one point, that Black people have pharyngeal pouches that white people lack. And he invents fictitious history when his evidence fails, imagining \u201cthe Negro in his own native jungle,\u201d brought into \u201ccontact with civilization\u201d by Europeans. Not to mention that the \u201cwhite man and the Negro\u201d is fundamentally a false dichotomy, which dooms the entire article\u2019s logic before it begins.\nNewhall\u2019s article should have never been approved for publication in a scientific magazine. But the conversation shouldn\u2019t revolve around whether Newhall\u2019s article used faulty induction (it did), or whether race science is a legitimate science (it\u2019s not). The conversation should revolve around whether certain research queries, however rigorous, are simply morally bad questions. This is where the editorial role of a public-facing magazine like the Yale Scientific bears a different responsibility than a reviewer for an academic journal like Nature. As journalists first, and scientists second, we should recognize that \u201cscience for the sake of science\u201d is never enough, because science never exists in a vacuum.\u00a0\nThe demand to simply have more moral sense gets lost among structures of Eurocentrism and exclusion which govern scientific communication. In journalism\u2014a field that already favors the white and wealthy\u2014scientific coverage is among the least diverse. According to the latest Pew Research Center report, only three percent of media journalists covering science and technology identify as Black, compared to the nationwide six percent. And for members of the National Association of Science Writers, in 2021, only one percent identified as Black.\nBeyond diversity at the editorial level, scientific communication is\u2014and will remain\u2014inaccessible if it limits itself to what gets published in leading research journals. A paper costs thousands of dollars to publish, and research itself is getting costlier. Such economic barriers are compounded for Black and women scientists, who are less likely to receive grants from the National Institutes of Health. While it\u2019s easier to source stories from the front pages of Nature, these findings originate from scientists who benefit by affiliation with well-endowed institutions. Meanwhile, on a global scale, the landscape of publishing marginalizes non-Western scholarship, stereotypically deemed \u201cunscientific.\u201d While there is invaluable knowledge possessed by indigenous populations about environmental sustainability, or by scientists in the global South on tropical diseases, they never receive the limelight of research journals. Here, scientific magazine boards have the capacity to recognize\u2014and rectify\u2014the inequities that arise at the level of academic publishing by broadening who is credited as an \u201cexpert.\u201dWhile DEI (diversity, equity, and inclusion) is often demeaned as a corporate buzzword, diversifying these stories matters. Scientific journalism is the link between academic research and public perception\u2014and in the scientific world, attention is currency. What gets published goes on to influence what research gets funded in the future. By being deliberate about these choices, the Yale Scientific Magazine can reach beyond the confines of its past, working toward a safer and fairer future.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/counterpoint-reckoning-with-the-ghosts-of-ysms-past-2/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Ammonium Chloride: Fertilizer Ingredient, Pickling Agent\u2026 Or The Sixth Taste?",
            "author": "Ethan Powell",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/powell_article_photo-500x332.jpeg"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Wikimedia\nSweet, sour, salty, and bitter were long believed to be the four basic human tastes. In the early twentieth century, a Japanese scientist claimed that the savory taste found in soy sauce was unique, and by 2002, \u201cumami\u201d was accepted as the fifth basic taste. Now, the discovery of a potential sixth taste\u2014ammonium chloride\u2014has brought scientists at the University of Southern California to the forefront of gastronomic research.\nDetectable in Scandinavian licorice, ammonium chloride has an enigmatic quality that recalls the sharpness of sea air or an earthy brininess. The compound, found in batteries and fertilizers, changes our perception of taste by modulating the flow of hydrogen ions, or protons, through OTOP1 receptors\u2014protein channels in our taste bud cells associated with the detection of sourness. When dissolved in water, some ammonium molecules lose a hydrogen ion to form ammonia, which diffuses into our taste bud cells and lowers the intracellular proton concentration. The difference in proton concentration across the cell membrane drives their movement through the OTOP1 receptors, affecting our perception of taste.\nResearchers speculate that ammonium chloride\u2019s distinctive flavor provided an evolutionary signal that steered ancient humans away from harmful substances. In experiments involving human cell cultures and live mice, researchers observed that mice with an intact OTOP1 receptor showed avoidance behaviors when introduced to ammonium chloride, while those without OTOP1 did not exhibit any reaction.\nAs gastronomes and scientists alike await further studies, this research paves the way for not only a new category of taste but also a deeper understanding of the origins behind our dietary choices.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/ammonium-chloride-fertilizer-ingredient-pickling-agent-or-the-sixth-taste/",
            "captions": [
                ""
            ]
        },
        {
            "title": "Life on Venus! Actually, No! Actually, Maybe?",
            "author": "William Archacki",
            "authorLogo": "",
            "date": "February 11, 2024",
            "thumbnail": [
                "https://www.yalescientific.org/wp-content/uploads/life-on-venus-Jungbin-Cha-Jaime-346x500.png"
            ],
            "publication": "The Yale Scientific",
            "topic": "Science and Technology",
            "content": "Image Courtesy of Jungbin Cha (Jaime)\nThe story goes that Isaac Newton was contemplating the orbit of the Moon when an apple fell on his head, and\u2014eureka! His theory of universal gravitation was born. Historians say this story about the apple is dubious, but it\u2019s still woven into the mythos of science because it illustrates how an unexpected observation can transform the way scientists understand an idea. A surprising insight, and presto, new science\u2014it sure worked in Newton\u2019s time.\u00a0\nSo now imagine you\u2019re Jane Greaves, a planetary astronomer at Cardiff University in Wales, and after eighteen months of crunching data from observations made in June 2017 on the James Clerk Maxwell Telescope in Hawai\u2018i, you\u2019ve convinced yourself of the impossible\u2014that you and your team have detected a signature of life emanating from the warm clouds of Earth\u2019s seemingly desolate neighbor Venus. Finding alien life might be as simple as looking next door. The apple has fallen. What comes next?\nAs indicators of life go, this signal from Venus was about as good as it gets. Greaves and her colleagues had detected a relatively small concentration of the gas phosphine, which is a molecule made of a phosphorus atom bonded to three hydrogen atoms. Astrobiologists call it a \u201cbiosignature gas.\u201d With limited exceptions, it is only produced by life. On Earth, anaerobic bacteria that live underwater are the only organisms known to partake in the strange and challenging chemistry required to produce something as peculiar as phosphine. And scientists in labs aren\u2019t much better: there is no known chemical mechanism by which phosphine can be produced without temperatures far more extreme than those found on Earth and Venus. If the phosphine in the atmosphere of Earth can only be created through life, is the same true on Venus?\nEncouraged by the results of their first observation, Greaves and her colleagues wasted no time to observe the Venusian atmosphere again with a more advanced telescope in March 2019. This time, they used the Atacama Large Millimeter Array radio telescope (ALMA) in Chile. Like the first telescope, ALMA recorded the intensity of radiation coming from Venus at different frequencies and performed a complex series of calculations to produce data that scientists could interpret, like a fingerprint for the concentrations of various gases. Once again, Greaves and her colleagues calculated a statistically significant concentration of phosphine in the Venusian atmosphere: about twenty molecules per billion located kilometers above the planet\u2019s surface in its thick clouds. And since phosphine breaks down under the conditions of the Venusian atmosphere, the team calculated that a constant influx of new phosphine into the atmosphere would be necessary for them to detect this.\nData in hand, Greaves and her colleagues had quite the paper to write. They had to explain to the scientific community that they had detected something that was either at odds with our modern knowledge of chemistry or evidence of alien life. In September 2020, they published their paper in the journal Nature Astronomy. In a press briefing for the Royal Astronomical Society, Greaves and three of her coauthors presented slides that cautiously broke their news. One slide reads, \u201cWe are claiming that we have detected phosphine gas whose existence is a mystery: either new chemistry or possibly life production.\u201d News outlets boasted headlines about the possibility of life on Venus, gently noting the possibility of unknown chemistry. But then in July 2021 came a shock. In the same journal, a different group of researchers responded with their own paper, brutally blunt in its title: \u201cNo evidence of phosphine in the atmosphere of Venus from independent analyses.\u201d\n\u201cIt felt pretty bad, on a personal level,\u201d Greaves said in a recent interview, reflecting on the scientific controversy that followed the response paper. The response paper shrouded their original publication in questions of scientific validity and academic rigor. \u201cThere was anxiety, in case we had made a genuine mistake\u2014but the critics had not involved us in any collegial discussion before publishing their critique,\u201d Greaves said.\nThe response paper opposed the original work on several fronts. First, the authors pointed out that the staff at ALMA had made an obscure but impactful mistake in their own data processing procedure before passing the data on to Greaves and her colleagues for their analyses. This mistake was corrected, as were two other small mistakes that the telescope staff discovered following an investigation, but it was not a fatal blow to Greaves\u2019 paper\u2014the signal was still there after adjusting the data. The bigger problem was that the response paper made the dramatic accusation of data misinterpretation. The signal, these authors claimed, came from a contaminant, not phosphine.\u00a0\nThe distinct frequency of radiation that phosphine absorbs\u2014the missing frequency in radiation from the atmosphere of Venus that alerted Greaves to phosphine\u2019s presence\u2014is close to the frequency associated with sulfur dioxide. Through their own calculations and analyses, the authors of the response paper argued that the signal Greaves picked up on was actually from sulfur dioxide.\u00a0\nBut wait!\u2014Greaves and her colleagues said in a third paper published in the same journal. Greaves\u2019 team had already considered this kind of contamination and ruled it out. \u201cWe looked at the criticisms and found (in most cases) the critics hadn\u2019t read the long supplement to our discovery paper, where we had already tested and answered the things they thought we\u2019d done wrong,\u201d Greaves said. The group reiterated their point from the first paper\u2014there is indeed phosphine on Venus\u2014and they recalculated their estimates for the concentration of phosphine based on the now-corrected ALMA data. Even after the revisions, it remains possible that phosphine is being actively generated on Venus by some as-of-yet unknown mechanism. \u201cI\u2019d love it to be life, but other origins would be cool too,\u201d Greaves said of the updated findings.\nGreaves noted that the scrutiny surrounding her group\u2019s work extended beyond just the response paper published in 2021. Some astronomers are still skeptical of the presence of phosphine on Venus in the absence of new data. But telescope time is tightly managed, so no one has been able to search for phosphine signals from Venus since the team\u2019s ALMA observation.\nGreaves also highlighted the personal side of academic vitriol. \u201cI still encounter problems, as does almost every woman astronomer I speak with,\u201d Greaves said. \u201cIn the Venus case, it\u2019s very clear that Anita [M. S. Richards] and I were the data analysts on the paper, and very clear also that people thought we must have made the most basic errors. It\u2019s hard to see how that can be\u2014given a quick search would have shown that we are both senior career stage and former staff at the telescopes we used for Venus\u2014unless it was easy to assume women are incompetent.\u201d\nThe meaning of the phosphine detected on Venus is beyond what scientists can currently explain. When pushing the boundaries of knowledge, science requires a high degree of caution\u2014after all, it took Newton two decades to publish his work on the theory of universal gravitation. So when answering the trickiest questions, equal parts skepticism and humility are required. We still don\u2019t know what\u2019s going on in the clouds of Venus, but it\u2019s worth sincerely endeavoring to figure it out.\n\u00a9 2021 Yale Scientific. All rights reserved",
            "url": "https://www.yalescientific.org/2024/02/life-on-venus-actually-no-actually-maybe/",
            "captions": [
                ""
            ]
        }
    ]
}